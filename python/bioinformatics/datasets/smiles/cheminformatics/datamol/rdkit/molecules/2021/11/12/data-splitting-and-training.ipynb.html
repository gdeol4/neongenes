<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Scaffold splitting and initial model training using chemprop | Neongenes dev blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Scaffold splitting and initial model training using chemprop" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Splitting the now cleaned data using a chemical space aware technique - scaffold splitting. Data is then trained using a directed message passing neural network (D-MPNN)." />
<meta property="og:description" content="Splitting the now cleaned data using a chemical space aware technique - scaffold splitting. Data is then trained using a directed message passing neural network (D-MPNN)." />
<link rel="canonical" href="https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html" />
<meta property="og:url" content="https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html" />
<meta property="og:site_name" content="Neongenes dev blog" />
<meta property="og:image" content="https://www.neongenes.com//images/play.gif" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-12T00:00:00-06:00" />
<script type="application/ld+json">
{"datePublished":"2021-11-12T00:00:00-06:00","url":"https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html","@type":"BlogPosting","image":"https://www.neongenes.com//images/play.gif","headline":"Scaffold splitting and initial model training using chemprop","dateModified":"2021-11-12T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html"},"description":"Splitting the now cleaned data using a chemical space aware technique - scaffold splitting. Data is then trained using a directed message passing neural network (D-MPNN).","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.neongenes.com//feed.xml" title="Neongenes dev blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3K90R9JCRH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3K90R9JCRH');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Neongenes dev blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Scaffold splitting and initial model training using chemprop</h1><p class="page-description">Splitting the now cleaned data using a chemical space aware technique - scaffold splitting. Data is then trained using a directed message passing neural network (D-MPNN).</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-12T00:00:00-06:00" itemprop="datePublished">
        Nov 12, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      104 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#bioinformatics">bioinformatics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#datasets">datasets</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#SMILES">SMILES</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#cheminformatics">cheminformatics</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#datamol">datamol</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#RDKit">RDKit</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#molecules">molecules</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/gdeol4/neongenes/tree/master/_notebooks/2021-11-12-data-splitting-and-training.ipynb.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/gdeol4/neongenes/blob/master/_notebooks/2021-11-12-data-splitting-and-training.ipynb.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-11-12-data-splitting-and-training.ipynb.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">chemprop</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">datamol</span> <span class="k">as</span> <span class="nn">dm</span>
<span class="kn">from</span> <span class="nn">rdkit</span> <span class="kn">import</span> <span class="n">Chem</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem.Scaffolds</span> <span class="kn">import</span> <span class="n">MurckoScaffold</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">chained_assignment</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># default=&#39;warn&#39;</span>


<span class="c1"># loading the datasets</span>
<span class="n">MolNet</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/MoleculeNet.csv&quot;</span><span class="p">)</span>
<span class="n">B3DB</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/B3DB.csv&quot;</span><span class="p">)</span>
<span class="n">b3_molecules</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/b3_molecules.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">scaffold_split</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mol&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;standard_smiles&quot;</span><span class="p">]]</span> <span class="c1"># generating moles from the standard_smiles column</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mol&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">dm</span><span class="o">.</span><span class="n">sanitize_mol</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sanifix</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">charge_neutral</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;mol&#39;</span><span class="p">]]</span> <span class="c1"># sanitize mol objects</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span> <span class="c1"># dropping NA values</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;scaffold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">MurckoScaffold</span><span class="o">.</span><span class="n">GetScaffoldForMol</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mol&quot;</span><span class="p">]]</span> <span class="c1"># generating scaffolds from mol object</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mol_scaffold_generic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">MurckoScaffold</span><span class="o">.</span><span class="n">MakeScaffoldGeneric</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;scaffold&quot;</span><span class="p">]]</span> <span class="c1"># generalizing scaffolds</span>
    <span class="c1"># convert the generic scaffold mol object back to a SMILES string format</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;smiles_scaffold_generic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">Chem</span><span class="o">.</span><span class="n">CanonSmiles</span><span class="p">(</span><span class="n">Chem</span><span class="o">.</span><span class="n">MolToSmiles</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;mol_scaffold_generic&quot;</span><span class="p">]]</span>
    
    <span class="k">return</span> <span class="n">df</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># results of the scaffold generating function</span>
<span class="n">data_split</span> <span class="o">=</span> <span class="n">scaffold_split</span><span class="p">(</span><span class="n">b3_molecules</span><span class="p">)</span>
<span class="n">data_split</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BBB+/BBB-</th>
      <th>SMILES</th>
      <th>mol</th>
      <th>standard_smiles</th>
      <th>selfies</th>
      <th>inchi</th>
      <th>inchikey</th>
      <th>scaffold</th>
      <th>mol_scaffold_generic</th>
      <th>smiles_scaffold_generic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>
      <td>&lt;img data-content="rdkit/molecule" src="data:i...</td>
      <td>CC(C)NCC(O)COc1cccc2ccccc12.[Cl-]</td>
      <td>[C][C][Branch1][C][C][N][C][C][Branch1][C][O][...</td>
      <td>InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-...</td>
      <td>ZMRUPTIKESYGQW-UHFFFAOYSA-M</td>
      <td>&lt;img data-content="rdkit/molecule" src="data:i...</td>
      <td>&lt;img data-content="rdkit/molecule" src="data:i...</td>
      <td>C1CCC2CCCCC2C1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the data prior to processing</span>
<span class="n">MolNet</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BBB+/BBB-</th>
      <th>SMILES</th>
      <th>mol</th>
      <th>standard_smiles</th>
      <th>selfies</th>
      <th>inchi</th>
      <th>inchikey</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>
      <td>&lt;img data-content="rdkit/molecule" src="data:i...</td>
      <td>CC(C)NCC(O)COc1cccc2ccccc12.[Cl-]</td>
      <td>[C][C][Branch1][C][C][N][C][C][Branch1][C][O][...</td>
      <td>InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-...</td>
      <td>ZMRUPTIKESYGQW-UHFFFAOYSA-M</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># A function to process the data for use with the chemprop library</span>
<span class="k">def</span> <span class="nf">chemprop_prep</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;mol&quot;</span><span class="p">,</span> <span class="s2">&quot;SMILES&quot;</span><span class="p">,</span> <span class="s2">&quot;selfies&quot;</span><span class="p">,</span> <span class="s2">&quot;inchi&quot;</span><span class="p">,</span> <span class="s2">&quot;inchikey&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># drop all columns except the smiles and target</span>
    <span class="n">df</span><span class="p">[</span><span class="s2">&quot;smiles&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;standard_smiles&quot;</span><span class="p">]</span> <span class="c1"># use standard smiles inplace of smiles</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;standard_smiles&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># drop this column now</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;smiles&quot;</span><span class="p">,</span> <span class="s2">&quot;BBB+/BBB-&quot;</span><span class="p">]]</span> <span class="c1"># reorder the columns with smiles first and target second</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;./data/&#39;</span> <span class="o">+</span> <span class="n">filename</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># save the file</span>

    <span class="k">return</span> <span class="n">df</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Processing the three different datasets</span>
<span class="n">molnet_chemprop</span> <span class="o">=</span> <span class="n">chemprop_prep</span><span class="p">(</span><span class="n">MolNet</span><span class="p">,</span> <span class="s1">&#39;molnet_chemprop&#39;</span><span class="p">)</span>
<span class="n">B3DB_chemprop</span> <span class="o">=</span> <span class="n">chemprop_prep</span><span class="p">(</span><span class="n">B3DB</span><span class="p">,</span> <span class="s1">&#39;B3DB_chemprep&#39;</span><span class="p">)</span>
<span class="n">b3_mol_chemprop</span> <span class="o">=</span> <span class="n">chemprop_prep</span><span class="p">(</span><span class="n">b3_molecules</span><span class="p">,</span> <span class="s1">&#39;B3DB_chemprep&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># results of processing</span>
<span class="n">molnet_chemprop</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>smiles</th>
      <th>BBB+/BBB-</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CC(C)NCC(O)COc1cccc2ccccc12.[Cl-]</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">smiles</span> <span class="o">=</span> <span class="s2">&quot;CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC&quot;</span>
<span class="c1"># convert SMILES string to RDKit mol object </span>
<span class="n">mol</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
<span class="c1"># create RDKit mol object corresponding to Bemis-Murcko scaffold of original compound</span>
<span class="n">mol_scaffold</span> <span class="o">=</span> <span class="n">MurckoScaffold</span><span class="o">.</span><span class="n">GetScaffoldForMol</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>
<span class="c1"># make the scaffold generic by replacing all atoms with carbons and all bonds with single bonds</span>
<span class="n">mol_scaffold_generic</span> <span class="o">=</span> <span class="n">MurckoScaffold</span><span class="o">.</span><span class="n">MakeScaffoldGeneric</span><span class="p">(</span><span class="n">mol_scaffold</span><span class="p">)</span>
<span class="c1"># convert the generic scaffold mol object back to a SMILES string format</span>
<span class="n">smiles_scaffold_generic</span> <span class="o">=</span> <span class="n">Chem</span><span class="o">.</span><span class="n">CanonSmiles</span><span class="p">(</span><span class="n">Chem</span><span class="o">.</span><span class="n">MolToSmiles</span><span class="p">(</span><span class="n">mol_scaffold_generic</span><span class="p">))</span>
<span class="c1"># display compound and its generic Bemis-Murcko scaffold</span>
<span class="n">display</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">mol_scaffold_generic</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smiles_scaffold_generic</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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" />
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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" />
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>C1CCC(CCC2C3CCCCC3CC3CCCCC32)CC1
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">arguments</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;--data_path&#39;</span><span class="p">,</span> <span class="s1">&#39;./data/chemprop_data.csv&#39;</span><span class="p">,</span>
    <span class="s1">&#39;--dataset_type&#39;</span><span class="p">,</span> <span class="s1">&#39;classification&#39;</span><span class="p">,</span>
    <span class="s1">&#39;--save_dir&#39;</span><span class="p">,</span> <span class="s1">&#39;./data/chemprop_checkpoints/&#39;</span><span class="p">,</span>
    <span class="s1">&#39;--split_type&#39;</span><span class="p">,</span> <span class="s1">&#39;scaffold_balanced&#39;</span><span class="p">,</span>
    <span class="s1">&#39;--separate_val_path&#39;</span><span class="p">,</span> <span class="s1">&#39;./data/chemprop_B3DB.csv&#39;</span><span class="p">,</span>
    <span class="s1">&#39;--num_folds&#39;</span><span class="p">,</span> <span class="s1">&#39;10&#39;</span><span class="p">,</span>

<span class="p">]</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">chemprop</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">TrainArgs</span><span class="p">()</span><span class="o">.</span><span class="n">parse_args</span><span class="p">(</span><span class="n">arguments</span><span class="p">)</span>
<span class="n">mean_score</span><span class="p">,</span> <span class="n">std_score</span> <span class="o">=</span> <span class="n">chemprop</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">train_func</span><span class="o">=</span><span class="n">chemprop</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">run_training</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9023 --control=9016 --hb=9015 --Session.signature_scheme=&#34;hmac-sha256&#34; --Session.key=b&#34;d428538a-db2b-40c8-b710-95eb7a929307&#34; --shell=9017 --transport=&#34;tcp&#34; --iopub=9024 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036lrc2sZ0NEBA3.json
Args
{&#39;activation&#39;: &#39;ReLU&#39;,
 &#39;aggregation&#39;: &#39;mean&#39;,
 &#39;aggregation_norm&#39;: 100,
 &#39;atom_descriptor_scaling&#39;: True,
 &#39;atom_descriptors&#39;: None,
 &#39;atom_descriptors_path&#39;: None,
 &#39;atom_descriptors_size&#39;: 0,
 &#39;atom_features_size&#39;: 0,
 &#39;atom_messages&#39;: False,
 &#39;batch_size&#39;: 50,
 &#39;bias&#39;: False,
 &#39;bond_feature_scaling&#39;: True,
 &#39;bond_features_path&#39;: None,
 &#39;bond_features_size&#39;: 0,
 &#39;cache_cutoff&#39;: 10000,
 &#39;checkpoint_dir&#39;: None,
 &#39;checkpoint_frzn&#39;: None,
 &#39;checkpoint_path&#39;: None,
 &#39;checkpoint_paths&#39;: None,
 &#39;class_balance&#39;: False,
 &#39;config_path&#39;: None,
 &#39;crossval_index_dir&#39;: None,
 &#39;crossval_index_file&#39;: None,
 &#39;crossval_index_sets&#39;: None,
 &#39;cuda&#39;: False,
 &#39;data_path&#39;: &#39;./data/chemprop_data.csv&#39;,
 &#39;data_weights_path&#39;: None,
 &#39;dataset_type&#39;: &#39;classification&#39;,
 &#39;depth&#39;: 3,
 &#39;device&#39;: device(type=&#39;cpu&#39;),
 &#39;dropout&#39;: 0.0,
 &#39;empty_cache&#39;: False,
 &#39;ensemble_size&#39;: 1,
 &#39;epochs&#39;: 30,
 &#39;explicit_h&#39;: False,
 &#39;extra_metrics&#39;: [],
 &#39;features_generator&#39;: None,
 &#39;features_only&#39;: False,
 &#39;features_path&#39;: None,
 &#39;features_scaling&#39;: True,
 &#39;features_size&#39;: None,
 &#39;ffn_hidden_size&#39;: 300,
 &#39;ffn_num_layers&#39;: 2,
 &#39;final_lr&#39;: 0.0001,
 &#39;folds_file&#39;: None,
 &#39;freeze_first_only&#39;: False,
 &#39;frzn_ffn_layers&#39;: 0,
 &#39;gpu&#39;: None,
 &#39;grad_clip&#39;: None,
 &#39;hidden_size&#39;: 300,
 &#39;ignore_columns&#39;: None,
 &#39;init_lr&#39;: 0.0001,
 &#39;log_frequency&#39;: 10,
 &#39;max_data_size&#39;: None,
 &#39;max_lr&#39;: 0.001,
 &#39;metric&#39;: &#39;auc&#39;,
 &#39;metrics&#39;: [&#39;auc&#39;],
 &#39;minimize_score&#39;: False,
 &#39;mpn_shared&#39;: False,
 &#39;multiclass_num_classes&#39;: 3,
 &#39;no_atom_descriptor_scaling&#39;: False,
 &#39;no_bond_features_scaling&#39;: False,
 &#39;no_cache_mol&#39;: False,
 &#39;no_cuda&#39;: False,
 &#39;no_features_scaling&#39;: False,
 &#39;num_folds&#39;: 10,
 &#39;num_lrs&#39;: 1,
 &#39;num_tasks&#39;: 1,
 &#39;num_workers&#39;: 8,
 &#39;number_of_molecules&#39;: 1,
 &#39;overwrite_default_atom_features&#39;: False,
 &#39;overwrite_default_bond_features&#39;: False,
 &#39;pytorch_seed&#39;: 0,
 &#39;quiet&#39;: False,
 &#39;reaction&#39;: False,
 &#39;reaction_mode&#39;: &#39;reac_diff&#39;,
 &#39;resume_experiment&#39;: False,
 &#39;save_dir&#39;: &#39;./data/chemprop_checkpoints/&#39;,
 &#39;save_preds&#39;: False,
 &#39;save_smiles_splits&#39;: False,
 &#39;seed&#39;: 0,
 &#39;separate_test_atom_descriptors_path&#39;: None,
 &#39;separate_test_bond_features_path&#39;: None,
 &#39;separate_test_features_path&#39;: None,
 &#39;separate_test_path&#39;: None,
 &#39;separate_val_atom_descriptors_path&#39;: None,
 &#39;separate_val_bond_features_path&#39;: None,
 &#39;separate_val_features_path&#39;: None,
 &#39;separate_val_path&#39;: &#39;./data/chemprop_B3DB.csv&#39;,
 &#39;show_individual_scores&#39;: False,
 &#39;smiles_columns&#39;: [&#39;smiles&#39;],
 &#39;split_sizes&#39;: (0.8, 0.1, 0.1),
 &#39;split_type&#39;: &#39;scaffold_balanced&#39;,
 &#39;target_columns&#39;: None,
 &#39;target_weights&#39;: None,
 &#39;task_names&#39;: [&#39;BBB+/BBB-&#39;],
 &#39;test&#39;: False,
 &#39;test_fold_index&#39;: None,
 &#39;train_data_size&#39;: None,
 &#39;undirected&#39;: False,
 &#39;use_input_features&#39;: False,
 &#39;val_fold_index&#39;: None,
 &#39;warmup_epochs&#39;: 2.0}
Loading data
2039it [00:00, 119837.26it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 226314.16it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 78354.75it/s]
Number of tasks = 1
Fold 0
Splitting data with seed 0
7807it [00:00, 48749.56it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 162493.77it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 65545.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 3347.05it/s]
Total scaffolds = 1,025 | train scaffolds = 924 | val scaffolds = 0 | test scaffolds = 101
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.7921e-01, PNorm = 34.0133, GNorm = 0.5342, lr_0 = 2.5469e-04
Loss = 5.3200e-01, PNorm = 34.0237, GNorm = 0.6107, lr_0 = 3.9531e-04
Loss = 5.1853e-01, PNorm = 34.0464, GNorm = 0.5553, lr_0 = 5.3594e-04
Validation auc = 0.731898
  3%|â–Ž         | 1/30 [00:38&lt;18:43, 38.74s/it]Epoch 1
Loss = 4.7001e-01, PNorm = 34.0900, GNorm = 1.9152, lr_0 = 6.9063e-04
Loss = 4.3204e-01, PNorm = 34.1271, GNorm = 0.6978, lr_0 = 8.3125e-04
Loss = 4.5837e-01, PNorm = 34.1749, GNorm = 2.8353, lr_0 = 9.7187e-04
Validation auc = 0.739573
  7%|â–‹         | 2/30 [01:01&lt;13:34, 29.08s/it]Epoch 2
Loss = 4.1592e-01, PNorm = 34.2418, GNorm = 0.8874, lr_0 = 9.7965e-04
Loss = 4.0019e-01, PNorm = 34.3068, GNorm = 0.3414, lr_0 = 9.5480e-04
Loss = 4.1145e-01, PNorm = 34.3543, GNorm = 0.6370, lr_0 = 9.3057e-04
Validation auc = 0.790529
 10%|â–ˆ         | 3/30 [01:23&lt;11:49, 26.26s/it]Epoch 3
Loss = 3.7677e-01, PNorm = 34.4208, GNorm = 0.9437, lr_0 = 9.0463e-04
Loss = 3.4925e-01, PNorm = 34.4773, GNorm = 0.5762, lr_0 = 8.8168e-04
Loss = 3.9518e-01, PNorm = 34.5250, GNorm = 0.4361, lr_0 = 8.5931e-04
Loss = 3.4804e-01, PNorm = 34.5879, GNorm = 0.7934, lr_0 = 8.3751e-04
Validation auc = 0.815596
 13%|â–ˆâ–Ž        | 4/30 [01:46&lt;10:46, 24.88s/it]Epoch 4
Loss = 3.5069e-01, PNorm = 34.6495, GNorm = 0.6996, lr_0 = 8.1626e-04
Loss = 3.1209e-01, PNorm = 34.7035, GNorm = 0.6323, lr_0 = 7.9555e-04
Loss = 3.6705e-01, PNorm = 34.7594, GNorm = 0.7795, lr_0 = 7.7537e-04
Validation auc = 0.849116
 17%|â–ˆâ–‹        | 5/30 [02:09&lt;09:59, 23.97s/it]Epoch 5
Loss = 3.7468e-01, PNorm = 34.8100, GNorm = 0.7911, lr_0 = 7.5570e-04
Loss = 3.0905e-01, PNorm = 34.8686, GNorm = 1.4186, lr_0 = 7.3653e-04
Loss = 2.6892e-01, PNorm = 34.9266, GNorm = 1.0121, lr_0 = 7.1784e-04
Validation auc = 0.853062
 20%|â–ˆâ–ˆ        | 6/30 [02:33&lt;09:36, 24.01s/it]Epoch 6
Loss = 3.0230e-01, PNorm = 34.9655, GNorm = 0.8728, lr_0 = 6.9783e-04
Loss = 3.1416e-01, PNorm = 35.0221, GNorm = 1.2014, lr_0 = 6.8013e-04
Loss = 2.7962e-01, PNorm = 35.0705, GNorm = 0.6963, lr_0 = 6.6287e-04
Validation auc = 0.840569
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:55&lt;08:57, 23.38s/it]Epoch 7
Loss = 1.8715e-01, PNorm = 35.1038, GNorm = 1.2228, lr_0 = 6.4605e-04
Loss = 3.1151e-01, PNorm = 35.1414, GNorm = 0.7543, lr_0 = 6.2966e-04
Loss = 2.9637e-01, PNorm = 35.1967, GNorm = 0.8723, lr_0 = 6.1369e-04
Loss = 3.1616e-01, PNorm = 35.2427, GNorm = 2.5857, lr_0 = 5.9812e-04
Loss = 5.2971e-01, PNorm = 35.2462, GNorm = 3.8233, lr_0 = 5.9658e-04
Validation auc = 0.854273
 27%|â–ˆâ–ˆâ–‹       | 8/30 [03:16&lt;08:16, 22.56s/it]Epoch 8
Loss = 3.1306e-01, PNorm = 35.2873, GNorm = 1.1070, lr_0 = 5.8145e-04
Loss = 2.8194e-01, PNorm = 35.3365, GNorm = 1.4047, lr_0 = 5.6669e-04
Loss = 2.7593e-01, PNorm = 35.3866, GNorm = 0.9889, lr_0 = 5.5232e-04
Validation auc = 0.855899
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:39&lt;08:01, 22.92s/it]Epoch 9
Loss = 2.8666e-01, PNorm = 35.4314, GNorm = 1.3941, lr_0 = 5.3830e-04
Loss = 2.5622e-01, PNorm = 35.4844, GNorm = 0.4744, lr_0 = 5.2465e-04
Loss = 3.1872e-01, PNorm = 35.5168, GNorm = 0.5933, lr_0 = 5.1133e-04
Validation auc = 0.871488
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [04:02&lt;07:38, 22.92s/it]Epoch 10
Loss = 2.9573e-01, PNorm = 35.5591, GNorm = 1.1211, lr_0 = 4.9836e-04
Loss = 2.6221e-01, PNorm = 35.6001, GNorm = 0.9222, lr_0 = 4.8572e-04
Loss = 2.6929e-01, PNorm = 35.6405, GNorm = 1.2863, lr_0 = 4.7339e-04
Validation auc = 0.867729
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [04:26&lt;07:20, 23.17s/it]Epoch 11
Loss = 2.7630e-01, PNorm = 35.6886, GNorm = 0.8642, lr_0 = 4.6020e-04
Loss = 2.6721e-01, PNorm = 35.7368, GNorm = 1.3450, lr_0 = 4.4852e-04
Loss = 3.1437e-01, PNorm = 35.7796, GNorm = 0.9707, lr_0 = 4.3714e-04
Loss = 2.7745e-01, PNorm = 35.8168, GNorm = 1.8431, lr_0 = 4.2605e-04
Validation auc = 0.873370
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:50&lt;06:59, 23.32s/it]Epoch 12
Loss = 2.3011e-01, PNorm = 35.8567, GNorm = 0.9368, lr_0 = 4.1524e-04
Loss = 3.0085e-01, PNorm = 35.8913, GNorm = 2.3247, lr_0 = 4.0471e-04
Loss = 2.4651e-01, PNorm = 35.9194, GNorm = 2.9509, lr_0 = 3.9444e-04
Validation auc = 0.867464
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [05:14&lt;06:39, 23.50s/it]Epoch 13
Loss = 2.3372e-01, PNorm = 35.9452, GNorm = 0.9986, lr_0 = 3.8443e-04
Loss = 2.2999e-01, PNorm = 35.9764, GNorm = 0.8525, lr_0 = 3.7468e-04
Loss = 2.2414e-01, PNorm = 36.0128, GNorm = 0.7044, lr_0 = 3.6517e-04
Validation auc = 0.875426
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:37&lt;06:14, 23.39s/it]Epoch 14
Loss = 2.0713e-01, PNorm = 36.0453, GNorm = 0.4335, lr_0 = 3.5500e-04
Loss = 2.3194e-01, PNorm = 36.0770, GNorm = 2.1658, lr_0 = 3.4599e-04
Loss = 2.5871e-01, PNorm = 36.1087, GNorm = 0.9426, lr_0 = 3.3721e-04
Validation auc = 0.876673
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [06:00&lt;05:51, 23.43s/it]Epoch 15
Loss = 2.8820e-01, PNorm = 36.1377, GNorm = 1.4118, lr_0 = 3.2866e-04
Loss = 2.2613e-01, PNorm = 36.1684, GNorm = 1.3319, lr_0 = 3.2032e-04
Loss = 2.0750e-01, PNorm = 36.1953, GNorm = 2.1855, lr_0 = 3.1219e-04
Loss = 2.7105e-01, PNorm = 36.2226, GNorm = 1.6245, lr_0 = 3.0427e-04
Validation auc = 0.865978
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:24&lt;05:30, 23.60s/it]Epoch 16
Loss = 2.4408e-01, PNorm = 36.2519, GNorm = 1.5706, lr_0 = 2.9579e-04
Loss = 2.2506e-01, PNorm = 36.2784, GNorm = 0.9227, lr_0 = 2.8828e-04
Loss = 2.0077e-01, PNorm = 36.3028, GNorm = 0.6776, lr_0 = 2.8097e-04
Validation auc = 0.878100
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:47&lt;05:05, 23.48s/it]Epoch 17
Loss = 2.0379e-01, PNorm = 36.3313, GNorm = 0.5450, lr_0 = 2.7384e-04
Loss = 2.1564e-01, PNorm = 36.3560, GNorm = 0.7152, lr_0 = 2.6689e-04
Loss = 1.8612e-01, PNorm = 36.3825, GNorm = 1.7715, lr_0 = 2.6012e-04
Validation auc = 0.879983
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [07:10&lt;04:39, 23.32s/it]Epoch 18
Loss = 2.1749e-01, PNorm = 36.4032, GNorm = 2.1023, lr_0 = 2.5352e-04
Loss = 2.0186e-01, PNorm = 36.4244, GNorm = 1.0254, lr_0 = 2.4709e-04
Loss = 2.2377e-01, PNorm = 36.4476, GNorm = 1.5030, lr_0 = 2.4082e-04
Validation auc = 0.877642
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:35&lt;04:20, 23.64s/it]Epoch 19
Loss = 2.1661e-01, PNorm = 36.4699, GNorm = 2.0885, lr_0 = 2.3411e-04
Loss = 1.9739e-01, PNorm = 36.4885, GNorm = 1.5452, lr_0 = 2.2817e-04
Loss = 1.8020e-01, PNorm = 36.5104, GNorm = 0.7588, lr_0 = 2.2238e-04
Loss = 2.1539e-01, PNorm = 36.5302, GNorm = 1.9140, lr_0 = 2.1674e-04
Validation auc = 0.874604
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:58&lt;03:55, 23.53s/it]Epoch 20
Loss = 2.0466e-01, PNorm = 36.5521, GNorm = 0.9277, lr_0 = 2.1124e-04
Loss = 1.9847e-01, PNorm = 36.5712, GNorm = 1.9312, lr_0 = 2.0588e-04
Loss = 1.7716e-01, PNorm = 36.5888, GNorm = 0.9575, lr_0 = 2.0066e-04
Validation auc = 0.881012
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [08:21&lt;03:31, 23.50s/it]Epoch 21
Loss = 1.2171e-01, PNorm = 36.6069, GNorm = 1.4518, lr_0 = 1.9557e-04
Loss = 2.1633e-01, PNorm = 36.6252, GNorm = 3.4335, lr_0 = 1.9060e-04
Loss = 1.9789e-01, PNorm = 36.6406, GNorm = 0.8608, lr_0 = 1.8577e-04
Validation auc = 0.880775
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:46&lt;03:10, 23.84s/it]Epoch 22
Loss = 1.7108e-01, PNorm = 36.6599, GNorm = 1.3346, lr_0 = 1.8059e-04
Loss = 2.0594e-01, PNorm = 36.6781, GNorm = 1.2820, lr_0 = 1.7601e-04
Loss = 2.1049e-01, PNorm = 36.6936, GNorm = 1.2921, lr_0 = 1.7154e-04
Loss = 1.4001e-01, PNorm = 36.7102, GNorm = 1.3220, lr_0 = 1.6719e-04
Validation auc = 0.878249
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [09:09&lt;02:45, 23.68s/it]Epoch 23
Loss = 1.8390e-01, PNorm = 36.7259, GNorm = 1.5580, lr_0 = 1.6295e-04
Loss = 1.5908e-01, PNorm = 36.7417, GNorm = 0.5529, lr_0 = 1.5882e-04
Loss = 1.9535e-01, PNorm = 36.7555, GNorm = 1.9520, lr_0 = 1.5479e-04
Validation auc = 0.879262
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:33&lt;02:22, 23.70s/it]Epoch 24
Loss = 1.9363e-01, PNorm = 36.7711, GNorm = 2.5496, lr_0 = 1.5047e-04
Loss = 1.7139e-01, PNorm = 36.7848, GNorm = 0.9105, lr_0 = 1.4665e-04
Loss = 1.9078e-01, PNorm = 36.7979, GNorm = 2.2030, lr_0 = 1.4293e-04
Validation auc = 0.881092
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:58&lt;02:00, 24.04s/it]Epoch 25
Loss = 2.0122e-01, PNorm = 36.8112, GNorm = 2.0350, lr_0 = 1.3931e-04
Loss = 1.7755e-01, PNorm = 36.8237, GNorm = 1.9924, lr_0 = 1.3577e-04
Loss = 1.6288e-01, PNorm = 36.8345, GNorm = 1.0033, lr_0 = 1.3233e-04
Validation auc = 0.879667
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [10:21&lt;01:35, 23.83s/it]Epoch 26
Loss = 1.7851e-01, PNorm = 36.8477, GNorm = 1.3995, lr_0 = 1.2897e-04
Loss = 1.6410e-01, PNorm = 36.8601, GNorm = 2.0577, lr_0 = 1.2570e-04
Loss = 1.6417e-01, PNorm = 36.8716, GNorm = 1.4548, lr_0 = 1.2251e-04
Loss = 1.9043e-01, PNorm = 36.8844, GNorm = 0.5458, lr_0 = 1.1940e-04
Loss = 1.3765e-01, PNorm = 36.8858, GNorm = 1.8756, lr_0 = 1.1909e-04
Validation auc = 0.878424
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:43&lt;01:09, 23.06s/it]Epoch 27
Loss = 1.7380e-01, PNorm = 36.8967, GNorm = 0.6299, lr_0 = 1.1607e-04
Loss = 1.7133e-01, PNorm = 36.9085, GNorm = 0.9839, lr_0 = 1.1313e-04
Loss = 1.5482e-01, PNorm = 36.9189, GNorm = 0.6951, lr_0 = 1.1026e-04
Validation auc = 0.878794
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [11:04&lt;00:45, 22.59s/it]Epoch 28
Loss = 1.7905e-01, PNorm = 36.9294, GNorm = 0.9441, lr_0 = 1.0746e-04
Loss = 1.6842e-01, PNorm = 36.9389, GNorm = 2.0891, lr_0 = 1.0473e-04
Loss = 1.6954e-01, PNorm = 36.9487, GNorm = 1.1413, lr_0 = 1.0208e-04
Validation auc = 0.877537
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [11:27&lt;00:22, 22.59s/it]Epoch 29
Loss = 1.2676e-01, PNorm = 36.9588, GNorm = 1.3964, lr_0 = 1.0000e-04
Loss = 1.6358e-01, PNorm = 36.9683, GNorm = 0.8904, lr_0 = 1.0000e-04
Loss = 1.7523e-01, PNorm = 36.9776, GNorm = 1.2408, lr_0 = 1.0000e-04
Validation auc = 0.877406
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:48&lt;00:00, 23.63s/it]
Model 0 best validation auc = 0.881092 on epoch 24
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.844660
Ensemble test auc = 0.844660
Fold 1
Splitting data with seed 1
7807it [00:00, 106844.77it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 169563.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 69328.88it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:01&lt;00:00, 1967.29it/s]
Total scaffolds = 1,025 | train scaffolds = 899 | val scaffolds = 0 | test scaffolds = 126
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.8283e-01, PNorm = 34.0132, GNorm = 0.9347, lr_0 = 2.5469e-04
Loss = 5.3997e-01, PNorm = 34.0187, GNorm = 0.2686, lr_0 = 3.9531e-04
Loss = 5.4015e-01, PNorm = 34.0372, GNorm = 0.8418, lr_0 = 5.3594e-04
Validation auc = 0.723354
  3%|â–Ž         | 1/30 [00:23&lt;11:32, 23.88s/it]Epoch 1
Loss = 5.0507e-01, PNorm = 34.0716, GNorm = 2.6406, lr_0 = 6.9063e-04
Loss = 4.3937e-01, PNorm = 34.1089, GNorm = 0.4836, lr_0 = 8.3125e-04
Loss = 4.9619e-01, PNorm = 34.1618, GNorm = 1.7031, lr_0 = 9.7187e-04
Validation auc = 0.790985
  7%|â–‹         | 2/30 [00:45&lt;10:38, 22.82s/it]Epoch 2
Loss = 4.5610e-01, PNorm = 34.2304, GNorm = 0.6527, lr_0 = 9.7965e-04
Loss = 4.6261e-01, PNorm = 34.3044, GNorm = 1.3506, lr_0 = 9.5480e-04
Loss = 4.0275e-01, PNorm = 34.3694, GNorm = 1.7302, lr_0 = 9.3057e-04
Validation auc = 0.806004
 10%|â–ˆ         | 3/30 [01:07&lt;09:56, 22.11s/it]Epoch 3
Loss = 4.1068e-01, PNorm = 34.4422, GNorm = 0.8234, lr_0 = 9.0463e-04
Loss = 4.4421e-01, PNorm = 34.4953, GNorm = 0.5707, lr_0 = 8.8168e-04
Loss = 3.5599e-01, PNorm = 34.5530, GNorm = 0.2221, lr_0 = 8.5931e-04
Loss = 3.7585e-01, PNorm = 34.5886, GNorm = 0.8107, lr_0 = 8.3751e-04
Validation auc = 0.816117
 13%|â–ˆâ–Ž        | 4/30 [01:28&lt;09:29, 21.89s/it]Epoch 4
Loss = 3.2671e-01, PNorm = 34.6467, GNorm = 1.4990, lr_0 = 8.1626e-04
Loss = 4.1754e-01, PNorm = 34.6924, GNorm = 1.5698, lr_0 = 7.9555e-04
Loss = 3.7652e-01, PNorm = 34.7473, GNorm = 0.7108, lr_0 = 7.7537e-04
Validation auc = 0.834371
 17%|â–ˆâ–‹        | 5/30 [01:51&lt;09:12, 22.12s/it]Epoch 5
Loss = 3.5562e-01, PNorm = 34.8102, GNorm = 0.7067, lr_0 = 7.5570e-04
Loss = 3.8079e-01, PNorm = 34.8607, GNorm = 0.6355, lr_0 = 7.3653e-04
Loss = 3.5995e-01, PNorm = 34.9105, GNorm = 1.0636, lr_0 = 7.1784e-04
Validation auc = 0.834212
 20%|â–ˆâ–ˆ        | 6/30 [02:12&lt;08:43, 21.80s/it]Epoch 6
Loss = 3.4494e-01, PNorm = 34.9751, GNorm = 0.5044, lr_0 = 6.9783e-04
Loss = 3.5540e-01, PNorm = 35.0362, GNorm = 2.7041, lr_0 = 6.8013e-04
Loss = 3.7456e-01, PNorm = 35.0753, GNorm = 1.2072, lr_0 = 6.6287e-04
Validation auc = 0.845199
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:35&lt;08:31, 22.26s/it]Epoch 7
Loss = 3.6567e-01, PNorm = 35.1313, GNorm = 0.5053, lr_0 = 6.4605e-04
Loss = 2.9606e-01, PNorm = 35.1913, GNorm = 2.0932, lr_0 = 6.2966e-04
Loss = 3.1622e-01, PNorm = 35.2301, GNorm = 2.0060, lr_0 = 6.1369e-04
Loss = 3.5755e-01, PNorm = 35.2781, GNorm = 1.0133, lr_0 = 5.9812e-04
Loss = 3.8792e-01, PNorm = 35.2826, GNorm = 0.7208, lr_0 = 5.9658e-04
Validation auc = 0.853250
 27%|â–ˆâ–ˆâ–‹       | 8/30 [03:00&lt;08:28, 23.11s/it]Epoch 8
Loss = 3.2643e-01, PNorm = 35.3344, GNorm = 0.6999, lr_0 = 5.8145e-04
Loss = 3.0346e-01, PNorm = 35.3856, GNorm = 0.6837, lr_0 = 5.6669e-04
Loss = 2.8790e-01, PNorm = 35.4334, GNorm = 0.6533, lr_0 = 5.5232e-04
Validation auc = 0.855157
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:24&lt;08:12, 23.45s/it]Epoch 9
Loss = 2.6723e-01, PNorm = 35.4871, GNorm = 0.8949, lr_0 = 5.3830e-04
Loss = 2.7581e-01, PNorm = 35.5388, GNorm = 0.7371, lr_0 = 5.2465e-04
Loss = 3.0116e-01, PNorm = 35.5795, GNorm = 0.8037, lr_0 = 5.1133e-04
Validation auc = 0.860529
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:48&lt;07:53, 23.67s/it]Epoch 10
Loss = 3.1910e-01, PNorm = 35.6263, GNorm = 1.7916, lr_0 = 4.9836e-04
Loss = 2.7589e-01, PNorm = 35.6775, GNorm = 1.0073, lr_0 = 4.8572e-04
Loss = 2.6230e-01, PNorm = 35.7196, GNorm = 1.6867, lr_0 = 4.7339e-04
Validation auc = 0.855913
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [04:13&lt;07:34, 23.94s/it]Epoch 11
Loss = 2.2269e-01, PNorm = 35.7685, GNorm = 0.5647, lr_0 = 4.6020e-04
Loss = 2.8032e-01, PNorm = 35.8202, GNorm = 0.9101, lr_0 = 4.4852e-04
Loss = 2.6989e-01, PNorm = 35.8575, GNorm = 0.7661, lr_0 = 4.3714e-04
Loss = 2.5243e-01, PNorm = 35.8924, GNorm = 1.8814, lr_0 = 4.2605e-04
Validation auc = 0.866222
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:35&lt;07:01, 23.39s/it]Epoch 12
Loss = 3.0864e-01, PNorm = 35.9291, GNorm = 2.4162, lr_0 = 4.1524e-04
Loss = 2.6324e-01, PNorm = 35.9657, GNorm = 1.0833, lr_0 = 4.0471e-04
Loss = 2.5254e-01, PNorm = 36.0018, GNorm = 0.8596, lr_0 = 3.9444e-04
Validation auc = 0.864480
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:58&lt;06:35, 23.29s/it]Epoch 13
Loss = 2.7847e-01, PNorm = 36.0386, GNorm = 1.0885, lr_0 = 3.8443e-04
Loss = 2.1106e-01, PNorm = 36.0755, GNorm = 0.7475, lr_0 = 3.7468e-04
Loss = 2.8272e-01, PNorm = 36.1032, GNorm = 1.4107, lr_0 = 3.6517e-04
Validation auc = 0.868644
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:23&lt;06:20, 23.79s/it]Epoch 14
Loss = 2.6149e-01, PNorm = 36.1385, GNorm = 0.9653, lr_0 = 3.5500e-04
Loss = 2.7012e-01, PNorm = 36.1748, GNorm = 0.9300, lr_0 = 3.4599e-04
Loss = 2.3500e-01, PNorm = 36.2065, GNorm = 0.9834, lr_0 = 3.3721e-04
Validation auc = 0.872554
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:48&lt;06:03, 24.25s/it]Epoch 15
Loss = 1.3722e-01, PNorm = 36.2363, GNorm = 0.7371, lr_0 = 3.2866e-04
Loss = 2.6957e-01, PNorm = 36.2676, GNorm = 1.2163, lr_0 = 3.2032e-04
Loss = 2.0775e-01, PNorm = 36.2973, GNorm = 0.7404, lr_0 = 3.1219e-04
Loss = 2.2550e-01, PNorm = 36.3213, GNorm = 1.2833, lr_0 = 3.0427e-04
Validation auc = 0.869664
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:14&lt;05:44, 24.57s/it]Epoch 16
Loss = 2.4413e-01, PNorm = 36.3483, GNorm = 0.9222, lr_0 = 2.9579e-04
Loss = 2.3373e-01, PNorm = 36.3762, GNorm = 0.6782, lr_0 = 2.8828e-04
Loss = 1.9903e-01, PNorm = 36.4009, GNorm = 1.7978, lr_0 = 2.8097e-04
Validation auc = 0.871752
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:39&lt;05:20, 24.68s/it]Epoch 17
Loss = 2.1133e-01, PNorm = 36.4263, GNorm = 0.9462, lr_0 = 2.7384e-04
Loss = 2.1816e-01, PNorm = 36.4528, GNorm = 0.9474, lr_0 = 2.6689e-04
Loss = 2.3951e-01, PNorm = 36.4767, GNorm = 0.9969, lr_0 = 2.6012e-04
Validation auc = 0.869897
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [07:03&lt;04:54, 24.57s/it]Epoch 18
Loss = 2.5544e-01, PNorm = 36.4969, GNorm = 1.2004, lr_0 = 2.5352e-04
Loss = 2.0932e-01, PNorm = 36.5184, GNorm = 0.7141, lr_0 = 2.4709e-04
Loss = 2.5558e-01, PNorm = 36.5406, GNorm = 0.8702, lr_0 = 2.4082e-04
Validation auc = 0.869473
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:30&lt;04:36, 25.18s/it]Epoch 19
Loss = 2.9814e-01, PNorm = 36.5635, GNorm = 1.9294, lr_0 = 2.3411e-04
Loss = 2.0657e-01, PNorm = 36.5883, GNorm = 0.8910, lr_0 = 2.2817e-04
Loss = 1.7860e-01, PNorm = 36.6074, GNorm = 1.3545, lr_0 = 2.2238e-04
Loss = 2.3013e-01, PNorm = 36.6244, GNorm = 1.1076, lr_0 = 2.1674e-04
Validation auc = 0.869637
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:53&lt;04:06, 24.66s/it]Epoch 20
Loss = 1.9790e-01, PNorm = 36.6436, GNorm = 0.4017, lr_0 = 2.1124e-04
Loss = 1.9631e-01, PNorm = 36.6651, GNorm = 1.2600, lr_0 = 2.0588e-04
Loss = 2.0615e-01, PNorm = 36.6825, GNorm = 1.9261, lr_0 = 2.0066e-04
Validation auc = 0.868412
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [08:17&lt;03:40, 24.48s/it]Epoch 21
Loss = 2.0785e-01, PNorm = 36.6980, GNorm = 0.9904, lr_0 = 1.9557e-04
Loss = 1.8450e-01, PNorm = 36.7161, GNorm = 2.2254, lr_0 = 1.9060e-04
Loss = 2.0003e-01, PNorm = 36.7311, GNorm = 0.5961, lr_0 = 1.8577e-04
Validation auc = 0.872807
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:42&lt;03:15, 24.46s/it]Epoch 22
Loss = 1.9961e-01, PNorm = 36.7495, GNorm = 0.7913, lr_0 = 1.8059e-04
Loss = 1.8202e-01, PNorm = 36.7663, GNorm = 1.5576, lr_0 = 1.7601e-04
Loss = 2.0640e-01, PNorm = 36.7824, GNorm = 2.6012, lr_0 = 1.7154e-04
Loss = 1.9832e-01, PNorm = 36.7937, GNorm = 0.7935, lr_0 = 1.6719e-04
Validation auc = 0.870136
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [09:04&lt;02:47, 23.89s/it]Epoch 23
Loss = 1.7012e-01, PNorm = 36.8093, GNorm = 0.9299, lr_0 = 1.6295e-04
Loss = 1.6535e-01, PNorm = 36.8235, GNorm = 0.9022, lr_0 = 1.5882e-04
Loss = 2.2565e-01, PNorm = 36.8362, GNorm = 0.6081, lr_0 = 1.5479e-04
Validation auc = 0.871655
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:28&lt;02:22, 23.75s/it]Epoch 24
Loss = 1.7154e-01, PNorm = 36.8516, GNorm = 1.2007, lr_0 = 1.5047e-04
Loss = 2.0130e-01, PNorm = 36.8641, GNorm = 0.8403, lr_0 = 1.4665e-04
Loss = 1.9262e-01, PNorm = 36.8771, GNorm = 1.6096, lr_0 = 1.4293e-04
Validation auc = 0.869651
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:50&lt;01:56, 23.25s/it]Epoch 25
Loss = 1.7977e-01, PNorm = 36.8901, GNorm = 0.5687, lr_0 = 1.3931e-04
Loss = 2.0113e-01, PNorm = 36.9016, GNorm = 0.8200, lr_0 = 1.3577e-04
Loss = 1.5470e-01, PNorm = 36.9153, GNorm = 1.3182, lr_0 = 1.3233e-04
Validation auc = 0.875535
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [10:12&lt;01:31, 22.85s/it]Epoch 26
Loss = 1.1032e-01, PNorm = 36.9278, GNorm = 0.7398, lr_0 = 1.2897e-04
Loss = 1.7223e-01, PNorm = 36.9396, GNorm = 1.5111, lr_0 = 1.2570e-04
Loss = 2.3340e-01, PNorm = 36.9518, GNorm = 1.4119, lr_0 = 1.2251e-04
Loss = 1.5973e-01, PNorm = 36.9620, GNorm = 0.6217, lr_0 = 1.1940e-04
Loss = 1.5186e-01, PNorm = 36.9632, GNorm = 2.1749, lr_0 = 1.1909e-04
Validation auc = 0.872548
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:33&lt;01:07, 22.49s/it]Epoch 27
Loss = 1.7789e-01, PNorm = 36.9714, GNorm = 1.5165, lr_0 = 1.1607e-04
Loss = 2.1012e-01, PNorm = 36.9808, GNorm = 1.7794, lr_0 = 1.1313e-04
Loss = 1.7228e-01, PNorm = 36.9913, GNorm = 1.9834, lr_0 = 1.1026e-04
Validation auc = 0.870228
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [10:57&lt;00:45, 22.78s/it]Epoch 28
Loss = 1.4317e-01, PNorm = 37.0015, GNorm = 0.5428, lr_0 = 1.0746e-04
Loss = 2.0754e-01, PNorm = 37.0132, GNorm = 1.9797, lr_0 = 1.0473e-04
Loss = 1.7099e-01, PNorm = 37.0217, GNorm = 1.8418, lr_0 = 1.0208e-04
Validation auc = 0.874042
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [11:18&lt;00:22, 22.42s/it]Epoch 29
Loss = 1.9134e-01, PNorm = 37.0333, GNorm = 2.0929, lr_0 = 1.0000e-04
Loss = 1.4536e-01, PNorm = 37.0410, GNorm = 1.1186, lr_0 = 1.0000e-04
Loss = 1.9219e-01, PNorm = 37.0507, GNorm = 1.4713, lr_0 = 1.0000e-04
Validation auc = 0.871245
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:39&lt;00:00, 23.33s/it]
Model 0 best validation auc = 0.875535 on epoch 25
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.859605
Ensemble test auc = 0.859605
Fold 2
Splitting data with seed 2
7807it [00:00, 93976.35it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 165957.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 66665.98it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 2241.03it/s]
Total scaffolds = 1,025 | train scaffolds = 871 | val scaffolds = 0 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 6.0362e-01, PNorm = 34.0126, GNorm = 0.6707, lr_0 = 2.5469e-04
Loss = 5.0584e-01, PNorm = 34.0185, GNorm = 0.3407, lr_0 = 3.9531e-04
Loss = 4.9781e-01, PNorm = 34.0381, GNorm = 0.3298, lr_0 = 5.3594e-04
Validation auc = 0.760552
  3%|â–Ž         | 1/30 [00:22&lt;11:05, 22.96s/it]Epoch 1
Loss = 4.6252e-01, PNorm = 34.0779, GNorm = 0.8323, lr_0 = 6.9063e-04
Loss = 4.4080e-01, PNorm = 34.1227, GNorm = 2.8627, lr_0 = 8.3125e-04
Loss = 4.6250e-01, PNorm = 34.1646, GNorm = 0.5142, lr_0 = 9.7187e-04
Validation auc = 0.790695
  7%|â–‹         | 2/30 [00:44&lt;10:22, 22.24s/it]Epoch 2
Loss = 4.0534e-01, PNorm = 34.2277, GNorm = 0.5855, lr_0 = 9.7965e-04
Loss = 4.1850e-01, PNorm = 34.2869, GNorm = 1.5344, lr_0 = 9.5480e-04
Loss = 3.9848e-01, PNorm = 34.3544, GNorm = 0.6003, lr_0 = 9.3057e-04
Validation auc = 0.824694
 10%|â–ˆ         | 3/30 [01:05&lt;09:44, 21.63s/it]Epoch 3
Loss = 3.3840e-01, PNorm = 34.4211, GNorm = 1.0208, lr_0 = 9.0463e-04
Loss = 4.2338e-01, PNorm = 34.4658, GNorm = 2.6432, lr_0 = 8.8168e-04
Loss = 4.6957e-01, PNorm = 34.5164, GNorm = 2.4411, lr_0 = 8.5931e-04
Loss = 4.1367e-01, PNorm = 34.5805, GNorm = 0.9025, lr_0 = 8.3751e-04
Validation auc = 0.825354
 13%|â–ˆâ–Ž        | 4/30 [01:27&lt;09:25, 21.74s/it]Epoch 4
Loss = 3.9201e-01, PNorm = 34.6501, GNorm = 0.6751, lr_0 = 8.1626e-04
Loss = 3.5608e-01, PNorm = 34.7110, GNorm = 0.2464, lr_0 = 7.9555e-04
Loss = 3.7925e-01, PNorm = 34.7609, GNorm = 1.6704, lr_0 = 7.7537e-04
Validation auc = 0.838017
 17%|â–ˆâ–‹        | 5/30 [01:49&lt;09:01, 21.66s/it]Epoch 5
Loss = 2.9262e-01, PNorm = 34.8032, GNorm = 0.8056, lr_0 = 7.5570e-04
Loss = 3.4921e-01, PNorm = 34.8425, GNorm = 0.6386, lr_0 = 7.3653e-04
Loss = 3.5358e-01, PNorm = 34.8934, GNorm = 0.9398, lr_0 = 7.1784e-04
Validation auc = 0.841108
 20%|â–ˆâ–ˆ        | 6/30 [02:09&lt;08:34, 21.42s/it]Epoch 6
Loss = 3.7898e-01, PNorm = 34.9461, GNorm = 1.7352, lr_0 = 6.9783e-04
Loss = 2.8961e-01, PNorm = 34.9995, GNorm = 0.7246, lr_0 = 6.8013e-04
Loss = 3.8121e-01, PNorm = 35.0442, GNorm = 1.4410, lr_0 = 6.6287e-04
Validation auc = 0.855532
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:32&lt;08:17, 21.63s/it]Epoch 7
Loss = 3.7778e-01, PNorm = 35.0863, GNorm = 0.9807, lr_0 = 6.4605e-04
Loss = 3.0422e-01, PNorm = 35.1288, GNorm = 1.0329, lr_0 = 6.2966e-04
Loss = 3.3546e-01, PNorm = 35.1729, GNorm = 1.1070, lr_0 = 6.1369e-04
Loss = 3.0829e-01, PNorm = 35.2123, GNorm = 0.6419, lr_0 = 5.9812e-04
Loss = 3.3615e-01, PNorm = 35.2163, GNorm = 2.7590, lr_0 = 5.9658e-04
Validation auc = 0.858447
 27%|â–ˆâ–ˆâ–‹       | 8/30 [02:53&lt;07:55, 21.60s/it]Epoch 8
Loss = 2.8547e-01, PNorm = 35.2628, GNorm = 0.4471, lr_0 = 5.8145e-04
Loss = 3.1165e-01, PNorm = 35.3067, GNorm = 0.9458, lr_0 = 5.6669e-04
Loss = 3.1942e-01, PNorm = 35.3441, GNorm = 0.7806, lr_0 = 5.5232e-04
Validation auc = 0.865120
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:14&lt;07:31, 21.51s/it]Epoch 9
Loss = 2.5204e-01, PNorm = 35.3841, GNorm = 0.8710, lr_0 = 5.3830e-04
Loss = 3.2551e-01, PNorm = 35.4262, GNorm = 0.5684, lr_0 = 5.2465e-04
Loss = 2.6458e-01, PNorm = 35.4691, GNorm = 2.5230, lr_0 = 5.1133e-04
Validation auc = 0.867362
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:36&lt;07:11, 21.57s/it]Epoch 10
Loss = 2.5710e-01, PNorm = 35.5074, GNorm = 0.7284, lr_0 = 4.9836e-04
Loss = 2.7672e-01, PNorm = 35.5509, GNorm = 0.8951, lr_0 = 4.8572e-04
Loss = 2.9099e-01, PNorm = 35.5904, GNorm = 1.2288, lr_0 = 4.7339e-04
Validation auc = 0.860585
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:57&lt;06:43, 21.22s/it]Epoch 11
Loss = 2.3208e-01, PNorm = 35.6297, GNorm = 0.7105, lr_0 = 4.6020e-04
Loss = 2.5835e-01, PNorm = 35.6634, GNorm = 1.8572, lr_0 = 4.4852e-04
Loss = 2.6463e-01, PNorm = 35.7016, GNorm = 0.9017, lr_0 = 4.3714e-04
Loss = 2.5494e-01, PNorm = 35.7439, GNorm = 2.5274, lr_0 = 4.2605e-04
Validation auc = 0.862331
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:17&lt;06:17, 20.96s/it]Epoch 12
Loss = 2.7021e-01, PNorm = 35.7715, GNorm = 0.6333, lr_0 = 4.1524e-04
Loss = 2.5902e-01, PNorm = 35.8035, GNorm = 1.9498, lr_0 = 4.0471e-04
Loss = 2.8274e-01, PNorm = 35.8342, GNorm = 1.3376, lr_0 = 3.9444e-04
Validation auc = 0.871743
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:37&lt;05:53, 20.79s/it]Epoch 13
Loss = 2.3532e-01, PNorm = 35.8605, GNorm = 2.3923, lr_0 = 3.8443e-04
Loss = 2.5791e-01, PNorm = 35.8861, GNorm = 2.1943, lr_0 = 3.7468e-04
Loss = 2.7460e-01, PNorm = 35.9150, GNorm = 1.5343, lr_0 = 3.6517e-04
Validation auc = 0.873620
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [04:58&lt;05:34, 20.89s/it]Epoch 14
Loss = 2.0399e-01, PNorm = 35.9476, GNorm = 1.4632, lr_0 = 3.5500e-04
Loss = 2.7089e-01, PNorm = 35.9726, GNorm = 1.6253, lr_0 = 3.4599e-04
Loss = 2.3401e-01, PNorm = 35.9997, GNorm = 0.7775, lr_0 = 3.3721e-04
Validation auc = 0.876425
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:19&lt;05:11, 20.78s/it]Epoch 15
Loss = 2.6768e-01, PNorm = 36.0240, GNorm = 0.9954, lr_0 = 3.2866e-04
Loss = 2.0685e-01, PNorm = 36.0548, GNorm = 1.8900, lr_0 = 3.2032e-04
Loss = 2.2412e-01, PNorm = 36.0833, GNorm = 0.5792, lr_0 = 3.1219e-04
Loss = 2.4476e-01, PNorm = 36.1085, GNorm = 1.6445, lr_0 = 3.0427e-04
Validation auc = 0.875596
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [05:40&lt;04:53, 20.96s/it]Epoch 16
Loss = 2.2949e-01, PNorm = 36.1305, GNorm = 0.9145, lr_0 = 2.9579e-04
Loss = 1.9585e-01, PNorm = 36.1505, GNorm = 0.4529, lr_0 = 2.8828e-04
Loss = 2.7090e-01, PNorm = 36.1746, GNorm = 0.7945, lr_0 = 2.8097e-04
Validation auc = 0.877208
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:04&lt;04:42, 21.73s/it]Epoch 17
Loss = 2.1816e-01, PNorm = 36.1949, GNorm = 2.0708, lr_0 = 2.7384e-04
Loss = 1.8441e-01, PNorm = 36.2158, GNorm = 1.0388, lr_0 = 2.6689e-04
Loss = 2.8637e-01, PNorm = 36.2391, GNorm = 0.9753, lr_0 = 2.6012e-04
Validation auc = 0.870138
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:25&lt;04:17, 21.45s/it]Epoch 18
Loss = 1.5308e-01, PNorm = 36.2586, GNorm = 2.1514, lr_0 = 2.5352e-04
Loss = 2.2635e-01, PNorm = 36.2779, GNorm = 1.0403, lr_0 = 2.4709e-04
Loss = 2.2665e-01, PNorm = 36.2964, GNorm = 1.3590, lr_0 = 2.4082e-04
Validation auc = 0.869019
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [06:45&lt;03:53, 21.22s/it]Epoch 19
Loss = 8.9551e-02, PNorm = 36.3192, GNorm = 0.7785, lr_0 = 2.3411e-04
Loss = 2.0486e-01, PNorm = 36.3410, GNorm = 0.7392, lr_0 = 2.2817e-04
Loss = 2.2939e-01, PNorm = 36.3640, GNorm = 1.2424, lr_0 = 2.2238e-04
Loss = 1.9926e-01, PNorm = 36.3786, GNorm = 0.7721, lr_0 = 2.1674e-04
Validation auc = 0.875981
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:08&lt;03:37, 21.72s/it]Epoch 20
Loss = 2.0309e-01, PNorm = 36.3941, GNorm = 2.4386, lr_0 = 2.1124e-04
Loss = 2.0890e-01, PNorm = 36.4104, GNorm = 1.4285, lr_0 = 2.0588e-04
Loss = 1.8153e-01, PNorm = 36.4284, GNorm = 0.5590, lr_0 = 2.0066e-04
Validation auc = 0.870780
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [07:30&lt;03:16, 21.84s/it]Epoch 21
Loss = 1.8481e-01, PNorm = 36.4460, GNorm = 2.7512, lr_0 = 1.9557e-04
Loss = 2.1980e-01, PNorm = 36.4644, GNorm = 2.2602, lr_0 = 1.9060e-04
Loss = 1.8008e-01, PNorm = 36.4805, GNorm = 0.9021, lr_0 = 1.8577e-04
Validation auc = 0.875258
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [07:51&lt;02:51, 21.44s/it]Epoch 22
Loss = 1.8978e-01, PNorm = 36.4971, GNorm = 0.7574, lr_0 = 1.8059e-04
Loss = 1.9064e-01, PNorm = 36.5102, GNorm = 1.5119, lr_0 = 1.7601e-04
Loss = 2.1171e-01, PNorm = 36.5234, GNorm = 0.6926, lr_0 = 1.7154e-04
Loss = 1.9472e-01, PNorm = 36.5373, GNorm = 0.9849, lr_0 = 1.6719e-04
Validation auc = 0.881586
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:14&lt;02:33, 21.89s/it]Epoch 23
Loss = 1.8850e-01, PNorm = 36.5525, GNorm = 1.5114, lr_0 = 1.6295e-04
Loss = 2.0301e-01, PNorm = 36.5675, GNorm = 1.0058, lr_0 = 1.5882e-04
Loss = 1.8228e-01, PNorm = 36.5804, GNorm = 1.7929, lr_0 = 1.5479e-04
Validation auc = 0.878990
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [08:36&lt;02:11, 22.00s/it]Epoch 24
Loss = 1.9413e-01, PNorm = 36.5934, GNorm = 0.9976, lr_0 = 1.5047e-04
Loss = 2.0365e-01, PNorm = 36.6074, GNorm = 0.7346, lr_0 = 1.4665e-04
Loss = 1.8043e-01, PNorm = 36.6215, GNorm = 0.6577, lr_0 = 1.4293e-04
Validation auc = 0.873295
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [08:59&lt;01:50, 22.16s/it]Epoch 25
Loss = 1.6548e-01, PNorm = 36.6328, GNorm = 0.7261, lr_0 = 1.3931e-04
Loss = 1.9304e-01, PNorm = 36.6451, GNorm = 1.2106, lr_0 = 1.3577e-04
Loss = 1.9536e-01, PNorm = 36.6578, GNorm = 0.9719, lr_0 = 1.3233e-04
Validation auc = 0.872888
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [09:21&lt;01:28, 22.22s/it]Epoch 26
Loss = 2.1892e-01, PNorm = 36.6704, GNorm = 1.1834, lr_0 = 1.2897e-04
Loss = 1.8540e-01, PNorm = 36.6827, GNorm = 2.2023, lr_0 = 1.2570e-04
Loss = 1.8935e-01, PNorm = 36.6935, GNorm = 1.6809, lr_0 = 1.2251e-04
Loss = 1.7464e-01, PNorm = 36.7032, GNorm = 1.7633, lr_0 = 1.1940e-04
Loss = 1.8098e-01, PNorm = 36.7042, GNorm = 3.0041, lr_0 = 1.1909e-04
Validation auc = 0.881022
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [09:42&lt;01:05, 21.91s/it]Epoch 27
Loss = 1.7639e-01, PNorm = 36.7141, GNorm = 1.2014, lr_0 = 1.1607e-04
Loss = 1.8164e-01, PNorm = 36.7256, GNorm = 1.2400, lr_0 = 1.1313e-04
Loss = 1.7504e-01, PNorm = 36.7352, GNorm = 3.4003, lr_0 = 1.1026e-04
Validation auc = 0.877288
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [10:03&lt;00:43, 21.74s/it]Epoch 28
Loss = 1.8956e-01, PNorm = 36.7454, GNorm = 2.1527, lr_0 = 1.0746e-04
Loss = 1.6665e-01, PNorm = 36.7553, GNorm = 1.3492, lr_0 = 1.0473e-04
Loss = 1.7506e-01, PNorm = 36.7639, GNorm = 1.7218, lr_0 = 1.0208e-04
Validation auc = 0.876728
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [10:26&lt;00:21, 21.90s/it]Epoch 29
Loss = 1.2047e-01, PNorm = 36.7740, GNorm = 1.0475, lr_0 = 1.0000e-04
Loss = 2.1471e-01, PNorm = 36.7832, GNorm = 1.2062, lr_0 = 1.0000e-04
Loss = 1.7566e-01, PNorm = 36.7917, GNorm = 2.2096, lr_0 = 1.0000e-04
Validation auc = 0.881241
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [10:49&lt;00:00, 21.65s/it]
Model 0 best validation auc = 0.881586 on epoch 22
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.884451
Ensemble test auc = 0.884451
Fold 3
Splitting data with seed 3
7807it [00:00, 109858.36it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 190240.36it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 70268.85it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 3095.88it/s]
Total scaffolds = 1,025 | train scaffolds = 783 | val scaffolds = 0 | test scaffolds = 242
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.8503e-01, PNorm = 34.0129, GNorm = 0.7183, lr_0 = 2.5469e-04
Loss = 5.3260e-01, PNorm = 34.0194, GNorm = 0.8494, lr_0 = 3.9531e-04
Loss = 5.2468e-01, PNorm = 34.0407, GNorm = 0.3495, lr_0 = 5.3594e-04
Validation auc = 0.753098
  3%|â–Ž         | 1/30 [00:23&lt;11:12, 23.20s/it]Epoch 1
Loss = 4.9305e-01, PNorm = 34.0837, GNorm = 1.5001, lr_0 = 6.9063e-04
Loss = 4.5417e-01, PNorm = 34.1229, GNorm = 1.2743, lr_0 = 8.3125e-04
Loss = 4.2560e-01, PNorm = 34.1709, GNorm = 0.3752, lr_0 = 9.7187e-04
Validation auc = 0.801727
  7%|â–‹         | 2/30 [00:43&lt;10:02, 21.52s/it]Epoch 2
Loss = 4.1467e-01, PNorm = 34.2309, GNorm = 2.1363, lr_0 = 9.7965e-04
Loss = 3.7320e-01, PNorm = 34.2967, GNorm = 2.4100, lr_0 = 9.5480e-04
Loss = 4.0981e-01, PNorm = 34.3477, GNorm = 1.3296, lr_0 = 9.3057e-04
Validation auc = 0.817309
 10%|â–ˆ         | 3/30 [01:04&lt;09:32, 21.22s/it]Epoch 3
Loss = 3.8771e-01, PNorm = 34.4124, GNorm = 0.6317, lr_0 = 9.0463e-04
Loss = 3.9085e-01, PNorm = 34.4764, GNorm = 1.6561, lr_0 = 8.8168e-04
Loss = 3.4792e-01, PNorm = 34.5298, GNorm = 0.5630, lr_0 = 8.5931e-04
Loss = 3.5220e-01, PNorm = 34.5699, GNorm = 1.3693, lr_0 = 8.3751e-04
Validation auc = 0.809701
 13%|â–ˆâ–Ž        | 4/30 [01:24&lt;08:57, 20.68s/it]Epoch 4
Loss = 3.3247e-01, PNorm = 34.6296, GNorm = 1.1420, lr_0 = 8.1626e-04
Loss = 3.5306e-01, PNorm = 34.6740, GNorm = 1.1846, lr_0 = 7.9555e-04
Loss = 3.3732e-01, PNorm = 34.7250, GNorm = 0.4723, lr_0 = 7.7537e-04
Validation auc = 0.844284
 17%|â–ˆâ–‹        | 5/30 [01:44&lt;08:31, 20.45s/it]Epoch 5
Loss = 3.3587e-01, PNorm = 34.7825, GNorm = 1.8932, lr_0 = 7.5570e-04
Loss = 3.0881e-01, PNorm = 34.8456, GNorm = 0.4694, lr_0 = 7.3653e-04
Loss = 3.7637e-01, PNorm = 34.8771, GNorm = 1.4360, lr_0 = 7.1784e-04
Validation auc = 0.850265
 20%|â–ˆâ–ˆ        | 6/30 [02:05&lt;08:13, 20.56s/it]Epoch 6
Loss = 2.9220e-01, PNorm = 34.9294, GNorm = 0.6241, lr_0 = 6.9783e-04
Loss = 3.2549e-01, PNorm = 34.9790, GNorm = 0.6818, lr_0 = 6.8013e-04
Loss = 3.0608e-01, PNorm = 35.0372, GNorm = 0.8883, lr_0 = 6.6287e-04
Validation auc = 0.849036
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:24&lt;07:47, 20.31s/it]Epoch 7
Loss = 2.5418e-01, PNorm = 35.0786, GNorm = 1.1208, lr_0 = 6.4605e-04
Loss = 2.9694e-01, PNorm = 35.1282, GNorm = 0.4616, lr_0 = 6.2966e-04
Loss = 3.2139e-01, PNorm = 35.1663, GNorm = 0.8886, lr_0 = 6.1369e-04
Loss = 3.0297e-01, PNorm = 35.2010, GNorm = 0.6191, lr_0 = 5.9812e-04
Loss = 3.7280e-01, PNorm = 35.2063, GNorm = 0.4405, lr_0 = 5.9658e-04
Validation auc = 0.852861
 27%|â–ˆâ–ˆâ–‹       | 8/30 [02:44&lt;07:24, 20.21s/it]Epoch 8
Loss = 2.8168e-01, PNorm = 35.2603, GNorm = 1.9431, lr_0 = 5.8145e-04
Loss = 3.2319e-01, PNorm = 35.3027, GNorm = 0.6268, lr_0 = 5.6669e-04
Loss = 2.8460e-01, PNorm = 35.3421, GNorm = 1.0085, lr_0 = 5.5232e-04
Validation auc = 0.869803
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:05&lt;07:09, 20.47s/it]Epoch 9
Loss = 2.4875e-01, PNorm = 35.3866, GNorm = 0.7201, lr_0 = 5.3830e-04
Loss = 2.9694e-01, PNorm = 35.4251, GNorm = 1.6812, lr_0 = 5.2465e-04
Loss = 2.7647e-01, PNorm = 35.4672, GNorm = 1.1003, lr_0 = 5.1133e-04
Validation auc = 0.866824
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:25&lt;06:45, 20.29s/it]Epoch 10
Loss = 2.1429e-01, PNorm = 35.5067, GNorm = 0.4265, lr_0 = 4.9836e-04
Loss = 2.6924e-01, PNorm = 35.5539, GNorm = 3.2518, lr_0 = 4.8572e-04
Loss = 3.3974e-01, PNorm = 35.5871, GNorm = 1.1372, lr_0 = 4.7339e-04
Validation auc = 0.865611
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:45&lt;06:22, 20.14s/it]Epoch 11
Loss = 2.5574e-01, PNorm = 35.6282, GNorm = 0.5900, lr_0 = 4.6020e-04
Loss = 2.7551e-01, PNorm = 35.6684, GNorm = 0.6836, lr_0 = 4.4852e-04
Loss = 2.5548e-01, PNorm = 35.7092, GNorm = 0.7596, lr_0 = 4.3714e-04
Loss = 2.6243e-01, PNorm = 35.7530, GNorm = 0.5971, lr_0 = 4.2605e-04
Validation auc = 0.854902
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:05&lt;06:02, 20.16s/it]Epoch 12
Loss = 2.7059e-01, PNorm = 35.7839, GNorm = 0.8614, lr_0 = 4.1524e-04
Loss = 2.6100e-01, PNorm = 35.8191, GNorm = 0.8910, lr_0 = 4.0471e-04
Loss = 2.3268e-01, PNorm = 35.8580, GNorm = 0.6772, lr_0 = 3.9444e-04
Validation auc = 0.879089
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:28&lt;05:53, 20.82s/it]Epoch 13
Loss = 2.4654e-01, PNorm = 35.8996, GNorm = 2.3554, lr_0 = 3.8443e-04
Loss = 2.4650e-01, PNorm = 35.9410, GNorm = 0.6923, lr_0 = 3.7468e-04
Loss = 2.7544e-01, PNorm = 35.9681, GNorm = 0.8501, lr_0 = 3.6517e-04
Validation auc = 0.879367
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [04:49&lt;05:38, 21.13s/it]Epoch 14
Loss = 2.1829e-01, PNorm = 35.9958, GNorm = 1.1294, lr_0 = 3.5500e-04
Loss = 2.2900e-01, PNorm = 36.0258, GNorm = 1.1646, lr_0 = 3.4599e-04
Loss = 2.5168e-01, PNorm = 36.0620, GNorm = 0.7692, lr_0 = 3.3721e-04
Validation auc = 0.880691
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:13&lt;05:26, 21.79s/it]Epoch 15
Loss = 1.7709e-01, PNorm = 36.0969, GNorm = 1.0523, lr_0 = 3.2866e-04
Loss = 2.4527e-01, PNorm = 36.1308, GNorm = 2.1124, lr_0 = 3.2032e-04
Loss = 2.2482e-01, PNorm = 36.1610, GNorm = 1.7217, lr_0 = 3.1219e-04
Loss = 2.3390e-01, PNorm = 36.1893, GNorm = 0.9631, lr_0 = 3.0427e-04
Validation auc = 0.880331
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [05:37&lt;05:13, 22.39s/it]Epoch 16
Loss = 2.1933e-01, PNorm = 36.2226, GNorm = 1.0130, lr_0 = 2.9579e-04
Loss = 2.1466e-01, PNorm = 36.2504, GNorm = 1.1862, lr_0 = 2.8828e-04
Loss = 2.1801e-01, PNorm = 36.2805, GNorm = 1.3128, lr_0 = 2.8097e-04
Validation auc = 0.883562
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [05:59&lt;04:52, 22.53s/it]Epoch 17
Loss = 1.9419e-01, PNorm = 36.3101, GNorm = 1.3975, lr_0 = 2.7384e-04
Loss = 2.0557e-01, PNorm = 36.3417, GNorm = 0.8939, lr_0 = 2.6689e-04
Loss = 2.3192e-01, PNorm = 36.3687, GNorm = 2.0555, lr_0 = 2.6012e-04
Validation auc = 0.886957
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:21&lt;04:25, 22.12s/it]Epoch 18
Loss = 2.3539e-01, PNorm = 36.3916, GNorm = 0.8720, lr_0 = 2.5352e-04
Loss = 2.1929e-01, PNorm = 36.4164, GNorm = 0.7058, lr_0 = 2.4709e-04
Loss = 2.4068e-01, PNorm = 36.4369, GNorm = 3.0150, lr_0 = 2.4082e-04
Validation auc = 0.881972
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [06:42&lt;04:02, 22.01s/it]Epoch 19
Loss = 2.8110e-01, PNorm = 36.4620, GNorm = 0.9777, lr_0 = 2.3411e-04
Loss = 1.8928e-01, PNorm = 36.4869, GNorm = 0.7610, lr_0 = 2.2817e-04
Loss = 1.8999e-01, PNorm = 36.5149, GNorm = 1.1548, lr_0 = 2.2238e-04
Loss = 2.0293e-01, PNorm = 36.5373, GNorm = 0.7328, lr_0 = 2.1674e-04
Validation auc = 0.882238
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:03&lt;03:37, 21.71s/it]Epoch 20
Loss = 1.4837e-01, PNorm = 36.5575, GNorm = 0.9761, lr_0 = 2.1124e-04
Loss = 2.4855e-01, PNorm = 36.5775, GNorm = 1.1418, lr_0 = 2.0588e-04
Loss = 1.9571e-01, PNorm = 36.5983, GNorm = 1.6342, lr_0 = 2.0066e-04
Validation auc = 0.885651
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [07:25&lt;03:15, 21.76s/it]Epoch 21
Loss = 1.8447e-01, PNorm = 36.6182, GNorm = 1.4701, lr_0 = 1.9557e-04
Loss = 2.0830e-01, PNorm = 36.6364, GNorm = 1.7001, lr_0 = 1.9060e-04
Loss = 1.9511e-01, PNorm = 36.6552, GNorm = 0.7673, lr_0 = 1.8577e-04
Validation auc = 0.881236
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [07:48&lt;02:57, 22.19s/it]Epoch 22
Loss = 1.6973e-01, PNorm = 36.6757, GNorm = 0.9187, lr_0 = 1.8059e-04
Loss = 1.8659e-01, PNorm = 36.6936, GNorm = 1.1550, lr_0 = 1.7601e-04
Loss = 1.7931e-01, PNorm = 36.7113, GNorm = 1.1469, lr_0 = 1.7154e-04
Loss = 1.9458e-01, PNorm = 36.7288, GNorm = 0.9962, lr_0 = 1.6719e-04
Validation auc = 0.886035
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:13&lt;02:41, 23.02s/it]Epoch 23
Loss = 1.6233e-01, PNorm = 36.7440, GNorm = 2.0711, lr_0 = 1.6295e-04
Loss = 1.8848e-01, PNorm = 36.7586, GNorm = 1.0342, lr_0 = 1.5882e-04
Loss = 2.2215e-01, PNorm = 36.7735, GNorm = 1.5878, lr_0 = 1.5479e-04
Validation auc = 0.884020
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [08:37&lt;02:18, 23.16s/it]Epoch 24
Loss = 1.8076e-01, PNorm = 36.7899, GNorm = 1.7198, lr_0 = 1.5047e-04
Loss = 1.8257e-01, PNorm = 36.8053, GNorm = 1.0520, lr_0 = 1.4665e-04
Loss = 1.9706e-01, PNorm = 36.8194, GNorm = 1.0626, lr_0 = 1.4293e-04
Validation auc = 0.890895
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:01&lt;01:56, 23.35s/it]Epoch 25
Loss = 2.0510e-01, PNorm = 36.8340, GNorm = 1.5704, lr_0 = 1.3931e-04
Loss = 1.6853e-01, PNorm = 36.8474, GNorm = 0.8417, lr_0 = 1.3577e-04
Loss = 1.5834e-01, PNorm = 36.8612, GNorm = 0.9323, lr_0 = 1.3233e-04
Validation auc = 0.891019
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [09:25&lt;01:34, 23.74s/it]Epoch 26
Loss = 2.0799e-01, PNorm = 36.8742, GNorm = 0.9327, lr_0 = 1.2897e-04
Loss = 1.7609e-01, PNorm = 36.8876, GNorm = 0.8374, lr_0 = 1.2570e-04
Loss = 1.6518e-01, PNorm = 36.9010, GNorm = 1.6749, lr_0 = 1.2251e-04
Loss = 1.7412e-01, PNorm = 36.9125, GNorm = 1.5180, lr_0 = 1.1940e-04
Loss = 1.5249e-01, PNorm = 36.9135, GNorm = 1.7315, lr_0 = 1.1909e-04
Validation auc = 0.891827
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [09:48&lt;01:10, 23.50s/it]Epoch 27
Loss = 1.6977e-01, PNorm = 36.9245, GNorm = 2.7031, lr_0 = 1.1607e-04
Loss = 1.6511e-01, PNorm = 36.9350, GNorm = 1.1789, lr_0 = 1.1313e-04
Loss = 1.6014e-01, PNorm = 36.9464, GNorm = 1.8058, lr_0 = 1.1026e-04
Validation auc = 0.886515
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [10:09&lt;00:45, 22.78s/it]Epoch 28
Loss = 1.6906e-01, PNorm = 36.9574, GNorm = 2.0566, lr_0 = 1.0746e-04
Loss = 1.5989e-01, PNorm = 36.9693, GNorm = 1.4375, lr_0 = 1.0473e-04
Loss = 1.5272e-01, PNorm = 36.9798, GNorm = 0.9655, lr_0 = 1.0208e-04
Validation auc = 0.889167
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [10:31&lt;00:22, 22.55s/it]Epoch 29
Loss = 1.8119e-01, PNorm = 36.9902, GNorm = 2.0362, lr_0 = 1.0000e-04
Loss = 1.5775e-01, PNorm = 36.9985, GNorm = 0.7633, lr_0 = 1.0000e-04
Loss = 1.8003e-01, PNorm = 37.0084, GNorm = 1.5576, lr_0 = 1.0000e-04
Validation auc = 0.878503
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [10:52&lt;00:00, 21.75s/it]
Model 0 best validation auc = 0.891827 on epoch 26
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.893417
Ensemble test auc = 0.893417
Fold 4
Splitting data with seed 4
7807it [00:00, 100326.71it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 173326.97it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 70270.96it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 2503.17it/s]
Total scaffolds = 1,025 | train scaffolds = 793 | val scaffolds = 0 | test scaffolds = 232
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.8904e-01, PNorm = 34.0130, GNorm = 0.4582, lr_0 = 2.5469e-04
Loss = 5.4910e-01, PNorm = 34.0167, GNorm = 0.3335, lr_0 = 3.9531e-04
Loss = 4.7079e-01, PNorm = 34.0347, GNorm = 0.4258, lr_0 = 5.3594e-04
Validation auc = 0.714421
  3%|â–Ž         | 1/30 [00:24&lt;11:44, 24.30s/it]Epoch 1
Loss = 4.4932e-01, PNorm = 34.0689, GNorm = 0.7341, lr_0 = 6.9063e-04
Loss = 4.5592e-01, PNorm = 34.1133, GNorm = 1.1783, lr_0 = 8.3125e-04
Loss = 4.6461e-01, PNorm = 34.1674, GNorm = 0.9487, lr_0 = 9.7187e-04
Validation auc = 0.802569
  7%|â–‹         | 2/30 [00:47&lt;10:54, 23.37s/it]Epoch 2
Loss = 4.4770e-01, PNorm = 34.2328, GNorm = 0.9698, lr_0 = 9.7965e-04
Loss = 3.7590e-01, PNorm = 34.3134, GNorm = 1.4789, lr_0 = 9.5480e-04
Loss = 3.8262e-01, PNorm = 34.3785, GNorm = 0.3217, lr_0 = 9.3057e-04
Validation auc = 0.816338
 10%|â–ˆ         | 3/30 [01:07&lt;09:58, 22.15s/it]Epoch 3
Loss = 4.1084e-01, PNorm = 34.4491, GNorm = 1.3773, lr_0 = 9.0463e-04
Loss = 4.2045e-01, PNorm = 34.5011, GNorm = 2.9319, lr_0 = 8.8168e-04
Loss = 4.0727e-01, PNorm = 34.5599, GNorm = 0.2623, lr_0 = 8.5931e-04
Loss = 3.7995e-01, PNorm = 34.6398, GNorm = 0.6466, lr_0 = 8.3751e-04
Validation auc = 0.816479
 13%|â–ˆâ–Ž        | 4/30 [01:28&lt;09:23, 21.66s/it]Epoch 4
Loss = 3.3837e-01, PNorm = 34.7114, GNorm = 0.8128, lr_0 = 8.1626e-04
Loss = 3.8992e-01, PNorm = 34.7621, GNorm = 1.0438, lr_0 = 7.9555e-04
Loss = 3.5696e-01, PNorm = 34.8062, GNorm = 1.3761, lr_0 = 7.7537e-04
Validation auc = 0.843436
 17%|â–ˆâ–‹        | 5/30 [01:50&lt;09:02, 21.68s/it]Epoch 5
Loss = 3.4266e-01, PNorm = 34.8671, GNorm = 0.6989, lr_0 = 7.5570e-04
Loss = 3.3413e-01, PNorm = 34.9265, GNorm = 0.7118, lr_0 = 7.3653e-04
Loss = 3.6780e-01, PNorm = 34.9783, GNorm = 0.8837, lr_0 = 7.1784e-04
Validation auc = 0.852989
 20%|â–ˆâ–ˆ        | 6/30 [02:11&lt;08:32, 21.36s/it]Epoch 6
Loss = 3.3458e-01, PNorm = 35.0243, GNorm = 1.1508, lr_0 = 6.9783e-04
Loss = 3.1381e-01, PNorm = 35.0788, GNorm = 0.8429, lr_0 = 6.8013e-04
Loss = 3.2376e-01, PNorm = 35.1350, GNorm = 0.7356, lr_0 = 6.6287e-04
Validation auc = 0.857785
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:32&lt;08:11, 21.37s/it]Epoch 7
Loss = 3.9145e-01, PNorm = 35.1828, GNorm = 0.7814, lr_0 = 6.4605e-04
Loss = 2.7528e-01, PNorm = 35.2190, GNorm = 0.8323, lr_0 = 6.2966e-04
Loss = 3.2363e-01, PNorm = 35.2726, GNorm = 1.8237, lr_0 = 6.1369e-04
Loss = 3.0749e-01, PNorm = 35.3255, GNorm = 2.0515, lr_0 = 5.9812e-04
Loss = 2.8228e-01, PNorm = 35.3293, GNorm = 0.7213, lr_0 = 5.9658e-04
Validation auc = 0.854700
 27%|â–ˆâ–ˆâ–‹       | 8/30 [02:56&lt;08:07, 22.17s/it]Epoch 8
Loss = 2.9411e-01, PNorm = 35.3831, GNorm = 1.5271, lr_0 = 5.8145e-04
Loss = 2.8510e-01, PNorm = 35.4336, GNorm = 0.5846, lr_0 = 5.6669e-04
Loss = 3.2167e-01, PNorm = 35.4799, GNorm = 0.7057, lr_0 = 5.5232e-04
Validation auc = 0.851165
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:19&lt;07:54, 22.59s/it]Epoch 9
Loss = 2.6575e-01, PNorm = 35.5124, GNorm = 0.7704, lr_0 = 5.3830e-04
Loss = 2.6473e-01, PNorm = 35.5572, GNorm = 0.5866, lr_0 = 5.2465e-04
Loss = 2.9093e-01, PNorm = 35.6069, GNorm = 0.7128, lr_0 = 5.1133e-04
Validation auc = 0.857636
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:43&lt;07:39, 22.98s/it]Epoch 10
Loss = 3.5403e-01, PNorm = 35.6530, GNorm = 0.7657, lr_0 = 4.9836e-04
Loss = 2.5887e-01, PNorm = 35.6959, GNorm = 0.6837, lr_0 = 4.8572e-04
Loss = 2.5052e-01, PNorm = 35.7403, GNorm = 0.5641, lr_0 = 4.7339e-04
Validation auc = 0.863423
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [04:09&lt;07:33, 23.88s/it]Epoch 11
Loss = 2.7768e-01, PNorm = 35.7913, GNorm = 1.3297, lr_0 = 4.6020e-04
Loss = 2.3540e-01, PNorm = 35.8298, GNorm = 0.5965, lr_0 = 4.4852e-04
Loss = 2.5308e-01, PNorm = 35.8713, GNorm = 1.3339, lr_0 = 4.3714e-04
Loss = 2.8692e-01, PNorm = 35.9113, GNorm = 0.5342, lr_0 = 4.2605e-04
Validation auc = 0.871476
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:32&lt;07:03, 23.50s/it]Epoch 12
Loss = 2.5221e-01, PNorm = 35.9515, GNorm = 0.6847, lr_0 = 4.1524e-04
Loss = 2.4157e-01, PNorm = 35.9993, GNorm = 0.9547, lr_0 = 4.0471e-04
Loss = 2.6724e-01, PNorm = 36.0337, GNorm = 0.9547, lr_0 = 3.9444e-04
Validation auc = 0.876039
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:55&lt;06:40, 23.55s/it]Epoch 13
Loss = 2.1849e-01, PNorm = 36.0666, GNorm = 1.0429, lr_0 = 3.8443e-04
Loss = 2.6876e-01, PNorm = 36.1041, GNorm = 0.6180, lr_0 = 3.7468e-04
Loss = 2.5427e-01, PNorm = 36.1407, GNorm = 1.7197, lr_0 = 3.6517e-04
Validation auc = 0.873085
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:20&lt;06:22, 23.91s/it]Epoch 14
Loss = 2.1584e-01, PNorm = 36.1751, GNorm = 0.7762, lr_0 = 3.5500e-04
Loss = 2.4688e-01, PNorm = 36.2082, GNorm = 1.1125, lr_0 = 3.4599e-04
Loss = 2.1242e-01, PNorm = 36.2445, GNorm = 1.2601, lr_0 = 3.3721e-04
Validation auc = 0.864683
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:44&lt;05:59, 23.95s/it]Epoch 15
Loss = 1.7947e-01, PNorm = 36.2788, GNorm = 0.4194, lr_0 = 3.2866e-04
Loss = 2.2289e-01, PNorm = 36.3048, GNorm = 0.6260, lr_0 = 3.2032e-04
Loss = 2.6165e-01, PNorm = 36.3329, GNorm = 0.6240, lr_0 = 3.1219e-04
Loss = 2.2531e-01, PNorm = 36.3659, GNorm = 0.7357, lr_0 = 3.0427e-04
Validation auc = 0.881949
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:06&lt;05:25, 23.25s/it]Epoch 16
Loss = 2.4698e-01, PNorm = 36.4025, GNorm = 0.8394, lr_0 = 2.9579e-04
Loss = 2.1054e-01, PNorm = 36.4361, GNorm = 0.5998, lr_0 = 2.8828e-04
Loss = 2.1337e-01, PNorm = 36.4674, GNorm = 1.2679, lr_0 = 2.8097e-04
Validation auc = 0.875559
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:27&lt;04:54, 22.65s/it]Epoch 17
Loss = 2.0708e-01, PNorm = 36.4913, GNorm = 0.9110, lr_0 = 2.7384e-04
Loss = 1.9125e-01, PNorm = 36.5212, GNorm = 0.8134, lr_0 = 2.6689e-04
Loss = 2.1184e-01, PNorm = 36.5505, GNorm = 0.6213, lr_0 = 2.6012e-04
Validation auc = 0.881293
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:50&lt;04:31, 22.64s/it]Epoch 18
Loss = 1.7150e-01, PNorm = 36.5733, GNorm = 1.0104, lr_0 = 2.5352e-04
Loss = 2.0804e-01, PNorm = 36.5983, GNorm = 0.9529, lr_0 = 2.4709e-04
Loss = 2.2783e-01, PNorm = 36.6194, GNorm = 1.5317, lr_0 = 2.4082e-04
Validation auc = 0.883125
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:13&lt;04:12, 22.98s/it]Epoch 19
Loss = 2.8598e-01, PNorm = 36.6457, GNorm = 2.1299, lr_0 = 2.3411e-04
Loss = 2.0476e-01, PNorm = 36.6710, GNorm = 0.8491, lr_0 = 2.2817e-04
Loss = 1.9721e-01, PNorm = 36.6963, GNorm = 2.5710, lr_0 = 2.2238e-04
Loss = 2.0929e-01, PNorm = 36.7201, GNorm = 0.7773, lr_0 = 2.1674e-04
Validation auc = 0.881723
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:35&lt;03:46, 22.61s/it]Epoch 20
Loss = 2.0260e-01, PNorm = 36.7383, GNorm = 1.5371, lr_0 = 2.1124e-04
Loss = 2.1149e-01, PNorm = 36.7575, GNorm = 2.3478, lr_0 = 2.0588e-04
Loss = 2.0423e-01, PNorm = 36.7785, GNorm = 1.1346, lr_0 = 2.0066e-04
Validation auc = 0.883188
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [07:57&lt;03:20, 22.26s/it]Epoch 21
Loss = 1.5742e-01, PNorm = 36.8023, GNorm = 1.2067, lr_0 = 1.9557e-04
Loss = 1.9617e-01, PNorm = 36.8247, GNorm = 1.3102, lr_0 = 1.9060e-04
Loss = 2.2532e-01, PNorm = 36.8430, GNorm = 2.1962, lr_0 = 1.8577e-04
Validation auc = 0.885361
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:18&lt;02:55, 21.97s/it]Epoch 22
Loss = 1.3227e-01, PNorm = 36.8661, GNorm = 0.5254, lr_0 = 1.8059e-04
Loss = 2.1334e-01, PNorm = 36.8861, GNorm = 0.9261, lr_0 = 1.7601e-04
Loss = 2.0413e-01, PNorm = 36.9028, GNorm = 1.7435, lr_0 = 1.7154e-04
Loss = 1.6772e-01, PNorm = 36.9223, GNorm = 0.8143, lr_0 = 1.6719e-04
Validation auc = 0.884290
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:39&lt;02:32, 21.77s/it]Epoch 23
Loss = 1.9666e-01, PNorm = 36.9405, GNorm = 0.9696, lr_0 = 1.6295e-04
Loss = 1.7601e-01, PNorm = 36.9563, GNorm = 1.4962, lr_0 = 1.5882e-04
Loss = 2.0059e-01, PNorm = 36.9728, GNorm = 1.8332, lr_0 = 1.5479e-04
Validation auc = 0.882020
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:01&lt;02:10, 21.68s/it]Epoch 24
Loss = 1.9019e-01, PNorm = 36.9908, GNorm = 1.6233, lr_0 = 1.5047e-04
Loss = 1.5421e-01, PNorm = 37.0075, GNorm = 0.9650, lr_0 = 1.4665e-04
Loss = 1.8616e-01, PNorm = 37.0246, GNorm = 0.6858, lr_0 = 1.4293e-04
Validation auc = 0.884285
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:25&lt;01:52, 22.59s/it]Epoch 25
Loss = 1.7820e-01, PNorm = 37.0395, GNorm = 1.5652, lr_0 = 1.3931e-04
Loss = 1.6335e-01, PNorm = 37.0534, GNorm = 1.0124, lr_0 = 1.3577e-04
Loss = 1.9755e-01, PNorm = 37.0685, GNorm = 0.6697, lr_0 = 1.3233e-04
Validation auc = 0.881236
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [09:46&lt;01:28, 22.05s/it]Epoch 26
Loss = 2.5348e-01, PNorm = 37.0818, GNorm = 1.0460, lr_0 = 1.2897e-04
Loss = 1.5218e-01, PNorm = 37.0944, GNorm = 1.1583, lr_0 = 1.2570e-04
Loss = 1.8730e-01, PNorm = 37.1069, GNorm = 1.1171, lr_0 = 1.2251e-04
Loss = 1.9544e-01, PNorm = 37.1206, GNorm = 3.5098, lr_0 = 1.1940e-04
Loss = 2.2225e-01, PNorm = 37.1214, GNorm = 2.6071, lr_0 = 1.1909e-04
Validation auc = 0.883871
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:09&lt;01:06, 22.21s/it]Epoch 27
Loss = 1.7266e-01, PNorm = 37.1319, GNorm = 1.5730, lr_0 = 1.1607e-04
Loss = 1.9641e-01, PNorm = 37.1425, GNorm = 1.2776, lr_0 = 1.1313e-04
Loss = 1.6487e-01, PNorm = 37.1540, GNorm = 1.2483, lr_0 = 1.1026e-04
Validation auc = 0.882866
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [10:31&lt;00:44, 22.31s/it]Epoch 28
Loss = 1.7875e-01, PNorm = 37.1672, GNorm = 1.7522, lr_0 = 1.0746e-04
Loss = 1.7473e-01, PNorm = 37.1794, GNorm = 0.7878, lr_0 = 1.0473e-04
Loss = 1.6981e-01, PNorm = 37.1904, GNorm = 1.3535, lr_0 = 1.0208e-04
Validation auc = 0.887590
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [10:54&lt;00:22, 22.54s/it]Epoch 29
Loss = 1.6088e-01, PNorm = 37.2021, GNorm = 1.2300, lr_0 = 1.0000e-04
Loss = 1.4213e-01, PNorm = 37.2127, GNorm = 1.5068, lr_0 = 1.0000e-04
Loss = 1.8074e-01, PNorm = 37.2235, GNorm = 1.3147, lr_0 = 1.0000e-04
Validation auc = 0.884358
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:18&lt;00:00, 22.61s/it]
Model 0 best validation auc = 0.887590 on epoch 28
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.938451
Ensemble test auc = 0.938451
Fold 5
Splitting data with seed 5
7807it [00:00, 104000.37it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 162498.60it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 69025.63it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 2255.84it/s]
Total scaffolds = 1,025 | train scaffolds = 906 | val scaffolds = 0 | test scaffolds = 119
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.8033e-01, PNorm = 34.0138, GNorm = 1.1787, lr_0 = 2.5469e-04
Loss = 5.4678e-01, PNorm = 34.0184, GNorm = 1.1154, lr_0 = 3.9531e-04
Loss = 5.5692e-01, PNorm = 34.0360, GNorm = 0.9338, lr_0 = 5.3594e-04
Validation auc = 0.735027
  3%|â–Ž         | 1/30 [00:25&lt;12:33, 25.97s/it]Epoch 1
Loss = 4.5970e-01, PNorm = 34.0777, GNorm = 2.2193, lr_0 = 6.9063e-04
Loss = 4.5579e-01, PNorm = 34.1152, GNorm = 2.7257, lr_0 = 8.3125e-04
Loss = 4.9135e-01, PNorm = 34.1634, GNorm = 0.7147, lr_0 = 9.7187e-04
Validation auc = 0.766746
  7%|â–‹         | 2/30 [00:48&lt;11:14, 24.07s/it]Epoch 2
Loss = 4.1898e-01, PNorm = 34.2314, GNorm = 0.5118, lr_0 = 9.7965e-04
Loss = 4.3117e-01, PNorm = 34.2876, GNorm = 1.2363, lr_0 = 9.5480e-04
Loss = 3.9515e-01, PNorm = 34.3500, GNorm = 0.7560, lr_0 = 9.3057e-04
Validation auc = 0.804363
 10%|â–ˆ         | 3/30 [01:10&lt;10:16, 22.85s/it]Epoch 3
Loss = 4.2600e-01, PNorm = 34.4209, GNorm = 1.2319, lr_0 = 9.0463e-04
Loss = 3.3194e-01, PNorm = 34.4872, GNorm = 1.0340, lr_0 = 8.8168e-04
Loss = 3.8497e-01, PNorm = 34.5392, GNorm = 2.0303, lr_0 = 8.5931e-04
Loss = 4.1747e-01, PNorm = 34.5918, GNorm = 0.6238, lr_0 = 8.3751e-04
Validation auc = 0.794418
 13%|â–ˆâ–Ž        | 4/30 [01:32&lt;09:51, 22.74s/it]Epoch 4
Loss = 3.7177e-01, PNorm = 34.6527, GNorm = 0.3393, lr_0 = 8.1626e-04
Loss = 3.2056e-01, PNorm = 34.7074, GNorm = 0.4336, lr_0 = 7.9555e-04
Loss = 3.7145e-01, PNorm = 34.7541, GNorm = 0.9259, lr_0 = 7.7537e-04
Validation auc = 0.834360
 17%|â–ˆâ–‹        | 5/30 [01:54&lt;09:19, 22.38s/it]Epoch 5
Loss = 3.1982e-01, PNorm = 34.8056, GNorm = 0.6751, lr_0 = 7.5570e-04
Loss = 3.2307e-01, PNorm = 34.8663, GNorm = 2.1552, lr_0 = 7.3653e-04
Loss = 3.6569e-01, PNorm = 34.9066, GNorm = 1.9811, lr_0 = 7.1784e-04
Validation auc = 0.837094
 20%|â–ˆâ–ˆ        | 6/30 [02:15&lt;08:47, 21.97s/it]Epoch 6
Loss = 3.7645e-01, PNorm = 34.9541, GNorm = 1.1249, lr_0 = 6.9783e-04
Loss = 2.9699e-01, PNorm = 35.0068, GNorm = 0.6845, lr_0 = 6.8013e-04
Loss = 3.3965e-01, PNorm = 35.0486, GNorm = 0.4158, lr_0 = 6.6287e-04
Validation auc = 0.842136
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:37&lt;08:22, 21.84s/it]Epoch 7
Loss = 3.6432e-01, PNorm = 35.0918, GNorm = 1.0273, lr_0 = 6.4605e-04
Loss = 2.7651e-01, PNorm = 35.1428, GNorm = 0.3162, lr_0 = 6.2966e-04
Loss = 3.2439e-01, PNorm = 35.1988, GNorm = 1.1205, lr_0 = 6.1369e-04
Loss = 3.3336e-01, PNorm = 35.2405, GNorm = 1.3062, lr_0 = 5.9812e-04
Loss = 3.3097e-01, PNorm = 35.2434, GNorm = 1.5771, lr_0 = 5.9658e-04
Validation auc = 0.849479
 27%|â–ˆâ–ˆâ–‹       | 8/30 [03:00&lt;08:07, 22.16s/it]Epoch 8
Loss = 3.1454e-01, PNorm = 35.2786, GNorm = 0.5499, lr_0 = 5.8145e-04
Loss = 2.8740e-01, PNorm = 35.3219, GNorm = 1.2451, lr_0 = 5.6669e-04
Loss = 3.2447e-01, PNorm = 35.3711, GNorm = 0.4027, lr_0 = 5.5232e-04
Validation auc = 0.853164
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:22&lt;07:47, 22.25s/it]Epoch 9
Loss = 2.6941e-01, PNorm = 35.4252, GNorm = 0.6284, lr_0 = 5.3830e-04
Loss = 2.5306e-01, PNorm = 35.4747, GNorm = 1.4621, lr_0 = 5.2465e-04
Loss = 2.8457e-01, PNorm = 35.5056, GNorm = 0.9449, lr_0 = 5.1133e-04
Validation auc = 0.852232
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:45&lt;07:32, 22.62s/it]Epoch 10
Loss = 3.5473e-01, PNorm = 35.5534, GNorm = 0.9740, lr_0 = 4.9836e-04
Loss = 2.5513e-01, PNorm = 35.5959, GNorm = 1.0464, lr_0 = 4.8572e-04
Loss = 2.3035e-01, PNorm = 35.6407, GNorm = 0.5048, lr_0 = 4.7339e-04
Validation auc = 0.873011
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [04:08&lt;07:11, 22.70s/it]Epoch 11
Loss = 2.1947e-01, PNorm = 35.6786, GNorm = 1.5859, lr_0 = 4.6020e-04
Loss = 2.9966e-01, PNorm = 35.7161, GNorm = 1.6161, lr_0 = 4.4852e-04
Loss = 2.3920e-01, PNorm = 35.7500, GNorm = 0.8140, lr_0 = 4.3714e-04
Loss = 2.5769e-01, PNorm = 35.7887, GNorm = 2.0964, lr_0 = 4.2605e-04
Validation auc = 0.876054
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:32&lt;06:54, 23.01s/it]Epoch 12
Loss = 2.6451e-01, PNorm = 35.8290, GNorm = 1.9923, lr_0 = 4.1524e-04
Loss = 2.9541e-01, PNorm = 35.8587, GNorm = 0.7680, lr_0 = 4.0471e-04
Loss = 2.3624e-01, PNorm = 35.8921, GNorm = 0.6564, lr_0 = 3.9444e-04
Validation auc = 0.872729
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:55&lt;06:33, 23.14s/it]Epoch 13
Loss = 2.4811e-01, PNorm = 35.9334, GNorm = 2.9048, lr_0 = 3.8443e-04
Loss = 2.4003e-01, PNorm = 35.9732, GNorm = 0.8903, lr_0 = 3.7468e-04
Loss = 3.1994e-01, PNorm = 36.0036, GNorm = 0.4857, lr_0 = 3.6517e-04
Validation auc = 0.873944
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:19&lt;06:11, 23.19s/it]Epoch 14
Loss = 2.3606e-01, PNorm = 36.0327, GNorm = 0.9651, lr_0 = 3.5500e-04
Loss = 2.1234e-01, PNorm = 36.0662, GNorm = 0.8828, lr_0 = 3.4599e-04
Loss = 2.6915e-01, PNorm = 36.0970, GNorm = 1.4575, lr_0 = 3.3721e-04
Validation auc = 0.868701
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:40&lt;05:38, 22.59s/it]Epoch 15
Loss = 3.0209e-01, PNorm = 36.1242, GNorm = 1.8489, lr_0 = 3.2866e-04
Loss = 2.2004e-01, PNorm = 36.1516, GNorm = 0.9104, lr_0 = 3.2032e-04
Loss = 2.0303e-01, PNorm = 36.1804, GNorm = 0.7067, lr_0 = 3.1219e-04
Loss = 2.5464e-01, PNorm = 36.2061, GNorm = 0.9119, lr_0 = 3.0427e-04
Validation auc = 0.876898
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:03&lt;05:19, 22.79s/it]Epoch 16
Loss = 2.1173e-01, PNorm = 36.2318, GNorm = 1.0047, lr_0 = 2.9579e-04
Loss = 2.3335e-01, PNorm = 36.2596, GNorm = 1.0415, lr_0 = 2.8828e-04
Loss = 2.5902e-01, PNorm = 36.2869, GNorm = 0.9950, lr_0 = 2.8097e-04
Validation auc = 0.875209
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:25&lt;04:53, 22.54s/it]Epoch 17
Loss = 1.9664e-01, PNorm = 36.3125, GNorm = 1.1060, lr_0 = 2.7384e-04
Loss = 2.0317e-01, PNorm = 36.3333, GNorm = 2.0615, lr_0 = 2.6689e-04
Loss = 2.3142e-01, PNorm = 36.3524, GNorm = 1.6721, lr_0 = 2.6012e-04
Validation auc = 0.876019
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:46&lt;04:25, 22.09s/it]Epoch 18
Loss = 1.6227e-01, PNorm = 36.3788, GNorm = 0.7457, lr_0 = 2.5352e-04
Loss = 2.0263e-01, PNorm = 36.4048, GNorm = 1.6899, lr_0 = 2.4709e-04
Loss = 1.5962e-01, PNorm = 36.4262, GNorm = 1.3443, lr_0 = 2.4082e-04
Validation auc = 0.874317
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:08&lt;04:01, 21.98s/it]Epoch 19
Loss = 2.8802e-01, PNorm = 36.4475, GNorm = 1.4766, lr_0 = 2.3411e-04
Loss = 2.0611e-01, PNorm = 36.4682, GNorm = 0.6141, lr_0 = 2.2817e-04
Loss = 1.7577e-01, PNorm = 36.4882, GNorm = 1.0868, lr_0 = 2.2238e-04
Loss = 2.1099e-01, PNorm = 36.5076, GNorm = 1.9374, lr_0 = 2.1674e-04
Validation auc = 0.872743
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:30&lt;03:39, 21.90s/it]Epoch 20
Loss = 2.2023e-01, PNorm = 36.5294, GNorm = 0.7959, lr_0 = 2.1124e-04
Loss = 1.7023e-01, PNorm = 36.5468, GNorm = 1.8680, lr_0 = 2.0588e-04
Loss = 2.1346e-01, PNorm = 36.5662, GNorm = 1.5853, lr_0 = 2.0066e-04
Validation auc = 0.876977
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [07:53&lt;03:21, 22.43s/it]Epoch 21
Loss = 1.6756e-01, PNorm = 36.5847, GNorm = 0.5861, lr_0 = 1.9557e-04
Loss = 2.1823e-01, PNorm = 36.6040, GNorm = 1.5526, lr_0 = 1.9060e-04
Loss = 1.6360e-01, PNorm = 36.6209, GNorm = 1.1944, lr_0 = 1.8577e-04
Validation auc = 0.879484
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:20&lt;03:08, 23.59s/it]Epoch 22
Loss = 1.9874e-01, PNorm = 36.6384, GNorm = 1.3396, lr_0 = 1.8059e-04
Loss = 1.5375e-01, PNorm = 36.6547, GNorm = 0.9037, lr_0 = 1.7601e-04
Loss = 1.8212e-01, PNorm = 36.6717, GNorm = 0.6833, lr_0 = 1.7154e-04
Loss = 2.2151e-01, PNorm = 36.6873, GNorm = 1.0785, lr_0 = 1.6719e-04
Validation auc = 0.880958
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:46&lt;02:51, 24.47s/it]Epoch 23
Loss = 1.9193e-01, PNorm = 36.7019, GNorm = 1.5677, lr_0 = 1.6295e-04
Loss = 1.9108e-01, PNorm = 36.7153, GNorm = 1.1084, lr_0 = 1.5882e-04
Loss = 1.5103e-01, PNorm = 36.7265, GNorm = 1.1219, lr_0 = 1.5479e-04
Validation auc = 0.882930
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:14&lt;02:32, 25.36s/it]Epoch 24
Loss = 1.3201e-01, PNorm = 36.7415, GNorm = 0.7428, lr_0 = 1.5047e-04
Loss = 1.8692e-01, PNorm = 36.7554, GNorm = 2.0888, lr_0 = 1.4665e-04
Loss = 1.9702e-01, PNorm = 36.7685, GNorm = 1.5603, lr_0 = 1.4293e-04
Validation auc = 0.880481
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:39&lt;02:06, 25.25s/it]Epoch 25
Loss = 1.1132e-01, PNorm = 36.7826, GNorm = 1.9829, lr_0 = 1.3931e-04
Loss = 1.5786e-01, PNorm = 36.7952, GNorm = 0.5368, lr_0 = 1.3577e-04
Loss = 1.6230e-01, PNorm = 36.8090, GNorm = 0.6102, lr_0 = 1.3233e-04
Validation auc = 0.879268
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [10:00&lt;01:36, 24.15s/it]Epoch 26
Loss = 2.0914e-01, PNorm = 36.8220, GNorm = 0.9017, lr_0 = 1.2897e-04
Loss = 2.0112e-01, PNorm = 36.8320, GNorm = 2.0825, lr_0 = 1.2570e-04
Loss = 1.5139e-01, PNorm = 36.8427, GNorm = 2.4840, lr_0 = 1.2251e-04
Loss = 1.6615e-01, PNorm = 36.8539, GNorm = 2.2876, lr_0 = 1.1940e-04
Loss = 1.4737e-01, PNorm = 36.8552, GNorm = 4.3809, lr_0 = 1.1909e-04
Validation auc = 0.880099
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:23&lt;01:10, 23.64s/it]Epoch 27
Loss = 1.8118e-01, PNorm = 36.8667, GNorm = 0.7281, lr_0 = 1.1607e-04
Loss = 1.6857e-01, PNorm = 36.8781, GNorm = 1.6661, lr_0 = 1.1313e-04
Loss = 1.3214e-01, PNorm = 36.8884, GNorm = 1.2085, lr_0 = 1.1026e-04
Validation auc = 0.878571
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [10:44&lt;00:45, 22.87s/it]Epoch 28
Loss = 1.7943e-01, PNorm = 36.8972, GNorm = 1.5619, lr_0 = 1.0746e-04
Loss = 1.6334e-01, PNorm = 36.9072, GNorm = 0.7111, lr_0 = 1.0473e-04
Loss = 1.4617e-01, PNorm = 36.9182, GNorm = 1.1304, lr_0 = 1.0208e-04
Validation auc = 0.880136
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [11:05&lt;00:22, 22.26s/it]Epoch 29
Loss = 1.4805e-01, PNorm = 36.9280, GNorm = 1.3807, lr_0 = 1.0000e-04
Loss = 1.6974e-01, PNorm = 36.9364, GNorm = 0.6806, lr_0 = 1.0000e-04
Loss = 1.7505e-01, PNorm = 36.9447, GNorm = 1.3101, lr_0 = 1.0000e-04
Validation auc = 0.878255
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:26&lt;00:00, 22.87s/it]
Model 0 best validation auc = 0.882930 on epoch 23
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.876687
Ensemble test auc = 0.876687
Fold 6
Splitting data with seed 6
7807it [00:00, 105404.74it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 199995.92it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 66009.49it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 2258.47it/s]
Total scaffolds = 1,025 | train scaffolds = 833 | val scaffolds = 0 | test scaffolds = 192
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.6182e-01, PNorm = 34.0132, GNorm = 0.6161, lr_0 = 2.5469e-04
Loss = 5.4864e-01, PNorm = 34.0188, GNorm = 0.4329, lr_0 = 3.9531e-04
Loss = 5.0555e-01, PNorm = 34.0376, GNorm = 0.5773, lr_0 = 5.3594e-04
Validation auc = 0.720839
  3%|â–Ž         | 1/30 [00:21&lt;10:13, 21.16s/it]Epoch 1
Loss = 4.5161e-01, PNorm = 34.0805, GNorm = 1.8178, lr_0 = 6.9063e-04
Loss = 4.9292e-01, PNorm = 34.1068, GNorm = 3.3809, lr_0 = 8.3125e-04
Loss = 4.5214e-01, PNorm = 34.1450, GNorm = 0.6624, lr_0 = 9.7187e-04
Validation auc = 0.795613
  7%|â–‹         | 2/30 [00:41&lt;09:43, 20.84s/it]Epoch 2
Loss = 4.6454e-01, PNorm = 34.1995, GNorm = 0.4109, lr_0 = 9.7965e-04
Loss = 3.9795e-01, PNorm = 34.2431, GNorm = 2.3008, lr_0 = 9.5480e-04
Loss = 3.5796e-01, PNorm = 34.2947, GNorm = 1.4976, lr_0 = 9.3057e-04
Validation auc = 0.817488
 10%|â–ˆ         | 3/30 [01:03&lt;09:29, 21.10s/it]Epoch 3
Loss = 4.2133e-01, PNorm = 34.3367, GNorm = 2.0550, lr_0 = 9.0463e-04
Loss = 4.6422e-01, PNorm = 34.3847, GNorm = 0.4307, lr_0 = 8.8168e-04
Loss = 4.3600e-01, PNorm = 34.4464, GNorm = 1.3578, lr_0 = 8.5931e-04
Loss = 3.7713e-01, PNorm = 34.5002, GNorm = 0.3976, lr_0 = 8.3751e-04
Validation auc = 0.814387
 13%|â–ˆâ–Ž        | 4/30 [01:23&lt;08:59, 20.74s/it]Epoch 4
Loss = 3.5375e-01, PNorm = 34.5522, GNorm = 1.5074, lr_0 = 8.1626e-04
Loss = 3.5896e-01, PNorm = 34.5938, GNorm = 0.5127, lr_0 = 7.9555e-04
Loss = 3.8334e-01, PNorm = 34.6308, GNorm = 1.0827, lr_0 = 7.7537e-04
Validation auc = 0.827489
 17%|â–ˆâ–‹        | 5/30 [01:43&lt;08:35, 20.62s/it]Epoch 5
Loss = 3.1088e-01, PNorm = 34.6880, GNorm = 0.9628, lr_0 = 7.5570e-04
Loss = 4.0120e-01, PNorm = 34.7423, GNorm = 0.4730, lr_0 = 7.3653e-04
Loss = 3.4849e-01, PNorm = 34.7869, GNorm = 0.4235, lr_0 = 7.1784e-04
Validation auc = 0.848541
 20%|â–ˆâ–ˆ        | 6/30 [02:04&lt;08:12, 20.52s/it]Epoch 6
Loss = 3.2776e-01, PNorm = 34.8429, GNorm = 2.2564, lr_0 = 6.9783e-04
Loss = 3.5925e-01, PNorm = 34.8844, GNorm = 1.3872, lr_0 = 6.8013e-04
Loss = 3.3250e-01, PNorm = 34.9391, GNorm = 0.3400, lr_0 = 6.6287e-04
Validation auc = 0.846812
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:25&lt;07:55, 20.69s/it]Epoch 7
Loss = 3.3242e-01, PNorm = 34.9893, GNorm = 0.5063, lr_0 = 6.4605e-04
Loss = 2.7401e-01, PNorm = 35.0454, GNorm = 0.8332, lr_0 = 6.2966e-04
Loss = 3.7172e-01, PNorm = 35.0911, GNorm = 0.8606, lr_0 = 6.1369e-04
Loss = 3.2611e-01, PNorm = 35.1325, GNorm = 0.6904, lr_0 = 5.9812e-04
Loss = 2.9493e-01, PNorm = 35.1374, GNorm = 0.4848, lr_0 = 5.9658e-04
Validation auc = 0.854277
 27%|â–ˆâ–ˆâ–‹       | 8/30 [02:45&lt;07:33, 20.61s/it]Epoch 8
Loss = 3.5267e-01, PNorm = 35.1835, GNorm = 0.5040, lr_0 = 5.8145e-04
Loss = 2.9611e-01, PNorm = 35.2405, GNorm = 1.5063, lr_0 = 5.6669e-04
Loss = 2.7431e-01, PNorm = 35.2899, GNorm = 1.9948, lr_0 = 5.5232e-04
Validation auc = 0.848035
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:05&lt;07:09, 20.46s/it]Epoch 9
Loss = 3.3042e-01, PNorm = 35.3289, GNorm = 0.5380, lr_0 = 5.3830e-04
Loss = 3.1613e-01, PNorm = 35.3795, GNorm = 1.5997, lr_0 = 5.2465e-04
Loss = 3.1015e-01, PNorm = 35.4274, GNorm = 0.5534, lr_0 = 5.1133e-04
Validation auc = 0.867727
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:27&lt;06:54, 20.75s/it]Epoch 10
Loss = 2.6779e-01, PNorm = 35.4678, GNorm = 0.4061, lr_0 = 4.9836e-04
Loss = 2.7977e-01, PNorm = 35.5126, GNorm = 1.1212, lr_0 = 4.8572e-04
Loss = 3.2023e-01, PNorm = 35.5553, GNorm = 1.8822, lr_0 = 4.7339e-04
Validation auc = 0.864423
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:47&lt;06:30, 20.57s/it]Epoch 11
Loss = 3.2623e-01, PNorm = 35.5952, GNorm = 1.3172, lr_0 = 4.6020e-04
Loss = 2.6594e-01, PNorm = 35.6291, GNorm = 0.8160, lr_0 = 4.4852e-04
Loss = 2.7306e-01, PNorm = 35.6642, GNorm = 2.5083, lr_0 = 4.3714e-04
Loss = 2.7640e-01, PNorm = 35.7069, GNorm = 1.2440, lr_0 = 4.2605e-04
Validation auc = 0.867787
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:07&lt;06:10, 20.57s/it]Epoch 12
Loss = 2.8383e-01, PNorm = 35.7498, GNorm = 0.6595, lr_0 = 4.1524e-04
Loss = 2.6669e-01, PNorm = 35.7861, GNorm = 0.6838, lr_0 = 4.0471e-04
Loss = 2.6751e-01, PNorm = 35.8190, GNorm = 1.5112, lr_0 = 3.9444e-04
Validation auc = 0.872715
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:29&lt;05:57, 21.04s/it]Epoch 13
Loss = 2.4573e-01, PNorm = 35.8542, GNorm = 0.9518, lr_0 = 3.8443e-04
Loss = 2.5258e-01, PNorm = 35.8918, GNorm = 0.7385, lr_0 = 3.7468e-04
Loss = 2.7146e-01, PNorm = 35.9213, GNorm = 0.7374, lr_0 = 3.6517e-04
Validation auc = 0.869090
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [04:50&lt;05:33, 20.85s/it]Epoch 14
Loss = 2.2748e-01, PNorm = 35.9547, GNorm = 0.9609, lr_0 = 3.5500e-04
Loss = 2.0082e-01, PNorm = 35.9866, GNorm = 0.9581, lr_0 = 3.4599e-04
Loss = 2.7723e-01, PNorm = 36.0187, GNorm = 0.5026, lr_0 = 3.3721e-04
Validation auc = 0.868104
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:11&lt;05:13, 20.92s/it]Epoch 15
Loss = 3.0154e-01, PNorm = 36.0463, GNorm = 1.4333, lr_0 = 3.2866e-04
Loss = 2.7512e-01, PNorm = 36.0731, GNorm = 1.4761, lr_0 = 3.2032e-04
Loss = 2.2682e-01, PNorm = 36.0994, GNorm = 0.5695, lr_0 = 3.1219e-04
Loss = 2.1509e-01, PNorm = 36.1298, GNorm = 1.5742, lr_0 = 3.0427e-04
Validation auc = 0.875658
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [05:34&lt;05:03, 21.65s/it]Epoch 16
Loss = 2.4645e-01, PNorm = 36.1587, GNorm = 1.4000, lr_0 = 2.9579e-04
Loss = 2.1079e-01, PNorm = 36.1864, GNorm = 0.7697, lr_0 = 2.8828e-04
Loss = 2.3936e-01, PNorm = 36.2159, GNorm = 1.7381, lr_0 = 2.8097e-04
Validation auc = 0.876264
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [05:56&lt;04:41, 21.64s/it]Epoch 17
Loss = 1.7706e-01, PNorm = 36.2408, GNorm = 1.4449, lr_0 = 2.7384e-04
Loss = 2.6606e-01, PNorm = 36.2667, GNorm = 1.2493, lr_0 = 2.6689e-04
Loss = 2.3528e-01, PNorm = 36.2863, GNorm = 0.5351, lr_0 = 2.6012e-04
Validation auc = 0.877279
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:18&lt;04:21, 21.78s/it]Epoch 18
Loss = 2.2911e-01, PNorm = 36.3074, GNorm = 0.8576, lr_0 = 2.5352e-04
Loss = 2.5532e-01, PNorm = 36.3298, GNorm = 1.3049, lr_0 = 2.4709e-04
Loss = 2.0325e-01, PNorm = 36.3527, GNorm = 0.7950, lr_0 = 2.4082e-04
Validation auc = 0.881196
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [06:40&lt;04:00, 21.90s/it]Epoch 19
Loss = 1.6380e-01, PNorm = 36.3749, GNorm = 1.2393, lr_0 = 2.3411e-04
Loss = 2.4719e-01, PNorm = 36.3915, GNorm = 1.5367, lr_0 = 2.2817e-04
Loss = 1.7361e-01, PNorm = 36.4108, GNorm = 1.9581, lr_0 = 2.2238e-04
Loss = 2.2462e-01, PNorm = 36.4303, GNorm = 1.4962, lr_0 = 2.1674e-04
Validation auc = 0.875450
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:02&lt;03:38, 21.86s/it]Epoch 20
Loss = 1.9001e-01, PNorm = 36.4510, GNorm = 0.9956, lr_0 = 2.1124e-04
Loss = 2.1640e-01, PNorm = 36.4719, GNorm = 1.4993, lr_0 = 2.0588e-04
Loss = 1.8828e-01, PNorm = 36.4908, GNorm = 0.7877, lr_0 = 2.0066e-04
Validation auc = 0.881552
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [07:23&lt;03:13, 21.52s/it]Epoch 21
Loss = 2.0541e-01, PNorm = 36.5054, GNorm = 1.2624, lr_0 = 1.9557e-04
Loss = 1.9978e-01, PNorm = 36.5225, GNorm = 0.9034, lr_0 = 1.9060e-04
Loss = 1.7407e-01, PNorm = 36.5379, GNorm = 1.3351, lr_0 = 1.8577e-04
Validation auc = 0.877829
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [07:44&lt;02:50, 21.37s/it]Epoch 22
Loss = 1.7511e-01, PNorm = 36.5563, GNorm = 0.8774, lr_0 = 1.8059e-04
Loss = 1.5307e-01, PNorm = 36.5738, GNorm = 2.4033, lr_0 = 1.7601e-04
Loss = 2.4618e-01, PNorm = 36.5901, GNorm = 1.7060, lr_0 = 1.7154e-04
Loss = 1.7840e-01, PNorm = 36.6022, GNorm = 1.0139, lr_0 = 1.6719e-04
Validation auc = 0.878885
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:05&lt;02:29, 21.30s/it]Epoch 23
Loss = 1.7602e-01, PNorm = 36.6166, GNorm = 2.6906, lr_0 = 1.6295e-04
Loss = 2.1315e-01, PNorm = 36.6297, GNorm = 3.1348, lr_0 = 1.5882e-04
Loss = 1.9032e-01, PNorm = 36.6446, GNorm = 1.4982, lr_0 = 1.5479e-04
Validation auc = 0.871594
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [08:27&lt;02:09, 21.52s/it]Epoch 24
Loss = 2.0369e-01, PNorm = 36.6579, GNorm = 2.8376, lr_0 = 1.5047e-04
Loss = 2.0615e-01, PNorm = 36.6703, GNorm = 1.4416, lr_0 = 1.4665e-04
Loss = 2.0013e-01, PNorm = 36.6799, GNorm = 0.9871, lr_0 = 1.4293e-04
Validation auc = 0.876537
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [08:47&lt;01:45, 21.13s/it]Epoch 25
Loss = 2.0016e-01, PNorm = 36.6933, GNorm = 2.2319, lr_0 = 1.3931e-04
Loss = 1.6291e-01, PNorm = 36.7061, GNorm = 0.7980, lr_0 = 1.3577e-04
Loss = 2.0881e-01, PNorm = 36.7186, GNorm = 1.1770, lr_0 = 1.3233e-04
Validation auc = 0.878787
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [09:09&lt;01:25, 21.26s/it]Epoch 26
Loss = 2.2723e-01, PNorm = 36.7291, GNorm = 1.8979, lr_0 = 1.2897e-04
Loss = 1.6891e-01, PNorm = 36.7399, GNorm = 0.9638, lr_0 = 1.2570e-04
Loss = 1.4573e-01, PNorm = 36.7516, GNorm = 1.4638, lr_0 = 1.2251e-04
Loss = 2.0396e-01, PNorm = 36.7623, GNorm = 1.6277, lr_0 = 1.1940e-04
Loss = 1.6013e-01, PNorm = 36.7631, GNorm = 2.0542, lr_0 = 1.1909e-04
Validation auc = 0.880557
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [09:30&lt;01:04, 21.37s/it]Epoch 27
Loss = 1.8082e-01, PNorm = 36.7736, GNorm = 1.5187, lr_0 = 1.1607e-04
Loss = 1.5974e-01, PNorm = 36.7825, GNorm = 0.9081, lr_0 = 1.1313e-04
Loss = 2.1324e-01, PNorm = 36.7908, GNorm = 1.2305, lr_0 = 1.1026e-04
Validation auc = 0.881096
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [09:51&lt;00:42, 21.08s/it]Epoch 28
Loss = 1.9306e-01, PNorm = 36.7998, GNorm = 1.4380, lr_0 = 1.0746e-04
Loss = 1.7735e-01, PNorm = 36.8071, GNorm = 2.7694, lr_0 = 1.0473e-04
Loss = 1.5423e-01, PNorm = 36.8164, GNorm = 1.1709, lr_0 = 1.0208e-04
Validation auc = 0.881583
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [10:11&lt;00:20, 20.95s/it]Epoch 29
Loss = 1.5280e-01, PNorm = 36.8263, GNorm = 1.7311, lr_0 = 1.0000e-04
Loss = 1.2902e-01, PNorm = 36.8350, GNorm = 1.4067, lr_0 = 1.0000e-04
Loss = 2.0477e-01, PNorm = 36.8446, GNorm = 1.5457, lr_0 = 1.0000e-04
Validation auc = 0.876813
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [10:33&lt;00:00, 21.12s/it]
Model 0 best validation auc = 0.881583 on epoch 28
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.906706
Ensemble test auc = 0.906706
Fold 7
Splitting data with seed 7
7807it [00:00, 113042.58it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 177270.81it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 70908.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 2455.84it/s]
Total scaffolds = 1,025 | train scaffolds = 863 | val scaffolds = 0 | test scaffolds = 162
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.9673e-01, PNorm = 34.0126, GNorm = 1.5348, lr_0 = 2.5469e-04
Loss = 4.9817e-01, PNorm = 34.0187, GNorm = 0.5062, lr_0 = 3.9531e-04
Loss = 4.7747e-01, PNorm = 34.0412, GNorm = 0.5017, lr_0 = 5.3594e-04
Validation auc = 0.755383
  3%|â–Ž         | 1/30 [00:21&lt;10:35, 21.92s/it]Epoch 1
Loss = 4.2505e-01, PNorm = 34.0760, GNorm = 0.6224, lr_0 = 6.9063e-04
Loss = 4.4959e-01, PNorm = 34.1135, GNorm = 1.4844, lr_0 = 8.3125e-04
Loss = 4.3547e-01, PNorm = 34.1558, GNorm = 1.4239, lr_0 = 9.7187e-04
Validation auc = 0.795760
  7%|â–‹         | 2/30 [00:43&lt;10:08, 21.75s/it]Epoch 2
Loss = 3.7337e-01, PNorm = 34.2097, GNorm = 3.4275, lr_0 = 9.7965e-04
Loss = 4.2502e-01, PNorm = 34.2627, GNorm = 0.5118, lr_0 = 9.5480e-04
Loss = 3.8550e-01, PNorm = 34.3194, GNorm = 0.9283, lr_0 = 9.3057e-04
Validation auc = 0.815194
 10%|â–ˆ         | 3/30 [01:04&lt;09:33, 21.25s/it]Epoch 3
Loss = 4.2547e-01, PNorm = 34.3732, GNorm = 1.1318, lr_0 = 9.0463e-04
Loss = 3.7796e-01, PNorm = 34.4303, GNorm = 1.2964, lr_0 = 8.8168e-04
Loss = 3.7880e-01, PNorm = 34.4900, GNorm = 0.8707, lr_0 = 8.5931e-04
Loss = 4.1805e-01, PNorm = 34.5363, GNorm = 1.7581, lr_0 = 8.3751e-04
Validation auc = 0.832049
 13%|â–ˆâ–Ž        | 4/30 [01:24&lt;09:05, 20.97s/it]Epoch 4
Loss = 3.8877e-01, PNorm = 34.5793, GNorm = 1.3541, lr_0 = 8.1626e-04
Loss = 3.3638e-01, PNorm = 34.6436, GNorm = 0.3741, lr_0 = 7.9555e-04
Loss = 3.2092e-01, PNorm = 34.6966, GNorm = 0.3562, lr_0 = 7.7537e-04
Validation auc = 0.814380
 17%|â–ˆâ–‹        | 5/30 [01:45&lt;08:39, 20.79s/it]Epoch 5
Loss = 3.5278e-01, PNorm = 34.7368, GNorm = 0.6656, lr_0 = 7.5570e-04
Loss = 3.2812e-01, PNorm = 34.7910, GNorm = 1.0830, lr_0 = 7.3653e-04
Loss = 3.5939e-01, PNorm = 34.8453, GNorm = 0.6897, lr_0 = 7.1784e-04
Validation auc = 0.846920
 20%|â–ˆâ–ˆ        | 6/30 [02:06&lt;08:22, 20.94s/it]Epoch 6
Loss = 3.1876e-01, PNorm = 34.9135, GNorm = 0.9794, lr_0 = 6.9783e-04
Loss = 3.0256e-01, PNorm = 34.9680, GNorm = 1.3468, lr_0 = 6.8013e-04
Loss = 3.1646e-01, PNorm = 35.0206, GNorm = 1.1073, lr_0 = 6.6287e-04
Validation auc = 0.854253
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:26&lt;07:57, 20.75s/it]Epoch 7
Loss = 2.7953e-01, PNorm = 35.0653, GNorm = 2.3032, lr_0 = 6.4605e-04
Loss = 3.2105e-01, PNorm = 35.1171, GNorm = 2.0512, lr_0 = 6.2966e-04
Loss = 3.0641e-01, PNorm = 35.1748, GNorm = 2.5586, lr_0 = 6.1369e-04
Loss = 3.7268e-01, PNorm = 35.2264, GNorm = 3.6927, lr_0 = 5.9812e-04
Loss = 4.5915e-01, PNorm = 35.2303, GNorm = 2.7772, lr_0 = 5.9658e-04
Validation auc = 0.855636
 27%|â–ˆâ–ˆâ–‹       | 8/30 [02:48&lt;07:39, 20.90s/it]Epoch 8
Loss = 3.4779e-01, PNorm = 35.2787, GNorm = 0.5849, lr_0 = 5.8145e-04
Loss = 3.4322e-01, PNorm = 35.3278, GNorm = 1.4557, lr_0 = 5.6669e-04
Loss = 2.9223e-01, PNorm = 35.3803, GNorm = 0.3259, lr_0 = 5.5232e-04
Validation auc = 0.857801
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:10&lt;07:27, 21.32s/it]Epoch 9
Loss = 3.3487e-01, PNorm = 35.4334, GNorm = 0.9138, lr_0 = 5.3830e-04
Loss = 2.4880e-01, PNorm = 35.4801, GNorm = 0.7187, lr_0 = 5.2465e-04
Loss = 2.8323e-01, PNorm = 35.5223, GNorm = 0.5790, lr_0 = 5.1133e-04
Validation auc = 0.863790
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:32&lt;07:09, 21.46s/it]Epoch 10
Loss = 2.5531e-01, PNorm = 35.5586, GNorm = 0.9180, lr_0 = 4.9836e-04
Loss = 2.7229e-01, PNorm = 35.5990, GNorm = 0.8368, lr_0 = 4.8572e-04
Loss = 3.0928e-01, PNorm = 35.6383, GNorm = 0.6118, lr_0 = 4.7339e-04
Validation auc = 0.867484
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:54&lt;06:53, 21.76s/it]Epoch 11
Loss = 3.7548e-01, PNorm = 35.6842, GNorm = 1.6515, lr_0 = 4.6020e-04
Loss = 2.4339e-01, PNorm = 35.7264, GNorm = 0.6287, lr_0 = 4.4852e-04
Loss = 3.0924e-01, PNorm = 35.7685, GNorm = 2.4178, lr_0 = 4.3714e-04
Loss = 2.9903e-01, PNorm = 35.8038, GNorm = 1.5291, lr_0 = 4.2605e-04
Validation auc = 0.867790
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:18&lt;06:42, 22.36s/it]Epoch 12
Loss = 2.5767e-01, PNorm = 35.8390, GNorm = 0.5539, lr_0 = 4.1524e-04
Loss = 2.7974e-01, PNorm = 35.8753, GNorm = 1.0584, lr_0 = 4.0471e-04
Loss = 2.9305e-01, PNorm = 35.9113, GNorm = 1.8703, lr_0 = 3.9444e-04
Validation auc = 0.872165
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:41&lt;06:25, 22.70s/it]Epoch 13
Loss = 2.6109e-01, PNorm = 35.9422, GNorm = 1.6873, lr_0 = 3.8443e-04
Loss = 2.4154e-01, PNorm = 35.9808, GNorm = 0.8882, lr_0 = 3.7468e-04
Loss = 2.8830e-01, PNorm = 36.0182, GNorm = 0.8957, lr_0 = 3.6517e-04
Validation auc = 0.867917
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:05&lt;06:09, 23.11s/it]Epoch 14
Loss = 2.1272e-01, PNorm = 36.0542, GNorm = 1.6273, lr_0 = 3.5500e-04
Loss = 2.5678e-01, PNorm = 36.0900, GNorm = 0.5082, lr_0 = 3.4599e-04
Loss = 2.4599e-01, PNorm = 36.1204, GNorm = 1.5795, lr_0 = 3.3721e-04
Validation auc = 0.869381
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:31&lt;05:58, 23.87s/it]Epoch 15
Loss = 3.2694e-01, PNorm = 36.1468, GNorm = 0.9686, lr_0 = 3.2866e-04
Loss = 2.5300e-01, PNorm = 36.1784, GNorm = 1.2536, lr_0 = 3.2032e-04
Loss = 2.2225e-01, PNorm = 36.2105, GNorm = 0.8472, lr_0 = 3.1219e-04
Loss = 2.5585e-01, PNorm = 36.2379, GNorm = 0.7422, lr_0 = 3.0427e-04
Validation auc = 0.875142
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [05:54&lt;05:32, 23.72s/it]Epoch 16
Loss = 1.9838e-01, PNorm = 36.2736, GNorm = 1.8348, lr_0 = 2.9579e-04
Loss = 2.7353e-01, PNorm = 36.2984, GNorm = 3.2385, lr_0 = 2.8828e-04
Loss = 2.2603e-01, PNorm = 36.3175, GNorm = 1.1745, lr_0 = 2.8097e-04
Validation auc = 0.876805
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:19&lt;05:10, 23.90s/it]Epoch 17
Loss = 1.8614e-01, PNorm = 36.3490, GNorm = 0.6584, lr_0 = 2.7384e-04
Loss = 2.1150e-01, PNorm = 36.3826, GNorm = 0.5984, lr_0 = 2.6689e-04
Loss = 2.4958e-01, PNorm = 36.4098, GNorm = 1.3179, lr_0 = 2.6012e-04
Validation auc = 0.876469
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:43&lt;04:49, 24.11s/it]Epoch 18
Loss = 2.3328e-01, PNorm = 36.4302, GNorm = 1.6945, lr_0 = 2.5352e-04
Loss = 1.9636e-01, PNorm = 36.4565, GNorm = 2.4367, lr_0 = 2.4709e-04
Loss = 2.3666e-01, PNorm = 36.4837, GNorm = 1.1126, lr_0 = 2.4082e-04
Validation auc = 0.874926
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:07&lt;04:25, 24.11s/it]Epoch 19
Loss = 2.0342e-01, PNorm = 36.5117, GNorm = 0.5979, lr_0 = 2.3411e-04
Loss = 2.1825e-01, PNorm = 36.5342, GNorm = 1.6542, lr_0 = 2.2817e-04
Loss = 2.0701e-01, PNorm = 36.5546, GNorm = 0.8762, lr_0 = 2.2238e-04
Loss = 2.1182e-01, PNorm = 36.5790, GNorm = 0.7950, lr_0 = 2.1674e-04
Validation auc = 0.875871
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:30&lt;03:56, 23.63s/it]Epoch 20
Loss = 2.1835e-01, PNorm = 36.6005, GNorm = 1.2816, lr_0 = 2.1124e-04
Loss = 1.8984e-01, PNorm = 36.6232, GNorm = 2.6008, lr_0 = 2.0588e-04
Loss = 2.3389e-01, PNorm = 36.6454, GNorm = 0.9049, lr_0 = 2.0066e-04
Validation auc = 0.877689
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [07:53&lt;03:32, 23.63s/it]Epoch 21
Loss = 2.2350e-01, PNorm = 36.6651, GNorm = 1.5218, lr_0 = 1.9557e-04
Loss = 2.0463e-01, PNorm = 36.6865, GNorm = 1.1106, lr_0 = 1.9060e-04
Loss = 2.1103e-01, PNorm = 36.7023, GNorm = 1.3653, lr_0 = 1.8577e-04
Validation auc = 0.879357
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:17&lt;03:07, 23.48s/it]Epoch 22
Loss = 1.7427e-01, PNorm = 36.7236, GNorm = 0.8589, lr_0 = 1.8059e-04
Loss = 2.2984e-01, PNorm = 36.7431, GNorm = 1.3823, lr_0 = 1.7601e-04
Loss = 1.7259e-01, PNorm = 36.7599, GNorm = 1.1141, lr_0 = 1.7154e-04
Loss = 2.1782e-01, PNorm = 36.7752, GNorm = 2.2384, lr_0 = 1.6719e-04
Validation auc = 0.880634
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:40&lt;02:45, 23.58s/it]Epoch 23
Loss = 2.1012e-01, PNorm = 36.7903, GNorm = 1.9463, lr_0 = 1.6295e-04
Loss = 1.9743e-01, PNorm = 36.8055, GNorm = 2.6711, lr_0 = 1.5882e-04
Loss = 1.9569e-01, PNorm = 36.8225, GNorm = 0.8472, lr_0 = 1.5479e-04
Validation auc = 0.876119
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:06&lt;02:24, 24.07s/it]Epoch 24
Loss = 1.6951e-01, PNorm = 36.8384, GNorm = 1.3965, lr_0 = 1.5047e-04
Loss = 2.0458e-01, PNorm = 36.8530, GNorm = 1.4777, lr_0 = 1.4665e-04
Loss = 2.1188e-01, PNorm = 36.8657, GNorm = 1.2790, lr_0 = 1.4293e-04
Validation auc = 0.880178
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:30&lt;02:01, 24.26s/it]Epoch 25
Loss = 1.9248e-01, PNorm = 36.8803, GNorm = 1.0131, lr_0 = 1.3931e-04
Loss = 1.6660e-01, PNorm = 36.8954, GNorm = 1.3230, lr_0 = 1.3577e-04
Loss = 2.0059e-01, PNorm = 36.9087, GNorm = 0.5384, lr_0 = 1.3233e-04
Validation auc = 0.877855
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [09:55&lt;01:38, 24.52s/it]Epoch 26
Loss = 8.8095e-02, PNorm = 36.9205, GNorm = 0.8437, lr_0 = 1.2897e-04
Loss = 2.1412e-01, PNorm = 36.9334, GNorm = 1.1261, lr_0 = 1.2570e-04
Loss = 1.9582e-01, PNorm = 36.9453, GNorm = 1.5304, lr_0 = 1.2251e-04
Loss = 1.9293e-01, PNorm = 36.9564, GNorm = 0.7216, lr_0 = 1.1940e-04
Loss = 1.0425e-01, PNorm = 36.9574, GNorm = 0.8109, lr_0 = 1.1909e-04
Validation auc = 0.880129
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:19&lt;01:12, 24.25s/it]Epoch 27
Loss = 1.5074e-01, PNorm = 36.9704, GNorm = 1.0898, lr_0 = 1.1607e-04
Loss = 2.0373e-01, PNorm = 36.9809, GNorm = 1.8491, lr_0 = 1.1313e-04
Loss = 1.7781e-01, PNorm = 36.9917, GNorm = 0.7160, lr_0 = 1.1026e-04
Validation auc = 0.880636
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [10:45&lt;00:49, 24.80s/it]Epoch 28
Loss = 1.6330e-01, PNorm = 37.0031, GNorm = 1.8308, lr_0 = 1.0746e-04
Loss = 1.9872e-01, PNorm = 37.0131, GNorm = 1.0970, lr_0 = 1.0473e-04
Loss = 1.8052e-01, PNorm = 37.0237, GNorm = 2.1910, lr_0 = 1.0208e-04
Validation auc = 0.882866
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [11:10&lt;00:24, 24.71s/it]Epoch 29
Loss = 1.5836e-01, PNorm = 37.0338, GNorm = 1.0602, lr_0 = 1.0000e-04
Loss = 1.5969e-01, PNorm = 37.0432, GNorm = 0.8004, lr_0 = 1.0000e-04
Loss = 1.7776e-01, PNorm = 37.0536, GNorm = 1.9000, lr_0 = 1.0000e-04
Validation auc = 0.880424
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:35&lt;00:00, 23.19s/it]
Model 0 best validation auc = 0.882866 on epoch 28
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.897564
Ensemble test auc = 0.897564
Fold 8
Splitting data with seed 8
7807it [00:00, 103998.71it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 132200.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 65545.84it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:01&lt;00:00, 1973.98it/s]
Total scaffolds = 1,025 | train scaffolds = 840 | val scaffolds = 0 | test scaffolds = 185
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.8649e-01, PNorm = 34.0131, GNorm = 0.7064, lr_0 = 2.5469e-04
Loss = 5.4676e-01, PNorm = 34.0175, GNorm = 0.6914, lr_0 = 3.9531e-04
Loss = 5.1271e-01, PNorm = 34.0337, GNorm = 1.0100, lr_0 = 5.3594e-04
Validation auc = 0.734512
  3%|â–Ž         | 1/30 [00:25&lt;12:24, 25.66s/it]Epoch 1
Loss = 4.5022e-01, PNorm = 34.0646, GNorm = 0.2913, lr_0 = 6.9063e-04
Loss = 5.3064e-01, PNorm = 34.1029, GNorm = 0.4107, lr_0 = 8.3125e-04
Loss = 4.2082e-01, PNorm = 34.1675, GNorm = 0.4234, lr_0 = 9.7187e-04
Validation auc = 0.799223
  7%|â–‹         | 2/30 [00:49&lt;11:21, 24.34s/it]Epoch 2
Loss = 4.9131e-01, PNorm = 34.2294, GNorm = 3.6234, lr_0 = 9.7965e-04
Loss = 4.3415e-01, PNorm = 34.2835, GNorm = 1.6113, lr_0 = 9.5480e-04
Loss = 4.2086e-01, PNorm = 34.3419, GNorm = 0.5353, lr_0 = 9.3057e-04
Validation auc = 0.811972
 10%|â–ˆ         | 3/30 [01:11&lt;10:33, 23.46s/it]Epoch 3
Loss = 3.2139e-01, PNorm = 34.4167, GNorm = 1.3411, lr_0 = 9.0463e-04
Loss = 3.5758e-01, PNorm = 34.4715, GNorm = 0.6067, lr_0 = 8.8168e-04
Loss = 4.4127e-01, PNorm = 34.5163, GNorm = 0.3850, lr_0 = 8.5931e-04
Loss = 3.9899e-01, PNorm = 34.5728, GNorm = 1.0117, lr_0 = 8.3751e-04
Validation auc = 0.824736
 13%|â–ˆâ–Ž        | 4/30 [01:34&lt;10:04, 23.25s/it]Epoch 4
Loss = 3.6112e-01, PNorm = 34.6351, GNorm = 0.3311, lr_0 = 8.1626e-04
Loss = 3.8032e-01, PNorm = 34.6835, GNorm = 0.7118, lr_0 = 7.9555e-04
Loss = 3.5960e-01, PNorm = 34.7333, GNorm = 0.5180, lr_0 = 7.7537e-04
Validation auc = 0.814832
 17%|â–ˆâ–‹        | 5/30 [01:57&lt;09:38, 23.14s/it]Epoch 5
Loss = 3.7811e-01, PNorm = 34.7901, GNorm = 0.4220, lr_0 = 7.5570e-04
Loss = 3.2375e-01, PNorm = 34.8457, GNorm = 0.3401, lr_0 = 7.3653e-04
Loss = 3.4894e-01, PNorm = 34.9037, GNorm = 0.3493, lr_0 = 7.1784e-04
Validation auc = 0.835459
 20%|â–ˆâ–ˆ        | 6/30 [02:20&lt;09:16, 23.20s/it]Epoch 6
Loss = 3.3213e-01, PNorm = 34.9734, GNorm = 0.4705, lr_0 = 6.9783e-04
Loss = 3.0268e-01, PNorm = 35.0354, GNorm = 0.6496, lr_0 = 6.8013e-04
Loss = 3.3222e-01, PNorm = 35.0953, GNorm = 0.4395, lr_0 = 6.6287e-04
Validation auc = 0.846089
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:44&lt;08:57, 23.38s/it]Epoch 7
Loss = 3.1684e-01, PNorm = 35.1481, GNorm = 0.3060, lr_0 = 6.4605e-04
Loss = 2.9548e-01, PNorm = 35.2107, GNorm = 0.6182, lr_0 = 6.2966e-04
Loss = 3.2000e-01, PNorm = 35.2648, GNorm = 1.1350, lr_0 = 6.1369e-04
Loss = 3.2855e-01, PNorm = 35.3141, GNorm = 1.7529, lr_0 = 5.9812e-04
Loss = 2.5370e-01, PNorm = 35.3196, GNorm = 0.6291, lr_0 = 5.9658e-04
Validation auc = 0.844342
 27%|â–ˆâ–ˆâ–‹       | 8/30 [03:06&lt;08:25, 22.97s/it]Epoch 8
Loss = 3.0773e-01, PNorm = 35.3746, GNorm = 0.6402, lr_0 = 5.8145e-04
Loss = 2.9196e-01, PNorm = 35.4290, GNorm = 1.5832, lr_0 = 5.6669e-04
Loss = 3.1052e-01, PNorm = 35.4759, GNorm = 1.6844, lr_0 = 5.5232e-04
Validation auc = 0.855234
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:30&lt;08:09, 23.32s/it]Epoch 9
Loss = 2.7800e-01, PNorm = 35.5202, GNorm = 1.4366, lr_0 = 5.3830e-04
Loss = 2.7946e-01, PNorm = 35.5743, GNorm = 0.9622, lr_0 = 5.2465e-04
Loss = 3.1169e-01, PNorm = 35.6304, GNorm = 1.8932, lr_0 = 5.1133e-04
Validation auc = 0.863928
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:54&lt;07:49, 23.46s/it]Epoch 10
Loss = 2.5310e-01, PNorm = 35.6694, GNorm = 0.6531, lr_0 = 4.9836e-04
Loss = 2.6976e-01, PNorm = 35.7218, GNorm = 0.8412, lr_0 = 4.8572e-04
Loss = 2.5824e-01, PNorm = 35.7754, GNorm = 1.0941, lr_0 = 4.7339e-04
Validation auc = 0.859331
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [04:17&lt;07:22, 23.30s/it]Epoch 11
Loss = 2.7343e-01, PNorm = 35.8134, GNorm = 0.7610, lr_0 = 4.6020e-04
Loss = 2.4235e-01, PNorm = 35.8557, GNorm = 0.8548, lr_0 = 4.4852e-04
Loss = 3.1253e-01, PNorm = 35.8929, GNorm = 0.4618, lr_0 = 4.3714e-04
Loss = 2.8434e-01, PNorm = 35.9287, GNorm = 0.6328, lr_0 = 4.2605e-04
Validation auc = 0.857417
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:39&lt;06:52, 22.89s/it]Epoch 12
Loss = 2.6903e-01, PNorm = 35.9740, GNorm = 0.7112, lr_0 = 4.1524e-04
Loss = 2.3436e-01, PNorm = 36.0131, GNorm = 1.8073, lr_0 = 4.0471e-04
Loss = 2.7593e-01, PNorm = 36.0518, GNorm = 1.3064, lr_0 = 3.9444e-04
Validation auc = 0.858900
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [05:01&lt;06:26, 22.73s/it]Epoch 13
Loss = 2.4428e-01, PNorm = 36.0851, GNorm = 2.4298, lr_0 = 3.8443e-04
Loss = 2.6900e-01, PNorm = 36.1198, GNorm = 0.5732, lr_0 = 3.7468e-04
Loss = 2.6997e-01, PNorm = 36.1496, GNorm = 0.9713, lr_0 = 3.6517e-04
Validation auc = 0.859750
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:24&lt;06:05, 22.86s/it]Epoch 14
Loss = 2.2789e-01, PNorm = 36.1912, GNorm = 1.6291, lr_0 = 3.5500e-04
Loss = 2.4061e-01, PNorm = 36.2352, GNorm = 0.7153, lr_0 = 3.4599e-04
Loss = 2.3716e-01, PNorm = 36.2668, GNorm = 0.7406, lr_0 = 3.3721e-04
Validation auc = 0.869236
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:46&lt;05:39, 22.63s/it]Epoch 15
Loss = 2.6546e-01, PNorm = 36.2957, GNorm = 1.5526, lr_0 = 3.2866e-04
Loss = 2.3108e-01, PNorm = 36.3296, GNorm = 0.9983, lr_0 = 3.2032e-04
Loss = 2.2666e-01, PNorm = 36.3640, GNorm = 1.0721, lr_0 = 3.1219e-04
Loss = 2.1325e-01, PNorm = 36.3973, GNorm = 1.2604, lr_0 = 3.0427e-04
Validation auc = 0.867841
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:10&lt;05:20, 22.91s/it]Epoch 16
Loss = 1.8263e-01, PNorm = 36.4279, GNorm = 0.5923, lr_0 = 2.9579e-04
Loss = 2.4053e-01, PNorm = 36.4532, GNorm = 0.9292, lr_0 = 2.8828e-04
Loss = 2.3996e-01, PNorm = 36.4802, GNorm = 1.2285, lr_0 = 2.8097e-04
Validation auc = 0.871301
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:34&lt;05:04, 23.40s/it]Epoch 17
Loss = 2.0343e-01, PNorm = 36.5121, GNorm = 0.7900, lr_0 = 2.7384e-04
Loss = 1.5995e-01, PNorm = 36.5461, GNorm = 0.5904, lr_0 = 2.6689e-04
Loss = 2.3919e-01, PNorm = 36.5722, GNorm = 2.0980, lr_0 = 2.6012e-04
Validation auc = 0.864505
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:57&lt;04:36, 23.07s/it]Epoch 18
Loss = 1.8148e-01, PNorm = 36.5922, GNorm = 1.5846, lr_0 = 2.5352e-04
Loss = 2.5366e-01, PNorm = 36.6149, GNorm = 0.7508, lr_0 = 2.4709e-04
Loss = 2.2465e-01, PNorm = 36.6443, GNorm = 0.6522, lr_0 = 2.4082e-04
Validation auc = 0.869615
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:20&lt;04:13, 23.02s/it]Epoch 19
Loss = 2.4635e-01, PNorm = 36.6733, GNorm = 1.3489, lr_0 = 2.3411e-04
Loss = 2.3557e-01, PNorm = 36.6984, GNorm = 1.1359, lr_0 = 2.2817e-04
Loss = 1.6692e-01, PNorm = 36.7249, GNorm = 0.8156, lr_0 = 2.2238e-04
Loss = 2.0582e-01, PNorm = 36.7497, GNorm = 0.7859, lr_0 = 2.1674e-04
Validation auc = 0.870811
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:43&lt;03:50, 23.03s/it]Epoch 20
Loss = 2.3595e-01, PNorm = 36.7687, GNorm = 2.1405, lr_0 = 2.1124e-04
Loss = 1.6743e-01, PNorm = 36.7912, GNorm = 1.8271, lr_0 = 2.0588e-04
Loss = 2.0801e-01, PNorm = 36.8151, GNorm = 1.2116, lr_0 = 2.0066e-04
Validation auc = 0.875582
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [08:07&lt;03:31, 23.47s/it]Epoch 21
Loss = 1.6087e-01, PNorm = 36.8302, GNorm = 1.2805, lr_0 = 1.9557e-04
Loss = 2.2082e-01, PNorm = 36.8504, GNorm = 0.8873, lr_0 = 1.9060e-04
Loss = 1.8606e-01, PNorm = 36.8717, GNorm = 0.7627, lr_0 = 1.8577e-04
Validation auc = 0.877031
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:30&lt;03:04, 23.11s/it]Epoch 22
Loss = 2.2158e-01, PNorm = 36.8915, GNorm = 2.4453, lr_0 = 1.8059e-04
Loss = 2.0853e-01, PNorm = 36.9117, GNorm = 0.8223, lr_0 = 1.7601e-04
Loss = 1.7528e-01, PNorm = 36.9325, GNorm = 2.4850, lr_0 = 1.7154e-04
Loss = 2.0993e-01, PNorm = 36.9486, GNorm = 2.8569, lr_0 = 1.6719e-04
Validation auc = 0.874757
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:55&lt;02:45, 23.68s/it]Epoch 23
Loss = 1.4639e-01, PNorm = 36.9654, GNorm = 0.7697, lr_0 = 1.6295e-04
Loss = 1.9275e-01, PNorm = 36.9816, GNorm = 1.3974, lr_0 = 1.5882e-04
Loss = 2.1059e-01, PNorm = 36.9961, GNorm = 1.5485, lr_0 = 1.5479e-04
Validation auc = 0.875779
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:20&lt;02:26, 24.34s/it]Epoch 24
Loss = 2.0678e-01, PNorm = 37.0133, GNorm = 1.3215, lr_0 = 1.5047e-04
Loss = 1.4689e-01, PNorm = 37.0280, GNorm = 1.1888, lr_0 = 1.4665e-04
Loss = 1.9324e-01, PNorm = 37.0431, GNorm = 1.3306, lr_0 = 1.4293e-04
Validation auc = 0.875084
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [09:46&lt;02:02, 24.57s/it]Epoch 25
Loss = 1.6089e-01, PNorm = 37.0576, GNorm = 1.1166, lr_0 = 1.3931e-04
Loss = 1.6333e-01, PNorm = 37.0707, GNorm = 1.0544, lr_0 = 1.3577e-04
Loss = 1.8117e-01, PNorm = 37.0841, GNorm = 1.3057, lr_0 = 1.3233e-04
Validation auc = 0.874240
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [10:10&lt;01:38, 24.53s/it]Epoch 26
Loss = 2.0404e-01, PNorm = 37.0970, GNorm = 2.9506, lr_0 = 1.2897e-04
Loss = 1.8924e-01, PNorm = 37.1089, GNorm = 1.3185, lr_0 = 1.2570e-04
Loss = 1.6666e-01, PNorm = 37.1222, GNorm = 0.9292, lr_0 = 1.2251e-04
Loss = 1.9692e-01, PNorm = 37.1330, GNorm = 2.2530, lr_0 = 1.1940e-04
Loss = 8.1838e-02, PNorm = 37.1342, GNorm = 1.3591, lr_0 = 1.1909e-04
Validation auc = 0.876953
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:36&lt;01:14, 25.00s/it]Epoch 27
Loss = 1.8200e-01, PNorm = 37.1469, GNorm = 1.7932, lr_0 = 1.1607e-04
Loss = 1.7436e-01, PNorm = 37.1568, GNorm = 1.1590, lr_0 = 1.1313e-04
Loss = 1.4737e-01, PNorm = 37.1697, GNorm = 0.6555, lr_0 = 1.1026e-04
Validation auc = 0.876077
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [11:00&lt;00:49, 24.64s/it]Epoch 28
Loss = 1.1868e-01, PNorm = 37.1807, GNorm = 0.7642, lr_0 = 1.0746e-04
Loss = 1.6770e-01, PNorm = 37.1898, GNorm = 0.9152, lr_0 = 1.0473e-04
Loss = 1.7687e-01, PNorm = 37.1999, GNorm = 1.1660, lr_0 = 1.0208e-04
Validation auc = 0.875336
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [11:22&lt;00:23, 23.79s/it]Epoch 29
Loss = 1.6006e-01, PNorm = 37.2104, GNorm = 2.7978, lr_0 = 1.0000e-04
Loss = 1.6464e-01, PNorm = 37.2212, GNorm = 1.4714, lr_0 = 1.0000e-04
Loss = 1.8973e-01, PNorm = 37.2316, GNorm = 2.1347, lr_0 = 1.0000e-04
Validation auc = 0.876871
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:44&lt;00:00, 23.47s/it]
Model 0 best validation auc = 0.877031 on epoch 21
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.899712
Ensemble test auc = 0.899712
Fold 9
Splitting data with seed 9
7807it [00:00, 102630.67it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 152942.94it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7807/7807 [00:00&lt;00:00, 68781.90it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2039/2039 [00:00&lt;00:00, 2724.10it/s]
Total scaffolds = 1,025 | train scaffolds = 822 | val scaffolds = 0 | test scaffolds = 203
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
  0%|          | 0/30 [00:00&lt;?, ?it/s]Epoch 0
Loss = 5.7355e-01, PNorm = 34.0135, GNorm = 1.3898, lr_0 = 2.5469e-04
Loss = 5.4916e-01, PNorm = 34.0176, GNorm = 1.3625, lr_0 = 3.9531e-04
Loss = 5.2713e-01, PNorm = 34.0341, GNorm = 0.1727, lr_0 = 5.3594e-04
Validation auc = 0.731387
  3%|â–Ž         | 1/30 [00:27&lt;13:22, 27.68s/it]Epoch 1
Loss = 5.6181e-01, PNorm = 34.0599, GNorm = 1.3737, lr_0 = 6.9063e-04
Loss = 5.4009e-01, PNorm = 34.0979, GNorm = 0.8545, lr_0 = 8.3125e-04
Loss = 4.9376e-01, PNorm = 34.1536, GNorm = 0.5686, lr_0 = 9.7187e-04
Validation auc = 0.761204
  7%|â–‹         | 2/30 [00:51&lt;11:45, 25.20s/it]Epoch 2
Loss = 5.3742e-01, PNorm = 34.2259, GNorm = 1.5691, lr_0 = 9.7965e-04
Loss = 3.9386e-01, PNorm = 34.3099, GNorm = 0.8096, lr_0 = 9.5480e-04
Loss = 4.4236e-01, PNorm = 34.3557, GNorm = 0.5507, lr_0 = 9.3057e-04
Validation auc = 0.791568
 10%|â–ˆ         | 3/30 [01:16&lt;11:16, 25.06s/it]Epoch 3
Loss = 4.2308e-01, PNorm = 34.4201, GNorm = 0.4710, lr_0 = 9.0463e-04
Loss = 4.2625e-01, PNorm = 34.4839, GNorm = 2.3323, lr_0 = 8.8168e-04
Loss = 3.4713e-01, PNorm = 34.5529, GNorm = 1.4637, lr_0 = 8.5931e-04
Loss = 4.2077e-01, PNorm = 34.5964, GNorm = 0.6571, lr_0 = 8.3751e-04
Validation auc = 0.827755
 13%|â–ˆâ–Ž        | 4/30 [01:38&lt;10:28, 24.19s/it]Epoch 4
Loss = 3.3712e-01, PNorm = 34.6475, GNorm = 1.0306, lr_0 = 8.1626e-04
Loss = 3.2588e-01, PNorm = 34.7061, GNorm = 1.6170, lr_0 = 7.9555e-04
Loss = 3.8492e-01, PNorm = 34.7481, GNorm = 0.3718, lr_0 = 7.7537e-04
Validation auc = 0.828054
 17%|â–ˆâ–‹        | 5/30 [02:02&lt;09:56, 23.87s/it]Epoch 5
Loss = 3.4264e-01, PNorm = 34.8038, GNorm = 0.4273, lr_0 = 7.5570e-04
Loss = 3.2844e-01, PNorm = 34.8629, GNorm = 1.2101, lr_0 = 7.3653e-04
Loss = 3.4978e-01, PNorm = 34.9220, GNorm = 1.1866, lr_0 = 7.1784e-04
Validation auc = 0.851047
 20%|â–ˆâ–ˆ        | 6/30 [02:24&lt;09:18, 23.29s/it]Epoch 6
Loss = 3.2186e-01, PNorm = 34.9997, GNorm = 0.7869, lr_0 = 6.9783e-04
Loss = 3.2372e-01, PNorm = 35.0719, GNorm = 0.4749, lr_0 = 6.8013e-04
Loss = 3.1195e-01, PNorm = 35.1244, GNorm = 2.0203, lr_0 = 6.6287e-04
Validation auc = 0.852341
 23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:47&lt;08:58, 23.40s/it]Epoch 7
Loss = 3.0974e-01, PNorm = 35.1811, GNorm = 1.7987, lr_0 = 6.4605e-04
Loss = 3.0368e-01, PNorm = 35.2501, GNorm = 1.4095, lr_0 = 6.2966e-04
Loss = 3.7589e-01, PNorm = 35.2954, GNorm = 2.1109, lr_0 = 6.1369e-04
Loss = 3.6816e-01, PNorm = 35.3463, GNorm = 0.7726, lr_0 = 5.9812e-04
Loss = 3.9080e-01, PNorm = 35.3516, GNorm = 0.4996, lr_0 = 5.9658e-04
Validation auc = 0.845782
 27%|â–ˆâ–ˆâ–‹       | 8/30 [03:10&lt;08:27, 23.08s/it]Epoch 8
Loss = 3.5167e-01, PNorm = 35.4028, GNorm = 0.4615, lr_0 = 5.8145e-04
Loss = 2.8388e-01, PNorm = 35.4565, GNorm = 0.9019, lr_0 = 5.6669e-04
Loss = 3.5399e-01, PNorm = 35.4984, GNorm = 0.5972, lr_0 = 5.5232e-04
Validation auc = 0.856509
 30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:33&lt;08:04, 23.07s/it]Epoch 9
Loss = 2.4704e-01, PNorm = 35.5443, GNorm = 0.9954, lr_0 = 5.3830e-04
Loss = 3.2154e-01, PNorm = 35.5865, GNorm = 1.9169, lr_0 = 5.2465e-04
Loss = 2.9224e-01, PNorm = 35.6308, GNorm = 0.8374, lr_0 = 5.1133e-04
Validation auc = 0.865598
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:58&lt;07:53, 23.69s/it]Epoch 10
Loss = 3.0247e-01, PNorm = 35.6612, GNorm = 0.8315, lr_0 = 4.9836e-04
Loss = 2.7513e-01, PNorm = 35.6949, GNorm = 1.1238, lr_0 = 4.8572e-04
Loss = 2.6106e-01, PNorm = 35.7404, GNorm = 1.6288, lr_0 = 4.7339e-04
Validation auc = 0.869175
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [04:21&lt;07:27, 23.54s/it]Epoch 11
Loss = 2.2082e-01, PNorm = 35.7909, GNorm = 0.7308, lr_0 = 4.6020e-04
Loss = 2.7329e-01, PNorm = 35.8341, GNorm = 0.6021, lr_0 = 4.4852e-04
Loss = 2.6603e-01, PNorm = 35.8722, GNorm = 0.9407, lr_0 = 4.3714e-04
Loss = 2.4075e-01, PNorm = 35.9113, GNorm = 2.0187, lr_0 = 4.2605e-04
Validation auc = 0.867018
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:45&lt;07:03, 23.55s/it]Epoch 12
Loss = 2.5492e-01, PNorm = 35.9484, GNorm = 1.0856, lr_0 = 4.1524e-04
Loss = 2.4939e-01, PNorm = 35.9858, GNorm = 0.4561, lr_0 = 4.0471e-04
Loss = 2.4741e-01, PNorm = 36.0232, GNorm = 1.5466, lr_0 = 3.9444e-04
Validation auc = 0.875294
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [05:09&lt;06:42, 23.67s/it]Epoch 13
Loss = 2.4982e-01, PNorm = 36.0614, GNorm = 2.4447, lr_0 = 3.8443e-04
Loss = 2.4805e-01, PNorm = 36.0925, GNorm = 1.2654, lr_0 = 3.7468e-04
Loss = 2.5467e-01, PNorm = 36.1294, GNorm = 1.3820, lr_0 = 3.6517e-04
Validation auc = 0.876470
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [05:35&lt;06:31, 24.45s/it]Epoch 14
Loss = 2.3493e-01, PNorm = 36.1666, GNorm = 0.9006, lr_0 = 3.5500e-04
Loss = 2.3090e-01, PNorm = 36.2007, GNorm = 0.9171, lr_0 = 3.4599e-04
Loss = 2.3686e-01, PNorm = 36.2300, GNorm = 2.0575, lr_0 = 3.3721e-04
Validation auc = 0.878013
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [06:02&lt;06:18, 25.20s/it]Epoch 15
Loss = 2.9026e-01, PNorm = 36.2573, GNorm = 1.3134, lr_0 = 3.2866e-04
Loss = 1.9981e-01, PNorm = 36.2863, GNorm = 0.7343, lr_0 = 3.2032e-04
Loss = 1.9687e-01, PNorm = 36.3116, GNorm = 1.6622, lr_0 = 3.1219e-04
Loss = 2.5691e-01, PNorm = 36.3379, GNorm = 0.8183, lr_0 = 3.0427e-04
Validation auc = 0.875972
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:28&lt;05:54, 25.36s/it]Epoch 16
Loss = 1.9455e-01, PNorm = 36.3669, GNorm = 1.2843, lr_0 = 2.9579e-04
Loss = 2.2575e-01, PNorm = 36.3932, GNorm = 0.6172, lr_0 = 2.8828e-04
Loss = 2.0250e-01, PNorm = 36.4198, GNorm = 0.9775, lr_0 = 2.8097e-04
Validation auc = 0.869266
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:53&lt;05:28, 25.28s/it]Epoch 17
Loss = 1.9697e-01, PNorm = 36.4458, GNorm = 2.1296, lr_0 = 2.7384e-04
Loss = 2.1166e-01, PNorm = 36.4693, GNorm = 1.2592, lr_0 = 2.6689e-04
Loss = 1.9109e-01, PNorm = 36.4920, GNorm = 1.2560, lr_0 = 2.6012e-04
Validation auc = 0.875670
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [07:16&lt;04:57, 24.80s/it]Epoch 18
Loss = 1.8643e-01, PNorm = 36.5195, GNorm = 1.2630, lr_0 = 2.5352e-04
Loss = 1.8821e-01, PNorm = 36.5462, GNorm = 1.1309, lr_0 = 2.4709e-04
Loss = 2.1482e-01, PNorm = 36.5691, GNorm = 2.0538, lr_0 = 2.4082e-04
Validation auc = 0.882305
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [07:43&lt;04:36, 25.18s/it]Epoch 19
Loss = 3.6615e-01, PNorm = 36.5870, GNorm = 1.2744, lr_0 = 2.3411e-04
Loss = 1.7905e-01, PNorm = 36.6064, GNorm = 1.4056, lr_0 = 2.2817e-04
Loss = 1.6863e-01, PNorm = 36.6280, GNorm = 0.8830, lr_0 = 2.2238e-04
Loss = 2.2525e-01, PNorm = 36.6487, GNorm = 1.1407, lr_0 = 2.1674e-04
Validation auc = 0.878234
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [08:06&lt;04:06, 24.65s/it]Epoch 20
Loss = 1.8261e-01, PNorm = 36.6677, GNorm = 0.5729, lr_0 = 2.1124e-04
Loss = 1.6636e-01, PNorm = 36.6873, GNorm = 2.5082, lr_0 = 2.0588e-04
Loss = 1.9284e-01, PNorm = 36.7066, GNorm = 0.6993, lr_0 = 2.0066e-04
Validation auc = 0.884596
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [08:28&lt;03:34, 23.88s/it]Epoch 21
Loss = 1.7006e-01, PNorm = 36.7234, GNorm = 1.4929, lr_0 = 1.9557e-04
Loss = 1.7874e-01, PNorm = 36.7407, GNorm = 2.4642, lr_0 = 1.9060e-04
Loss = 1.8300e-01, PNorm = 36.7556, GNorm = 1.3921, lr_0 = 1.8577e-04
Validation auc = 0.880451
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:50&lt;03:07, 23.41s/it]Epoch 22
Loss = 2.2415e-01, PNorm = 36.7748, GNorm = 3.0747, lr_0 = 1.8059e-04
Loss = 1.8420e-01, PNorm = 36.7904, GNorm = 1.5966, lr_0 = 1.7601e-04
Loss = 1.8406e-01, PNorm = 36.8065, GNorm = 3.2764, lr_0 = 1.7154e-04
Loss = 1.7007e-01, PNorm = 36.8239, GNorm = 2.2602, lr_0 = 1.6719e-04
Validation auc = 0.880731
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [09:13&lt;02:42, 23.24s/it]Epoch 23
Loss = 1.8307e-01, PNorm = 36.8388, GNorm = 0.9624, lr_0 = 1.6295e-04
Loss = 1.6942e-01, PNorm = 36.8528, GNorm = 1.5294, lr_0 = 1.5882e-04
Loss = 1.9677e-01, PNorm = 36.8652, GNorm = 2.0170, lr_0 = 1.5479e-04
Validation auc = 0.883153
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:37&lt;02:19, 23.31s/it]Epoch 24
Loss = 1.9167e-01, PNorm = 36.8796, GNorm = 1.6526, lr_0 = 1.5047e-04
Loss = 1.7906e-01, PNorm = 36.8896, GNorm = 1.4202, lr_0 = 1.4665e-04
Loss = 1.6134e-01, PNorm = 36.9037, GNorm = 1.5846, lr_0 = 1.4293e-04
Validation auc = 0.884527
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [10:02&lt;01:59, 23.95s/it]Epoch 25
Loss = 2.1820e-01, PNorm = 36.9145, GNorm = 2.8235, lr_0 = 1.3931e-04
Loss = 1.5305e-01, PNorm = 36.9264, GNorm = 1.3115, lr_0 = 1.3577e-04
Loss = 1.4523e-01, PNorm = 36.9400, GNorm = 2.9751, lr_0 = 1.3233e-04
Validation auc = 0.884324
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [10:28&lt;01:37, 24.48s/it]Epoch 26
Loss = 1.0589e-01, PNorm = 36.9495, GNorm = 0.5398, lr_0 = 1.2897e-04
Loss = 1.7584e-01, PNorm = 36.9614, GNorm = 0.7777, lr_0 = 1.2570e-04
Loss = 1.7186e-01, PNorm = 36.9732, GNorm = 1.1555, lr_0 = 1.2251e-04
Loss = 1.6196e-01, PNorm = 36.9816, GNorm = 0.6087, lr_0 = 1.1940e-04
Loss = 7.2826e-02, PNorm = 36.9825, GNorm = 1.8686, lr_0 = 1.1909e-04
Validation auc = 0.883706
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [10:52&lt;01:13, 24.43s/it]Epoch 27
Loss = 1.8395e-01, PNorm = 36.9932, GNorm = 1.1524, lr_0 = 1.1607e-04
Loss = 1.4853e-01, PNorm = 37.0025, GNorm = 2.9369, lr_0 = 1.1313e-04
Loss = 1.5653e-01, PNorm = 37.0122, GNorm = 1.2032, lr_0 = 1.1026e-04
Validation auc = 0.884723
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [11:16&lt;00:48, 24.35s/it]Epoch 28
Loss = 1.3687e-01, PNorm = 37.0222, GNorm = 1.2745, lr_0 = 1.0746e-04
Loss = 1.4577e-01, PNorm = 37.0320, GNorm = 1.0341, lr_0 = 1.0473e-04
Loss = 2.0489e-01, PNorm = 37.0415, GNorm = 3.6318, lr_0 = 1.0208e-04
Validation auc = 0.884838
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [11:41&lt;00:24, 24.34s/it]Epoch 29
Loss = 1.5350e-01, PNorm = 37.0487, GNorm = 1.8702, lr_0 = 1.0000e-04
Loss = 1.7822e-01, PNorm = 37.0573, GNorm = 1.4119, lr_0 = 1.0000e-04
Loss = 1.2261e-01, PNorm = 37.0653, GNorm = 1.2145, lr_0 = 1.0000e-04
Validation auc = 0.884231
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [12:05&lt;00:00, 24.19s/it]
Model 0 best validation auc = 0.884838 on epoch 28
Loading pretrained parameter &#34;encoder.encoder.0.cached_zero_vector&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_i.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_h.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.weight&#34;.
Loading pretrained parameter &#34;encoder.encoder.0.W_o.bias&#34;.
Loading pretrained parameter &#34;ffn.1.weight&#34;.
Loading pretrained parameter &#34;ffn.1.bias&#34;.
Loading pretrained parameter &#34;ffn.4.weight&#34;.
Loading pretrained parameter &#34;ffn.4.bias&#34;.
Model 0 test auc = 0.898943
Ensemble test auc = 0.898943
10-fold cross validation
	Seed 0 ==&gt; test auc = 0.844660
	Seed 1 ==&gt; test auc = 0.859605
	Seed 2 ==&gt; test auc = 0.884451
	Seed 3 ==&gt; test auc = 0.893417
	Seed 4 ==&gt; test auc = 0.938451
	Seed 5 ==&gt; test auc = 0.876687
	Seed 6 ==&gt; test auc = 0.906706
	Seed 7 ==&gt; test auc = 0.897564
	Seed 8 ==&gt; test auc = 0.899712
	Seed 9 ==&gt; test auc = 0.898943
Overall test auc = 0.890020 +/- 0.024612
Elapsed time = 1:54:20
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="gdeol4/neongenes"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Notes on machine learning, bioinformatics, and programming.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/gdeol4" title="gdeol4"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/gurkamal-deol-508675174" title="gurkamal-deol-508675174"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
