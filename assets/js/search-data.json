{
  
    
        "post0": {
            "title": "Scaffold splitting and initial model training using chemprop",
            "content": "Chemprop . I found the chemprop library in the paper A Deep Learning Approach to Antibiotic Discovery30102-1), it uses the directed message passing neural network (D-MPNN) described in Analyzing Learned Molecular Representations for Property Prediction. . The drug discovery workflow described in the paper uses a training dataset of 2335 molecules with binary e.coli growth inhibition labels to train a classification model. . The D-MPNN architecture as described in the paper: . The D-MPNN architecture translates the graph representation of a molecule into a continuous vector via a directed bond-based message passing approach. This builds a molecular representation by iteratively aggregating the features of individual atoms and bonds. The model operates by passing “messages” along bonds that encode information about neighboring atoms and bonds. By applying this message passing operation multiple times, the model constructs higher-level bond messages that contain information about larger chemical substructures. The highest-level bond messages are then combined into a single continuous vector representing the entire molecule. . The researchers generated molecular features using RDKit to tackle overfitting, increased algorithm robustness by using an ensemble of classifers, and optimized hyperparameters with bayesian optimization. The model achaived a ROC-AUC of 0.896 on test data. . This notebook will apply the neural network to the dataset of blood brain barrier molecules gathered in the previous notebooks. . Scaffold splitting . Distributional shift is a change in the data distribution between an algorithm&#39;s training dataset, and a dataset it encounters when deployed. Distributional shifts are common in the field of molecular property prediction where chemical space is huge and different areas of it exhibit high structural heterogeneity.The shifts tend to be large and difficult to handle for machine learning models. . Scaffold splitting is one solution to this distributional shift. Its first described in &quot;The properties of known drugs. 1. Molecular frameworks: . A molecular scaffold reduces the chemical structure of a compound to its core components, essentially by removing all side chains and only keeping ring systems and parts which link together ring systems. An additional option for making molecular scaffolds even more general is to “forget” the identities of the bonds and atoms by replacing all atoms with carbons and all bonds with single bonds. . Measuring out-of-distribution generalisation is of particular relevance . Different molecular data sets obtained by distinct pharmaceutical companies and research groups often contain compounds from vastly different areas of chemical space that exhibit high structural heterogeneity. An elegant solution for the modelling of such distributional shifts in chemical space is given by the idea of scaffold splitting. . A molecule compared to its scaffold below: . Molecular compound and its generic Bemis-Murcko scaffold . from rdkit import Chem from rdkit.Chem.Scaffolds import MurckoScaffold # define compound via its SMILES string smiles = &quot;CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC&quot; # convert SMILES string to RDKit mol object mol = Chem.MolFromSmiles(smiles) # create RDKit mol object corresponding to Bemis-Murcko scaffold of original compound mol_scaffold = MurckoScaffold.GetScaffoldForMol(mol) # make the scaffold generic by replacing all atoms with carbons and all bonds with single bonds mol_scaffold_generic = MurckoScaffold.MakeScaffoldGeneric(mol_scaffold) # convert the generic scaffold mol object back to a SMILES string format smiles_scaffold_generic = Chem.CanonSmiles(Chem.MolToSmiles(mol_scaffold_generic)) # display compound and its generic Bemis-Murcko scaffold display(mol) print(smiles) display(mol_scaffold_generic) print(smiles_scaffold_generic) . CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC . C1CCC(CCC2C3CCCCC3CC3CCCCC32)CC1 . # import packages import chemprop import pandas as pd import datamol as dm pd.options.mode.chained_assignment = None # default=&#39;warn&#39; # loading the datasets MolNet = pd.read_csv(&quot;data/MoleculeNet.csv&quot;) B3DB = pd.read_csv(&quot;data/B3DB.csv&quot;) b3_molecules = pd.read_csv(&quot;data/b3_molecules.csv&quot;) . def scaffold_split(df): df[&quot;mol&quot;] = [Chem.MolFromSmiles(x) for x in df[&quot;standard_smiles&quot;]] # generating moles from the standard_smiles column df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=True) for x in df[&#39;mol&#39;]] # sanitize mol objects df = df.dropna() # dropping NA values df[&quot;scaffold&quot;] = [MurckoScaffold.GetScaffoldForMol(x) for x in df[&quot;mol&quot;]] # generating scaffolds from mol object df[&quot;mol_scaffold_generic&quot;] = [MurckoScaffold.MakeScaffoldGeneric(x) for x in df[&quot;scaffold&quot;]] # generalizing scaffolds # convert the generic scaffold mol object back to a SMILES string format df[&quot;smiles_scaffold_generic&quot;] = [Chem.CanonSmiles(Chem.MolToSmiles(x)) for x in df[&quot;mol_scaffold_generic&quot;]] return df . # the data prior to processing MolNet.head(1) . BBB+/BBB- SMILES mol standard_smiles selfies inchi inchikey . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | . # results of the scaffold generating function data_split = scaffold_split(b3_molecules) data_split.head(1) . BBB+/BBB- SMILES mol standard_smiles selfies inchi inchikey scaffold mol_scaffold_generic smiles_scaffold_generic . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | C1CCC2CCCCC2C1 | . # A function to process the data for use with the chemprop library def chemprop_prep(df, filename): df = df.drop([&quot;mol&quot;, &quot;SMILES&quot;, &quot;selfies&quot;, &quot;inchi&quot;, &quot;inchikey&quot;], axis=1) # drop all columns except the smiles and target df[&quot;smiles&quot;] = df[&quot;standard_smiles&quot;] # use standard smiles inplace of smiles df = df.drop([&quot;standard_smiles&quot;], axis=1) # drop this column now df = df[[&quot;smiles&quot;, &quot;BBB+/BBB-&quot;]] # reorder the columns with smiles first and target second df.to_csv(&#39;./data/&#39; + filename + &#39;.csv&#39;, index=False) # save the file return df . # Processing the three different datasets molnet_chemprop = chemprop_prep(MolNet, &#39;molnet_chemprop&#39;) B3DB_chemprop = chemprop_prep(B3DB, &#39;B3DB_chemprep&#39;) b3_mol_chemprop = chemprop_prep(b3_molecules, &#39;b3_mol_chemprop&#39;) . # results of processing molnet_chemprop.head(1) . smiles BBB+/BBB- . 0 CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | 1 | . . CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC . C1CCC(CCC2C3CCCCC3CC3CCCCC32)CC1 . arguments = [ &#39;--data_path&#39;, &#39;./data/molnet_chemprop.csv&#39;, &#39;--dataset_type&#39;, &#39;classification&#39;, &#39;--save_dir&#39;, &#39;./data/chemprop_checkpoints/&#39;, &#39;--split_type&#39;, &#39;scaffold_balanced&#39;, # &#39;--separate_val_path&#39;, &#39;./data/chemprop_B3DB.csv&#39;, &#39;--num_folds&#39;, &#39;10&#39;, &#39;--class_balance&#39;, &#39;--features_generator&#39;, &#39;rdkit_2d_normalized&#39;, &#39;--no_features_scaling&#39;, &#39;--quiet&#39; ] args = chemprop.args.TrainArgs().parse_args(arguments) mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training) . 2039it [00:00, 119828.86it/s] 100%|██████████| 2039/2039 [02:20&lt;00:00, 14.53it/s] 100%|██████████| 2039/2039 [00:00&lt;00:00, 67907.37it/s] Fold 0 100%|██████████| 2039/2039 [00:00&lt;00:00, 3649.46it/s] 100%|██████████| 30/30 [01:51&lt;00:00, 3.73s/it] Model 0 best validation auc = 0.926059 on epoch 8 Model 0 test auc = 0.928767 Ensemble test auc = 0.928767 Fold 1 100%|██████████| 2039/2039 [00:00&lt;00:00, 3489.41it/s] 100%|██████████| 30/30 [01:51&lt;00:00, 3.72s/it] Model 0 best validation auc = 0.886265 on epoch 19 Model 0 test auc = 0.903879 Ensemble test auc = 0.903879 Fold 2 100%|██████████| 2039/2039 [00:00&lt;00:00, 3452.67it/s] 100%|██████████| 30/30 [01:46&lt;00:00, 3.55s/it] Model 0 best validation auc = 0.917212 on epoch 29 Model 0 test auc = 0.955724 Ensemble test auc = 0.955724 Fold 3 100%|██████████| 2039/2039 [00:00&lt;00:00, 3602.29it/s] 100%|██████████| 30/30 [01:56&lt;00:00, 3.88s/it] Model 0 best validation auc = 0.886939 on epoch 5 Model 0 test auc = 0.862450 Ensemble test auc = 0.862450 Fold 4 100%|██████████| 2039/2039 [00:00&lt;00:00, 3449.09it/s] 100%|██████████| 30/30 [01:47&lt;00:00, 3.59s/it] Model 0 best validation auc = 0.897674 on epoch 3 Model 0 test auc = 0.890246 Ensemble test auc = 0.890246 Fold 5 100%|██████████| 2039/2039 [00:00&lt;00:00, 3590.55it/s] 100%|██████████| 30/30 [01:42&lt;00:00, 3.43s/it] Model 0 best validation auc = 0.977661 on epoch 7 Model 0 test auc = 0.892326 Ensemble test auc = 0.892326 Fold 6 100%|██████████| 2039/2039 [00:00&lt;00:00, 3417.71it/s] 100%|██████████| 30/30 [01:48&lt;00:00, 3.61s/it] Model 0 best validation auc = 0.924837 on epoch 29 Model 0 test auc = 0.886606 Ensemble test auc = 0.886606 Fold 7 100%|██████████| 2039/2039 [00:00&lt;00:00, 3561.41it/s] 100%|██████████| 30/30 [01:54&lt;00:00, 3.82s/it] Model 0 best validation auc = 0.946760 on epoch 24 Model 0 test auc = 0.951849 Ensemble test auc = 0.951849 Fold 8 100%|██████████| 2039/2039 [00:00&lt;00:00, 3527.51it/s] 100%|██████████| 30/30 [01:52&lt;00:00, 3.75s/it] Model 0 best validation auc = 0.890004 on epoch 29 Model 0 test auc = 0.906486 Ensemble test auc = 0.906486 Fold 9 100%|██████████| 2039/2039 [00:00&lt;00:00, 3542.86it/s] 100%|██████████| 30/30 [01:46&lt;00:00, 3.56s/it] Model 0 best validation auc = 0.899198 on epoch 22 Model 0 test auc = 0.937866 Ensemble test auc = 0.937866 10-fold cross validation Seed 0 ==&gt; test auc = 0.928767 Seed 1 ==&gt; test auc = 0.903879 Seed 2 ==&gt; test auc = 0.955724 Seed 3 ==&gt; test auc = 0.862450 Seed 4 ==&gt; test auc = 0.890246 Seed 5 ==&gt; test auc = 0.892326 Seed 6 ==&gt; test auc = 0.886606 Seed 7 ==&gt; test auc = 0.951849 Seed 8 ==&gt; test auc = 0.906486 Seed 9 ==&gt; test auc = 0.937866 Overall test auc = 0.911620 +/- 0.029164 Elapsed time = 0:20:54 . arguments = [ &#39;--data_path&#39;, &#39;./data/molnet_chemprop.csv&#39;, &#39;--dataset_type&#39;, &#39;classification&#39;, &#39;--save_dir&#39;, &#39;./data/chemprop_checkpoints/&#39;, &#39;--split_type&#39;, &#39;scaffold_balanced&#39;, # &#39;--separate_val_path&#39;, &#39;./data/chemprop_B3DB.csv&#39;, &#39;--num_folds&#39;, &#39;10&#39;, &#39;--class_balance&#39;, &#39;--features_generator&#39;, &#39;rdkit_2d_normalized&#39;, &#39;--no_features_scaling&#39;, &#39;--quiet&#39;, &#39;--epochs&#39;, &#39;100&#39; ] args = chemprop.args.TrainArgs().parse_args(arguments) mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training) . 2039it [00:00, 119820.47it/s] 100%|██████████| 2039/2039 [02:19&lt;00:00, 14.63it/s] 100%|██████████| 2039/2039 [00:00&lt;00:00, 72760.41it/s] Fold 0 100%|██████████| 2039/2039 [00:00&lt;00:00, 3660.57it/s] 100%|██████████| 100/100 [05:48&lt;00:00, 3.48s/it] Model 0 best validation auc = 0.926682 on epoch 8 Model 0 test auc = 0.929177 Ensemble test auc = 0.929177 Fold 1 100%|██████████| 2039/2039 [00:00&lt;00:00, 3486.36it/s] 100%|██████████| 100/100 [05:56&lt;00:00, 3.57s/it] Model 0 best validation auc = 0.895276 on epoch 67 Model 0 test auc = 0.852848 Ensemble test auc = 0.852848 Fold 2 100%|██████████| 2039/2039 [00:00&lt;00:00, 3494.12it/s] 100%|██████████| 100/100 [05:50&lt;00:00, 3.50s/it] Model 0 best validation auc = 0.932624 on epoch 39 Model 0 test auc = 0.944112 Ensemble test auc = 0.944112 Fold 3 100%|██████████| 2039/2039 [00:00&lt;00:00, 3524.44it/s] 100%|██████████| 100/100 [06:18&lt;00:00, 3.78s/it] Model 0 best validation auc = 0.886531 on epoch 5 Model 0 test auc = 0.862913 Ensemble test auc = 0.862913 Fold 4 100%|██████████| 2039/2039 [00:00&lt;00:00, 3468.74it/s] 100%|██████████| 100/100 [05:39&lt;00:00, 3.40s/it] Model 0 best validation auc = 0.897674 on epoch 3 Model 0 test auc = 0.890246 Ensemble test auc = 0.890246 Fold 5 100%|██████████| 2039/2039 [00:00&lt;00:00, 3527.38it/s] 100%|██████████| 100/100 [05:06&lt;00:00, 3.07s/it] Model 0 best validation auc = 0.977892 on epoch 7 Model 0 test auc = 0.893487 Ensemble test auc = 0.893487 Fold 6 100%|██████████| 2039/2039 [00:00&lt;00:00, 3832.74it/s] 100%|██████████| 100/100 [05:23&lt;00:00, 3.23s/it] Model 0 best validation auc = 0.925359 on epoch 42 Model 0 test auc = 0.881697 Ensemble test auc = 0.881697 Fold 7 100%|██████████| 2039/2039 [00:00&lt;00:00, 3797.06it/s] 100%|██████████| 100/100 [15:55:05&lt;00:00, 573.05s/it] Model 0 best validation auc = 0.958971 on epoch 24 Model 0 test auc = 0.941933 Ensemble test auc = 0.941933 Fold 8 100%|██████████| 2039/2039 [00:00&lt;00:00, 3446.91it/s] 100%|██████████| 100/100 [05:52&lt;00:00, 3.53s/it] Model 0 best validation auc = 0.896662 on epoch 39 Model 0 test auc = 0.920437 Ensemble test auc = 0.920437 Fold 9 100%|██████████| 2039/2039 [00:00&lt;00:00, 3790.66it/s] 100%|██████████| 100/100 [06:04&lt;00:00, 3.64s/it] Model 0 best validation auc = 0.906584 on epoch 73 Model 0 test auc = 0.917494 Ensemble test auc = 0.917494 10-fold cross validation Seed 0 ==&gt; test auc = 0.929177 Seed 1 ==&gt; test auc = 0.852848 Seed 2 ==&gt; test auc = 0.944112 Seed 3 ==&gt; test auc = 0.862913 Seed 4 ==&gt; test auc = 0.890246 Seed 5 ==&gt; test auc = 0.893487 Seed 6 ==&gt; test auc = 0.881697 Seed 7 ==&gt; test auc = 0.941933 Seed 8 ==&gt; test auc = 0.920437 Seed 9 ==&gt; test auc = 0.917494 Overall test auc = 0.903435 +/- 0.030385 Elapsed time = 16:49:39 . arguments = [ &#39;--data_path&#39;, &#39;./data/molnet_chemprop.csv&#39;, &#39;--dataset_type&#39;, &#39;classification&#39;, &#39;--save_dir&#39;, &#39;./data/chemprop_checkpoints/&#39;, &#39;--split_type&#39;, &#39;scaffold_balanced&#39;, # &#39;--separate_val_path&#39;, &#39;./data/chemprop_B3DB.csv&#39;, &#39;--num_folds&#39;, &#39;30&#39;, &#39;--class_balance&#39;, &#39;--features_generator&#39;, &#39;rdkit_2d_normalized&#39;, &#39;--no_features_scaling&#39;, &#39;--quiet&#39;, &#39;--epochs&#39;, &#39;20&#39;, ] args = chemprop.args.TrainArgs().parse_args(arguments) mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training) . 2039it [00:00, 115354.96it/s] 100%|██████████| 2039/2039 [02:26&lt;00:00, 13.90it/s] 100%|██████████| 2039/2039 [00:00&lt;00:00, 70246.13it/s] Fold 0 100%|██████████| 2039/2039 [00:00&lt;00:00, 3198.03it/s] 100%|██████████| 20/20 [01:18&lt;00:00, 3.92s/it] Model 0 best validation auc = 0.926821 on epoch 8 Model 0 test auc = 0.928630 Ensemble test auc = 0.928630 Fold 1 100%|██████████| 2039/2039 [00:00&lt;00:00, 3446.10it/s] 100%|██████████| 20/20 [01:17&lt;00:00, 3.85s/it] Model 0 best validation auc = 0.885102 on epoch 19 Model 0 test auc = 0.907636 Ensemble test auc = 0.907636 Fold 2 100%|██████████| 2039/2039 [00:00&lt;00:00, 3500.73it/s] 100%|██████████| 20/20 [01:13&lt;00:00, 3.65s/it] Model 0 best validation auc = 0.888843 on epoch 13 Model 0 test auc = 0.943526 Ensemble test auc = 0.943526 Fold 3 100%|██████████| 2039/2039 [00:00&lt;00:00, 3339.00it/s] 100%|██████████| 20/20 [01:17&lt;00:00, 3.88s/it] Model 0 best validation auc = 0.888367 on epoch 10 Model 0 test auc = 0.882607 Ensemble test auc = 0.882607 Fold 4 100%|██████████| 2039/2039 [00:00&lt;00:00, 3680.91it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.51s/it] Model 0 best validation auc = 0.897674 on epoch 3 Model 0 test auc = 0.890246 Ensemble test auc = 0.890246 Fold 5 100%|██████████| 2039/2039 [00:00&lt;00:00, 3002.23it/s] 100%|██████████| 20/20 [01:07&lt;00:00, 3.40s/it] Model 0 best validation auc = 0.977430 on epoch 7 Model 0 test auc = 0.892559 Ensemble test auc = 0.892559 Fold 6 100%|██████████| 2039/2039 [00:00&lt;00:00, 3506.35it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.51s/it] Model 0 best validation auc = 0.914641 on epoch 14 Model 0 test auc = 0.870606 Ensemble test auc = 0.870606 Fold 7 100%|██████████| 2039/2039 [00:00&lt;00:00, 3521.76it/s] 100%|██████████| 20/20 [01:13&lt;00:00, 3.68s/it] Model 0 best validation auc = 0.941224 on epoch 19 Model 0 test auc = 0.947479 Ensemble test auc = 0.947479 Fold 8 100%|██████████| 2039/2039 [00:00&lt;00:00, 3667.39it/s] 100%|██████████| 20/20 [01:11&lt;00:00, 3.59s/it] Model 0 best validation auc = 0.878470 on epoch 14 Model 0 test auc = 0.903720 Ensemble test auc = 0.903720 Fold 9 100%|██████████| 2039/2039 [00:00&lt;00:00, 3618.25it/s] 100%|██████████| 20/20 [01:08&lt;00:00, 3.40s/it] Model 0 best validation auc = 0.893467 on epoch 12 Model 0 test auc = 0.930991 Ensemble test auc = 0.930991 Fold 10 100%|██████████| 2039/2039 [00:00&lt;00:00, 3185.49it/s] 100%|██████████| 20/20 [01:04&lt;00:00, 3.20s/it] Model 0 best validation auc = 0.973233 on epoch 3 Model 0 test auc = 0.795291 Ensemble test auc = 0.795291 Fold 11 100%|██████████| 2039/2039 [00:00&lt;00:00, 3338.71it/s] 100%|██████████| 20/20 [01:13&lt;00:00, 3.68s/it] Model 0 best validation auc = 0.914947 on epoch 9 Model 0 test auc = 0.894284 Ensemble test auc = 0.894284 Fold 12 100%|██████████| 2039/2039 [00:00&lt;00:00, 3031.36it/s] 100%|██████████| 20/20 [01:12&lt;00:00, 3.63s/it] Model 0 best validation auc = 0.948983 on epoch 18 Model 0 test auc = 0.936275 Ensemble test auc = 0.936275 Fold 13 100%|██████████| 2039/2039 [00:00&lt;00:00, 3049.59it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.51s/it] Model 0 best validation auc = 0.894911 on epoch 15 Model 0 test auc = 0.930272 Ensemble test auc = 0.930272 Fold 14 100%|██████████| 2039/2039 [00:00&lt;00:00, 3026.89it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.51s/it] Model 0 best validation auc = 0.861163 on epoch 18 Model 0 test auc = 0.950706 Ensemble test auc = 0.950706 Fold 15 100%|██████████| 2039/2039 [00:00&lt;00:00, 2850.29it/s] 100%|██████████| 20/20 [01:13&lt;00:00, 3.66s/it] Model 0 best validation auc = 0.919349 on epoch 19 Model 0 test auc = 0.919849 Ensemble test auc = 0.919849 Fold 16 100%|██████████| 2039/2039 [00:00&lt;00:00, 3105.26it/s] 100%|██████████| 20/20 [01:12&lt;00:00, 3.61s/it] Model 0 best validation auc = 0.898079 on epoch 4 Model 0 test auc = 0.877632 Ensemble test auc = 0.877632 Fold 17 100%|██████████| 2039/2039 [00:00&lt;00:00, 3053.11it/s] 100%|██████████| 20/20 [01:12&lt;00:00, 3.62s/it] Model 0 best validation auc = 0.940944 on epoch 3 Model 0 test auc = 0.871467 Ensemble test auc = 0.871467 Fold 18 100%|██████████| 2039/2039 [00:00&lt;00:00, 3029.89it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.54s/it] Model 0 best validation auc = 0.956202 on epoch 13 Model 0 test auc = 0.888110 Ensemble test auc = 0.888110 Fold 19 100%|██████████| 2039/2039 [00:00&lt;00:00, 2782.88it/s] 100%|██████████| 20/20 [01:09&lt;00:00, 3.50s/it] Model 0 best validation auc = 0.860850 on epoch 18 Model 0 test auc = 0.905920 Ensemble test auc = 0.905920 Fold 20 100%|██████████| 2039/2039 [00:00&lt;00:00, 2923.21it/s] 100%|██████████| 20/20 [01:11&lt;00:00, 3.56s/it] Model 0 best validation auc = 0.913857 on epoch 19 Model 0 test auc = 0.921946 Ensemble test auc = 0.921946 Fold 21 100%|██████████| 2039/2039 [00:00&lt;00:00, 3163.69it/s] 100%|██████████| 20/20 [01:08&lt;00:00, 3.44s/it] Model 0 best validation auc = 0.901703 on epoch 19 Model 0 test auc = 0.928851 Ensemble test auc = 0.928851 Fold 22 100%|██████████| 2039/2039 [00:00&lt;00:00, 3015.63it/s] 100%|██████████| 20/20 [01:17&lt;00:00, 3.89s/it] Model 0 best validation auc = 0.854831 on epoch 16 Model 0 test auc = 0.870864 Ensemble test auc = 0.870864 Fold 23 100%|██████████| 2039/2039 [00:00&lt;00:00, 3229.34it/s] 100%|██████████| 20/20 [01:16&lt;00:00, 3.85s/it] Model 0 best validation auc = 0.902544 on epoch 19 Model 0 test auc = 0.865779 Ensemble test auc = 0.865779 Fold 24 100%|██████████| 2039/2039 [00:00&lt;00:00, 2723.16it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.53s/it] Model 0 best validation auc = 0.947491 on epoch 13 Model 0 test auc = 0.902960 Ensemble test auc = 0.902960 Fold 25 100%|██████████| 2039/2039 [00:00&lt;00:00, 3096.56it/s] 100%|██████████| 20/20 [01:13&lt;00:00, 3.66s/it] Model 0 best validation auc = 0.922910 on epoch 19 Model 0 test auc = 0.946100 Ensemble test auc = 0.946100 Fold 26 100%|██████████| 2039/2039 [00:00&lt;00:00, 2965.28it/s] 100%|██████████| 20/20 [01:10&lt;00:00, 3.53s/it] Model 0 best validation auc = 0.951224 on epoch 7 Model 0 test auc = 0.900540 Ensemble test auc = 0.900540 Fold 27 100%|██████████| 2039/2039 [00:00&lt;00:00, 3309.55it/s] 100%|██████████| 20/20 [01:05&lt;00:00, 3.28s/it] Model 0 best validation auc = 0.898920 on epoch 19 Model 0 test auc = 0.923984 Ensemble test auc = 0.923984 Fold 28 100%|██████████| 2039/2039 [00:00&lt;00:00, 3210.55it/s] 100%|██████████| 20/20 [01:01&lt;00:00, 3.09s/it] Model 0 best validation auc = 0.921916 on epoch 18 Model 0 test auc = 0.900345 Ensemble test auc = 0.900345 Fold 29 100%|██████████| 2039/2039 [00:00&lt;00:00, 3534.62it/s] 100%|██████████| 20/20 [01:07&lt;00:00, 3.38s/it] Model 0 best validation auc = 0.881122 on epoch 19 Model 0 test auc = 0.905261 Ensemble test auc = 0.905261 30-fold cross validation Seed 0 ==&gt; test auc = 0.928630 Seed 1 ==&gt; test auc = 0.907636 Seed 2 ==&gt; test auc = 0.943526 Seed 3 ==&gt; test auc = 0.882607 Seed 4 ==&gt; test auc = 0.890246 Seed 5 ==&gt; test auc = 0.892559 Seed 6 ==&gt; test auc = 0.870606 Seed 7 ==&gt; test auc = 0.947479 Seed 8 ==&gt; test auc = 0.903720 Seed 9 ==&gt; test auc = 0.930991 Seed 10 ==&gt; test auc = 0.795291 Seed 11 ==&gt; test auc = 0.894284 Seed 12 ==&gt; test auc = 0.936275 Seed 13 ==&gt; test auc = 0.930272 Seed 14 ==&gt; test auc = 0.950706 Seed 15 ==&gt; test auc = 0.919849 Seed 16 ==&gt; test auc = 0.877632 Seed 17 ==&gt; test auc = 0.871467 Seed 18 ==&gt; test auc = 0.888110 Seed 19 ==&gt; test auc = 0.905920 Seed 20 ==&gt; test auc = 0.921946 Seed 21 ==&gt; test auc = 0.928851 Seed 22 ==&gt; test auc = 0.870864 Seed 23 ==&gt; test auc = 0.865779 Seed 24 ==&gt; test auc = 0.902960 Seed 25 ==&gt; test auc = 0.946100 Seed 26 ==&gt; test auc = 0.900540 Seed 27 ==&gt; test auc = 0.923984 Seed 28 ==&gt; test auc = 0.900345 Seed 29 ==&gt; test auc = 0.905261 Overall test auc = 0.904481 +/- 0.031870 Elapsed time = 0:38:51 .",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html",
            "date": " • Nov 12, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Building a drug discovery web app - the roadmap",
            "content": "My goal: . The end goal for this project is to build a web app dashboard to monitor the accuracy of machine learning models on generating and classifying molecules with blood brain barrier permeability. . My goal is to train a classification model using the D-MPNN architecture, screen the Drug Repurposing Hub for molecules identified as blood brain barrier permeable, mutate the top 10 molecules with the STONED SELFIES algorithm, check these molecules for existing drugs, predict toxicity and other molecular properties. . B3_screen -&gt; a web app that classifies molecules as blood brain barrier permeable or not. .",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/drug%20discovery/rdkit/2021/11/11/project-1-machine-learning.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/drug%20discovery/rdkit/2021/11/11/project-1-machine-learning.html",
            "date": " • Nov 11, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Processing the B3DB brain-blood barrier dataset",
            "content": "Gathering data on blood brain barrier permeability . This post is a part of a fullstack machine learning web app project and this notebook contains the data needed to build and train the models. The goal in this post is to clean and preprocess the B3DB dataset and merge it with the blood brain permeability data from MoleculeNet. The merged dataset should contain nearly 10,000 molecules labeled with their ability to pass through the blood brain barrier. The notebook provided in the B3DB repository also contains an interesting PCA plot, which is a good starting place for EDA when the data is merged. . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from rdkit import Chem from rdkit.Chem import AllChem from sklearn.decomposition import PCA import datamol as dm %matplotlib inline . Removing, remapping, and creating features . This dataset has features that can be dropped since they won&#39;t contribute to model training. Some features are then calculated from the SMILES data. . # reading in the data bbb_df = pd.read_csv(&quot;data/B3DB_classification.tsv&quot;, sep=&quot; t&quot;) # dropping columns bbb_df = bbb_df.drop([&quot;CID&quot;, &quot;logBB&quot;, &quot;Inchi&quot;, &quot;threshold&quot;, &quot;reference&quot;, &quot;group&quot;, &quot;comments&quot;, &quot;NO.&quot;, &quot;IUPAC_name&quot;, &quot;compound_name&quot;], axis=1) # mapping given labels to binary bbb_df[&#39;BBB+/BBB-&#39;] = bbb_df[&#39;BBB+/BBB-&#39;].map({&#39;BBB+&#39;: 1, &#39;BBB-&#39;: 0}) . Feature generation . The function below processes and generates features such as mol objects, selfies, inchi, and inchikeys for each molecule using the datamol library. . # preprocessing function for molecules def preprocess_smiles(df): df[&quot;mol&quot;] = [dm.to_mol(x) for x in df[&#39;SMILES&#39;]] # generating mols from SMILES df[&quot;mol&quot;] = [dm.fix_mol(x) for x in df[&#39;mol&#39;]] # Fixing mols df = df.dropna() # dropping NA values df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=False) for x in df[&#39;mol&#39;]] # sanitize mol objects df[&quot;mol&quot;] = [dm.standardize_mol(x, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True) for x in df[&#39;mol&#39;]] # standardize mol objects df[&quot;standard_smiles&quot;] = [dm.standardize_smiles(x) for x in df[&#39;SMILES&#39;]] # standardize SMILES df[&quot;selfies&quot;] = [dm.to_selfies(x) for x in df[&#39;mol&#39;]] # generate SELFIES df[&quot;inchi&quot;] = [dm.to_inchi(x) for x in df[&#39;mol&#39;]] # Generating InChi df[&quot;inchikey&quot;] = [dm.to_inchikey(x) for x in df[&#39;mol&#39;]] # Generating InChIKey return df data_clean = preprocess_smiles(bbb_df) # Making a copy of the dataframe for later B3DB = data_clean data_clean.head() # Saving the data as B3DB; after where its found data_clean.to_csv(&#39;./data/B3DB.csv&#39;, index=False) . Merging the two datasets . The datasets would have ideally added up to 9846 molecules but that doesnt account for duplicates. Since the B3DB consists of data from across 50 studies, I assumed most of the molecules from MoleculeNet would appear in B3DB. . Counting the unique inchikey values confirmed this, leaving the final dataset with 8091 molecules. This number is lower than the sum of both dataframes but it adds 284 novel compounds to the final dataset. . # Loading the MoleculeNet dataset MolNet = pd.read_csv(&quot;data/MoleculeNet.csv&quot;) # concatenating both dataframes final_df = pd.concat([MolNet, B3DB]) . # Number of molecules before filtering for duplicates final_df.shape . (9846, 7) . # inchikey values should be unique to each molecule final_df.inchikey.value_counts() . FXHJGPDCPMCUKW-UHFFFAOYSA-N 4 UHSKFQJFRQCDBE-UHFFFAOYSA-N 4 CSIVCTHRYRVJCI-UHFFFAOYSA-N 4 UUQMNUMQCIQDMZ-UHFFFAOYSA-N 4 XHMYQXZLVLGNKX-UHFFFAOYSA-N 3 .. XYGVIBXOJOOCFR-BTJKTKAUSA-N 1 NINYZUDVKTUKIA-UHFFFAOYSA-N 1 BVCKFLJARNKCSS-ZJLJEUSSSA-N 1 HOCWPKXKMNXINF-CJIHYQBJSA-N 1 UWHAHBDBSBVMIY-VUXXLBMGSA-N 1 Name: inchikey, Length: 8091, dtype: int64 . # Dropping duplicates based on unique inchikey values final_df = final_df.drop_duplicates(subset=&#39;inchikey&#39;, keep=&quot;first&quot;) # Saving the final dataframe as b3_molecules final_df.to_csv(&#39;./data/b3_molecules.csv&#39;, index=False) . PCA analysis . PCA does not discard any variables and instead it reduces the number of dimensions by constructing principal components. Principal components describe variation and account for the varied influences of the original features. . Each SMILES string will have a morgan fingerprint generated. These fingerprints are binary 2048 bit arrays which describe molecular structure. . Three plots were made, the first using the MolNet dataset, the B3DB data next, and the combined data last. . # MolNet # compute ECFP6 Morgan fingerprints with radius 3 fps_molnet = [] for idx, row in MolNet.iterrows(): mol = Chem.MolFromSmiles(row[&quot;SMILES&quot;]) mol = Chem.AddHs(mol) fp = AllChem.GetMorganFingerprintAsBitVect(mol=mol, radius=3, nBits=2048, useChirality=True, useFeatures=False) fps_molnet.append(fp.ToBitString()) # Computing ECFP6 fingerprints for B3DB fps_B3DB = [] for idx, row in B3DB.iterrows(): mol = Chem.MolFromSmiles(row[&quot;SMILES&quot;]) mol = Chem.AddHs(mol) fp = AllChem.GetMorganFingerprintAsBitVect(mol=mol, radius=3, nBits=2048, useChirality=True, useFeatures=False) fps_B3DB.append(fp.ToBitString()) # Computing ECFP6 fingerprints for B3DB fps_final = [] for idx, row in final_df.iterrows(): mol = Chem.MolFromSmiles(row[&quot;SMILES&quot;]) mol = Chem.AddHs(mol) fp = AllChem.GetMorganFingerprintAsBitVect(mol=mol, radius=3, nBits=2048, useChirality=True, useFeatures=False) fps_final.append(fp.ToBitString()) # Create a numpy array and use the u1 datatype (uint8 8-bit unsigned integer) fps_arr_molnet = np.array([np.fromiter(fp, &quot;u1&quot;) for fp in fps_molnet]) fps_arr_B3DB = np.array([np.fromiter(fp, &quot;u1&quot;) for fp in fps_B3DB]) fps_arr_final = np.array([np.fromiter(fp, &quot;u1&quot;) for fp in fps_final]) # PCA on MolNet molecules molnet_fps = pd.DataFrame(fps_arr_molnet, index=MolNet.index) molnet_fps = pd.concat([MolNet, molnet_fps], axis=1) pca_molnet = PCA(n_components=2) arr_fp_embedded = pca.fit_transform(fps_arr_molnet) molnet_fps[&quot;PC_1&quot;] = arr_fp_embedded[:, 0] molnet_fps[&quot;PC_2&quot;] = arr_fp_embedded[:, 1] # PCA on B3DB molecules B3DB_fps = pd.DataFrame(fps_arr_B3DB, index=B3DB.index) B3DB_fps = pd.concat([B3DB, B3DB_fps], axis=1) pca_B3DB = PCA(n_components=2) arr_fp_embedded = pca.fit_transform(fps_arr_B3DB) B3DB_fps[&quot;PC_1&quot;] = arr_fp_embedded[:, 0] B3DB_fps[&quot;PC_2&quot;] = arr_fp_embedded[:, 1] # PCA on final set of molecules final_fps = pd.DataFrame(fps_arr_final, index=final_df.index) final_fps = pd.concat([final_df, final_fps], axis=1) pca_final = PCA(n_components=2) arr_fp_embedded = pca.fit_transform(fps_arr_final) final_fps[&quot;PC_1&quot;] = arr_fp_embedded[:, 0] final_fps[&quot;PC_2&quot;] = arr_fp_embedded[:, 1] . PCA Visualizations . PCA of molecules in the MolecularNet dataset . fig_molnet = plt.figure(figsize=(15, 10)) plt.xlabel(&quot;PC 1&quot;, fontsize=14) plt.ylabel(&quot;PC 2&quot;, fontsize=14) sns.scatterplot(data=molnet_fps, x=&quot;PC_1&quot;, y=&quot;PC_2&quot;, hue=&quot;BBB+/BBB-&quot;, palette=sns.color_palette([&quot;hotpink&quot;, &quot;dodgerblue&quot;]), linewidth=0.1, ).set(title=&#39;PCA of molecules in the MolecularNet dataset&#39;) plt.show() . PCA of molecules in the B3DB dataset . fig_B3DB = plt.figure(figsize=(15, 10)) plt.xlabel(&quot;PC 1&quot;, fontsize=14) plt.ylabel(&quot;PC 2&quot;, fontsize=14) sns.scatterplot(data=B3DB_fps, x=&quot;PC_1&quot;, y=&quot;PC_2&quot;, hue=&quot;BBB+/BBB-&quot;, palette=sns.color_palette([&quot;hotpink&quot;, &quot;dodgerblue&quot;]), linewidth=0.1, ).set(title=&#39;PCA of molecules in the B3DB dataset&#39;) plt.show() . PCA of molecules in the combined and filtered dataset . fig_final = plt.figure(figsize=(15, 10)) plt.xlabel(&quot;PC 1&quot;, fontsize=14) plt.ylabel(&quot;PC 2&quot;, fontsize=14) sns.scatterplot(data=final_fps, x=&quot;PC_1&quot;, y=&quot;PC_2&quot;, hue=&quot;BBB+/BBB-&quot;, palette=sns.color_palette([&quot;hotpink&quot;, &quot;dodgerblue&quot;]), linewidth=0.1, ).set(title=&#39;PCA of molecules in the combined and filtered dataset&#39;) plt.show() .",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/09/using-the-B3DB-dataset.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/09/using-the-B3DB-dataset.html",
            "date": " • Nov 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Preprocessing a dataset of blood brain barrier molecules with Datamol",
            "content": "SMILES (Simplified Molecular Input Line Entry System) is a standard notation representing the molecular structure of a compound as a string representation that can be understood by a computer. The SMILES notation consists of a handful of rules which allow for converting the string to an image or graph. SMILES can then be easily used for generating further representations to train machine learning models with. . import datamol as dm import pandas as pd pd.options.mode.chained_assignment = None # default=&#39;warn&#39; . BBBP_df = pd.read_csv(&quot;data/BBBP.csv&quot;) BBBP_df.head() . num name p_np smiles . 0 1 | Propanolol | 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | . 1 2 | Terbutylchlorambucil | 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | . 2 3 | 40730 | 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | . 3 4 | 24 | 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | . 4 5 | cloxacillin | 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | . The dataframe shows 4 named columns, including the &quot;num&quot; of the molecule, the name, a binary label for blood brain barrier permeability status &quot;p_np&quot;, and the SMILES string. . # The name and number can be dropped BBBP_df = BBBP_df.drop([&quot;num&quot;, &quot;name&quot;], axis=1) # Checking the data for null values BBBP_df[&quot;smiles&quot;].isnull().values.any() # Renaming the binary label to &quot;BBB+/BBB-&quot; for clarity BBBP_df.columns = [&#39;BBB+/BBB-&#39;, &#39;SMILES&#39;] . BBBP_df . BBB+/BBB- SMILES . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | . 1 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | . 2 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | . 3 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | . 4 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | . ... ... | ... | . 2045 1 | C1=C(Cl)C(=C(C2=C1NC(=O)C(N2)=O)[N+](=O)[O-])Cl | . 2046 1 | [C@H]3([N]2C1=C(C(=NC=N1)N)N=C2)[C@@H]([C@@H](... | . 2047 1 | [O+]1=N[N](C=C1[N-]C(NC2=CC=CC=C2)=O)C(CC3=CC=... | . 2048 1 | C1=C(OC)C(=CC2=C1C(=[N+](C(=C2CC)C)[NH-])C3=CC... | . 2049 1 | [N+](=NCC(=O)N[C@@H]([C@H](O)C1=CC=C([N+]([O-]... | . 2050 rows × 2 columns . Mols and smiles need to be sanitized as it will leave us with SMILES that are complete nonesense, for example, errors resulting from kekulization. . . RDkit generates the alternate position of double bonds, and then (in a second step they call &quot;aromatization&quot;) labels the ring as aromatic. In panel (2), there are three possible Lewis structures contributing to the actual structure (i.e. there is resonance), so the software would have to generate all three to be able to search for identical structures. [1] . Below is a function using datamol to preprocess the dataset, including steps to generate mol objects, SELFIES, inchi and inchikeys for each molecule. The function also standardizes mols and SMILES, drops NA values, and returns a dataframe. . def preprocess_smiles(df): df[&quot;mol&quot;] = [dm.to_mol(x) for x in df[&#39;SMILES&#39;]] # generating mols from SMILES df[&quot;mol&quot;] = [dm.fix_mol(x) for x in df[&#39;mol&#39;]] # Fixing mols df = df.dropna() # dropping NA values df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=False) for x in df[&#39;mol&#39;]] # sanitize mol objects df[&quot;mol&quot;] = [dm.standardize_mol(x, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True) for x in df[&#39;mol&#39;]] # standardize mol objects df[&quot;standard_smiles&quot;] = [dm.standardize_smiles(x) for x in df[&#39;SMILES&#39;]] # standardize SMILES df[&quot;selfies&quot;] = [dm.to_selfies(x) for x in df[&#39;mol&#39;]] # generate SELFIES df[&quot;inchi&quot;] = [dm.to_inchi(x) for x in df[&#39;mol&#39;]] # Generating InChi df[&quot;inchikey&quot;] = [dm.to_inchikey(x) for x in df[&#39;mol&#39;]] # Generating InChIKey return df . Running the function and taking a look at the outputs . data_clean = preprocess_smiles(BBBP_df) . data_clean.shape . (2039, 7) . data_clean.head() . BBB+/BBB- SMILES mol standard_smiles selfies inchi inchikey . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | . 1 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)(C)OC(=O)CCCc1ccc(N(CCCl)CCCl)cc1 | [C][C][Branch1][C][C][Branch1][C][C][O][C][=Br... | InChI=1S/C18H27Cl2NO2/c1-18(2,3)23-17(22)6-4-5... | SZXDOYFHSIIZCF-UHFFFAOYSA-N | . 2 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23 | [C][C][C][O][C][=C][Branch1][N][N][C][C][N][Br... | InChI=1S/C18H20FN3O4/c1-10-9-26-17-14-11(16(23... | GSDSWSVVBLHKDQ-UHFFFAOYSA-N | . 3 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(=O)NCCCOc1cccc(CN2CCCCC2)c1 | [C][C][=Branch1][C][=O][N][C][C][C][O][C][=C][... | InChI=1S/C17H26N2O2/c1-15(20)18-9-6-12-21-17-8... | FAXLXLJWHQJMPK-UHFFFAOYSA-N | . 4 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | Cc1onc(-c2ccccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[C@@H... | [C][C][O][N][=C][Branch1][#Branch2][C][=C][C][... | InChI=1S/C19H18ClN3O5S/c1-8-11(12(22-28-8)9-6-... | LQOLIRLGBULYKD-JKIFEVAISA-N | . The data contains a 3:1 ratio of positive to negeative labels, which creates a bias towards molecules with blood brain permeability properties. This may need to be addressed when training models. The next steps are to save the cleaned data for further analysis. . counts = data_clean[&#39;BBB+/BBB-&#39;].value_counts().to_dict() print(counts) . {1: 1560, 0: 479} . data_clean.to_csv(&#39;./data/MoleculeNet.csv&#39;, index=False) . References . Urbaczek, Sascha. A consistent cheminformatics framework for automated virtual screening. Ph.D. Thesis, Universität Hamburg, August 2014. URL: http://ediss.sub.uni-hamburg.de/volltexte/2015/7349/; URN: urn:nbn:de:gbv:18-73491; PDF via Semantic Scholar |",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/10/22/working-with-SMILES.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/10/22/working-with-SMILES.html",
            "date": " • Oct 22, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Writing a function in python to perform a restriction enzyme digest",
            "content": "Creating a restriction enzyme dictionary . Restriction enzymes are proteins produced by bacteria that cleave DNA at specific sites along the molecule. The enzyme functions on a specific, short nucleotide sequence and cuts the DNA only at that specific site, which is known as restriction site or target sequence. In the bacterial cell, restriction enzymes cleave foreign DNA, thus eliminating infecting organisms. The activity of a restriction enzyme can be defined by its recognition site on the DNA sequence and the position relative to the recognition site, at which it cuts the DNA. . # create enzyme dictionary restrictionEnzymes = {} # add &quot;bamH1&quot; and &quot;sma1&quot; enzymes, their target sequence, and position releative to the recognition site restrictionEnzymes[&#39;bamH1&#39;] = [&#39;ggatcc&#39;,0] restrictionEnzymes[&#39;sma1&#39;] = [&#39;cccggg&#39;,2] # a function to calculate the molecular weight of dna sequences def oligoMolecularWeight(sequence): # create a dictionairy of DNA basepair molecular weights dnaMolecularWeight = {&#39;a&#39;:313.2,&#39;c&#39;:289.2,&#39;t&#39;:304.2,&#39;g&#39;:329.2} # initialize molecular weight molecularWeight = 0.0 # iterate through DNA sequnce and update weight of sequence for base in sequence: molecularWeight += dnaMolecularWeight[base] return molecularWeight # the primary function for restriction digest def digest(sequence, enzyme): # set target sequence target = restrictionEnzymes[enzyme][0] # enzyme cut position relative to recognition site cutPosition = restrictionEnzymes[enzyme][1] # a list to collect DNA fragments fragments = [] # counter for the position of the last restriction site; beginning of sequence found = 0 # a variable to store the position of the last cut; end of sequence lastCut = found # variable to set where to search for the next site from searchFrom = lastCut while found != -1: found = sequence.find(target, searchFrom) if found != -1: fragment = sequence[lastCut:found+cutPosition] mwt = oligoMolecularWeight(fragment) fragments.append((fragment,mwt)) else: fragment = sequence[lastCut:] mwt = oligoMolecularWeight(fragment) fragments.append((fragment,mwt)) lastCut = found + cutPosition searchFrom = lastCut + 1 return fragments . Running the function on a test sequence results in the following: . digestSequence = &quot;gcgatgctaggatccgcgatcgcgtacgatcgtacgcggtacggacggatccttctc&quot; . digested_dna = digest(digestSequence,&#39;bamH1&#39;) . print(digested_dna) . [(&#39;gcgatgcta&#39;, 2800.7999999999997), (&#39;ggatccgcgatcgcgtacgatcgtacgcggtacggac&#39;, 11478.400000000005), (&#39;ggatccttctc&#39;, 3345.1999999999994)] .",
            "url": "https://www.neongenes.com//python/bioinformatics/restriction%20enzyme/function/2021/10/18/restriction-enzyme-digest.html",
            "relUrl": "/python/bioinformatics/restriction%20enzyme/function/2021/10/18/restriction-enzyme-digest.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "A primer on Apache Airflow",
            "content": "What is airflow? . Airflow is a platform used to author, schedule, and monitor workflows. It’s essentially a queuing system that runs on a metadata database and a scheduler that runs tasks. Workflows are written as Directed Acyclic Graphs (DAGs). A workflow and DAG are interchangeable. . What are DAGs? . A DAG is a collection of tasks you want to run and are organized in a way that illustrates dependencies and relationships between tasks. . The image below shows how a DAG is a unidirectional, acyclic graph, where each node in the graph is a task and edges define dependencies among tasks. There is no case where you should be able to go backwards from a forward node to one that&#39;s already been executed. . . A DAG can be broken up into smaller and smaller jobs and gives the user full control by generating dynamic pipelines written in code. Airflow DAGs are also extensible and can scale. DAGs are powerful because they allow for collaborative, manageable, and testable workflows. A bonus is that Airflow is developed in python and can interface with any python API. . . The image above shows how Airflow divides the tasks into branches so that if one fails, there is still output from the other. Also, the processing time is reduced as parallel computing occurs. The chances of failure should decrease overall as each task is independent. . How are tasks executed? . An operator represents a single task in a workflow that helps carry out your task (running a python function for example). Operators determine what actually gets to be done when your dag runs. A task is an operator when instantiated. It is something on which the worker works upon. . Airflow Architecture . Metadata — is a relational database with info on task state, such as the top ten tasks consuming the most memory, it contains all data pertaining to jobs currently running as well as historical data. . | Scheduler — decides which task to run, when, and in what order. . | Web server— the UI which is essentially a flask app that talks to the metadata. . | Executor — performs the task at ground level. The executor is a message queuing process which figures out which workers will execute which tasks. The default is the sequential executor — which cannot run tasks in parallel — meaning it can’t be used for production level code. The local executor can be used too which will run tasks till all resources on the server are at capacity. This is good for a moderate amount of DAGs. Both of these are used in single node clusters and therefore cannot be used to scaled. . | Multi node clusters — have the same components and only the scheduler and web server are placed in the same node (master), the workers are placed in a separate instance. This set up works well because it allows for scaling by letting you add more multi-node clusters (celery is the executor of choice here for python). . | . If you&#39;re not dealing with terabytes of data then it&#39;s better to have the scheduler, web server, and executor together in the master node/cluster. The downside is that this single cluster approach runs everything on the same machine, so if you make a change to a DAG/scheduler, then you need to restart the entire workflow — even tasks that were in the process of executing. Celery avoids this. . . If you do build a distributed workflow with celery then a queuing system component is needed (like Redis). For local workflows, the queuing is handled by the system. . The life cycle of a task . The scheduler periodically checks the DAG folder to see if there are any DAGS that need to be run. . | If any DAGS are found pending execution, the scheduler creates a diagram for it, which is an instantiation of a DAG in real time. . | The scheduler will update the DAG state to running in the metadata and the tasks will execute. . | The scheduler then reads the DAG and puts the tasks in order of execution into the queuing system in the form of a message. Each message contains info like DAG ID, TASK ID, and function to be executed. . | The status of these tasks changes to queued at that point. . | The executor then begins to execute tasks and sends fail/success messages for the tasks to the metadata. . | The scheduler finally updates the status of the diagram when all tasks have run to success or fail. . |",
            "url": "https://www.neongenes.com//data-engineering/python/airflow/dag/2021/04/20/airflow-primer.html",
            "relUrl": "/data-engineering/python/airflow/dag/2021/04/20/airflow-primer.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://www.neongenes.com//markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://www.neongenes.com//about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.neongenes.com//robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}