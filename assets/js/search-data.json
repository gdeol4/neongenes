{
  
    
        "post0": {
            "title": "Scaffold splitting and initial model training using chemprop",
            "content": "import chemprop import pandas as pd import datamol as dm from rdkit import Chem from rdkit.Chem.Scaffolds import MurckoScaffold pd.options.mode.chained_assignment = None # default=&#39;warn&#39; # loading the datasets MolNet = pd.read_csv(&quot;data/MoleculeNet.csv&quot;) B3DB = pd.read_csv(&quot;data/B3DB.csv&quot;) b3_molecules = pd.read_csv(&quot;data/b3_molecules.csv&quot;) . WARNING:root:No normalization for BCUT2D_MWHI WARNING:root:No normalization for BCUT2D_MWLOW WARNING:root:No normalization for BCUT2D_CHGHI WARNING:root:No normalization for BCUT2D_CHGLO WARNING:root:No normalization for BCUT2D_LOGPHI WARNING:root:No normalization for BCUT2D_LOGPLOW WARNING:root:No normalization for BCUT2D_MRHI WARNING:root:No normalization for BCUT2D_MRLOW . def scaffold_split(df): df[&quot;mol&quot;] = [Chem.MolFromSmiles(x) for x in df[&quot;standard_smiles&quot;]] # generating moles from the standard_smiles column df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=True) for x in df[&#39;mol&#39;]] # sanitize mol objects df = df.dropna() # dropping NA values df[&quot;scaffold&quot;] = [MurckoScaffold.GetScaffoldForMol(x) for x in df[&quot;mol&quot;]] # generating scaffolds from mol object df[&quot;mol_scaffold_generic&quot;] = [MurckoScaffold.MakeScaffoldGeneric(x) for x in df[&quot;scaffold&quot;]] # generalizing scaffolds # convert the generic scaffold mol object back to a SMILES string format df[&quot;smiles_scaffold_generic&quot;] = [Chem.CanonSmiles(Chem.MolToSmiles(x)) for x in df[&quot;mol_scaffold_generic&quot;]] return df . # results of the scaffold generating function data_split = scaffold_split(b3_molecules) data_split.head(1) . BBB+/BBB- SMILES mol standard_smiles selfies inchi inchikey scaffold mol_scaffold_generic smiles_scaffold_generic . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | C1CCC2CCCCC2C1 | . # the data prior to processing MolNet.head(1) . BBB+/BBB- SMILES mol standard_smiles selfies inchi inchikey . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | . # A function to process the data for use with the chemprop library def chemprop_prep(df, filename): df = df.drop([&quot;mol&quot;, &quot;SMILES&quot;, &quot;selfies&quot;, &quot;inchi&quot;, &quot;inchikey&quot;], axis=1) # drop all columns except the smiles and target df[&quot;smiles&quot;] = df[&quot;standard_smiles&quot;] # use standard smiles inplace of smiles df = df.drop([&quot;standard_smiles&quot;], axis=1) # drop this column now df = df[[&quot;smiles&quot;, &quot;BBB+/BBB-&quot;]] # reorder the columns with smiles first and target second df.to_csv(&#39;./data/&#39; + filename + &#39;.csv&#39;, index=False) # save the file return df . # Processing the three different datasets molnet_chemprop = chemprop_prep(MolNet, &#39;molnet_chemprop&#39;) B3DB_chemprop = chemprop_prep(B3DB, &#39;B3DB_chemprep&#39;) b3_mol_chemprop = chemprop_prep(b3_molecules, &#39;b3_mol_chemprop&#39;) . # results of processing molnet_chemprop.head(1) . smiles BBB+/BBB- . 0 CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | 1 | . smiles = &quot;CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC&quot; # convert SMILES string to RDKit mol object mol = Chem.MolFromSmiles(smiles) # create RDKit mol object corresponding to Bemis-Murcko scaffold of original compound mol_scaffold = MurckoScaffold.GetScaffoldForMol(mol) # make the scaffold generic by replacing all atoms with carbons and all bonds with single bonds mol_scaffold_generic = MurckoScaffold.MakeScaffoldGeneric(mol_scaffold) # convert the generic scaffold mol object back to a SMILES string format smiles_scaffold_generic = Chem.CanonSmiles(Chem.MolToSmiles(mol_scaffold_generic)) # display compound and its generic Bemis-Murcko scaffold display(mol) print(smiles) display(mol_scaffold_generic) print(smiles_scaffold_generic) . CN1CCCCC1CCN2C3=CC=CC=C3SC4=C2C=C(C=C4)SC . C1CCC(CCC2C3CCCCC3CC3CCCCC32)CC1 . arguments = [ &#39;--data_path&#39;, &#39;./data/molnet_chemprop.csv&#39;, &#39;--dataset_type&#39;, &#39;classification&#39;, &#39;--save_dir&#39;, &#39;./data/chemprop_checkpoints/&#39;, &#39;--split_type&#39;, &#39;scaffold_balanced&#39;, # &#39;--separate_val_path&#39;, &#39;./data/chemprop_B3DB.csv&#39;, &#39;--num_folds&#39;, &#39;10&#39;, &#39;--class_balance&#39;, &#39;--features_generator&#39;, &#39;rdkit_2d_normalized&#39;, &#39;--no_features_scaling&#39;, &#39;--quiet&#39; ] args = chemprop.args.TrainArgs().parse_args(arguments) mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training) . 2039it [00:00, 119828.86it/s] 100%|██████████| 2039/2039 [02:20&lt;00:00, 14.53it/s] 100%|██████████| 2039/2039 [00:00&lt;00:00, 67907.37it/s] Fold 0 100%|██████████| 2039/2039 [00:00&lt;00:00, 3649.46it/s] 100%|██████████| 30/30 [01:51&lt;00:00, 3.73s/it] Model 0 best validation auc = 0.926059 on epoch 8 Model 0 test auc = 0.928767 Ensemble test auc = 0.928767 Fold 1 100%|██████████| 2039/2039 [00:00&lt;00:00, 3489.41it/s] 100%|██████████| 30/30 [01:51&lt;00:00, 3.72s/it] Model 0 best validation auc = 0.886265 on epoch 19 Model 0 test auc = 0.903879 Ensemble test auc = 0.903879 Fold 2 100%|██████████| 2039/2039 [00:00&lt;00:00, 3452.67it/s] 100%|██████████| 30/30 [01:46&lt;00:00, 3.55s/it] Model 0 best validation auc = 0.917212 on epoch 29 Model 0 test auc = 0.955724 Ensemble test auc = 0.955724 Fold 3 100%|██████████| 2039/2039 [00:00&lt;00:00, 3602.29it/s] 100%|██████████| 30/30 [01:56&lt;00:00, 3.88s/it] Model 0 best validation auc = 0.886939 on epoch 5 Model 0 test auc = 0.862450 Ensemble test auc = 0.862450 Fold 4 100%|██████████| 2039/2039 [00:00&lt;00:00, 3449.09it/s] 100%|██████████| 30/30 [01:47&lt;00:00, 3.59s/it] Model 0 best validation auc = 0.897674 on epoch 3 Model 0 test auc = 0.890246 Ensemble test auc = 0.890246 Fold 5 100%|██████████| 2039/2039 [00:00&lt;00:00, 3590.55it/s] 100%|██████████| 30/30 [01:42&lt;00:00, 3.43s/it] Model 0 best validation auc = 0.977661 on epoch 7 Model 0 test auc = 0.892326 Ensemble test auc = 0.892326 Fold 6 100%|██████████| 2039/2039 [00:00&lt;00:00, 3417.71it/s] 100%|██████████| 30/30 [01:48&lt;00:00, 3.61s/it] Model 0 best validation auc = 0.924837 on epoch 29 Model 0 test auc = 0.886606 Ensemble test auc = 0.886606 Fold 7 100%|██████████| 2039/2039 [00:00&lt;00:00, 3561.41it/s] 100%|██████████| 30/30 [01:54&lt;00:00, 3.82s/it] Model 0 best validation auc = 0.946760 on epoch 24 Model 0 test auc = 0.951849 Ensemble test auc = 0.951849 Fold 8 100%|██████████| 2039/2039 [00:00&lt;00:00, 3527.51it/s] 100%|██████████| 30/30 [01:52&lt;00:00, 3.75s/it] Model 0 best validation auc = 0.890004 on epoch 29 Model 0 test auc = 0.906486 Ensemble test auc = 0.906486 Fold 9 100%|██████████| 2039/2039 [00:00&lt;00:00, 3542.86it/s] 100%|██████████| 30/30 [01:46&lt;00:00, 3.56s/it] Model 0 best validation auc = 0.899198 on epoch 22 Model 0 test auc = 0.937866 Ensemble test auc = 0.937866 10-fold cross validation Seed 0 ==&gt; test auc = 0.928767 Seed 1 ==&gt; test auc = 0.903879 Seed 2 ==&gt; test auc = 0.955724 Seed 3 ==&gt; test auc = 0.862450 Seed 4 ==&gt; test auc = 0.890246 Seed 5 ==&gt; test auc = 0.892326 Seed 6 ==&gt; test auc = 0.886606 Seed 7 ==&gt; test auc = 0.951849 Seed 8 ==&gt; test auc = 0.906486 Seed 9 ==&gt; test auc = 0.937866 Overall test auc = 0.911620 +/- 0.029164 Elapsed time = 0:20:54 . arguments = [ &#39;--data_path&#39;, &#39;./data/molnet_chemprop.csv&#39;, &#39;--dataset_type&#39;, &#39;classification&#39;, &#39;--save_dir&#39;, &#39;./data/chemprop_checkpoints/&#39;, &#39;--split_type&#39;, &#39;scaffold_balanced&#39;, # &#39;--separate_val_path&#39;, &#39;./data/chemprop_B3DB.csv&#39;, &#39;--num_folds&#39;, &#39;10&#39;, &#39;--class_balance&#39;, &#39;--features_generator&#39;, &#39;rdkit_2d_normalized&#39;, &#39;--no_features_scaling&#39;, &#39;--quiet&#39;, &#39;--epochs&#39;, &#39;100&#39; ] args = chemprop.args.TrainArgs().parse_args(arguments) mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training) . 2039it [00:00, 119820.47it/s] 100%|██████████| 2039/2039 [02:19&lt;00:00, 14.63it/s] 100%|██████████| 2039/2039 [00:00&lt;00:00, 72760.41it/s] Fold 0 100%|██████████| 2039/2039 [00:00&lt;00:00, 3660.57it/s] 100%|██████████| 100/100 [05:48&lt;00:00, 3.48s/it] Model 0 best validation auc = 0.926682 on epoch 8 Model 0 test auc = 0.929177 Ensemble test auc = 0.929177 Fold 1 100%|██████████| 2039/2039 [00:00&lt;00:00, 3486.36it/s] 100%|██████████| 100/100 [05:56&lt;00:00, 3.57s/it] Model 0 best validation auc = 0.895276 on epoch 67 Model 0 test auc = 0.852848 Ensemble test auc = 0.852848 Fold 2 100%|██████████| 2039/2039 [00:00&lt;00:00, 3494.12it/s] 100%|██████████| 100/100 [05:50&lt;00:00, 3.50s/it] Model 0 best validation auc = 0.932624 on epoch 39 Model 0 test auc = 0.944112 Ensemble test auc = 0.944112 Fold 3 100%|██████████| 2039/2039 [00:00&lt;00:00, 3524.44it/s] 100%|██████████| 100/100 [06:18&lt;00:00, 3.78s/it] Model 0 best validation auc = 0.886531 on epoch 5 Model 0 test auc = 0.862913 Ensemble test auc = 0.862913 Fold 4 100%|██████████| 2039/2039 [00:00&lt;00:00, 3468.74it/s] 100%|██████████| 100/100 [05:39&lt;00:00, 3.40s/it] Model 0 best validation auc = 0.897674 on epoch 3 Model 0 test auc = 0.890246 Ensemble test auc = 0.890246 Fold 5 100%|██████████| 2039/2039 [00:00&lt;00:00, 3527.38it/s] 100%|██████████| 100/100 [05:06&lt;00:00, 3.07s/it] Model 0 best validation auc = 0.977892 on epoch 7 Model 0 test auc = 0.893487 Ensemble test auc = 0.893487 Fold 6 100%|██████████| 2039/2039 [00:00&lt;00:00, 3832.74it/s] 100%|██████████| 100/100 [05:23&lt;00:00, 3.23s/it] Model 0 best validation auc = 0.925359 on epoch 42 Model 0 test auc = 0.881697 Ensemble test auc = 0.881697 Fold 7 100%|██████████| 2039/2039 [00:00&lt;00:00, 3797.06it/s] 100%|██████████| 100/100 [15:55:05&lt;00:00, 573.05s/it] Model 0 best validation auc = 0.958971 on epoch 24 Model 0 test auc = 0.941933 Ensemble test auc = 0.941933 Fold 8 100%|██████████| 2039/2039 [00:00&lt;00:00, 3446.91it/s] 100%|██████████| 100/100 [05:52&lt;00:00, 3.53s/it] Model 0 best validation auc = 0.896662 on epoch 39 Model 0 test auc = 0.920437 Ensemble test auc = 0.920437 Fold 9 100%|██████████| 2039/2039 [00:00&lt;00:00, 3790.66it/s] 100%|██████████| 100/100 [06:04&lt;00:00, 3.64s/it] Model 0 best validation auc = 0.906584 on epoch 73 Model 0 test auc = 0.917494 Ensemble test auc = 0.917494 10-fold cross validation Seed 0 ==&gt; test auc = 0.929177 Seed 1 ==&gt; test auc = 0.852848 Seed 2 ==&gt; test auc = 0.944112 Seed 3 ==&gt; test auc = 0.862913 Seed 4 ==&gt; test auc = 0.890246 Seed 5 ==&gt; test auc = 0.893487 Seed 6 ==&gt; test auc = 0.881697 Seed 7 ==&gt; test auc = 0.941933 Seed 8 ==&gt; test auc = 0.920437 Seed 9 ==&gt; test auc = 0.917494 Overall test auc = 0.903435 +/- 0.030385 Elapsed time = 16:49:39 .",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/12/data-splitting-and-training.ipynb.html",
            "date": " • Nov 12, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Building a drug discovery web app - the roadmap",
            "content": "My goal: . The end goal for this project is to build a web app dashboard to monitor the accuracy of machine learning models on generating and classifying molecules with blood brain barrier permeability. .",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/drug%20discovery/rdkit/2021/11/11/project-1-machine-learning.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/drug%20discovery/rdkit/2021/11/11/project-1-machine-learning.html",
            "date": " • Nov 11, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Processing the B3DB brain-blood barrier dataset",
            "content": "Gathering data on blood brain barrier permeability . This post is a part of a fullstack machine learning web app project and this notebook contains the data needed to build and train the models. The goal in this post is to clean and preprocess the B3DB dataset and merge it with the blood brain permeability data from MoleculeNet. The merged dataset should contain nearly 10,000 molecules labeled with their ability to pass through the blood brain barrier. The notebook provided in the B3DB repository also contains an interesting PCA plot, which is a good starting place for EDA when the data is merged. . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from rdkit import Chem from rdkit.Chem import AllChem from sklearn.decomposition import PCA import datamol as dm %matplotlib inline . Removing, remapping, and creating features . This dataset has features that can be dropped since they won&#39;t contribute to model training. Some features are then calculated from the SMILES data. . # reading in the data bbb_df = pd.read_csv(&quot;data/B3DB_classification.tsv&quot;, sep=&quot; t&quot;) # dropping columns bbb_df = bbb_df.drop([&quot;CID&quot;, &quot;logBB&quot;, &quot;Inchi&quot;, &quot;threshold&quot;, &quot;reference&quot;, &quot;group&quot;, &quot;comments&quot;, &quot;NO.&quot;, &quot;IUPAC_name&quot;, &quot;compound_name&quot;], axis=1) # mapping given labels to binary bbb_df[&#39;BBB+/BBB-&#39;] = bbb_df[&#39;BBB+/BBB-&#39;].map({&#39;BBB+&#39;: 1, &#39;BBB-&#39;: 0}) . Feature generation . The function below processes and generates features such as mol objects, selfies, inchi, and inchikeys for each molecule using the datamol library. . # preprocessing function for molecules def preprocess_smiles(df): df[&quot;mol&quot;] = [dm.to_mol(x) for x in df[&#39;SMILES&#39;]] # generating mols from SMILES df[&quot;mol&quot;] = [dm.fix_mol(x) for x in df[&#39;mol&#39;]] # Fixing mols df = df.dropna() # dropping NA values df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=False) for x in df[&#39;mol&#39;]] # sanitize mol objects df[&quot;mol&quot;] = [dm.standardize_mol(x, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True) for x in df[&#39;mol&#39;]] # standardize mol objects df[&quot;standard_smiles&quot;] = [dm.standardize_smiles(x) for x in df[&#39;SMILES&#39;]] # standardize SMILES df[&quot;selfies&quot;] = [dm.to_selfies(x) for x in df[&#39;mol&#39;]] # generate SELFIES df[&quot;inchi&quot;] = [dm.to_inchi(x) for x in df[&#39;mol&#39;]] # Generating InChi df[&quot;inchikey&quot;] = [dm.to_inchikey(x) for x in df[&#39;mol&#39;]] # Generating InChIKey return df data_clean = preprocess_smiles(bbb_df) # Making a copy of the dataframe for later B3DB = data_clean data_clean.head() # Saving the data as B3DB; after where its found data_clean.to_csv(&#39;./data/B3DB.csv&#39;, index=False) . Merging the two datasets . The datasets would have ideally added up to 9846 molecules but that doesnt account for duplicates. Since the B3DB consists of data from across 50 studies, I assumed most of the molecules from MoleculeNet would appear in B3DB. . Counting the unique inchikey values confirmed this, leaving the final dataset with 8091 molecules. This number is lower than the sum of both dataframes but it adds 284 novel compounds to the final dataset. . # Loading the MoleculeNet dataset MolNet = pd.read_csv(&quot;data/MoleculeNet.csv&quot;) # concatenating both dataframes final_df = pd.concat([MolNet, B3DB]) . # Number of molecules before filtering for duplicates final_df.shape . (9846, 7) . # inchikey values should be unique to each molecule final_df.inchikey.value_counts() . FXHJGPDCPMCUKW-UHFFFAOYSA-N 4 UHSKFQJFRQCDBE-UHFFFAOYSA-N 4 CSIVCTHRYRVJCI-UHFFFAOYSA-N 4 UUQMNUMQCIQDMZ-UHFFFAOYSA-N 4 XHMYQXZLVLGNKX-UHFFFAOYSA-N 3 .. XYGVIBXOJOOCFR-BTJKTKAUSA-N 1 NINYZUDVKTUKIA-UHFFFAOYSA-N 1 BVCKFLJARNKCSS-ZJLJEUSSSA-N 1 HOCWPKXKMNXINF-CJIHYQBJSA-N 1 UWHAHBDBSBVMIY-VUXXLBMGSA-N 1 Name: inchikey, Length: 8091, dtype: int64 . # Dropping duplicates based on unique inchikey values final_df = final_df.drop_duplicates(subset=&#39;inchikey&#39;, keep=&quot;first&quot;) # Saving the final dataframe as b3_molecules final_df.to_csv(&#39;./data/b3_molecules.csv&#39;, index=False) . PCA analysis . PCA does not discard any variables and instead it reduces the number of dimensions by constructing principal components. Principal components describe variation and account for the varied influences of the original features. . Each SMILES string will have a morgan fingerprint generated. These fingerprints are binary 2048 bit arrays which describe molecular structure. . Three plots were made, the first using the MolNet dataset, the B3DB data next, and the combined data last. . # MolNet # compute ECFP6 Morgan fingerprints with radius 3 fps_molnet = [] for idx, row in MolNet.iterrows(): mol = Chem.MolFromSmiles(row[&quot;SMILES&quot;]) mol = Chem.AddHs(mol) fp = AllChem.GetMorganFingerprintAsBitVect(mol=mol, radius=3, nBits=2048, useChirality=True, useFeatures=False) fps_molnet.append(fp.ToBitString()) # Computing ECFP6 fingerprints for B3DB fps_B3DB = [] for idx, row in B3DB.iterrows(): mol = Chem.MolFromSmiles(row[&quot;SMILES&quot;]) mol = Chem.AddHs(mol) fp = AllChem.GetMorganFingerprintAsBitVect(mol=mol, radius=3, nBits=2048, useChirality=True, useFeatures=False) fps_B3DB.append(fp.ToBitString()) # Computing ECFP6 fingerprints for B3DB fps_final = [] for idx, row in final_df.iterrows(): mol = Chem.MolFromSmiles(row[&quot;SMILES&quot;]) mol = Chem.AddHs(mol) fp = AllChem.GetMorganFingerprintAsBitVect(mol=mol, radius=3, nBits=2048, useChirality=True, useFeatures=False) fps_final.append(fp.ToBitString()) # Create a numpy array and use the u1 datatype (uint8 8-bit unsigned integer) fps_arr_molnet = np.array([np.fromiter(fp, &quot;u1&quot;) for fp in fps_molnet]) fps_arr_B3DB = np.array([np.fromiter(fp, &quot;u1&quot;) for fp in fps_B3DB]) fps_arr_final = np.array([np.fromiter(fp, &quot;u1&quot;) for fp in fps_final]) # PCA on MolNet molecules molnet_fps = pd.DataFrame(fps_arr_molnet, index=MolNet.index) molnet_fps = pd.concat([MolNet, molnet_fps], axis=1) pca_molnet = PCA(n_components=2) arr_fp_embedded = pca.fit_transform(fps_arr_molnet) molnet_fps[&quot;PC_1&quot;] = arr_fp_embedded[:, 0] molnet_fps[&quot;PC_2&quot;] = arr_fp_embedded[:, 1] # PCA on B3DB molecules B3DB_fps = pd.DataFrame(fps_arr_B3DB, index=B3DB.index) B3DB_fps = pd.concat([B3DB, B3DB_fps], axis=1) pca_B3DB = PCA(n_components=2) arr_fp_embedded = pca.fit_transform(fps_arr_B3DB) B3DB_fps[&quot;PC_1&quot;] = arr_fp_embedded[:, 0] B3DB_fps[&quot;PC_2&quot;] = arr_fp_embedded[:, 1] # PCA on final set of molecules final_fps = pd.DataFrame(fps_arr_final, index=final_df.index) final_fps = pd.concat([final_df, final_fps], axis=1) pca_final = PCA(n_components=2) arr_fp_embedded = pca.fit_transform(fps_arr_final) final_fps[&quot;PC_1&quot;] = arr_fp_embedded[:, 0] final_fps[&quot;PC_2&quot;] = arr_fp_embedded[:, 1] . PCA Visualizations . PCA of molecules in the MolecularNet dataset . fig_molnet = plt.figure(figsize=(15, 10)) plt.xlabel(&quot;PC 1&quot;, fontsize=14) plt.ylabel(&quot;PC 2&quot;, fontsize=14) sns.scatterplot(data=molnet_fps, x=&quot;PC_1&quot;, y=&quot;PC_2&quot;, hue=&quot;BBB+/BBB-&quot;, palette=sns.color_palette([&quot;hotpink&quot;, &quot;dodgerblue&quot;]), linewidth=0.1, ).set(title=&#39;PCA of molecules in the MolecularNet dataset&#39;) plt.show() . PCA of molecules in the B3DB dataset . fig_B3DB = plt.figure(figsize=(15, 10)) plt.xlabel(&quot;PC 1&quot;, fontsize=14) plt.ylabel(&quot;PC 2&quot;, fontsize=14) sns.scatterplot(data=B3DB_fps, x=&quot;PC_1&quot;, y=&quot;PC_2&quot;, hue=&quot;BBB+/BBB-&quot;, palette=sns.color_palette([&quot;hotpink&quot;, &quot;dodgerblue&quot;]), linewidth=0.1, ).set(title=&#39;PCA of molecules in the B3DB dataset&#39;) plt.show() . PCA of molecules in the combined and filtered dataset . fig_final = plt.figure(figsize=(15, 10)) plt.xlabel(&quot;PC 1&quot;, fontsize=14) plt.ylabel(&quot;PC 2&quot;, fontsize=14) sns.scatterplot(data=final_fps, x=&quot;PC_1&quot;, y=&quot;PC_2&quot;, hue=&quot;BBB+/BBB-&quot;, palette=sns.color_palette([&quot;hotpink&quot;, &quot;dodgerblue&quot;]), linewidth=0.1, ).set(title=&#39;PCA of molecules in the combined and filtered dataset&#39;) plt.show() .",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/09/using-the-B3DB-dataset.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/09/using-the-B3DB-dataset.html",
            "date": " • Nov 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Preprocessing a dataset of blood brain barrier molecules with Datamol",
            "content": "SMILES (Simplified Molecular Input Line Entry System) is a standard notation representing the molecular structure of a compound as a string representation that can be understood by a computer. The SMILES notation consists of a handful of rules which allow for converting the string to an image or graph. SMILES can then be easily used for generating further representations to train machine learning models with. . import datamol as dm import pandas as pd pd.options.mode.chained_assignment = None # default=&#39;warn&#39; . BBBP_df = pd.read_csv(&quot;data/BBBP.csv&quot;) BBBP_df.head() . num name p_np smiles . 0 1 | Propanolol | 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | . 1 2 | Terbutylchlorambucil | 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | . 2 3 | 40730 | 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | . 3 4 | 24 | 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | . 4 5 | cloxacillin | 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | . The dataframe shows 4 named columns, including the &quot;num&quot; of the molecule, the name, a binary label for blood brain barrier permeability status &quot;p_np&quot;, and the SMILES string. . # The name and number can be dropped BBBP_df = BBBP_df.drop([&quot;num&quot;, &quot;name&quot;], axis=1) # Checking the data for null values BBBP_df[&quot;smiles&quot;].isnull().values.any() # Renaming the binary label to &quot;BBB+/BBB-&quot; for clarity BBBP_df.columns = [&#39;BBB+/BBB-&#39;, &#39;SMILES&#39;] . BBBP_df . BBB+/BBB- SMILES . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | . 1 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | . 2 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | . 3 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | . 4 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | . ... ... | ... | . 2045 1 | C1=C(Cl)C(=C(C2=C1NC(=O)C(N2)=O)[N+](=O)[O-])Cl | . 2046 1 | [C@H]3([N]2C1=C(C(=NC=N1)N)N=C2)[C@@H]([C@@H](... | . 2047 1 | [O+]1=N[N](C=C1[N-]C(NC2=CC=CC=C2)=O)C(CC3=CC=... | . 2048 1 | C1=C(OC)C(=CC2=C1C(=[N+](C(=C2CC)C)[NH-])C3=CC... | . 2049 1 | [N+](=NCC(=O)N[C@@H]([C@H](O)C1=CC=C([N+]([O-]... | . 2050 rows × 2 columns . Mols and smiles need to be sanitized as it will leave us with SMILES that are complete nonesense, for example, errors resulting from kekulization. . . RDkit generates the alternate position of double bonds, and then (in a second step they call &quot;aromatization&quot;) labels the ring as aromatic. In panel (2), there are three possible Lewis structures contributing to the actual structure (i.e. there is resonance), so the software would have to generate all three to be able to search for identical structures. [1] . Below is a function using datamol to preprocess the dataset, including steps to generate mol objects, SELFIES, inchi and inchikeys for each molecule. The function also standardizes mols and SMILES, drops NA values, and returns a dataframe. . def preprocess_smiles(df): df[&quot;mol&quot;] = [dm.to_mol(x) for x in df[&#39;SMILES&#39;]] # generating mols from SMILES df[&quot;mol&quot;] = [dm.fix_mol(x) for x in df[&#39;mol&#39;]] # Fixing mols df = df.dropna() # dropping NA values df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=False) for x in df[&#39;mol&#39;]] # sanitize mol objects df[&quot;mol&quot;] = [dm.standardize_mol(x, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True) for x in df[&#39;mol&#39;]] # standardize mol objects df[&quot;standard_smiles&quot;] = [dm.standardize_smiles(x) for x in df[&#39;SMILES&#39;]] # standardize SMILES df[&quot;selfies&quot;] = [dm.to_selfies(x) for x in df[&#39;mol&#39;]] # generate SELFIES df[&quot;inchi&quot;] = [dm.to_inchi(x) for x in df[&#39;mol&#39;]] # Generating InChi df[&quot;inchikey&quot;] = [dm.to_inchikey(x) for x in df[&#39;mol&#39;]] # Generating InChIKey return df . Running the function and taking a look at the outputs . data_clean = preprocess_smiles(BBBP_df) . data_clean.shape . (2039, 7) . data_clean.head() . BBB+/BBB- SMILES mol standard_smiles selfies inchi inchikey . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | . 1 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)(C)OC(=O)CCCc1ccc(N(CCCl)CCCl)cc1 | [C][C][Branch1][C][C][Branch1][C][C][O][C][=Br... | InChI=1S/C18H27Cl2NO2/c1-18(2,3)23-17(22)6-4-5... | SZXDOYFHSIIZCF-UHFFFAOYSA-N | . 2 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23 | [C][C][C][O][C][=C][Branch1][N][N][C][C][N][Br... | InChI=1S/C18H20FN3O4/c1-10-9-26-17-14-11(16(23... | GSDSWSVVBLHKDQ-UHFFFAOYSA-N | . 3 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(=O)NCCCOc1cccc(CN2CCCCC2)c1 | [C][C][=Branch1][C][=O][N][C][C][C][O][C][=C][... | InChI=1S/C17H26N2O2/c1-15(20)18-9-6-12-21-17-8... | FAXLXLJWHQJMPK-UHFFFAOYSA-N | . 4 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | Cc1onc(-c2ccccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[C@@H... | [C][C][O][N][=C][Branch1][#Branch2][C][=C][C][... | InChI=1S/C19H18ClN3O5S/c1-8-11(12(22-28-8)9-6-... | LQOLIRLGBULYKD-JKIFEVAISA-N | . The data contains a 3:1 ratio of positive to negeative labels, which creates a bias towards molecules with blood brain permeability properties. This may need to be addressed when training models. The next steps are to save the cleaned data for further analysis. . counts = data_clean[&#39;BBB+/BBB-&#39;].value_counts().to_dict() print(counts) . {1: 1560, 0: 479} . data_clean.to_csv(&#39;./data/MoleculeNet.csv&#39;, index=False) . References . Urbaczek, Sascha. A consistent cheminformatics framework for automated virtual screening. Ph.D. Thesis, Universität Hamburg, August 2014. URL: http://ediss.sub.uni-hamburg.de/volltexte/2015/7349/; URN: urn:nbn:de:gbv:18-73491; PDF via Semantic Scholar |",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/10/22/working-with-SMILES.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/10/22/working-with-SMILES.html",
            "date": " • Oct 22, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Writing a function in python to perform a restriction enzyme digest",
            "content": "Creating a restriction enzyme dictionary . Restriction enzymes are proteins produced by bacteria that cleave DNA at specific sites along the molecule. The enzyme functions on a specific, short nucleotide sequence and cuts the DNA only at that specific site, which is known as restriction site or target sequence. In the bacterial cell, restriction enzymes cleave foreign DNA, thus eliminating infecting organisms. The activity of a restriction enzyme can be defined by its recognition site on the DNA sequence and the position relative to the recognition site, at which it cuts the DNA. . # create enzyme dictionary restrictionEnzymes = {} # add &quot;bamH1&quot; and &quot;sma1&quot; enzymes, their target sequence, and position releative to the recognition site restrictionEnzymes[&#39;bamH1&#39;] = [&#39;ggatcc&#39;,0] restrictionEnzymes[&#39;sma1&#39;] = [&#39;cccggg&#39;,2] # a function to calculate the molecular weight of dna sequences def oligoMolecularWeight(sequence): # create a dictionairy of DNA basepair molecular weights dnaMolecularWeight = {&#39;a&#39;:313.2,&#39;c&#39;:289.2,&#39;t&#39;:304.2,&#39;g&#39;:329.2} # initialize molecular weight molecularWeight = 0.0 # iterate through DNA sequnce and update weight of sequence for base in sequence: molecularWeight += dnaMolecularWeight[base] return molecularWeight # the primary function for restriction digest def digest(sequence, enzyme): # set target sequence target = restrictionEnzymes[enzyme][0] # enzyme cut position relative to recognition site cutPosition = restrictionEnzymes[enzyme][1] # a list to collect DNA fragments fragments = [] # counter for the position of the last restriction site; beginning of sequence found = 0 # a variable to store the position of the last cut; end of sequence lastCut = found # variable to set where to search for the next site from searchFrom = lastCut while found != -1: found = sequence.find(target, searchFrom) if found != -1: fragment = sequence[lastCut:found+cutPosition] mwt = oligoMolecularWeight(fragment) fragments.append((fragment,mwt)) else: fragment = sequence[lastCut:] mwt = oligoMolecularWeight(fragment) fragments.append((fragment,mwt)) lastCut = found + cutPosition searchFrom = lastCut + 1 return fragments . Running the function on a test sequence results in the following: . digestSequence = &quot;gcgatgctaggatccgcgatcgcgtacgatcgtacgcggtacggacggatccttctc&quot; . digested_dna = digest(digestSequence,&#39;bamH1&#39;) . print(digested_dna) . [(&#39;gcgatgcta&#39;, 2800.7999999999997), (&#39;ggatccgcgatcgcgtacgatcgtacgcggtacggac&#39;, 11478.400000000005), (&#39;ggatccttctc&#39;, 3345.1999999999994)] .",
            "url": "https://www.neongenes.com//python/bioinformatics/restriction%20enzyme/function/2021/10/18/restriction-enzyme-digest.html",
            "relUrl": "/python/bioinformatics/restriction%20enzyme/function/2021/10/18/restriction-enzyme-digest.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "A primer on Apache Airflow",
            "content": "What is airflow? . Airflow is a platform used to author, schedule, and monitor workflows. It’s essentially a queuing system that runs on a metadata database and a scheduler that runs tasks. Workflows are written as Directed Acyclic Graphs (DAGs). A workflow and DAG are interchangeable. . What are DAGs? . A DAG is a collection of tasks you want to run and are organized in a way that illustrates dependencies and relationships between tasks. . The image below shows how a DAG is a unidirectional, acyclic graph, where each node in the graph is a task and edges define dependencies among tasks. There is no case where you should be able to go backwards from a forward node to one that&#39;s already been executed. . . A DAG can be broken up into smaller and smaller jobs and gives the user full control by generating dynamic pipelines written in code. Airflow DAGs are also extensible and can scale. DAGs are powerful because they allow for collaborative, manageable, and testable workflows. A bonus is that Airflow is developed in python and can interface with any python API. . . The image above shows how Airflow divides the tasks into branches so that if one fails, there is still output from the other. Also, the processing time is reduced as parallel computing occurs. The chances of failure should decrease overall as each task is independent. . How are tasks executed? . An operator represents a single task in a workflow that helps carry out your task (running a python function for example). Operators determine what actually gets to be done when your dag runs. A task is an operator when instantiated. It is something on which the worker works upon. . Airflow Architecture . Metadata — is a relational database with info on task state, such as the top ten tasks consuming the most memory, it contains all data pertaining to jobs currently running as well as historical data. . | Scheduler — decides which task to run, when, and in what order. . | Web server— the UI which is essentially a flask app that talks to the metadata. . | Executor — performs the task at ground level. The executor is a message queuing process which figures out which workers will execute which tasks. The default is the sequential executor — which cannot run tasks in parallel — meaning it can’t be used for production level code. The local executor can be used too which will run tasks till all resources on the server are at capacity. This is good for a moderate amount of DAGs. Both of these are used in single node clusters and therefore cannot be used to scaled. . | Multi node clusters — have the same components and only the scheduler and web server are placed in the same node (master), the workers are placed in a separate instance. This set up works well because it allows for scaling by letting you add more multi-node clusters (celery is the executor of choice here for python). . | . If you&#39;re not dealing with terabytes of data then it&#39;s better to have the scheduler, web server, and executor together in the master node/cluster. The downside is that this single cluster approach runs everything on the same machine, so if you make a change to a DAG/scheduler, then you need to restart the entire workflow — even tasks that were in the process of executing. Celery avoids this. . . If you do build a distributed workflow with celery then a queuing system component is needed (like Redis). For local workflows, the queuing is handled by the system. . The life cycle of a task . The scheduler periodically checks the DAG folder to see if there are any DAGS that need to be run. . | If any DAGS are found pending execution, the scheduler creates a diagram for it, which is an instantiation of a DAG in real time. . | The scheduler will update the DAG state to running in the metadata and the tasks will execute. . | The scheduler then reads the DAG and puts the tasks in order of execution into the queuing system in the form of a message. Each message contains info like DAG ID, TASK ID, and function to be executed. . | The status of these tasks changes to queued at that point. . | The executor then begins to execute tasks and sends fail/success messages for the tasks to the metadata. . | The scheduler finally updates the status of the diagram when all tasks have run to success or fail. . |",
            "url": "https://www.neongenes.com//data-engineering/python/airflow/dag/2021/04/20/airflow-primer.html",
            "relUrl": "/data-engineering/python/airflow/dag/2021/04/20/airflow-primer.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://www.neongenes.com//markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://www.neongenes.com//about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.neongenes.com//robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}