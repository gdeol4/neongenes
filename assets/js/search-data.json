{
  
    
        "post0": {
            "title": "Working with the B3DB brain-blood barrier dataset",
            "content": "",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/09/using-the-B3DB-dataset.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/11/09/using-the-B3DB-dataset.html",
            "date": " • Nov 9, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Preprocessing a dataset of blood brain barrier molecules with Datamol",
            "content": "SMILES (Simplified Molecular Input Line Entry System) is a standard notation representing the molecular structure of a compound as a string representation that can be understood by a computer. The SMILES notation consists of a handful of rules which allow for converting the string to an image or graph. SMILES can then be easily used for generating further representations to train machine learning models with. . import datamol as dm import pandas as pd pd.options.mode.chained_assignment = None # default=&#39;warn&#39; . BBBP_df = pd.read_csv(&quot;data/BBBP.csv&quot;) BBBP_df.head() . num name p_np smiles . 0 1 | Propanolol | 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | . 1 2 | Terbutylchlorambucil | 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | . 2 3 | 40730 | 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | . 3 4 | 24 | 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | . 4 5 | cloxacillin | 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | . The dataframe shows 4 named columns, including the &quot;num&quot; of the molecule, the name, a binary label for blood brain barrier permeability status &quot;p_np&quot;, and the SMILES string. . # The name and number can be dropped BBBP_df = BBBP_df.drop([&quot;num&quot;, &quot;name&quot;], axis=1) # Checking the data for null values BBBP_df[&quot;smiles&quot;].isnull().values.any() . False . Mols and smiles need to be sanitized as it will leave us with SMILES that are complete nonesense, for example, errors resulting from kekulization. . . RDkit generates the alternate position of double bonds, and then (in a second step they call &quot;aromatization&quot;) labels the ring as aromatic. In panel (2), there are three possible Lewis structures contributing to the actual structure (i.e. there is resonance), so the software would have to generate all three to be able to search for identical structures. [1] . Below is a function using datamol to preprocess the dataset, including steps to generate mol objects, SELFIES, inchi and inchikeys for each molecule. The function also standardizes mols and SMILES, drops NA values, and returns a dataframe. . def preprocess_smiles(df): df[&quot;mol&quot;] = [dm.to_mol(x) for x in df[&#39;smiles&#39;]] # generating mols from SMILES df[&quot;mol&quot;] = [dm.fix_mol(x) for x in df[&#39;mol&#39;]] # Fixing mols df = df.dropna() # dropping NA values df[&quot;mol&quot;] = [dm.sanitize_mol(x, sanifix=True, charge_neutral=False) for x in df[&#39;mol&#39;]] # sanitize mol objects df[&quot;mol&quot;] = [dm.standardize_mol(x, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True) for x in df[&#39;mol&#39;]] # standardize mol objects df[&quot;standard_smiles&quot;] = [dm.standardize_smiles(x) for x in df[&#39;smiles&#39;]] # standardize SMILES df[&quot;selfies&quot;] = [dm.to_selfies(x) for x in df[&#39;mol&#39;]] # generate SELFIES df[&quot;inchi&quot;] = [dm.to_inchi(x) for x in df[&#39;mol&#39;]] # Generating InChi df[&quot;inchikey&quot;] = [dm.to_inchikey(x) for x in df[&#39;mol&#39;]] # Generating InChIKey return df . Running the function and taking a look at the outputs . data_clean = preprocess_smiles(BBBP_df) . data_clean.shape . (2039, 7) . data_clean.head() . p_np smiles mol standard_smiles selfies inchi inchikey . 0 1 | [Cl].CC(C)NCC(O)COc1cccc2ccccc12 | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)NCC(O)COc1cccc2ccccc12.[Cl-] | [C][C][Branch1][C][C][N][C][C][Branch1][C][O][... | InChI=1S/C16H21NO2.ClH/c1-12(2)17-10-14(18)11-... | ZMRUPTIKESYGQW-UHFFFAOYSA-M | . 1 1 | C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(C)(C)OC(=O)CCCc1ccc(N(CCCl)CCCl)cc1 | [C][C][Branch1][C][C][Branch1][C][C][O][C][=Br... | InChI=1S/C18H27Cl2NO2/c1-18(2,3)23-17(22)6-4-5... | SZXDOYFHSIIZCF-UHFFFAOYSA-N | . 2 1 | c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC1COc2c(N3CCN(C)CC3)c(F)cc3c(=O)c(C(=O)O)cn1c23 | [C][C][C][O][C][=C][Branch1][N][N][C][C][N][Br... | InChI=1S/C18H20FN3O4/c1-10-9-26-17-14-11(16(23... | GSDSWSVVBLHKDQ-UHFFFAOYSA-N | . 3 1 | C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | CC(=O)NCCCOc1cccc(CN2CCCCC2)c1 | [C][C][=Branch1][C][=O][N][C][C][C][O][C][=C][... | InChI=1S/C17H26N2O2/c1-15(20)18-9-6-12-21-17-8... | FAXLXLJWHQJMPK-UHFFFAOYSA-N | . 4 1 | Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... | &lt;img data-content=&quot;rdkit/molecule&quot; src=&quot;data:i... | Cc1onc(-c2ccccc2Cl)c1C(=O)N[C@@H]1C(=O)N2[C@@H... | [C][C][O][N][=C][Branch1][#Branch2][C][=C][C][... | InChI=1S/C19H18ClN3O5S/c1-8-11(12(22-28-8)9-6-... | LQOLIRLGBULYKD-JKIFEVAISA-N | . The data contains a 3:1 ratio of positive to negeative labels, which creates a bias towards molecules with blood brain permeability properties. This may need to be addressed when training models. . counts = data_clean[&#39;p_np&#39;].value_counts().to_dict() print(counts) . {1: 1560, 0: 479} . References . Urbaczek, Sascha. A consistent cheminformatics framework for automated virtual screening. Ph.D. Thesis, Universität Hamburg, August 2014. URL: http://ediss.sub.uni-hamburg.de/volltexte/2015/7349/; URN: urn:nbn:de:gbv:18-73491; PDF via Semantic Scholar |",
            "url": "https://www.neongenes.com//python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/10/22/working-with-SMILES.html",
            "relUrl": "/python/bioinformatics/datasets/smiles/cheminformatics/datamol/rdkit/molecules/2021/10/22/working-with-SMILES.html",
            "date": " • Oct 22, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Writing a function in python to perform a restriction enzyme digest",
            "content": "Creating a restriction enzyme dictionary . Restriction enzymes are proteins produced by bacteria that cleave DNA at specific sites along the molecule. The enzyme functions on a specific, short nucleotide sequence and cuts the DNA only at that specific site, which is known as restriction site or target sequence. In the bacterial cell, restriction enzymes cleave foreign DNA, thus eliminating infecting organisms. The activity of a restriction enzyme can be defined by its recognition site on the DNA sequence and the position relative to the recognition site, at which it cuts the DNA. . # create enzyme dictionary restrictionEnzymes = {} # add &quot;bamH1&quot; and &quot;sma1&quot; enzymes, their target sequence, and position releative to the recognition site restrictionEnzymes[&#39;bamH1&#39;] = [&#39;ggatcc&#39;,0] restrictionEnzymes[&#39;sma1&#39;] = [&#39;cccggg&#39;,2] # a function to calculate the molecular weight of dna sequences def oligoMolecularWeight(sequence): # create a dictionairy of DNA basepair molecular weights dnaMolecularWeight = {&#39;a&#39;:313.2,&#39;c&#39;:289.2,&#39;t&#39;:304.2,&#39;g&#39;:329.2} # initialize molecular weight molecularWeight = 0.0 # iterate through DNA sequnce and update weight of sequence for base in sequence: molecularWeight += dnaMolecularWeight[base] return molecularWeight # the primary function for restriction digest def digest(sequence, enzyme): # set target sequence target = restrictionEnzymes[enzyme][0] # enzyme cut position relative to recognition site cutPosition = restrictionEnzymes[enzyme][1] # a list to collect DNA fragments fragments = [] # counter for the position of the last restriction site; beginning of sequence found = 0 # a variable to store the position of the last cut; end of sequence lastCut = found # variable to set where to search for the next site from searchFrom = lastCut while found != -1: found = sequence.find(target, searchFrom) if found != -1: fragment = sequence[lastCut:found+cutPosition] mwt = oligoMolecularWeight(fragment) fragments.append((fragment,mwt)) else: fragment = sequence[lastCut:] mwt = oligoMolecularWeight(fragment) fragments.append((fragment,mwt)) lastCut = found + cutPosition searchFrom = lastCut + 1 return fragments . Running the function on a test sequence results in the following: . digestSequence = &quot;gcgatgctaggatccgcgatcgcgtacgatcgtacgcggtacggacggatccttctc&quot; . digested_dna = digest(digestSequence,&#39;bamH1&#39;) . print(digested_dna) . [(&#39;gcgatgcta&#39;, 2800.7999999999997), (&#39;ggatccgcgatcgcgtacgatcgtacgcggtacggac&#39;, 11478.400000000005), (&#39;ggatccttctc&#39;, 3345.1999999999994)] .",
            "url": "https://www.neongenes.com//python/bioinformatics/restriction%20enzyme/function/2021/10/18/restriction-enzyme-digest.html",
            "relUrl": "/python/bioinformatics/restriction%20enzyme/function/2021/10/18/restriction-enzyme-digest.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "A primer on Apache Airflow",
            "content": "What is airflow? . Airflow is a platform used to author, schedule, and monitor workflows. It’s essentially a queuing system that runs on a metadata database and a scheduler that runs tasks. Workflows are written as Directed Acyclic Graphs (DAGs). A workflow and DAG are interchangeable. . What are DAGs? . A DAG is a collection of tasks you want to run and are organized in a way that illustrates dependencies and relationships between tasks. . The image below shows how a DAG is a unidirectional, acyclic graph, where each node in the graph is a task and edges define dependencies among tasks. There is no case where you should be able to go backwards from a forward node to one that&#39;s already been executed. . . A DAG can be broken up into smaller and smaller jobs and gives the user full control by generating dynamic pipelines written in code. Airflow DAGs are also extensible and can scale. DAGs are powerful because they allow for collaborative, manageable, and testable workflows. A bonus is that Airflow is developed in python and can interface with any python API. . . The image above shows how Airflow divides the tasks into branches so that if one fails, there is still output from the other. Also, the processing time is reduced as parallel computing occurs. The chances of failure should decrease overall as each task is independent. . How are tasks executed? . An operator represents a single task in a workflow that helps carry out your task (running a python function for example). Operators determine what actually gets to be done when your dag runs. A task is an operator when instantiated. It is something on which the worker works upon. . Airflow Architecture . Metadata — is a relational database with info on task state, such as the top ten tasks consuming the most memory, it contains all data pertaining to jobs currently running as well as historical data. . | Scheduler — decides which task to run, when, and in what order. . | Web server— the UI which is essentially a flask app that talks to the metadata. . | Executor — performs the task at ground level. The executor is a message queuing process which figures out which workers will execute which tasks. The default is the sequential executor — which cannot run tasks in parallel — meaning it can’t be used for production level code. The local executor can be used too which will run tasks till all resources on the server are at capacity. This is good for a moderate amount of DAGs. Both of these are used in single node clusters and therefore cannot be used to scaled. . | Multi node clusters — have the same components and only the scheduler and web server are placed in the same node (master), the workers are placed in a separate instance. This set up works well because it allows for scaling by letting you add more multi-node clusters (celery is the executor of choice here for python). . | . If you&#39;re not dealing with terabytes of data then it&#39;s better to have the scheduler, web server, and executor together in the master node/cluster. The downside is that this single cluster approach runs everything on the same machine, so if you make a change to a DAG/scheduler, then you need to restart the entire workflow — even tasks that were in the process of executing. Celery avoids this. . . If you do build a distributed workflow with celery then a queuing system component is needed (like Redis). For local workflows, the queuing is handled by the system. . The life cycle of a task . The scheduler periodically checks the DAG folder to see if there are any DAGS that need to be run. . | If any DAGS are found pending execution, the scheduler creates a diagram for it, which is an instantiation of a DAG in real time. . | The scheduler will update the DAG state to running in the metadata and the tasks will execute. . | The scheduler then reads the DAG and puts the tasks in order of execution into the queuing system in the form of a message. Each message contains info like DAG ID, TASK ID, and function to be executed. . | The status of these tasks changes to queued at that point. . | The executor then begins to execute tasks and sends fail/success messages for the tasks to the metadata. . | The scheduler finally updates the status of the diagram when all tasks have run to success or fail. . |",
            "url": "https://www.neongenes.com//data-engineering/python/airflow/dag/2021/04/20/airflow-primer.html",
            "relUrl": "/data-engineering/python/airflow/dag/2021/04/20/airflow-primer.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://www.neongenes.com//markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://www.neongenes.com//about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://www.neongenes.com//robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}