Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9023 --control=9016 --hb=9015 --Session.signature_scheme="hmac-sha256" --Session.key=b"d428538a-db2b-40c8-b710-95eb7a929307" --shell=9017 --transport="tcp" --iopub=9024 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036lrc2sZ0NEBA3.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/chemprop_data.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': './data/B3DB.csv',
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9023 --control=9016 --hb=9015 --Session.signature_scheme="hmac-sha256" --Session.key=b"d428538a-db2b-40c8-b710-95eb7a929307" --shell=9017 --transport="tcp" --iopub=9024 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036lrc2sZ0NEBA3.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/chemprop_data.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': './data/B3DB.csv',
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9023 --control=9016 --hb=9015 --Session.signature_scheme="hmac-sha256" --Session.key=b"d428538a-db2b-40c8-b710-95eb7a929307" --shell=9017 --transport="tcp" --iopub=9024 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036lrc2sZ0NEBA3.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/chemprop_data.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'num_folds': 10,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': './data/chemprop_B3DB.csv',
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total scaffolds = 1,025 | train scaffolds = 924 | val scaffolds = 0 | test scaffolds = 101
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.7921e-01, PNorm = 34.0133, GNorm = 0.5342, lr_0 = 2.5469e-04
Loss = 5.3200e-01, PNorm = 34.0237, GNorm = 0.6107, lr_0 = 3.9531e-04
Loss = 5.1853e-01, PNorm = 34.0464, GNorm = 0.5553, lr_0 = 5.3594e-04
Validation auc = 0.731898
Epoch 1
Loss = 4.7001e-01, PNorm = 34.0900, GNorm = 1.9152, lr_0 = 6.9063e-04
Loss = 4.3204e-01, PNorm = 34.1271, GNorm = 0.6978, lr_0 = 8.3125e-04
Loss = 4.5837e-01, PNorm = 34.1749, GNorm = 2.8353, lr_0 = 9.7187e-04
Validation auc = 0.739573
Epoch 2
Loss = 4.1592e-01, PNorm = 34.2418, GNorm = 0.8874, lr_0 = 9.7965e-04
Loss = 4.0019e-01, PNorm = 34.3068, GNorm = 0.3414, lr_0 = 9.5480e-04
Loss = 4.1145e-01, PNorm = 34.3543, GNorm = 0.6370, lr_0 = 9.3057e-04
Validation auc = 0.790529
Epoch 3
Loss = 3.7677e-01, PNorm = 34.4208, GNorm = 0.9437, lr_0 = 9.0463e-04
Loss = 3.4925e-01, PNorm = 34.4773, GNorm = 0.5762, lr_0 = 8.8168e-04
Loss = 3.9518e-01, PNorm = 34.5250, GNorm = 0.4361, lr_0 = 8.5931e-04
Loss = 3.4804e-01, PNorm = 34.5879, GNorm = 0.7934, lr_0 = 8.3751e-04
Validation auc = 0.815596
Epoch 4
Loss = 3.5069e-01, PNorm = 34.6495, GNorm = 0.6996, lr_0 = 8.1626e-04
Loss = 3.1209e-01, PNorm = 34.7035, GNorm = 0.6323, lr_0 = 7.9555e-04
Loss = 3.6705e-01, PNorm = 34.7594, GNorm = 0.7795, lr_0 = 7.7537e-04
Validation auc = 0.849116
Epoch 5
Loss = 3.7468e-01, PNorm = 34.8100, GNorm = 0.7911, lr_0 = 7.5570e-04
Loss = 3.0905e-01, PNorm = 34.8686, GNorm = 1.4186, lr_0 = 7.3653e-04
Loss = 2.6892e-01, PNorm = 34.9266, GNorm = 1.0121, lr_0 = 7.1784e-04
Validation auc = 0.853062
Epoch 6
Loss = 3.0230e-01, PNorm = 34.9655, GNorm = 0.8728, lr_0 = 6.9783e-04
Loss = 3.1416e-01, PNorm = 35.0221, GNorm = 1.2014, lr_0 = 6.8013e-04
Loss = 2.7962e-01, PNorm = 35.0705, GNorm = 0.6963, lr_0 = 6.6287e-04
Validation auc = 0.840569
Epoch 7
Loss = 1.8715e-01, PNorm = 35.1038, GNorm = 1.2228, lr_0 = 6.4605e-04
Loss = 3.1151e-01, PNorm = 35.1414, GNorm = 0.7543, lr_0 = 6.2966e-04
Loss = 2.9637e-01, PNorm = 35.1967, GNorm = 0.8723, lr_0 = 6.1369e-04
Loss = 3.1616e-01, PNorm = 35.2427, GNorm = 2.5857, lr_0 = 5.9812e-04
Loss = 5.2971e-01, PNorm = 35.2462, GNorm = 3.8233, lr_0 = 5.9658e-04
Validation auc = 0.854273
Epoch 8
Loss = 3.1306e-01, PNorm = 35.2873, GNorm = 1.1070, lr_0 = 5.8145e-04
Loss = 2.8194e-01, PNorm = 35.3365, GNorm = 1.4047, lr_0 = 5.6669e-04
Loss = 2.7593e-01, PNorm = 35.3866, GNorm = 0.9889, lr_0 = 5.5232e-04
Validation auc = 0.855899
Epoch 9
Loss = 2.8666e-01, PNorm = 35.4314, GNorm = 1.3941, lr_0 = 5.3830e-04
Loss = 2.5622e-01, PNorm = 35.4844, GNorm = 0.4744, lr_0 = 5.2465e-04
Loss = 3.1872e-01, PNorm = 35.5168, GNorm = 0.5933, lr_0 = 5.1133e-04
Validation auc = 0.871488
Epoch 10
Loss = 2.9573e-01, PNorm = 35.5591, GNorm = 1.1211, lr_0 = 4.9836e-04
Loss = 2.6221e-01, PNorm = 35.6001, GNorm = 0.9222, lr_0 = 4.8572e-04
Loss = 2.6929e-01, PNorm = 35.6405, GNorm = 1.2863, lr_0 = 4.7339e-04
Validation auc = 0.867729
Epoch 11
Loss = 2.7630e-01, PNorm = 35.6886, GNorm = 0.8642, lr_0 = 4.6020e-04
Loss = 2.6721e-01, PNorm = 35.7368, GNorm = 1.3450, lr_0 = 4.4852e-04
Loss = 3.1437e-01, PNorm = 35.7796, GNorm = 0.9707, lr_0 = 4.3714e-04
Loss = 2.7745e-01, PNorm = 35.8168, GNorm = 1.8431, lr_0 = 4.2605e-04
Validation auc = 0.873370
Epoch 12
Loss = 2.3011e-01, PNorm = 35.8567, GNorm = 0.9368, lr_0 = 4.1524e-04
Loss = 3.0085e-01, PNorm = 35.8913, GNorm = 2.3247, lr_0 = 4.0471e-04
Loss = 2.4651e-01, PNorm = 35.9194, GNorm = 2.9509, lr_0 = 3.9444e-04
Validation auc = 0.867464
Epoch 13
Loss = 2.3372e-01, PNorm = 35.9452, GNorm = 0.9986, lr_0 = 3.8443e-04
Loss = 2.2999e-01, PNorm = 35.9764, GNorm = 0.8525, lr_0 = 3.7468e-04
Loss = 2.2414e-01, PNorm = 36.0128, GNorm = 0.7044, lr_0 = 3.6517e-04
Validation auc = 0.875426
Epoch 14
Loss = 2.0713e-01, PNorm = 36.0453, GNorm = 0.4335, lr_0 = 3.5500e-04
Loss = 2.3194e-01, PNorm = 36.0770, GNorm = 2.1658, lr_0 = 3.4599e-04
Loss = 2.5871e-01, PNorm = 36.1087, GNorm = 0.9426, lr_0 = 3.3721e-04
Validation auc = 0.876673
Epoch 15
Loss = 2.8820e-01, PNorm = 36.1377, GNorm = 1.4118, lr_0 = 3.2866e-04
Loss = 2.2613e-01, PNorm = 36.1684, GNorm = 1.3319, lr_0 = 3.2032e-04
Loss = 2.0750e-01, PNorm = 36.1953, GNorm = 2.1855, lr_0 = 3.1219e-04
Loss = 2.7105e-01, PNorm = 36.2226, GNorm = 1.6245, lr_0 = 3.0427e-04
Validation auc = 0.865978
Epoch 16
Loss = 2.4408e-01, PNorm = 36.2519, GNorm = 1.5706, lr_0 = 2.9579e-04
Loss = 2.2506e-01, PNorm = 36.2784, GNorm = 0.9227, lr_0 = 2.8828e-04
Loss = 2.0077e-01, PNorm = 36.3028, GNorm = 0.6776, lr_0 = 2.8097e-04
Validation auc = 0.878100
Epoch 17
Loss = 2.0379e-01, PNorm = 36.3313, GNorm = 0.5450, lr_0 = 2.7384e-04
Loss = 2.1564e-01, PNorm = 36.3560, GNorm = 0.7152, lr_0 = 2.6689e-04
Loss = 1.8612e-01, PNorm = 36.3825, GNorm = 1.7715, lr_0 = 2.6012e-04
Validation auc = 0.879983
Epoch 18
Loss = 2.1749e-01, PNorm = 36.4032, GNorm = 2.1023, lr_0 = 2.5352e-04
Loss = 2.0186e-01, PNorm = 36.4244, GNorm = 1.0254, lr_0 = 2.4709e-04
Loss = 2.2377e-01, PNorm = 36.4476, GNorm = 1.5030, lr_0 = 2.4082e-04
Validation auc = 0.877642
Epoch 19
Loss = 2.1661e-01, PNorm = 36.4699, GNorm = 2.0885, lr_0 = 2.3411e-04
Loss = 1.9739e-01, PNorm = 36.4885, GNorm = 1.5452, lr_0 = 2.2817e-04
Loss = 1.8020e-01, PNorm = 36.5104, GNorm = 0.7588, lr_0 = 2.2238e-04
Loss = 2.1539e-01, PNorm = 36.5302, GNorm = 1.9140, lr_0 = 2.1674e-04
Validation auc = 0.874604
Epoch 20
Loss = 2.0466e-01, PNorm = 36.5521, GNorm = 0.9277, lr_0 = 2.1124e-04
Loss = 1.9847e-01, PNorm = 36.5712, GNorm = 1.9312, lr_0 = 2.0588e-04
Loss = 1.7716e-01, PNorm = 36.5888, GNorm = 0.9575, lr_0 = 2.0066e-04
Validation auc = 0.881012
Epoch 21
Loss = 1.2171e-01, PNorm = 36.6069, GNorm = 1.4518, lr_0 = 1.9557e-04
Loss = 2.1633e-01, PNorm = 36.6252, GNorm = 3.4335, lr_0 = 1.9060e-04
Loss = 1.9789e-01, PNorm = 36.6406, GNorm = 0.8608, lr_0 = 1.8577e-04
Validation auc = 0.880775
Epoch 22
Loss = 1.7108e-01, PNorm = 36.6599, GNorm = 1.3346, lr_0 = 1.8059e-04
Loss = 2.0594e-01, PNorm = 36.6781, GNorm = 1.2820, lr_0 = 1.7601e-04
Loss = 2.1049e-01, PNorm = 36.6936, GNorm = 1.2921, lr_0 = 1.7154e-04
Loss = 1.4001e-01, PNorm = 36.7102, GNorm = 1.3220, lr_0 = 1.6719e-04
Validation auc = 0.878249
Epoch 23
Loss = 1.8390e-01, PNorm = 36.7259, GNorm = 1.5580, lr_0 = 1.6295e-04
Loss = 1.5908e-01, PNorm = 36.7417, GNorm = 0.5529, lr_0 = 1.5882e-04
Loss = 1.9535e-01, PNorm = 36.7555, GNorm = 1.9520, lr_0 = 1.5479e-04
Validation auc = 0.879262
Epoch 24
Loss = 1.9363e-01, PNorm = 36.7711, GNorm = 2.5496, lr_0 = 1.5047e-04
Loss = 1.7139e-01, PNorm = 36.7848, GNorm = 0.9105, lr_0 = 1.4665e-04
Loss = 1.9078e-01, PNorm = 36.7979, GNorm = 2.2030, lr_0 = 1.4293e-04
Validation auc = 0.881092
Epoch 25
Loss = 2.0122e-01, PNorm = 36.8112, GNorm = 2.0350, lr_0 = 1.3931e-04
Loss = 1.7755e-01, PNorm = 36.8237, GNorm = 1.9924, lr_0 = 1.3577e-04
Loss = 1.6288e-01, PNorm = 36.8345, GNorm = 1.0033, lr_0 = 1.3233e-04
Validation auc = 0.879667
Epoch 26
Loss = 1.7851e-01, PNorm = 36.8477, GNorm = 1.3995, lr_0 = 1.2897e-04
Loss = 1.6410e-01, PNorm = 36.8601, GNorm = 2.0577, lr_0 = 1.2570e-04
Loss = 1.6417e-01, PNorm = 36.8716, GNorm = 1.4548, lr_0 = 1.2251e-04
Loss = 1.9043e-01, PNorm = 36.8844, GNorm = 0.5458, lr_0 = 1.1940e-04
Loss = 1.3765e-01, PNorm = 36.8858, GNorm = 1.8756, lr_0 = 1.1909e-04
Validation auc = 0.878424
Epoch 27
Loss = 1.7380e-01, PNorm = 36.8967, GNorm = 0.6299, lr_0 = 1.1607e-04
Loss = 1.7133e-01, PNorm = 36.9085, GNorm = 0.9839, lr_0 = 1.1313e-04
Loss = 1.5482e-01, PNorm = 36.9189, GNorm = 0.6951, lr_0 = 1.1026e-04
Validation auc = 0.878794
Epoch 28
Loss = 1.7905e-01, PNorm = 36.9294, GNorm = 0.9441, lr_0 = 1.0746e-04
Loss = 1.6842e-01, PNorm = 36.9389, GNorm = 2.0891, lr_0 = 1.0473e-04
Loss = 1.6954e-01, PNorm = 36.9487, GNorm = 1.1413, lr_0 = 1.0208e-04
Validation auc = 0.877537
Epoch 29
Loss = 1.2676e-01, PNorm = 36.9588, GNorm = 1.3964, lr_0 = 1.0000e-04
Loss = 1.6358e-01, PNorm = 36.9683, GNorm = 0.8904, lr_0 = 1.0000e-04
Loss = 1.7523e-01, PNorm = 36.9776, GNorm = 1.2408, lr_0 = 1.0000e-04
Validation auc = 0.877406
Model 0 best validation auc = 0.881092 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.844660
Ensemble test auc = 0.844660
Fold 1
Splitting data with seed 1
Total scaffolds = 1,025 | train scaffolds = 899 | val scaffolds = 0 | test scaffolds = 126
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.8283e-01, PNorm = 34.0132, GNorm = 0.9347, lr_0 = 2.5469e-04
Loss = 5.3997e-01, PNorm = 34.0187, GNorm = 0.2686, lr_0 = 3.9531e-04
Loss = 5.4015e-01, PNorm = 34.0372, GNorm = 0.8418, lr_0 = 5.3594e-04
Validation auc = 0.723354
Epoch 1
Loss = 5.0507e-01, PNorm = 34.0716, GNorm = 2.6406, lr_0 = 6.9063e-04
Loss = 4.3937e-01, PNorm = 34.1089, GNorm = 0.4836, lr_0 = 8.3125e-04
Loss = 4.9619e-01, PNorm = 34.1618, GNorm = 1.7031, lr_0 = 9.7187e-04
Validation auc = 0.790985
Epoch 2
Loss = 4.5610e-01, PNorm = 34.2304, GNorm = 0.6527, lr_0 = 9.7965e-04
Loss = 4.6261e-01, PNorm = 34.3044, GNorm = 1.3506, lr_0 = 9.5480e-04
Loss = 4.0275e-01, PNorm = 34.3694, GNorm = 1.7302, lr_0 = 9.3057e-04
Validation auc = 0.806004
Epoch 3
Loss = 4.1068e-01, PNorm = 34.4422, GNorm = 0.8234, lr_0 = 9.0463e-04
Loss = 4.4421e-01, PNorm = 34.4953, GNorm = 0.5707, lr_0 = 8.8168e-04
Loss = 3.5599e-01, PNorm = 34.5530, GNorm = 0.2221, lr_0 = 8.5931e-04
Loss = 3.7585e-01, PNorm = 34.5886, GNorm = 0.8107, lr_0 = 8.3751e-04
Validation auc = 0.816117
Epoch 4
Loss = 3.2671e-01, PNorm = 34.6467, GNorm = 1.4990, lr_0 = 8.1626e-04
Loss = 4.1754e-01, PNorm = 34.6924, GNorm = 1.5698, lr_0 = 7.9555e-04
Loss = 3.7652e-01, PNorm = 34.7473, GNorm = 0.7108, lr_0 = 7.7537e-04
Validation auc = 0.834371
Epoch 5
Loss = 3.5562e-01, PNorm = 34.8102, GNorm = 0.7067, lr_0 = 7.5570e-04
Loss = 3.8079e-01, PNorm = 34.8607, GNorm = 0.6355, lr_0 = 7.3653e-04
Loss = 3.5995e-01, PNorm = 34.9105, GNorm = 1.0636, lr_0 = 7.1784e-04
Validation auc = 0.834212
Epoch 6
Loss = 3.4494e-01, PNorm = 34.9751, GNorm = 0.5044, lr_0 = 6.9783e-04
Loss = 3.5540e-01, PNorm = 35.0362, GNorm = 2.7041, lr_0 = 6.8013e-04
Loss = 3.7456e-01, PNorm = 35.0753, GNorm = 1.2072, lr_0 = 6.6287e-04
Validation auc = 0.845199
Epoch 7
Loss = 3.6567e-01, PNorm = 35.1313, GNorm = 0.5053, lr_0 = 6.4605e-04
Loss = 2.9606e-01, PNorm = 35.1913, GNorm = 2.0932, lr_0 = 6.2966e-04
Loss = 3.1622e-01, PNorm = 35.2301, GNorm = 2.0060, lr_0 = 6.1369e-04
Loss = 3.5755e-01, PNorm = 35.2781, GNorm = 1.0133, lr_0 = 5.9812e-04
Loss = 3.8792e-01, PNorm = 35.2826, GNorm = 0.7208, lr_0 = 5.9658e-04
Validation auc = 0.853250
Epoch 8
Loss = 3.2643e-01, PNorm = 35.3344, GNorm = 0.6999, lr_0 = 5.8145e-04
Loss = 3.0346e-01, PNorm = 35.3856, GNorm = 0.6837, lr_0 = 5.6669e-04
Loss = 2.8790e-01, PNorm = 35.4334, GNorm = 0.6533, lr_0 = 5.5232e-04
Validation auc = 0.855157
Epoch 9
Loss = 2.6723e-01, PNorm = 35.4871, GNorm = 0.8949, lr_0 = 5.3830e-04
Loss = 2.7581e-01, PNorm = 35.5388, GNorm = 0.7371, lr_0 = 5.2465e-04
Loss = 3.0116e-01, PNorm = 35.5795, GNorm = 0.8037, lr_0 = 5.1133e-04
Validation auc = 0.860529
Epoch 10
Loss = 3.1910e-01, PNorm = 35.6263, GNorm = 1.7916, lr_0 = 4.9836e-04
Loss = 2.7589e-01, PNorm = 35.6775, GNorm = 1.0073, lr_0 = 4.8572e-04
Loss = 2.6230e-01, PNorm = 35.7196, GNorm = 1.6867, lr_0 = 4.7339e-04
Validation auc = 0.855913
Epoch 11
Loss = 2.2269e-01, PNorm = 35.7685, GNorm = 0.5647, lr_0 = 4.6020e-04
Loss = 2.8032e-01, PNorm = 35.8202, GNorm = 0.9101, lr_0 = 4.4852e-04
Loss = 2.6989e-01, PNorm = 35.8575, GNorm = 0.7661, lr_0 = 4.3714e-04
Loss = 2.5243e-01, PNorm = 35.8924, GNorm = 1.8814, lr_0 = 4.2605e-04
Validation auc = 0.866222
Epoch 12
Loss = 3.0864e-01, PNorm = 35.9291, GNorm = 2.4162, lr_0 = 4.1524e-04
Loss = 2.6324e-01, PNorm = 35.9657, GNorm = 1.0833, lr_0 = 4.0471e-04
Loss = 2.5254e-01, PNorm = 36.0018, GNorm = 0.8596, lr_0 = 3.9444e-04
Validation auc = 0.864480
Epoch 13
Loss = 2.7847e-01, PNorm = 36.0386, GNorm = 1.0885, lr_0 = 3.8443e-04
Loss = 2.1106e-01, PNorm = 36.0755, GNorm = 0.7475, lr_0 = 3.7468e-04
Loss = 2.8272e-01, PNorm = 36.1032, GNorm = 1.4107, lr_0 = 3.6517e-04
Validation auc = 0.868644
Epoch 14
Loss = 2.6149e-01, PNorm = 36.1385, GNorm = 0.9653, lr_0 = 3.5500e-04
Loss = 2.7012e-01, PNorm = 36.1748, GNorm = 0.9300, lr_0 = 3.4599e-04
Loss = 2.3500e-01, PNorm = 36.2065, GNorm = 0.9834, lr_0 = 3.3721e-04
Validation auc = 0.872554
Epoch 15
Loss = 1.3722e-01, PNorm = 36.2363, GNorm = 0.7371, lr_0 = 3.2866e-04
Loss = 2.6957e-01, PNorm = 36.2676, GNorm = 1.2163, lr_0 = 3.2032e-04
Loss = 2.0775e-01, PNorm = 36.2973, GNorm = 0.7404, lr_0 = 3.1219e-04
Loss = 2.2550e-01, PNorm = 36.3213, GNorm = 1.2833, lr_0 = 3.0427e-04
Validation auc = 0.869664
Epoch 16
Loss = 2.4413e-01, PNorm = 36.3483, GNorm = 0.9222, lr_0 = 2.9579e-04
Loss = 2.3373e-01, PNorm = 36.3762, GNorm = 0.6782, lr_0 = 2.8828e-04
Loss = 1.9903e-01, PNorm = 36.4009, GNorm = 1.7978, lr_0 = 2.8097e-04
Validation auc = 0.871752
Epoch 17
Loss = 2.1133e-01, PNorm = 36.4263, GNorm = 0.9462, lr_0 = 2.7384e-04
Loss = 2.1816e-01, PNorm = 36.4528, GNorm = 0.9474, lr_0 = 2.6689e-04
Loss = 2.3951e-01, PNorm = 36.4767, GNorm = 0.9969, lr_0 = 2.6012e-04
Validation auc = 0.869897
Epoch 18
Loss = 2.5544e-01, PNorm = 36.4969, GNorm = 1.2004, lr_0 = 2.5352e-04
Loss = 2.0932e-01, PNorm = 36.5184, GNorm = 0.7141, lr_0 = 2.4709e-04
Loss = 2.5558e-01, PNorm = 36.5406, GNorm = 0.8702, lr_0 = 2.4082e-04
Validation auc = 0.869473
Epoch 19
Loss = 2.9814e-01, PNorm = 36.5635, GNorm = 1.9294, lr_0 = 2.3411e-04
Loss = 2.0657e-01, PNorm = 36.5883, GNorm = 0.8910, lr_0 = 2.2817e-04
Loss = 1.7860e-01, PNorm = 36.6074, GNorm = 1.3545, lr_0 = 2.2238e-04
Loss = 2.3013e-01, PNorm = 36.6244, GNorm = 1.1076, lr_0 = 2.1674e-04
Validation auc = 0.869637
Epoch 20
Loss = 1.9790e-01, PNorm = 36.6436, GNorm = 0.4017, lr_0 = 2.1124e-04
Loss = 1.9631e-01, PNorm = 36.6651, GNorm = 1.2600, lr_0 = 2.0588e-04
Loss = 2.0615e-01, PNorm = 36.6825, GNorm = 1.9261, lr_0 = 2.0066e-04
Validation auc = 0.868412
Epoch 21
Loss = 2.0785e-01, PNorm = 36.6980, GNorm = 0.9904, lr_0 = 1.9557e-04
Loss = 1.8450e-01, PNorm = 36.7161, GNorm = 2.2254, lr_0 = 1.9060e-04
Loss = 2.0003e-01, PNorm = 36.7311, GNorm = 0.5961, lr_0 = 1.8577e-04
Validation auc = 0.872807
Epoch 22
Loss = 1.9961e-01, PNorm = 36.7495, GNorm = 0.7913, lr_0 = 1.8059e-04
Loss = 1.8202e-01, PNorm = 36.7663, GNorm = 1.5576, lr_0 = 1.7601e-04
Loss = 2.0640e-01, PNorm = 36.7824, GNorm = 2.6012, lr_0 = 1.7154e-04
Loss = 1.9832e-01, PNorm = 36.7937, GNorm = 0.7935, lr_0 = 1.6719e-04
Validation auc = 0.870136
Epoch 23
Loss = 1.7012e-01, PNorm = 36.8093, GNorm = 0.9299, lr_0 = 1.6295e-04
Loss = 1.6535e-01, PNorm = 36.8235, GNorm = 0.9022, lr_0 = 1.5882e-04
Loss = 2.2565e-01, PNorm = 36.8362, GNorm = 0.6081, lr_0 = 1.5479e-04
Validation auc = 0.871655
Epoch 24
Loss = 1.7154e-01, PNorm = 36.8516, GNorm = 1.2007, lr_0 = 1.5047e-04
Loss = 2.0130e-01, PNorm = 36.8641, GNorm = 0.8403, lr_0 = 1.4665e-04
Loss = 1.9262e-01, PNorm = 36.8771, GNorm = 1.6096, lr_0 = 1.4293e-04
Validation auc = 0.869651
Epoch 25
Loss = 1.7977e-01, PNorm = 36.8901, GNorm = 0.5687, lr_0 = 1.3931e-04
Loss = 2.0113e-01, PNorm = 36.9016, GNorm = 0.8200, lr_0 = 1.3577e-04
Loss = 1.5470e-01, PNorm = 36.9153, GNorm = 1.3182, lr_0 = 1.3233e-04
Validation auc = 0.875535
Epoch 26
Loss = 1.1032e-01, PNorm = 36.9278, GNorm = 0.7398, lr_0 = 1.2897e-04
Loss = 1.7223e-01, PNorm = 36.9396, GNorm = 1.5111, lr_0 = 1.2570e-04
Loss = 2.3340e-01, PNorm = 36.9518, GNorm = 1.4119, lr_0 = 1.2251e-04
Loss = 1.5973e-01, PNorm = 36.9620, GNorm = 0.6217, lr_0 = 1.1940e-04
Loss = 1.5186e-01, PNorm = 36.9632, GNorm = 2.1749, lr_0 = 1.1909e-04
Validation auc = 0.872548
Epoch 27
Loss = 1.7789e-01, PNorm = 36.9714, GNorm = 1.5165, lr_0 = 1.1607e-04
Loss = 2.1012e-01, PNorm = 36.9808, GNorm = 1.7794, lr_0 = 1.1313e-04
Loss = 1.7228e-01, PNorm = 36.9913, GNorm = 1.9834, lr_0 = 1.1026e-04
Validation auc = 0.870228
Epoch 28
Loss = 1.4317e-01, PNorm = 37.0015, GNorm = 0.5428, lr_0 = 1.0746e-04
Loss = 2.0754e-01, PNorm = 37.0132, GNorm = 1.9797, lr_0 = 1.0473e-04
Loss = 1.7099e-01, PNorm = 37.0217, GNorm = 1.8418, lr_0 = 1.0208e-04
Validation auc = 0.874042
Epoch 29
Loss = 1.9134e-01, PNorm = 37.0333, GNorm = 2.0929, lr_0 = 1.0000e-04
Loss = 1.4536e-01, PNorm = 37.0410, GNorm = 1.1186, lr_0 = 1.0000e-04
Loss = 1.9219e-01, PNorm = 37.0507, GNorm = 1.4713, lr_0 = 1.0000e-04
Validation auc = 0.871245
Model 0 best validation auc = 0.875535 on epoch 25
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.859605
Ensemble test auc = 0.859605
Fold 2
Splitting data with seed 2
Total scaffolds = 1,025 | train scaffolds = 871 | val scaffolds = 0 | test scaffolds = 154
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 6.0362e-01, PNorm = 34.0126, GNorm = 0.6707, lr_0 = 2.5469e-04
Loss = 5.0584e-01, PNorm = 34.0185, GNorm = 0.3407, lr_0 = 3.9531e-04
Loss = 4.9781e-01, PNorm = 34.0381, GNorm = 0.3298, lr_0 = 5.3594e-04
Validation auc = 0.760552
Epoch 1
Loss = 4.6252e-01, PNorm = 34.0779, GNorm = 0.8323, lr_0 = 6.9063e-04
Loss = 4.4080e-01, PNorm = 34.1227, GNorm = 2.8627, lr_0 = 8.3125e-04
Loss = 4.6250e-01, PNorm = 34.1646, GNorm = 0.5142, lr_0 = 9.7187e-04
Validation auc = 0.790695
Epoch 2
Loss = 4.0534e-01, PNorm = 34.2277, GNorm = 0.5855, lr_0 = 9.7965e-04
Loss = 4.1850e-01, PNorm = 34.2869, GNorm = 1.5344, lr_0 = 9.5480e-04
Loss = 3.9848e-01, PNorm = 34.3544, GNorm = 0.6003, lr_0 = 9.3057e-04
Validation auc = 0.824694
Epoch 3
Loss = 3.3840e-01, PNorm = 34.4211, GNorm = 1.0208, lr_0 = 9.0463e-04
Loss = 4.2338e-01, PNorm = 34.4658, GNorm = 2.6432, lr_0 = 8.8168e-04
Loss = 4.6957e-01, PNorm = 34.5164, GNorm = 2.4411, lr_0 = 8.5931e-04
Loss = 4.1367e-01, PNorm = 34.5805, GNorm = 0.9025, lr_0 = 8.3751e-04
Validation auc = 0.825354
Epoch 4
Loss = 3.9201e-01, PNorm = 34.6501, GNorm = 0.6751, lr_0 = 8.1626e-04
Loss = 3.5608e-01, PNorm = 34.7110, GNorm = 0.2464, lr_0 = 7.9555e-04
Loss = 3.7925e-01, PNorm = 34.7609, GNorm = 1.6704, lr_0 = 7.7537e-04
Validation auc = 0.838017
Epoch 5
Loss = 2.9262e-01, PNorm = 34.8032, GNorm = 0.8056, lr_0 = 7.5570e-04
Loss = 3.4921e-01, PNorm = 34.8425, GNorm = 0.6386, lr_0 = 7.3653e-04
Loss = 3.5358e-01, PNorm = 34.8934, GNorm = 0.9398, lr_0 = 7.1784e-04
Validation auc = 0.841108
Epoch 6
Loss = 3.7898e-01, PNorm = 34.9461, GNorm = 1.7352, lr_0 = 6.9783e-04
Loss = 2.8961e-01, PNorm = 34.9995, GNorm = 0.7246, lr_0 = 6.8013e-04
Loss = 3.8121e-01, PNorm = 35.0442, GNorm = 1.4410, lr_0 = 6.6287e-04
Validation auc = 0.855532
Epoch 7
Loss = 3.7778e-01, PNorm = 35.0863, GNorm = 0.9807, lr_0 = 6.4605e-04
Loss = 3.0422e-01, PNorm = 35.1288, GNorm = 1.0329, lr_0 = 6.2966e-04
Loss = 3.3546e-01, PNorm = 35.1729, GNorm = 1.1070, lr_0 = 6.1369e-04
Loss = 3.0829e-01, PNorm = 35.2123, GNorm = 0.6419, lr_0 = 5.9812e-04
Loss = 3.3615e-01, PNorm = 35.2163, GNorm = 2.7590, lr_0 = 5.9658e-04
Validation auc = 0.858447
Epoch 8
Loss = 2.8547e-01, PNorm = 35.2628, GNorm = 0.4471, lr_0 = 5.8145e-04
Loss = 3.1165e-01, PNorm = 35.3067, GNorm = 0.9458, lr_0 = 5.6669e-04
Loss = 3.1942e-01, PNorm = 35.3441, GNorm = 0.7806, lr_0 = 5.5232e-04
Validation auc = 0.865120
Epoch 9
Loss = 2.5204e-01, PNorm = 35.3841, GNorm = 0.8710, lr_0 = 5.3830e-04
Loss = 3.2551e-01, PNorm = 35.4262, GNorm = 0.5684, lr_0 = 5.2465e-04
Loss = 2.6458e-01, PNorm = 35.4691, GNorm = 2.5230, lr_0 = 5.1133e-04
Validation auc = 0.867362
Epoch 10
Loss = 2.5710e-01, PNorm = 35.5074, GNorm = 0.7284, lr_0 = 4.9836e-04
Loss = 2.7672e-01, PNorm = 35.5509, GNorm = 0.8951, lr_0 = 4.8572e-04
Loss = 2.9099e-01, PNorm = 35.5904, GNorm = 1.2288, lr_0 = 4.7339e-04
Validation auc = 0.860585
Epoch 11
Loss = 2.3208e-01, PNorm = 35.6297, GNorm = 0.7105, lr_0 = 4.6020e-04
Loss = 2.5835e-01, PNorm = 35.6634, GNorm = 1.8572, lr_0 = 4.4852e-04
Loss = 2.6463e-01, PNorm = 35.7016, GNorm = 0.9017, lr_0 = 4.3714e-04
Loss = 2.5494e-01, PNorm = 35.7439, GNorm = 2.5274, lr_0 = 4.2605e-04
Validation auc = 0.862331
Epoch 12
Loss = 2.7021e-01, PNorm = 35.7715, GNorm = 0.6333, lr_0 = 4.1524e-04
Loss = 2.5902e-01, PNorm = 35.8035, GNorm = 1.9498, lr_0 = 4.0471e-04
Loss = 2.8274e-01, PNorm = 35.8342, GNorm = 1.3376, lr_0 = 3.9444e-04
Validation auc = 0.871743
Epoch 13
Loss = 2.3532e-01, PNorm = 35.8605, GNorm = 2.3923, lr_0 = 3.8443e-04
Loss = 2.5791e-01, PNorm = 35.8861, GNorm = 2.1943, lr_0 = 3.7468e-04
Loss = 2.7460e-01, PNorm = 35.9150, GNorm = 1.5343, lr_0 = 3.6517e-04
Validation auc = 0.873620
Epoch 14
Loss = 2.0399e-01, PNorm = 35.9476, GNorm = 1.4632, lr_0 = 3.5500e-04
Loss = 2.7089e-01, PNorm = 35.9726, GNorm = 1.6253, lr_0 = 3.4599e-04
Loss = 2.3401e-01, PNorm = 35.9997, GNorm = 0.7775, lr_0 = 3.3721e-04
Validation auc = 0.876425
Epoch 15
Loss = 2.6768e-01, PNorm = 36.0240, GNorm = 0.9954, lr_0 = 3.2866e-04
Loss = 2.0685e-01, PNorm = 36.0548, GNorm = 1.8900, lr_0 = 3.2032e-04
Loss = 2.2412e-01, PNorm = 36.0833, GNorm = 0.5792, lr_0 = 3.1219e-04
Loss = 2.4476e-01, PNorm = 36.1085, GNorm = 1.6445, lr_0 = 3.0427e-04
Validation auc = 0.875596
Epoch 16
Loss = 2.2949e-01, PNorm = 36.1305, GNorm = 0.9145, lr_0 = 2.9579e-04
Loss = 1.9585e-01, PNorm = 36.1505, GNorm = 0.4529, lr_0 = 2.8828e-04
Loss = 2.7090e-01, PNorm = 36.1746, GNorm = 0.7945, lr_0 = 2.8097e-04
Validation auc = 0.877208
Epoch 17
Loss = 2.1816e-01, PNorm = 36.1949, GNorm = 2.0708, lr_0 = 2.7384e-04
Loss = 1.8441e-01, PNorm = 36.2158, GNorm = 1.0388, lr_0 = 2.6689e-04
Loss = 2.8637e-01, PNorm = 36.2391, GNorm = 0.9753, lr_0 = 2.6012e-04
Validation auc = 0.870138
Epoch 18
Loss = 1.5308e-01, PNorm = 36.2586, GNorm = 2.1514, lr_0 = 2.5352e-04
Loss = 2.2635e-01, PNorm = 36.2779, GNorm = 1.0403, lr_0 = 2.4709e-04
Loss = 2.2665e-01, PNorm = 36.2964, GNorm = 1.3590, lr_0 = 2.4082e-04
Validation auc = 0.869019
Epoch 19
Loss = 8.9551e-02, PNorm = 36.3192, GNorm = 0.7785, lr_0 = 2.3411e-04
Loss = 2.0486e-01, PNorm = 36.3410, GNorm = 0.7392, lr_0 = 2.2817e-04
Loss = 2.2939e-01, PNorm = 36.3640, GNorm = 1.2424, lr_0 = 2.2238e-04
Loss = 1.9926e-01, PNorm = 36.3786, GNorm = 0.7721, lr_0 = 2.1674e-04
Validation auc = 0.875981
Epoch 20
Loss = 2.0309e-01, PNorm = 36.3941, GNorm = 2.4386, lr_0 = 2.1124e-04
Loss = 2.0890e-01, PNorm = 36.4104, GNorm = 1.4285, lr_0 = 2.0588e-04
Loss = 1.8153e-01, PNorm = 36.4284, GNorm = 0.5590, lr_0 = 2.0066e-04
Validation auc = 0.870780
Epoch 21
Loss = 1.8481e-01, PNorm = 36.4460, GNorm = 2.7512, lr_0 = 1.9557e-04
Loss = 2.1980e-01, PNorm = 36.4644, GNorm = 2.2602, lr_0 = 1.9060e-04
Loss = 1.8008e-01, PNorm = 36.4805, GNorm = 0.9021, lr_0 = 1.8577e-04
Validation auc = 0.875258
Epoch 22
Loss = 1.8978e-01, PNorm = 36.4971, GNorm = 0.7574, lr_0 = 1.8059e-04
Loss = 1.9064e-01, PNorm = 36.5102, GNorm = 1.5119, lr_0 = 1.7601e-04
Loss = 2.1171e-01, PNorm = 36.5234, GNorm = 0.6926, lr_0 = 1.7154e-04
Loss = 1.9472e-01, PNorm = 36.5373, GNorm = 0.9849, lr_0 = 1.6719e-04
Validation auc = 0.881586
Epoch 23
Loss = 1.8850e-01, PNorm = 36.5525, GNorm = 1.5114, lr_0 = 1.6295e-04
Loss = 2.0301e-01, PNorm = 36.5675, GNorm = 1.0058, lr_0 = 1.5882e-04
Loss = 1.8228e-01, PNorm = 36.5804, GNorm = 1.7929, lr_0 = 1.5479e-04
Validation auc = 0.878990
Epoch 24
Loss = 1.9413e-01, PNorm = 36.5934, GNorm = 0.9976, lr_0 = 1.5047e-04
Loss = 2.0365e-01, PNorm = 36.6074, GNorm = 0.7346, lr_0 = 1.4665e-04
Loss = 1.8043e-01, PNorm = 36.6215, GNorm = 0.6577, lr_0 = 1.4293e-04
Validation auc = 0.873295
Epoch 25
Loss = 1.6548e-01, PNorm = 36.6328, GNorm = 0.7261, lr_0 = 1.3931e-04
Loss = 1.9304e-01, PNorm = 36.6451, GNorm = 1.2106, lr_0 = 1.3577e-04
Loss = 1.9536e-01, PNorm = 36.6578, GNorm = 0.9719, lr_0 = 1.3233e-04
Validation auc = 0.872888
Epoch 26
Loss = 2.1892e-01, PNorm = 36.6704, GNorm = 1.1834, lr_0 = 1.2897e-04
Loss = 1.8540e-01, PNorm = 36.6827, GNorm = 2.2023, lr_0 = 1.2570e-04
Loss = 1.8935e-01, PNorm = 36.6935, GNorm = 1.6809, lr_0 = 1.2251e-04
Loss = 1.7464e-01, PNorm = 36.7032, GNorm = 1.7633, lr_0 = 1.1940e-04
Loss = 1.8098e-01, PNorm = 36.7042, GNorm = 3.0041, lr_0 = 1.1909e-04
Validation auc = 0.881022
Epoch 27
Loss = 1.7639e-01, PNorm = 36.7141, GNorm = 1.2014, lr_0 = 1.1607e-04
Loss = 1.8164e-01, PNorm = 36.7256, GNorm = 1.2400, lr_0 = 1.1313e-04
Loss = 1.7504e-01, PNorm = 36.7352, GNorm = 3.4003, lr_0 = 1.1026e-04
Validation auc = 0.877288
Epoch 28
Loss = 1.8956e-01, PNorm = 36.7454, GNorm = 2.1527, lr_0 = 1.0746e-04
Loss = 1.6665e-01, PNorm = 36.7553, GNorm = 1.3492, lr_0 = 1.0473e-04
Loss = 1.7506e-01, PNorm = 36.7639, GNorm = 1.7218, lr_0 = 1.0208e-04
Validation auc = 0.876728
Epoch 29
Loss = 1.2047e-01, PNorm = 36.7740, GNorm = 1.0475, lr_0 = 1.0000e-04
Loss = 2.1471e-01, PNorm = 36.7832, GNorm = 1.2062, lr_0 = 1.0000e-04
Loss = 1.7566e-01, PNorm = 36.7917, GNorm = 2.2096, lr_0 = 1.0000e-04
Validation auc = 0.881241
Model 0 best validation auc = 0.881586 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.884451
Ensemble test auc = 0.884451
Fold 3
Splitting data with seed 3
Total scaffolds = 1,025 | train scaffolds = 783 | val scaffolds = 0 | test scaffolds = 242
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.8503e-01, PNorm = 34.0129, GNorm = 0.7183, lr_0 = 2.5469e-04
Loss = 5.3260e-01, PNorm = 34.0194, GNorm = 0.8494, lr_0 = 3.9531e-04
Loss = 5.2468e-01, PNorm = 34.0407, GNorm = 0.3495, lr_0 = 5.3594e-04
Validation auc = 0.753098
Epoch 1
Loss = 4.9305e-01, PNorm = 34.0837, GNorm = 1.5001, lr_0 = 6.9063e-04
Loss = 4.5417e-01, PNorm = 34.1229, GNorm = 1.2743, lr_0 = 8.3125e-04
Loss = 4.2560e-01, PNorm = 34.1709, GNorm = 0.3752, lr_0 = 9.7187e-04
Validation auc = 0.801727
Epoch 2
Loss = 4.1467e-01, PNorm = 34.2309, GNorm = 2.1363, lr_0 = 9.7965e-04
Loss = 3.7320e-01, PNorm = 34.2967, GNorm = 2.4100, lr_0 = 9.5480e-04
Loss = 4.0981e-01, PNorm = 34.3477, GNorm = 1.3296, lr_0 = 9.3057e-04
Validation auc = 0.817309
Epoch 3
Loss = 3.8771e-01, PNorm = 34.4124, GNorm = 0.6317, lr_0 = 9.0463e-04
Loss = 3.9085e-01, PNorm = 34.4764, GNorm = 1.6561, lr_0 = 8.8168e-04
Loss = 3.4792e-01, PNorm = 34.5298, GNorm = 0.5630, lr_0 = 8.5931e-04
Loss = 3.5220e-01, PNorm = 34.5699, GNorm = 1.3693, lr_0 = 8.3751e-04
Validation auc = 0.809701
Epoch 4
Loss = 3.3247e-01, PNorm = 34.6296, GNorm = 1.1420, lr_0 = 8.1626e-04
Loss = 3.5306e-01, PNorm = 34.6740, GNorm = 1.1846, lr_0 = 7.9555e-04
Loss = 3.3732e-01, PNorm = 34.7250, GNorm = 0.4723, lr_0 = 7.7537e-04
Validation auc = 0.844284
Epoch 5
Loss = 3.3587e-01, PNorm = 34.7825, GNorm = 1.8932, lr_0 = 7.5570e-04
Loss = 3.0881e-01, PNorm = 34.8456, GNorm = 0.4694, lr_0 = 7.3653e-04
Loss = 3.7637e-01, PNorm = 34.8771, GNorm = 1.4360, lr_0 = 7.1784e-04
Validation auc = 0.850265
Epoch 6
Loss = 2.9220e-01, PNorm = 34.9294, GNorm = 0.6241, lr_0 = 6.9783e-04
Loss = 3.2549e-01, PNorm = 34.9790, GNorm = 0.6818, lr_0 = 6.8013e-04
Loss = 3.0608e-01, PNorm = 35.0372, GNorm = 0.8883, lr_0 = 6.6287e-04
Validation auc = 0.849036
Epoch 7
Loss = 2.5418e-01, PNorm = 35.0786, GNorm = 1.1208, lr_0 = 6.4605e-04
Loss = 2.9694e-01, PNorm = 35.1282, GNorm = 0.4616, lr_0 = 6.2966e-04
Loss = 3.2139e-01, PNorm = 35.1663, GNorm = 0.8886, lr_0 = 6.1369e-04
Loss = 3.0297e-01, PNorm = 35.2010, GNorm = 0.6191, lr_0 = 5.9812e-04
Loss = 3.7280e-01, PNorm = 35.2063, GNorm = 0.4405, lr_0 = 5.9658e-04
Validation auc = 0.852861
Epoch 8
Loss = 2.8168e-01, PNorm = 35.2603, GNorm = 1.9431, lr_0 = 5.8145e-04
Loss = 3.2319e-01, PNorm = 35.3027, GNorm = 0.6268, lr_0 = 5.6669e-04
Loss = 2.8460e-01, PNorm = 35.3421, GNorm = 1.0085, lr_0 = 5.5232e-04
Validation auc = 0.869803
Epoch 9
Loss = 2.4875e-01, PNorm = 35.3866, GNorm = 0.7201, lr_0 = 5.3830e-04
Loss = 2.9694e-01, PNorm = 35.4251, GNorm = 1.6812, lr_0 = 5.2465e-04
Loss = 2.7647e-01, PNorm = 35.4672, GNorm = 1.1003, lr_0 = 5.1133e-04
Validation auc = 0.866824
Epoch 10
Loss = 2.1429e-01, PNorm = 35.5067, GNorm = 0.4265, lr_0 = 4.9836e-04
Loss = 2.6924e-01, PNorm = 35.5539, GNorm = 3.2518, lr_0 = 4.8572e-04
Loss = 3.3974e-01, PNorm = 35.5871, GNorm = 1.1372, lr_0 = 4.7339e-04
Validation auc = 0.865611
Epoch 11
Loss = 2.5574e-01, PNorm = 35.6282, GNorm = 0.5900, lr_0 = 4.6020e-04
Loss = 2.7551e-01, PNorm = 35.6684, GNorm = 0.6836, lr_0 = 4.4852e-04
Loss = 2.5548e-01, PNorm = 35.7092, GNorm = 0.7596, lr_0 = 4.3714e-04
Loss = 2.6243e-01, PNorm = 35.7530, GNorm = 0.5971, lr_0 = 4.2605e-04
Validation auc = 0.854902
Epoch 12
Loss = 2.7059e-01, PNorm = 35.7839, GNorm = 0.8614, lr_0 = 4.1524e-04
Loss = 2.6100e-01, PNorm = 35.8191, GNorm = 0.8910, lr_0 = 4.0471e-04
Loss = 2.3268e-01, PNorm = 35.8580, GNorm = 0.6772, lr_0 = 3.9444e-04
Validation auc = 0.879089
Epoch 13
Loss = 2.4654e-01, PNorm = 35.8996, GNorm = 2.3554, lr_0 = 3.8443e-04
Loss = 2.4650e-01, PNorm = 35.9410, GNorm = 0.6923, lr_0 = 3.7468e-04
Loss = 2.7544e-01, PNorm = 35.9681, GNorm = 0.8501, lr_0 = 3.6517e-04
Validation auc = 0.879367
Epoch 14
Loss = 2.1829e-01, PNorm = 35.9958, GNorm = 1.1294, lr_0 = 3.5500e-04
Loss = 2.2900e-01, PNorm = 36.0258, GNorm = 1.1646, lr_0 = 3.4599e-04
Loss = 2.5168e-01, PNorm = 36.0620, GNorm = 0.7692, lr_0 = 3.3721e-04
Validation auc = 0.880691
Epoch 15
Loss = 1.7709e-01, PNorm = 36.0969, GNorm = 1.0523, lr_0 = 3.2866e-04
Loss = 2.4527e-01, PNorm = 36.1308, GNorm = 2.1124, lr_0 = 3.2032e-04
Loss = 2.2482e-01, PNorm = 36.1610, GNorm = 1.7217, lr_0 = 3.1219e-04
Loss = 2.3390e-01, PNorm = 36.1893, GNorm = 0.9631, lr_0 = 3.0427e-04
Validation auc = 0.880331
Epoch 16
Loss = 2.1933e-01, PNorm = 36.2226, GNorm = 1.0130, lr_0 = 2.9579e-04
Loss = 2.1466e-01, PNorm = 36.2504, GNorm = 1.1862, lr_0 = 2.8828e-04
Loss = 2.1801e-01, PNorm = 36.2805, GNorm = 1.3128, lr_0 = 2.8097e-04
Validation auc = 0.883562
Epoch 17
Loss = 1.9419e-01, PNorm = 36.3101, GNorm = 1.3975, lr_0 = 2.7384e-04
Loss = 2.0557e-01, PNorm = 36.3417, GNorm = 0.8939, lr_0 = 2.6689e-04
Loss = 2.3192e-01, PNorm = 36.3687, GNorm = 2.0555, lr_0 = 2.6012e-04
Validation auc = 0.886957
Epoch 18
Loss = 2.3539e-01, PNorm = 36.3916, GNorm = 0.8720, lr_0 = 2.5352e-04
Loss = 2.1929e-01, PNorm = 36.4164, GNorm = 0.7058, lr_0 = 2.4709e-04
Loss = 2.4068e-01, PNorm = 36.4369, GNorm = 3.0150, lr_0 = 2.4082e-04
Validation auc = 0.881972
Epoch 19
Loss = 2.8110e-01, PNorm = 36.4620, GNorm = 0.9777, lr_0 = 2.3411e-04
Loss = 1.8928e-01, PNorm = 36.4869, GNorm = 0.7610, lr_0 = 2.2817e-04
Loss = 1.8999e-01, PNorm = 36.5149, GNorm = 1.1548, lr_0 = 2.2238e-04
Loss = 2.0293e-01, PNorm = 36.5373, GNorm = 0.7328, lr_0 = 2.1674e-04
Validation auc = 0.882238
Epoch 20
Loss = 1.4837e-01, PNorm = 36.5575, GNorm = 0.9761, lr_0 = 2.1124e-04
Loss = 2.4855e-01, PNorm = 36.5775, GNorm = 1.1418, lr_0 = 2.0588e-04
Loss = 1.9571e-01, PNorm = 36.5983, GNorm = 1.6342, lr_0 = 2.0066e-04
Validation auc = 0.885651
Epoch 21
Loss = 1.8447e-01, PNorm = 36.6182, GNorm = 1.4701, lr_0 = 1.9557e-04
Loss = 2.0830e-01, PNorm = 36.6364, GNorm = 1.7001, lr_0 = 1.9060e-04
Loss = 1.9511e-01, PNorm = 36.6552, GNorm = 0.7673, lr_0 = 1.8577e-04
Validation auc = 0.881236
Epoch 22
Loss = 1.6973e-01, PNorm = 36.6757, GNorm = 0.9187, lr_0 = 1.8059e-04
Loss = 1.8659e-01, PNorm = 36.6936, GNorm = 1.1550, lr_0 = 1.7601e-04
Loss = 1.7931e-01, PNorm = 36.7113, GNorm = 1.1469, lr_0 = 1.7154e-04
Loss = 1.9458e-01, PNorm = 36.7288, GNorm = 0.9962, lr_0 = 1.6719e-04
Validation auc = 0.886035
Epoch 23
Loss = 1.6233e-01, PNorm = 36.7440, GNorm = 2.0711, lr_0 = 1.6295e-04
Loss = 1.8848e-01, PNorm = 36.7586, GNorm = 1.0342, lr_0 = 1.5882e-04
Loss = 2.2215e-01, PNorm = 36.7735, GNorm = 1.5878, lr_0 = 1.5479e-04
Validation auc = 0.884020
Epoch 24
Loss = 1.8076e-01, PNorm = 36.7899, GNorm = 1.7198, lr_0 = 1.5047e-04
Loss = 1.8257e-01, PNorm = 36.8053, GNorm = 1.0520, lr_0 = 1.4665e-04
Loss = 1.9706e-01, PNorm = 36.8194, GNorm = 1.0626, lr_0 = 1.4293e-04
Validation auc = 0.890895
Epoch 25
Loss = 2.0510e-01, PNorm = 36.8340, GNorm = 1.5704, lr_0 = 1.3931e-04
Loss = 1.6853e-01, PNorm = 36.8474, GNorm = 0.8417, lr_0 = 1.3577e-04
Loss = 1.5834e-01, PNorm = 36.8612, GNorm = 0.9323, lr_0 = 1.3233e-04
Validation auc = 0.891019
Epoch 26
Loss = 2.0799e-01, PNorm = 36.8742, GNorm = 0.9327, lr_0 = 1.2897e-04
Loss = 1.7609e-01, PNorm = 36.8876, GNorm = 0.8374, lr_0 = 1.2570e-04
Loss = 1.6518e-01, PNorm = 36.9010, GNorm = 1.6749, lr_0 = 1.2251e-04
Loss = 1.7412e-01, PNorm = 36.9125, GNorm = 1.5180, lr_0 = 1.1940e-04
Loss = 1.5249e-01, PNorm = 36.9135, GNorm = 1.7315, lr_0 = 1.1909e-04
Validation auc = 0.891827
Epoch 27
Loss = 1.6977e-01, PNorm = 36.9245, GNorm = 2.7031, lr_0 = 1.1607e-04
Loss = 1.6511e-01, PNorm = 36.9350, GNorm = 1.1789, lr_0 = 1.1313e-04
Loss = 1.6014e-01, PNorm = 36.9464, GNorm = 1.8058, lr_0 = 1.1026e-04
Validation auc = 0.886515
Epoch 28
Loss = 1.6906e-01, PNorm = 36.9574, GNorm = 2.0566, lr_0 = 1.0746e-04
Loss = 1.5989e-01, PNorm = 36.9693, GNorm = 1.4375, lr_0 = 1.0473e-04
Loss = 1.5272e-01, PNorm = 36.9798, GNorm = 0.9655, lr_0 = 1.0208e-04
Validation auc = 0.889167
Epoch 29
Loss = 1.8119e-01, PNorm = 36.9902, GNorm = 2.0362, lr_0 = 1.0000e-04
Loss = 1.5775e-01, PNorm = 36.9985, GNorm = 0.7633, lr_0 = 1.0000e-04
Loss = 1.8003e-01, PNorm = 37.0084, GNorm = 1.5576, lr_0 = 1.0000e-04
Validation auc = 0.878503
Model 0 best validation auc = 0.891827 on epoch 26
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.893417
Ensemble test auc = 0.893417
Fold 4
Splitting data with seed 4
Total scaffolds = 1,025 | train scaffolds = 793 | val scaffolds = 0 | test scaffolds = 232
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.8904e-01, PNorm = 34.0130, GNorm = 0.4582, lr_0 = 2.5469e-04
Loss = 5.4910e-01, PNorm = 34.0167, GNorm = 0.3335, lr_0 = 3.9531e-04
Loss = 4.7079e-01, PNorm = 34.0347, GNorm = 0.4258, lr_0 = 5.3594e-04
Validation auc = 0.714421
Epoch 1
Loss = 4.4932e-01, PNorm = 34.0689, GNorm = 0.7341, lr_0 = 6.9063e-04
Loss = 4.5592e-01, PNorm = 34.1133, GNorm = 1.1783, lr_0 = 8.3125e-04
Loss = 4.6461e-01, PNorm = 34.1674, GNorm = 0.9487, lr_0 = 9.7187e-04
Validation auc = 0.802569
Epoch 2
Loss = 4.4770e-01, PNorm = 34.2328, GNorm = 0.9698, lr_0 = 9.7965e-04
Loss = 3.7590e-01, PNorm = 34.3134, GNorm = 1.4789, lr_0 = 9.5480e-04
Loss = 3.8262e-01, PNorm = 34.3785, GNorm = 0.3217, lr_0 = 9.3057e-04
Validation auc = 0.816338
Epoch 3
Loss = 4.1084e-01, PNorm = 34.4491, GNorm = 1.3773, lr_0 = 9.0463e-04
Loss = 4.2045e-01, PNorm = 34.5011, GNorm = 2.9319, lr_0 = 8.8168e-04
Loss = 4.0727e-01, PNorm = 34.5599, GNorm = 0.2623, lr_0 = 8.5931e-04
Loss = 3.7995e-01, PNorm = 34.6398, GNorm = 0.6466, lr_0 = 8.3751e-04
Validation auc = 0.816479
Epoch 4
Loss = 3.3837e-01, PNorm = 34.7114, GNorm = 0.8128, lr_0 = 8.1626e-04
Loss = 3.8992e-01, PNorm = 34.7621, GNorm = 1.0438, lr_0 = 7.9555e-04
Loss = 3.5696e-01, PNorm = 34.8062, GNorm = 1.3761, lr_0 = 7.7537e-04
Validation auc = 0.843436
Epoch 5
Loss = 3.4266e-01, PNorm = 34.8671, GNorm = 0.6989, lr_0 = 7.5570e-04
Loss = 3.3413e-01, PNorm = 34.9265, GNorm = 0.7118, lr_0 = 7.3653e-04
Loss = 3.6780e-01, PNorm = 34.9783, GNorm = 0.8837, lr_0 = 7.1784e-04
Validation auc = 0.852989
Epoch 6
Loss = 3.3458e-01, PNorm = 35.0243, GNorm = 1.1508, lr_0 = 6.9783e-04
Loss = 3.1381e-01, PNorm = 35.0788, GNorm = 0.8429, lr_0 = 6.8013e-04
Loss = 3.2376e-01, PNorm = 35.1350, GNorm = 0.7356, lr_0 = 6.6287e-04
Validation auc = 0.857785
Epoch 7
Loss = 3.9145e-01, PNorm = 35.1828, GNorm = 0.7814, lr_0 = 6.4605e-04
Loss = 2.7528e-01, PNorm = 35.2190, GNorm = 0.8323, lr_0 = 6.2966e-04
Loss = 3.2363e-01, PNorm = 35.2726, GNorm = 1.8237, lr_0 = 6.1369e-04
Loss = 3.0749e-01, PNorm = 35.3255, GNorm = 2.0515, lr_0 = 5.9812e-04
Loss = 2.8228e-01, PNorm = 35.3293, GNorm = 0.7213, lr_0 = 5.9658e-04
Validation auc = 0.854700
Epoch 8
Loss = 2.9411e-01, PNorm = 35.3831, GNorm = 1.5271, lr_0 = 5.8145e-04
Loss = 2.8510e-01, PNorm = 35.4336, GNorm = 0.5846, lr_0 = 5.6669e-04
Loss = 3.2167e-01, PNorm = 35.4799, GNorm = 0.7057, lr_0 = 5.5232e-04
Validation auc = 0.851165
Epoch 9
Loss = 2.6575e-01, PNorm = 35.5124, GNorm = 0.7704, lr_0 = 5.3830e-04
Loss = 2.6473e-01, PNorm = 35.5572, GNorm = 0.5866, lr_0 = 5.2465e-04
Loss = 2.9093e-01, PNorm = 35.6069, GNorm = 0.7128, lr_0 = 5.1133e-04
Validation auc = 0.857636
Epoch 10
Loss = 3.5403e-01, PNorm = 35.6530, GNorm = 0.7657, lr_0 = 4.9836e-04
Loss = 2.5887e-01, PNorm = 35.6959, GNorm = 0.6837, lr_0 = 4.8572e-04
Loss = 2.5052e-01, PNorm = 35.7403, GNorm = 0.5641, lr_0 = 4.7339e-04
Validation auc = 0.863423
Epoch 11
Loss = 2.7768e-01, PNorm = 35.7913, GNorm = 1.3297, lr_0 = 4.6020e-04
Loss = 2.3540e-01, PNorm = 35.8298, GNorm = 0.5965, lr_0 = 4.4852e-04
Loss = 2.5308e-01, PNorm = 35.8713, GNorm = 1.3339, lr_0 = 4.3714e-04
Loss = 2.8692e-01, PNorm = 35.9113, GNorm = 0.5342, lr_0 = 4.2605e-04
Validation auc = 0.871476
Epoch 12
Loss = 2.5221e-01, PNorm = 35.9515, GNorm = 0.6847, lr_0 = 4.1524e-04
Loss = 2.4157e-01, PNorm = 35.9993, GNorm = 0.9547, lr_0 = 4.0471e-04
Loss = 2.6724e-01, PNorm = 36.0337, GNorm = 0.9547, lr_0 = 3.9444e-04
Validation auc = 0.876039
Epoch 13
Loss = 2.1849e-01, PNorm = 36.0666, GNorm = 1.0429, lr_0 = 3.8443e-04
Loss = 2.6876e-01, PNorm = 36.1041, GNorm = 0.6180, lr_0 = 3.7468e-04
Loss = 2.5427e-01, PNorm = 36.1407, GNorm = 1.7197, lr_0 = 3.6517e-04
Validation auc = 0.873085
Epoch 14
Loss = 2.1584e-01, PNorm = 36.1751, GNorm = 0.7762, lr_0 = 3.5500e-04
Loss = 2.4688e-01, PNorm = 36.2082, GNorm = 1.1125, lr_0 = 3.4599e-04
Loss = 2.1242e-01, PNorm = 36.2445, GNorm = 1.2601, lr_0 = 3.3721e-04
Validation auc = 0.864683
Epoch 15
Loss = 1.7947e-01, PNorm = 36.2788, GNorm = 0.4194, lr_0 = 3.2866e-04
Loss = 2.2289e-01, PNorm = 36.3048, GNorm = 0.6260, lr_0 = 3.2032e-04
Loss = 2.6165e-01, PNorm = 36.3329, GNorm = 0.6240, lr_0 = 3.1219e-04
Loss = 2.2531e-01, PNorm = 36.3659, GNorm = 0.7357, lr_0 = 3.0427e-04
Validation auc = 0.881949
Epoch 16
Loss = 2.4698e-01, PNorm = 36.4025, GNorm = 0.8394, lr_0 = 2.9579e-04
Loss = 2.1054e-01, PNorm = 36.4361, GNorm = 0.5998, lr_0 = 2.8828e-04
Loss = 2.1337e-01, PNorm = 36.4674, GNorm = 1.2679, lr_0 = 2.8097e-04
Validation auc = 0.875559
Epoch 17
Loss = 2.0708e-01, PNorm = 36.4913, GNorm = 0.9110, lr_0 = 2.7384e-04
Loss = 1.9125e-01, PNorm = 36.5212, GNorm = 0.8134, lr_0 = 2.6689e-04
Loss = 2.1184e-01, PNorm = 36.5505, GNorm = 0.6213, lr_0 = 2.6012e-04
Validation auc = 0.881293
Epoch 18
Loss = 1.7150e-01, PNorm = 36.5733, GNorm = 1.0104, lr_0 = 2.5352e-04
Loss = 2.0804e-01, PNorm = 36.5983, GNorm = 0.9529, lr_0 = 2.4709e-04
Loss = 2.2783e-01, PNorm = 36.6194, GNorm = 1.5317, lr_0 = 2.4082e-04
Validation auc = 0.883125
Epoch 19
Loss = 2.8598e-01, PNorm = 36.6457, GNorm = 2.1299, lr_0 = 2.3411e-04
Loss = 2.0476e-01, PNorm = 36.6710, GNorm = 0.8491, lr_0 = 2.2817e-04
Loss = 1.9721e-01, PNorm = 36.6963, GNorm = 2.5710, lr_0 = 2.2238e-04
Loss = 2.0929e-01, PNorm = 36.7201, GNorm = 0.7773, lr_0 = 2.1674e-04
Validation auc = 0.881723
Epoch 20
Loss = 2.0260e-01, PNorm = 36.7383, GNorm = 1.5371, lr_0 = 2.1124e-04
Loss = 2.1149e-01, PNorm = 36.7575, GNorm = 2.3478, lr_0 = 2.0588e-04
Loss = 2.0423e-01, PNorm = 36.7785, GNorm = 1.1346, lr_0 = 2.0066e-04
Validation auc = 0.883188
Epoch 21
Loss = 1.5742e-01, PNorm = 36.8023, GNorm = 1.2067, lr_0 = 1.9557e-04
Loss = 1.9617e-01, PNorm = 36.8247, GNorm = 1.3102, lr_0 = 1.9060e-04
Loss = 2.2532e-01, PNorm = 36.8430, GNorm = 2.1962, lr_0 = 1.8577e-04
Validation auc = 0.885361
Epoch 22
Loss = 1.3227e-01, PNorm = 36.8661, GNorm = 0.5254, lr_0 = 1.8059e-04
Loss = 2.1334e-01, PNorm = 36.8861, GNorm = 0.9261, lr_0 = 1.7601e-04
Loss = 2.0413e-01, PNorm = 36.9028, GNorm = 1.7435, lr_0 = 1.7154e-04
Loss = 1.6772e-01, PNorm = 36.9223, GNorm = 0.8143, lr_0 = 1.6719e-04
Validation auc = 0.884290
Epoch 23
Loss = 1.9666e-01, PNorm = 36.9405, GNorm = 0.9696, lr_0 = 1.6295e-04
Loss = 1.7601e-01, PNorm = 36.9563, GNorm = 1.4962, lr_0 = 1.5882e-04
Loss = 2.0059e-01, PNorm = 36.9728, GNorm = 1.8332, lr_0 = 1.5479e-04
Validation auc = 0.882020
Epoch 24
Loss = 1.9019e-01, PNorm = 36.9908, GNorm = 1.6233, lr_0 = 1.5047e-04
Loss = 1.5421e-01, PNorm = 37.0075, GNorm = 0.9650, lr_0 = 1.4665e-04
Loss = 1.8616e-01, PNorm = 37.0246, GNorm = 0.6858, lr_0 = 1.4293e-04
Validation auc = 0.884285
Epoch 25
Loss = 1.7820e-01, PNorm = 37.0395, GNorm = 1.5652, lr_0 = 1.3931e-04
Loss = 1.6335e-01, PNorm = 37.0534, GNorm = 1.0124, lr_0 = 1.3577e-04
Loss = 1.9755e-01, PNorm = 37.0685, GNorm = 0.6697, lr_0 = 1.3233e-04
Validation auc = 0.881236
Epoch 26
Loss = 2.5348e-01, PNorm = 37.0818, GNorm = 1.0460, lr_0 = 1.2897e-04
Loss = 1.5218e-01, PNorm = 37.0944, GNorm = 1.1583, lr_0 = 1.2570e-04
Loss = 1.8730e-01, PNorm = 37.1069, GNorm = 1.1171, lr_0 = 1.2251e-04
Loss = 1.9544e-01, PNorm = 37.1206, GNorm = 3.5098, lr_0 = 1.1940e-04
Loss = 2.2225e-01, PNorm = 37.1214, GNorm = 2.6071, lr_0 = 1.1909e-04
Validation auc = 0.883871
Epoch 27
Loss = 1.7266e-01, PNorm = 37.1319, GNorm = 1.5730, lr_0 = 1.1607e-04
Loss = 1.9641e-01, PNorm = 37.1425, GNorm = 1.2776, lr_0 = 1.1313e-04
Loss = 1.6487e-01, PNorm = 37.1540, GNorm = 1.2483, lr_0 = 1.1026e-04
Validation auc = 0.882866
Epoch 28
Loss = 1.7875e-01, PNorm = 37.1672, GNorm = 1.7522, lr_0 = 1.0746e-04
Loss = 1.7473e-01, PNorm = 37.1794, GNorm = 0.7878, lr_0 = 1.0473e-04
Loss = 1.6981e-01, PNorm = 37.1904, GNorm = 1.3535, lr_0 = 1.0208e-04
Validation auc = 0.887590
Epoch 29
Loss = 1.6088e-01, PNorm = 37.2021, GNorm = 1.2300, lr_0 = 1.0000e-04
Loss = 1.4213e-01, PNorm = 37.2127, GNorm = 1.5068, lr_0 = 1.0000e-04
Loss = 1.8074e-01, PNorm = 37.2235, GNorm = 1.3147, lr_0 = 1.0000e-04
Validation auc = 0.884358
Model 0 best validation auc = 0.887590 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.938451
Ensemble test auc = 0.938451
Fold 5
Splitting data with seed 5
Total scaffolds = 1,025 | train scaffolds = 906 | val scaffolds = 0 | test scaffolds = 119
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.8033e-01, PNorm = 34.0138, GNorm = 1.1787, lr_0 = 2.5469e-04
Loss = 5.4678e-01, PNorm = 34.0184, GNorm = 1.1154, lr_0 = 3.9531e-04
Loss = 5.5692e-01, PNorm = 34.0360, GNorm = 0.9338, lr_0 = 5.3594e-04
Validation auc = 0.735027
Epoch 1
Loss = 4.5970e-01, PNorm = 34.0777, GNorm = 2.2193, lr_0 = 6.9063e-04
Loss = 4.5579e-01, PNorm = 34.1152, GNorm = 2.7257, lr_0 = 8.3125e-04
Loss = 4.9135e-01, PNorm = 34.1634, GNorm = 0.7147, lr_0 = 9.7187e-04
Validation auc = 0.766746
Epoch 2
Loss = 4.1898e-01, PNorm = 34.2314, GNorm = 0.5118, lr_0 = 9.7965e-04
Loss = 4.3117e-01, PNorm = 34.2876, GNorm = 1.2363, lr_0 = 9.5480e-04
Loss = 3.9515e-01, PNorm = 34.3500, GNorm = 0.7560, lr_0 = 9.3057e-04
Validation auc = 0.804363
Epoch 3
Loss = 4.2600e-01, PNorm = 34.4209, GNorm = 1.2319, lr_0 = 9.0463e-04
Loss = 3.3194e-01, PNorm = 34.4872, GNorm = 1.0340, lr_0 = 8.8168e-04
Loss = 3.8497e-01, PNorm = 34.5392, GNorm = 2.0303, lr_0 = 8.5931e-04
Loss = 4.1747e-01, PNorm = 34.5918, GNorm = 0.6238, lr_0 = 8.3751e-04
Validation auc = 0.794418
Epoch 4
Loss = 3.7177e-01, PNorm = 34.6527, GNorm = 0.3393, lr_0 = 8.1626e-04
Loss = 3.2056e-01, PNorm = 34.7074, GNorm = 0.4336, lr_0 = 7.9555e-04
Loss = 3.7145e-01, PNorm = 34.7541, GNorm = 0.9259, lr_0 = 7.7537e-04
Validation auc = 0.834360
Epoch 5
Loss = 3.1982e-01, PNorm = 34.8056, GNorm = 0.6751, lr_0 = 7.5570e-04
Loss = 3.2307e-01, PNorm = 34.8663, GNorm = 2.1552, lr_0 = 7.3653e-04
Loss = 3.6569e-01, PNorm = 34.9066, GNorm = 1.9811, lr_0 = 7.1784e-04
Validation auc = 0.837094
Epoch 6
Loss = 3.7645e-01, PNorm = 34.9541, GNorm = 1.1249, lr_0 = 6.9783e-04
Loss = 2.9699e-01, PNorm = 35.0068, GNorm = 0.6845, lr_0 = 6.8013e-04
Loss = 3.3965e-01, PNorm = 35.0486, GNorm = 0.4158, lr_0 = 6.6287e-04
Validation auc = 0.842136
Epoch 7
Loss = 3.6432e-01, PNorm = 35.0918, GNorm = 1.0273, lr_0 = 6.4605e-04
Loss = 2.7651e-01, PNorm = 35.1428, GNorm = 0.3162, lr_0 = 6.2966e-04
Loss = 3.2439e-01, PNorm = 35.1988, GNorm = 1.1205, lr_0 = 6.1369e-04
Loss = 3.3336e-01, PNorm = 35.2405, GNorm = 1.3062, lr_0 = 5.9812e-04
Loss = 3.3097e-01, PNorm = 35.2434, GNorm = 1.5771, lr_0 = 5.9658e-04
Validation auc = 0.849479
Epoch 8
Loss = 3.1454e-01, PNorm = 35.2786, GNorm = 0.5499, lr_0 = 5.8145e-04
Loss = 2.8740e-01, PNorm = 35.3219, GNorm = 1.2451, lr_0 = 5.6669e-04
Loss = 3.2447e-01, PNorm = 35.3711, GNorm = 0.4027, lr_0 = 5.5232e-04
Validation auc = 0.853164
Epoch 9
Loss = 2.6941e-01, PNorm = 35.4252, GNorm = 0.6284, lr_0 = 5.3830e-04
Loss = 2.5306e-01, PNorm = 35.4747, GNorm = 1.4621, lr_0 = 5.2465e-04
Loss = 2.8457e-01, PNorm = 35.5056, GNorm = 0.9449, lr_0 = 5.1133e-04
Validation auc = 0.852232
Epoch 10
Loss = 3.5473e-01, PNorm = 35.5534, GNorm = 0.9740, lr_0 = 4.9836e-04
Loss = 2.5513e-01, PNorm = 35.5959, GNorm = 1.0464, lr_0 = 4.8572e-04
Loss = 2.3035e-01, PNorm = 35.6407, GNorm = 0.5048, lr_0 = 4.7339e-04
Validation auc = 0.873011
Epoch 11
Loss = 2.1947e-01, PNorm = 35.6786, GNorm = 1.5859, lr_0 = 4.6020e-04
Loss = 2.9966e-01, PNorm = 35.7161, GNorm = 1.6161, lr_0 = 4.4852e-04
Loss = 2.3920e-01, PNorm = 35.7500, GNorm = 0.8140, lr_0 = 4.3714e-04
Loss = 2.5769e-01, PNorm = 35.7887, GNorm = 2.0964, lr_0 = 4.2605e-04
Validation auc = 0.876054
Epoch 12
Loss = 2.6451e-01, PNorm = 35.8290, GNorm = 1.9923, lr_0 = 4.1524e-04
Loss = 2.9541e-01, PNorm = 35.8587, GNorm = 0.7680, lr_0 = 4.0471e-04
Loss = 2.3624e-01, PNorm = 35.8921, GNorm = 0.6564, lr_0 = 3.9444e-04
Validation auc = 0.872729
Epoch 13
Loss = 2.4811e-01, PNorm = 35.9334, GNorm = 2.9048, lr_0 = 3.8443e-04
Loss = 2.4003e-01, PNorm = 35.9732, GNorm = 0.8903, lr_0 = 3.7468e-04
Loss = 3.1994e-01, PNorm = 36.0036, GNorm = 0.4857, lr_0 = 3.6517e-04
Validation auc = 0.873944
Epoch 14
Loss = 2.3606e-01, PNorm = 36.0327, GNorm = 0.9651, lr_0 = 3.5500e-04
Loss = 2.1234e-01, PNorm = 36.0662, GNorm = 0.8828, lr_0 = 3.4599e-04
Loss = 2.6915e-01, PNorm = 36.0970, GNorm = 1.4575, lr_0 = 3.3721e-04
Validation auc = 0.868701
Epoch 15
Loss = 3.0209e-01, PNorm = 36.1242, GNorm = 1.8489, lr_0 = 3.2866e-04
Loss = 2.2004e-01, PNorm = 36.1516, GNorm = 0.9104, lr_0 = 3.2032e-04
Loss = 2.0303e-01, PNorm = 36.1804, GNorm = 0.7067, lr_0 = 3.1219e-04
Loss = 2.5464e-01, PNorm = 36.2061, GNorm = 0.9119, lr_0 = 3.0427e-04
Validation auc = 0.876898
Epoch 16
Loss = 2.1173e-01, PNorm = 36.2318, GNorm = 1.0047, lr_0 = 2.9579e-04
Loss = 2.3335e-01, PNorm = 36.2596, GNorm = 1.0415, lr_0 = 2.8828e-04
Loss = 2.5902e-01, PNorm = 36.2869, GNorm = 0.9950, lr_0 = 2.8097e-04
Validation auc = 0.875209
Epoch 17
Loss = 1.9664e-01, PNorm = 36.3125, GNorm = 1.1060, lr_0 = 2.7384e-04
Loss = 2.0317e-01, PNorm = 36.3333, GNorm = 2.0615, lr_0 = 2.6689e-04
Loss = 2.3142e-01, PNorm = 36.3524, GNorm = 1.6721, lr_0 = 2.6012e-04
Validation auc = 0.876019
Epoch 18
Loss = 1.6227e-01, PNorm = 36.3788, GNorm = 0.7457, lr_0 = 2.5352e-04
Loss = 2.0263e-01, PNorm = 36.4048, GNorm = 1.6899, lr_0 = 2.4709e-04
Loss = 1.5962e-01, PNorm = 36.4262, GNorm = 1.3443, lr_0 = 2.4082e-04
Validation auc = 0.874317
Epoch 19
Loss = 2.8802e-01, PNorm = 36.4475, GNorm = 1.4766, lr_0 = 2.3411e-04
Loss = 2.0611e-01, PNorm = 36.4682, GNorm = 0.6141, lr_0 = 2.2817e-04
Loss = 1.7577e-01, PNorm = 36.4882, GNorm = 1.0868, lr_0 = 2.2238e-04
Loss = 2.1099e-01, PNorm = 36.5076, GNorm = 1.9374, lr_0 = 2.1674e-04
Validation auc = 0.872743
Epoch 20
Loss = 2.2023e-01, PNorm = 36.5294, GNorm = 0.7959, lr_0 = 2.1124e-04
Loss = 1.7023e-01, PNorm = 36.5468, GNorm = 1.8680, lr_0 = 2.0588e-04
Loss = 2.1346e-01, PNorm = 36.5662, GNorm = 1.5853, lr_0 = 2.0066e-04
Validation auc = 0.876977
Epoch 21
Loss = 1.6756e-01, PNorm = 36.5847, GNorm = 0.5861, lr_0 = 1.9557e-04
Loss = 2.1823e-01, PNorm = 36.6040, GNorm = 1.5526, lr_0 = 1.9060e-04
Loss = 1.6360e-01, PNorm = 36.6209, GNorm = 1.1944, lr_0 = 1.8577e-04
Validation auc = 0.879484
Epoch 22
Loss = 1.9874e-01, PNorm = 36.6384, GNorm = 1.3396, lr_0 = 1.8059e-04
Loss = 1.5375e-01, PNorm = 36.6547, GNorm = 0.9037, lr_0 = 1.7601e-04
Loss = 1.8212e-01, PNorm = 36.6717, GNorm = 0.6833, lr_0 = 1.7154e-04
Loss = 2.2151e-01, PNorm = 36.6873, GNorm = 1.0785, lr_0 = 1.6719e-04
Validation auc = 0.880958
Epoch 23
Loss = 1.9193e-01, PNorm = 36.7019, GNorm = 1.5677, lr_0 = 1.6295e-04
Loss = 1.9108e-01, PNorm = 36.7153, GNorm = 1.1084, lr_0 = 1.5882e-04
Loss = 1.5103e-01, PNorm = 36.7265, GNorm = 1.1219, lr_0 = 1.5479e-04
Validation auc = 0.882930
Epoch 24
Loss = 1.3201e-01, PNorm = 36.7415, GNorm = 0.7428, lr_0 = 1.5047e-04
Loss = 1.8692e-01, PNorm = 36.7554, GNorm = 2.0888, lr_0 = 1.4665e-04
Loss = 1.9702e-01, PNorm = 36.7685, GNorm = 1.5603, lr_0 = 1.4293e-04
Validation auc = 0.880481
Epoch 25
Loss = 1.1132e-01, PNorm = 36.7826, GNorm = 1.9829, lr_0 = 1.3931e-04
Loss = 1.5786e-01, PNorm = 36.7952, GNorm = 0.5368, lr_0 = 1.3577e-04
Loss = 1.6230e-01, PNorm = 36.8090, GNorm = 0.6102, lr_0 = 1.3233e-04
Validation auc = 0.879268
Epoch 26
Loss = 2.0914e-01, PNorm = 36.8220, GNorm = 0.9017, lr_0 = 1.2897e-04
Loss = 2.0112e-01, PNorm = 36.8320, GNorm = 2.0825, lr_0 = 1.2570e-04
Loss = 1.5139e-01, PNorm = 36.8427, GNorm = 2.4840, lr_0 = 1.2251e-04
Loss = 1.6615e-01, PNorm = 36.8539, GNorm = 2.2876, lr_0 = 1.1940e-04
Loss = 1.4737e-01, PNorm = 36.8552, GNorm = 4.3809, lr_0 = 1.1909e-04
Validation auc = 0.880099
Epoch 27
Loss = 1.8118e-01, PNorm = 36.8667, GNorm = 0.7281, lr_0 = 1.1607e-04
Loss = 1.6857e-01, PNorm = 36.8781, GNorm = 1.6661, lr_0 = 1.1313e-04
Loss = 1.3214e-01, PNorm = 36.8884, GNorm = 1.2085, lr_0 = 1.1026e-04
Validation auc = 0.878571
Epoch 28
Loss = 1.7943e-01, PNorm = 36.8972, GNorm = 1.5619, lr_0 = 1.0746e-04
Loss = 1.6334e-01, PNorm = 36.9072, GNorm = 0.7111, lr_0 = 1.0473e-04
Loss = 1.4617e-01, PNorm = 36.9182, GNorm = 1.1304, lr_0 = 1.0208e-04
Validation auc = 0.880136
Epoch 29
Loss = 1.4805e-01, PNorm = 36.9280, GNorm = 1.3807, lr_0 = 1.0000e-04
Loss = 1.6974e-01, PNorm = 36.9364, GNorm = 0.6806, lr_0 = 1.0000e-04
Loss = 1.7505e-01, PNorm = 36.9447, GNorm = 1.3101, lr_0 = 1.0000e-04
Validation auc = 0.878255
Model 0 best validation auc = 0.882930 on epoch 23
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.876687
Ensemble test auc = 0.876687
Fold 6
Splitting data with seed 6
Total scaffolds = 1,025 | train scaffolds = 833 | val scaffolds = 0 | test scaffolds = 192
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.6182e-01, PNorm = 34.0132, GNorm = 0.6161, lr_0 = 2.5469e-04
Loss = 5.4864e-01, PNorm = 34.0188, GNorm = 0.4329, lr_0 = 3.9531e-04
Loss = 5.0555e-01, PNorm = 34.0376, GNorm = 0.5773, lr_0 = 5.3594e-04
Validation auc = 0.720839
Epoch 1
Loss = 4.5161e-01, PNorm = 34.0805, GNorm = 1.8178, lr_0 = 6.9063e-04
Loss = 4.9292e-01, PNorm = 34.1068, GNorm = 3.3809, lr_0 = 8.3125e-04
Loss = 4.5214e-01, PNorm = 34.1450, GNorm = 0.6624, lr_0 = 9.7187e-04
Validation auc = 0.795613
Epoch 2
Loss = 4.6454e-01, PNorm = 34.1995, GNorm = 0.4109, lr_0 = 9.7965e-04
Loss = 3.9795e-01, PNorm = 34.2431, GNorm = 2.3008, lr_0 = 9.5480e-04
Loss = 3.5796e-01, PNorm = 34.2947, GNorm = 1.4976, lr_0 = 9.3057e-04
Validation auc = 0.817488
Epoch 3
Loss = 4.2133e-01, PNorm = 34.3367, GNorm = 2.0550, lr_0 = 9.0463e-04
Loss = 4.6422e-01, PNorm = 34.3847, GNorm = 0.4307, lr_0 = 8.8168e-04
Loss = 4.3600e-01, PNorm = 34.4464, GNorm = 1.3578, lr_0 = 8.5931e-04
Loss = 3.7713e-01, PNorm = 34.5002, GNorm = 0.3976, lr_0 = 8.3751e-04
Validation auc = 0.814387
Epoch 4
Loss = 3.5375e-01, PNorm = 34.5522, GNorm = 1.5074, lr_0 = 8.1626e-04
Loss = 3.5896e-01, PNorm = 34.5938, GNorm = 0.5127, lr_0 = 7.9555e-04
Loss = 3.8334e-01, PNorm = 34.6308, GNorm = 1.0827, lr_0 = 7.7537e-04
Validation auc = 0.827489
Epoch 5
Loss = 3.1088e-01, PNorm = 34.6880, GNorm = 0.9628, lr_0 = 7.5570e-04
Loss = 4.0120e-01, PNorm = 34.7423, GNorm = 0.4730, lr_0 = 7.3653e-04
Loss = 3.4849e-01, PNorm = 34.7869, GNorm = 0.4235, lr_0 = 7.1784e-04
Validation auc = 0.848541
Epoch 6
Loss = 3.2776e-01, PNorm = 34.8429, GNorm = 2.2564, lr_0 = 6.9783e-04
Loss = 3.5925e-01, PNorm = 34.8844, GNorm = 1.3872, lr_0 = 6.8013e-04
Loss = 3.3250e-01, PNorm = 34.9391, GNorm = 0.3400, lr_0 = 6.6287e-04
Validation auc = 0.846812
Epoch 7
Loss = 3.3242e-01, PNorm = 34.9893, GNorm = 0.5063, lr_0 = 6.4605e-04
Loss = 2.7401e-01, PNorm = 35.0454, GNorm = 0.8332, lr_0 = 6.2966e-04
Loss = 3.7172e-01, PNorm = 35.0911, GNorm = 0.8606, lr_0 = 6.1369e-04
Loss = 3.2611e-01, PNorm = 35.1325, GNorm = 0.6904, lr_0 = 5.9812e-04
Loss = 2.9493e-01, PNorm = 35.1374, GNorm = 0.4848, lr_0 = 5.9658e-04
Validation auc = 0.854277
Epoch 8
Loss = 3.5267e-01, PNorm = 35.1835, GNorm = 0.5040, lr_0 = 5.8145e-04
Loss = 2.9611e-01, PNorm = 35.2405, GNorm = 1.5063, lr_0 = 5.6669e-04
Loss = 2.7431e-01, PNorm = 35.2899, GNorm = 1.9948, lr_0 = 5.5232e-04
Validation auc = 0.848035
Epoch 9
Loss = 3.3042e-01, PNorm = 35.3289, GNorm = 0.5380, lr_0 = 5.3830e-04
Loss = 3.1613e-01, PNorm = 35.3795, GNorm = 1.5997, lr_0 = 5.2465e-04
Loss = 3.1015e-01, PNorm = 35.4274, GNorm = 0.5534, lr_0 = 5.1133e-04
Validation auc = 0.867727
Epoch 10
Loss = 2.6779e-01, PNorm = 35.4678, GNorm = 0.4061, lr_0 = 4.9836e-04
Loss = 2.7977e-01, PNorm = 35.5126, GNorm = 1.1212, lr_0 = 4.8572e-04
Loss = 3.2023e-01, PNorm = 35.5553, GNorm = 1.8822, lr_0 = 4.7339e-04
Validation auc = 0.864423
Epoch 11
Loss = 3.2623e-01, PNorm = 35.5952, GNorm = 1.3172, lr_0 = 4.6020e-04
Loss = 2.6594e-01, PNorm = 35.6291, GNorm = 0.8160, lr_0 = 4.4852e-04
Loss = 2.7306e-01, PNorm = 35.6642, GNorm = 2.5083, lr_0 = 4.3714e-04
Loss = 2.7640e-01, PNorm = 35.7069, GNorm = 1.2440, lr_0 = 4.2605e-04
Validation auc = 0.867787
Epoch 12
Loss = 2.8383e-01, PNorm = 35.7498, GNorm = 0.6595, lr_0 = 4.1524e-04
Loss = 2.6669e-01, PNorm = 35.7861, GNorm = 0.6838, lr_0 = 4.0471e-04
Loss = 2.6751e-01, PNorm = 35.8190, GNorm = 1.5112, lr_0 = 3.9444e-04
Validation auc = 0.872715
Epoch 13
Loss = 2.4573e-01, PNorm = 35.8542, GNorm = 0.9518, lr_0 = 3.8443e-04
Loss = 2.5258e-01, PNorm = 35.8918, GNorm = 0.7385, lr_0 = 3.7468e-04
Loss = 2.7146e-01, PNorm = 35.9213, GNorm = 0.7374, lr_0 = 3.6517e-04
Validation auc = 0.869090
Epoch 14
Loss = 2.2748e-01, PNorm = 35.9547, GNorm = 0.9609, lr_0 = 3.5500e-04
Loss = 2.0082e-01, PNorm = 35.9866, GNorm = 0.9581, lr_0 = 3.4599e-04
Loss = 2.7723e-01, PNorm = 36.0187, GNorm = 0.5026, lr_0 = 3.3721e-04
Validation auc = 0.868104
Epoch 15
Loss = 3.0154e-01, PNorm = 36.0463, GNorm = 1.4333, lr_0 = 3.2866e-04
Loss = 2.7512e-01, PNorm = 36.0731, GNorm = 1.4761, lr_0 = 3.2032e-04
Loss = 2.2682e-01, PNorm = 36.0994, GNorm = 0.5695, lr_0 = 3.1219e-04
Loss = 2.1509e-01, PNorm = 36.1298, GNorm = 1.5742, lr_0 = 3.0427e-04
Validation auc = 0.875658
Epoch 16
Loss = 2.4645e-01, PNorm = 36.1587, GNorm = 1.4000, lr_0 = 2.9579e-04
Loss = 2.1079e-01, PNorm = 36.1864, GNorm = 0.7697, lr_0 = 2.8828e-04
Loss = 2.3936e-01, PNorm = 36.2159, GNorm = 1.7381, lr_0 = 2.8097e-04
Validation auc = 0.876264
Epoch 17
Loss = 1.7706e-01, PNorm = 36.2408, GNorm = 1.4449, lr_0 = 2.7384e-04
Loss = 2.6606e-01, PNorm = 36.2667, GNorm = 1.2493, lr_0 = 2.6689e-04
Loss = 2.3528e-01, PNorm = 36.2863, GNorm = 0.5351, lr_0 = 2.6012e-04
Validation auc = 0.877279
Epoch 18
Loss = 2.2911e-01, PNorm = 36.3074, GNorm = 0.8576, lr_0 = 2.5352e-04
Loss = 2.5532e-01, PNorm = 36.3298, GNorm = 1.3049, lr_0 = 2.4709e-04
Loss = 2.0325e-01, PNorm = 36.3527, GNorm = 0.7950, lr_0 = 2.4082e-04
Validation auc = 0.881196
Epoch 19
Loss = 1.6380e-01, PNorm = 36.3749, GNorm = 1.2393, lr_0 = 2.3411e-04
Loss = 2.4719e-01, PNorm = 36.3915, GNorm = 1.5367, lr_0 = 2.2817e-04
Loss = 1.7361e-01, PNorm = 36.4108, GNorm = 1.9581, lr_0 = 2.2238e-04
Loss = 2.2462e-01, PNorm = 36.4303, GNorm = 1.4962, lr_0 = 2.1674e-04
Validation auc = 0.875450
Epoch 20
Loss = 1.9001e-01, PNorm = 36.4510, GNorm = 0.9956, lr_0 = 2.1124e-04
Loss = 2.1640e-01, PNorm = 36.4719, GNorm = 1.4993, lr_0 = 2.0588e-04
Loss = 1.8828e-01, PNorm = 36.4908, GNorm = 0.7877, lr_0 = 2.0066e-04
Validation auc = 0.881552
Epoch 21
Loss = 2.0541e-01, PNorm = 36.5054, GNorm = 1.2624, lr_0 = 1.9557e-04
Loss = 1.9978e-01, PNorm = 36.5225, GNorm = 0.9034, lr_0 = 1.9060e-04
Loss = 1.7407e-01, PNorm = 36.5379, GNorm = 1.3351, lr_0 = 1.8577e-04
Validation auc = 0.877829
Epoch 22
Loss = 1.7511e-01, PNorm = 36.5563, GNorm = 0.8774, lr_0 = 1.8059e-04
Loss = 1.5307e-01, PNorm = 36.5738, GNorm = 2.4033, lr_0 = 1.7601e-04
Loss = 2.4618e-01, PNorm = 36.5901, GNorm = 1.7060, lr_0 = 1.7154e-04
Loss = 1.7840e-01, PNorm = 36.6022, GNorm = 1.0139, lr_0 = 1.6719e-04
Validation auc = 0.878885
Epoch 23
Loss = 1.7602e-01, PNorm = 36.6166, GNorm = 2.6906, lr_0 = 1.6295e-04
Loss = 2.1315e-01, PNorm = 36.6297, GNorm = 3.1348, lr_0 = 1.5882e-04
Loss = 1.9032e-01, PNorm = 36.6446, GNorm = 1.4982, lr_0 = 1.5479e-04
Validation auc = 0.871594
Epoch 24
Loss = 2.0369e-01, PNorm = 36.6579, GNorm = 2.8376, lr_0 = 1.5047e-04
Loss = 2.0615e-01, PNorm = 36.6703, GNorm = 1.4416, lr_0 = 1.4665e-04
Loss = 2.0013e-01, PNorm = 36.6799, GNorm = 0.9871, lr_0 = 1.4293e-04
Validation auc = 0.876537
Epoch 25
Loss = 2.0016e-01, PNorm = 36.6933, GNorm = 2.2319, lr_0 = 1.3931e-04
Loss = 1.6291e-01, PNorm = 36.7061, GNorm = 0.7980, lr_0 = 1.3577e-04
Loss = 2.0881e-01, PNorm = 36.7186, GNorm = 1.1770, lr_0 = 1.3233e-04
Validation auc = 0.878787
Epoch 26
Loss = 2.2723e-01, PNorm = 36.7291, GNorm = 1.8979, lr_0 = 1.2897e-04
Loss = 1.6891e-01, PNorm = 36.7399, GNorm = 0.9638, lr_0 = 1.2570e-04
Loss = 1.4573e-01, PNorm = 36.7516, GNorm = 1.4638, lr_0 = 1.2251e-04
Loss = 2.0396e-01, PNorm = 36.7623, GNorm = 1.6277, lr_0 = 1.1940e-04
Loss = 1.6013e-01, PNorm = 36.7631, GNorm = 2.0542, lr_0 = 1.1909e-04
Validation auc = 0.880557
Epoch 27
Loss = 1.8082e-01, PNorm = 36.7736, GNorm = 1.5187, lr_0 = 1.1607e-04
Loss = 1.5974e-01, PNorm = 36.7825, GNorm = 0.9081, lr_0 = 1.1313e-04
Loss = 2.1324e-01, PNorm = 36.7908, GNorm = 1.2305, lr_0 = 1.1026e-04
Validation auc = 0.881096
Epoch 28
Loss = 1.9306e-01, PNorm = 36.7998, GNorm = 1.4380, lr_0 = 1.0746e-04
Loss = 1.7735e-01, PNorm = 36.8071, GNorm = 2.7694, lr_0 = 1.0473e-04
Loss = 1.5423e-01, PNorm = 36.8164, GNorm = 1.1709, lr_0 = 1.0208e-04
Validation auc = 0.881583
Epoch 29
Loss = 1.5280e-01, PNorm = 36.8263, GNorm = 1.7311, lr_0 = 1.0000e-04
Loss = 1.2902e-01, PNorm = 36.8350, GNorm = 1.4067, lr_0 = 1.0000e-04
Loss = 2.0477e-01, PNorm = 36.8446, GNorm = 1.5457, lr_0 = 1.0000e-04
Validation auc = 0.876813
Model 0 best validation auc = 0.881583 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.906706
Ensemble test auc = 0.906706
Fold 7
Splitting data with seed 7
Total scaffolds = 1,025 | train scaffolds = 863 | val scaffolds = 0 | test scaffolds = 162
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.9673e-01, PNorm = 34.0126, GNorm = 1.5348, lr_0 = 2.5469e-04
Loss = 4.9817e-01, PNorm = 34.0187, GNorm = 0.5062, lr_0 = 3.9531e-04
Loss = 4.7747e-01, PNorm = 34.0412, GNorm = 0.5017, lr_0 = 5.3594e-04
Validation auc = 0.755383
Epoch 1
Loss = 4.2505e-01, PNorm = 34.0760, GNorm = 0.6224, lr_0 = 6.9063e-04
Loss = 4.4959e-01, PNorm = 34.1135, GNorm = 1.4844, lr_0 = 8.3125e-04
Loss = 4.3547e-01, PNorm = 34.1558, GNorm = 1.4239, lr_0 = 9.7187e-04
Validation auc = 0.795760
Epoch 2
Loss = 3.7337e-01, PNorm = 34.2097, GNorm = 3.4275, lr_0 = 9.7965e-04
Loss = 4.2502e-01, PNorm = 34.2627, GNorm = 0.5118, lr_0 = 9.5480e-04
Loss = 3.8550e-01, PNorm = 34.3194, GNorm = 0.9283, lr_0 = 9.3057e-04
Validation auc = 0.815194
Epoch 3
Loss = 4.2547e-01, PNorm = 34.3732, GNorm = 1.1318, lr_0 = 9.0463e-04
Loss = 3.7796e-01, PNorm = 34.4303, GNorm = 1.2964, lr_0 = 8.8168e-04
Loss = 3.7880e-01, PNorm = 34.4900, GNorm = 0.8707, lr_0 = 8.5931e-04
Loss = 4.1805e-01, PNorm = 34.5363, GNorm = 1.7581, lr_0 = 8.3751e-04
Validation auc = 0.832049
Epoch 4
Loss = 3.8877e-01, PNorm = 34.5793, GNorm = 1.3541, lr_0 = 8.1626e-04
Loss = 3.3638e-01, PNorm = 34.6436, GNorm = 0.3741, lr_0 = 7.9555e-04
Loss = 3.2092e-01, PNorm = 34.6966, GNorm = 0.3562, lr_0 = 7.7537e-04
Validation auc = 0.814380
Epoch 5
Loss = 3.5278e-01, PNorm = 34.7368, GNorm = 0.6656, lr_0 = 7.5570e-04
Loss = 3.2812e-01, PNorm = 34.7910, GNorm = 1.0830, lr_0 = 7.3653e-04
Loss = 3.5939e-01, PNorm = 34.8453, GNorm = 0.6897, lr_0 = 7.1784e-04
Validation auc = 0.846920
Epoch 6
Loss = 3.1876e-01, PNorm = 34.9135, GNorm = 0.9794, lr_0 = 6.9783e-04
Loss = 3.0256e-01, PNorm = 34.9680, GNorm = 1.3468, lr_0 = 6.8013e-04
Loss = 3.1646e-01, PNorm = 35.0206, GNorm = 1.1073, lr_0 = 6.6287e-04
Validation auc = 0.854253
Epoch 7
Loss = 2.7953e-01, PNorm = 35.0653, GNorm = 2.3032, lr_0 = 6.4605e-04
Loss = 3.2105e-01, PNorm = 35.1171, GNorm = 2.0512, lr_0 = 6.2966e-04
Loss = 3.0641e-01, PNorm = 35.1748, GNorm = 2.5586, lr_0 = 6.1369e-04
Loss = 3.7268e-01, PNorm = 35.2264, GNorm = 3.6927, lr_0 = 5.9812e-04
Loss = 4.5915e-01, PNorm = 35.2303, GNorm = 2.7772, lr_0 = 5.9658e-04
Validation auc = 0.855636
Epoch 8
Loss = 3.4779e-01, PNorm = 35.2787, GNorm = 0.5849, lr_0 = 5.8145e-04
Loss = 3.4322e-01, PNorm = 35.3278, GNorm = 1.4557, lr_0 = 5.6669e-04
Loss = 2.9223e-01, PNorm = 35.3803, GNorm = 0.3259, lr_0 = 5.5232e-04
Validation auc = 0.857801
Epoch 9
Loss = 3.3487e-01, PNorm = 35.4334, GNorm = 0.9138, lr_0 = 5.3830e-04
Loss = 2.4880e-01, PNorm = 35.4801, GNorm = 0.7187, lr_0 = 5.2465e-04
Loss = 2.8323e-01, PNorm = 35.5223, GNorm = 0.5790, lr_0 = 5.1133e-04
Validation auc = 0.863790
Epoch 10
Loss = 2.5531e-01, PNorm = 35.5586, GNorm = 0.9180, lr_0 = 4.9836e-04
Loss = 2.7229e-01, PNorm = 35.5990, GNorm = 0.8368, lr_0 = 4.8572e-04
Loss = 3.0928e-01, PNorm = 35.6383, GNorm = 0.6118, lr_0 = 4.7339e-04
Validation auc = 0.867484
Epoch 11
Loss = 3.7548e-01, PNorm = 35.6842, GNorm = 1.6515, lr_0 = 4.6020e-04
Loss = 2.4339e-01, PNorm = 35.7264, GNorm = 0.6287, lr_0 = 4.4852e-04
Loss = 3.0924e-01, PNorm = 35.7685, GNorm = 2.4178, lr_0 = 4.3714e-04
Loss = 2.9903e-01, PNorm = 35.8038, GNorm = 1.5291, lr_0 = 4.2605e-04
Validation auc = 0.867790
Epoch 12
Loss = 2.5767e-01, PNorm = 35.8390, GNorm = 0.5539, lr_0 = 4.1524e-04
Loss = 2.7974e-01, PNorm = 35.8753, GNorm = 1.0584, lr_0 = 4.0471e-04
Loss = 2.9305e-01, PNorm = 35.9113, GNorm = 1.8703, lr_0 = 3.9444e-04
Validation auc = 0.872165
Epoch 13
Loss = 2.6109e-01, PNorm = 35.9422, GNorm = 1.6873, lr_0 = 3.8443e-04
Loss = 2.4154e-01, PNorm = 35.9808, GNorm = 0.8882, lr_0 = 3.7468e-04
Loss = 2.8830e-01, PNorm = 36.0182, GNorm = 0.8957, lr_0 = 3.6517e-04
Validation auc = 0.867917
Epoch 14
Loss = 2.1272e-01, PNorm = 36.0542, GNorm = 1.6273, lr_0 = 3.5500e-04
Loss = 2.5678e-01, PNorm = 36.0900, GNorm = 0.5082, lr_0 = 3.4599e-04
Loss = 2.4599e-01, PNorm = 36.1204, GNorm = 1.5795, lr_0 = 3.3721e-04
Validation auc = 0.869381
Epoch 15
Loss = 3.2694e-01, PNorm = 36.1468, GNorm = 0.9686, lr_0 = 3.2866e-04
Loss = 2.5300e-01, PNorm = 36.1784, GNorm = 1.2536, lr_0 = 3.2032e-04
Loss = 2.2225e-01, PNorm = 36.2105, GNorm = 0.8472, lr_0 = 3.1219e-04
Loss = 2.5585e-01, PNorm = 36.2379, GNorm = 0.7422, lr_0 = 3.0427e-04
Validation auc = 0.875142
Epoch 16
Loss = 1.9838e-01, PNorm = 36.2736, GNorm = 1.8348, lr_0 = 2.9579e-04
Loss = 2.7353e-01, PNorm = 36.2984, GNorm = 3.2385, lr_0 = 2.8828e-04
Loss = 2.2603e-01, PNorm = 36.3175, GNorm = 1.1745, lr_0 = 2.8097e-04
Validation auc = 0.876805
Epoch 17
Loss = 1.8614e-01, PNorm = 36.3490, GNorm = 0.6584, lr_0 = 2.7384e-04
Loss = 2.1150e-01, PNorm = 36.3826, GNorm = 0.5984, lr_0 = 2.6689e-04
Loss = 2.4958e-01, PNorm = 36.4098, GNorm = 1.3179, lr_0 = 2.6012e-04
Validation auc = 0.876469
Epoch 18
Loss = 2.3328e-01, PNorm = 36.4302, GNorm = 1.6945, lr_0 = 2.5352e-04
Loss = 1.9636e-01, PNorm = 36.4565, GNorm = 2.4367, lr_0 = 2.4709e-04
Loss = 2.3666e-01, PNorm = 36.4837, GNorm = 1.1126, lr_0 = 2.4082e-04
Validation auc = 0.874926
Epoch 19
Loss = 2.0342e-01, PNorm = 36.5117, GNorm = 0.5979, lr_0 = 2.3411e-04
Loss = 2.1825e-01, PNorm = 36.5342, GNorm = 1.6542, lr_0 = 2.2817e-04
Loss = 2.0701e-01, PNorm = 36.5546, GNorm = 0.8762, lr_0 = 2.2238e-04
Loss = 2.1182e-01, PNorm = 36.5790, GNorm = 0.7950, lr_0 = 2.1674e-04
Validation auc = 0.875871
Epoch 20
Loss = 2.1835e-01, PNorm = 36.6005, GNorm = 1.2816, lr_0 = 2.1124e-04
Loss = 1.8984e-01, PNorm = 36.6232, GNorm = 2.6008, lr_0 = 2.0588e-04
Loss = 2.3389e-01, PNorm = 36.6454, GNorm = 0.9049, lr_0 = 2.0066e-04
Validation auc = 0.877689
Epoch 21
Loss = 2.2350e-01, PNorm = 36.6651, GNorm = 1.5218, lr_0 = 1.9557e-04
Loss = 2.0463e-01, PNorm = 36.6865, GNorm = 1.1106, lr_0 = 1.9060e-04
Loss = 2.1103e-01, PNorm = 36.7023, GNorm = 1.3653, lr_0 = 1.8577e-04
Validation auc = 0.879357
Epoch 22
Loss = 1.7427e-01, PNorm = 36.7236, GNorm = 0.8589, lr_0 = 1.8059e-04
Loss = 2.2984e-01, PNorm = 36.7431, GNorm = 1.3823, lr_0 = 1.7601e-04
Loss = 1.7259e-01, PNorm = 36.7599, GNorm = 1.1141, lr_0 = 1.7154e-04
Loss = 2.1782e-01, PNorm = 36.7752, GNorm = 2.2384, lr_0 = 1.6719e-04
Validation auc = 0.880634
Epoch 23
Loss = 2.1012e-01, PNorm = 36.7903, GNorm = 1.9463, lr_0 = 1.6295e-04
Loss = 1.9743e-01, PNorm = 36.8055, GNorm = 2.6711, lr_0 = 1.5882e-04
Loss = 1.9569e-01, PNorm = 36.8225, GNorm = 0.8472, lr_0 = 1.5479e-04
Validation auc = 0.876119
Epoch 24
Loss = 1.6951e-01, PNorm = 36.8384, GNorm = 1.3965, lr_0 = 1.5047e-04
Loss = 2.0458e-01, PNorm = 36.8530, GNorm = 1.4777, lr_0 = 1.4665e-04
Loss = 2.1188e-01, PNorm = 36.8657, GNorm = 1.2790, lr_0 = 1.4293e-04
Validation auc = 0.880178
Epoch 25
Loss = 1.9248e-01, PNorm = 36.8803, GNorm = 1.0131, lr_0 = 1.3931e-04
Loss = 1.6660e-01, PNorm = 36.8954, GNorm = 1.3230, lr_0 = 1.3577e-04
Loss = 2.0059e-01, PNorm = 36.9087, GNorm = 0.5384, lr_0 = 1.3233e-04
Validation auc = 0.877855
Epoch 26
Loss = 8.8095e-02, PNorm = 36.9205, GNorm = 0.8437, lr_0 = 1.2897e-04
Loss = 2.1412e-01, PNorm = 36.9334, GNorm = 1.1261, lr_0 = 1.2570e-04
Loss = 1.9582e-01, PNorm = 36.9453, GNorm = 1.5304, lr_0 = 1.2251e-04
Loss = 1.9293e-01, PNorm = 36.9564, GNorm = 0.7216, lr_0 = 1.1940e-04
Loss = 1.0425e-01, PNorm = 36.9574, GNorm = 0.8109, lr_0 = 1.1909e-04
Validation auc = 0.880129
Epoch 27
Loss = 1.5074e-01, PNorm = 36.9704, GNorm = 1.0898, lr_0 = 1.1607e-04
Loss = 2.0373e-01, PNorm = 36.9809, GNorm = 1.8491, lr_0 = 1.1313e-04
Loss = 1.7781e-01, PNorm = 36.9917, GNorm = 0.7160, lr_0 = 1.1026e-04
Validation auc = 0.880636
Epoch 28
Loss = 1.6330e-01, PNorm = 37.0031, GNorm = 1.8308, lr_0 = 1.0746e-04
Loss = 1.9872e-01, PNorm = 37.0131, GNorm = 1.0970, lr_0 = 1.0473e-04
Loss = 1.8052e-01, PNorm = 37.0237, GNorm = 2.1910, lr_0 = 1.0208e-04
Validation auc = 0.882866
Epoch 29
Loss = 1.5836e-01, PNorm = 37.0338, GNorm = 1.0602, lr_0 = 1.0000e-04
Loss = 1.5969e-01, PNorm = 37.0432, GNorm = 0.8004, lr_0 = 1.0000e-04
Loss = 1.7776e-01, PNorm = 37.0536, GNorm = 1.9000, lr_0 = 1.0000e-04
Validation auc = 0.880424
Model 0 best validation auc = 0.882866 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.897564
Ensemble test auc = 0.897564
Fold 8
Splitting data with seed 8
Total scaffolds = 1,025 | train scaffolds = 840 | val scaffolds = 0 | test scaffolds = 185
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.8649e-01, PNorm = 34.0131, GNorm = 0.7064, lr_0 = 2.5469e-04
Loss = 5.4676e-01, PNorm = 34.0175, GNorm = 0.6914, lr_0 = 3.9531e-04
Loss = 5.1271e-01, PNorm = 34.0337, GNorm = 1.0100, lr_0 = 5.3594e-04
Validation auc = 0.734512
Epoch 1
Loss = 4.5022e-01, PNorm = 34.0646, GNorm = 0.2913, lr_0 = 6.9063e-04
Loss = 5.3064e-01, PNorm = 34.1029, GNorm = 0.4107, lr_0 = 8.3125e-04
Loss = 4.2082e-01, PNorm = 34.1675, GNorm = 0.4234, lr_0 = 9.7187e-04
Validation auc = 0.799223
Epoch 2
Loss = 4.9131e-01, PNorm = 34.2294, GNorm = 3.6234, lr_0 = 9.7965e-04
Loss = 4.3415e-01, PNorm = 34.2835, GNorm = 1.6113, lr_0 = 9.5480e-04
Loss = 4.2086e-01, PNorm = 34.3419, GNorm = 0.5353, lr_0 = 9.3057e-04
Validation auc = 0.811972
Epoch 3
Loss = 3.2139e-01, PNorm = 34.4167, GNorm = 1.3411, lr_0 = 9.0463e-04
Loss = 3.5758e-01, PNorm = 34.4715, GNorm = 0.6067, lr_0 = 8.8168e-04
Loss = 4.4127e-01, PNorm = 34.5163, GNorm = 0.3850, lr_0 = 8.5931e-04
Loss = 3.9899e-01, PNorm = 34.5728, GNorm = 1.0117, lr_0 = 8.3751e-04
Validation auc = 0.824736
Epoch 4
Loss = 3.6112e-01, PNorm = 34.6351, GNorm = 0.3311, lr_0 = 8.1626e-04
Loss = 3.8032e-01, PNorm = 34.6835, GNorm = 0.7118, lr_0 = 7.9555e-04
Loss = 3.5960e-01, PNorm = 34.7333, GNorm = 0.5180, lr_0 = 7.7537e-04
Validation auc = 0.814832
Epoch 5
Loss = 3.7811e-01, PNorm = 34.7901, GNorm = 0.4220, lr_0 = 7.5570e-04
Loss = 3.2375e-01, PNorm = 34.8457, GNorm = 0.3401, lr_0 = 7.3653e-04
Loss = 3.4894e-01, PNorm = 34.9037, GNorm = 0.3493, lr_0 = 7.1784e-04
Validation auc = 0.835459
Epoch 6
Loss = 3.3213e-01, PNorm = 34.9734, GNorm = 0.4705, lr_0 = 6.9783e-04
Loss = 3.0268e-01, PNorm = 35.0354, GNorm = 0.6496, lr_0 = 6.8013e-04
Loss = 3.3222e-01, PNorm = 35.0953, GNorm = 0.4395, lr_0 = 6.6287e-04
Validation auc = 0.846089
Epoch 7
Loss = 3.1684e-01, PNorm = 35.1481, GNorm = 0.3060, lr_0 = 6.4605e-04
Loss = 2.9548e-01, PNorm = 35.2107, GNorm = 0.6182, lr_0 = 6.2966e-04
Loss = 3.2000e-01, PNorm = 35.2648, GNorm = 1.1350, lr_0 = 6.1369e-04
Loss = 3.2855e-01, PNorm = 35.3141, GNorm = 1.7529, lr_0 = 5.9812e-04
Loss = 2.5370e-01, PNorm = 35.3196, GNorm = 0.6291, lr_0 = 5.9658e-04
Validation auc = 0.844342
Epoch 8
Loss = 3.0773e-01, PNorm = 35.3746, GNorm = 0.6402, lr_0 = 5.8145e-04
Loss = 2.9196e-01, PNorm = 35.4290, GNorm = 1.5832, lr_0 = 5.6669e-04
Loss = 3.1052e-01, PNorm = 35.4759, GNorm = 1.6844, lr_0 = 5.5232e-04
Validation auc = 0.855234
Epoch 9
Loss = 2.7800e-01, PNorm = 35.5202, GNorm = 1.4366, lr_0 = 5.3830e-04
Loss = 2.7946e-01, PNorm = 35.5743, GNorm = 0.9622, lr_0 = 5.2465e-04
Loss = 3.1169e-01, PNorm = 35.6304, GNorm = 1.8932, lr_0 = 5.1133e-04
Validation auc = 0.863928
Epoch 10
Loss = 2.5310e-01, PNorm = 35.6694, GNorm = 0.6531, lr_0 = 4.9836e-04
Loss = 2.6976e-01, PNorm = 35.7218, GNorm = 0.8412, lr_0 = 4.8572e-04
Loss = 2.5824e-01, PNorm = 35.7754, GNorm = 1.0941, lr_0 = 4.7339e-04
Validation auc = 0.859331
Epoch 11
Loss = 2.7343e-01, PNorm = 35.8134, GNorm = 0.7610, lr_0 = 4.6020e-04
Loss = 2.4235e-01, PNorm = 35.8557, GNorm = 0.8548, lr_0 = 4.4852e-04
Loss = 3.1253e-01, PNorm = 35.8929, GNorm = 0.4618, lr_0 = 4.3714e-04
Loss = 2.8434e-01, PNorm = 35.9287, GNorm = 0.6328, lr_0 = 4.2605e-04
Validation auc = 0.857417
Epoch 12
Loss = 2.6903e-01, PNorm = 35.9740, GNorm = 0.7112, lr_0 = 4.1524e-04
Loss = 2.3436e-01, PNorm = 36.0131, GNorm = 1.8073, lr_0 = 4.0471e-04
Loss = 2.7593e-01, PNorm = 36.0518, GNorm = 1.3064, lr_0 = 3.9444e-04
Validation auc = 0.858900
Epoch 13
Loss = 2.4428e-01, PNorm = 36.0851, GNorm = 2.4298, lr_0 = 3.8443e-04
Loss = 2.6900e-01, PNorm = 36.1198, GNorm = 0.5732, lr_0 = 3.7468e-04
Loss = 2.6997e-01, PNorm = 36.1496, GNorm = 0.9713, lr_0 = 3.6517e-04
Validation auc = 0.859750
Epoch 14
Loss = 2.2789e-01, PNorm = 36.1912, GNorm = 1.6291, lr_0 = 3.5500e-04
Loss = 2.4061e-01, PNorm = 36.2352, GNorm = 0.7153, lr_0 = 3.4599e-04
Loss = 2.3716e-01, PNorm = 36.2668, GNorm = 0.7406, lr_0 = 3.3721e-04
Validation auc = 0.869236
Epoch 15
Loss = 2.6546e-01, PNorm = 36.2957, GNorm = 1.5526, lr_0 = 3.2866e-04
Loss = 2.3108e-01, PNorm = 36.3296, GNorm = 0.9983, lr_0 = 3.2032e-04
Loss = 2.2666e-01, PNorm = 36.3640, GNorm = 1.0721, lr_0 = 3.1219e-04
Loss = 2.1325e-01, PNorm = 36.3973, GNorm = 1.2604, lr_0 = 3.0427e-04
Validation auc = 0.867841
Epoch 16
Loss = 1.8263e-01, PNorm = 36.4279, GNorm = 0.5923, lr_0 = 2.9579e-04
Loss = 2.4053e-01, PNorm = 36.4532, GNorm = 0.9292, lr_0 = 2.8828e-04
Loss = 2.3996e-01, PNorm = 36.4802, GNorm = 1.2285, lr_0 = 2.8097e-04
Validation auc = 0.871301
Epoch 17
Loss = 2.0343e-01, PNorm = 36.5121, GNorm = 0.7900, lr_0 = 2.7384e-04
Loss = 1.5995e-01, PNorm = 36.5461, GNorm = 0.5904, lr_0 = 2.6689e-04
Loss = 2.3919e-01, PNorm = 36.5722, GNorm = 2.0980, lr_0 = 2.6012e-04
Validation auc = 0.864505
Epoch 18
Loss = 1.8148e-01, PNorm = 36.5922, GNorm = 1.5846, lr_0 = 2.5352e-04
Loss = 2.5366e-01, PNorm = 36.6149, GNorm = 0.7508, lr_0 = 2.4709e-04
Loss = 2.2465e-01, PNorm = 36.6443, GNorm = 0.6522, lr_0 = 2.4082e-04
Validation auc = 0.869615
Epoch 19
Loss = 2.4635e-01, PNorm = 36.6733, GNorm = 1.3489, lr_0 = 2.3411e-04
Loss = 2.3557e-01, PNorm = 36.6984, GNorm = 1.1359, lr_0 = 2.2817e-04
Loss = 1.6692e-01, PNorm = 36.7249, GNorm = 0.8156, lr_0 = 2.2238e-04
Loss = 2.0582e-01, PNorm = 36.7497, GNorm = 0.7859, lr_0 = 2.1674e-04
Validation auc = 0.870811
Epoch 20
Loss = 2.3595e-01, PNorm = 36.7687, GNorm = 2.1405, lr_0 = 2.1124e-04
Loss = 1.6743e-01, PNorm = 36.7912, GNorm = 1.8271, lr_0 = 2.0588e-04
Loss = 2.0801e-01, PNorm = 36.8151, GNorm = 1.2116, lr_0 = 2.0066e-04
Validation auc = 0.875582
Epoch 21
Loss = 1.6087e-01, PNorm = 36.8302, GNorm = 1.2805, lr_0 = 1.9557e-04
Loss = 2.2082e-01, PNorm = 36.8504, GNorm = 0.8873, lr_0 = 1.9060e-04
Loss = 1.8606e-01, PNorm = 36.8717, GNorm = 0.7627, lr_0 = 1.8577e-04
Validation auc = 0.877031
Epoch 22
Loss = 2.2158e-01, PNorm = 36.8915, GNorm = 2.4453, lr_0 = 1.8059e-04
Loss = 2.0853e-01, PNorm = 36.9117, GNorm = 0.8223, lr_0 = 1.7601e-04
Loss = 1.7528e-01, PNorm = 36.9325, GNorm = 2.4850, lr_0 = 1.7154e-04
Loss = 2.0993e-01, PNorm = 36.9486, GNorm = 2.8569, lr_0 = 1.6719e-04
Validation auc = 0.874757
Epoch 23
Loss = 1.4639e-01, PNorm = 36.9654, GNorm = 0.7697, lr_0 = 1.6295e-04
Loss = 1.9275e-01, PNorm = 36.9816, GNorm = 1.3974, lr_0 = 1.5882e-04
Loss = 2.1059e-01, PNorm = 36.9961, GNorm = 1.5485, lr_0 = 1.5479e-04
Validation auc = 0.875779
Epoch 24
Loss = 2.0678e-01, PNorm = 37.0133, GNorm = 1.3215, lr_0 = 1.5047e-04
Loss = 1.4689e-01, PNorm = 37.0280, GNorm = 1.1888, lr_0 = 1.4665e-04
Loss = 1.9324e-01, PNorm = 37.0431, GNorm = 1.3306, lr_0 = 1.4293e-04
Validation auc = 0.875084
Epoch 25
Loss = 1.6089e-01, PNorm = 37.0576, GNorm = 1.1166, lr_0 = 1.3931e-04
Loss = 1.6333e-01, PNorm = 37.0707, GNorm = 1.0544, lr_0 = 1.3577e-04
Loss = 1.8117e-01, PNorm = 37.0841, GNorm = 1.3057, lr_0 = 1.3233e-04
Validation auc = 0.874240
Epoch 26
Loss = 2.0404e-01, PNorm = 37.0970, GNorm = 2.9506, lr_0 = 1.2897e-04
Loss = 1.8924e-01, PNorm = 37.1089, GNorm = 1.3185, lr_0 = 1.2570e-04
Loss = 1.6666e-01, PNorm = 37.1222, GNorm = 0.9292, lr_0 = 1.2251e-04
Loss = 1.9692e-01, PNorm = 37.1330, GNorm = 2.2530, lr_0 = 1.1940e-04
Loss = 8.1838e-02, PNorm = 37.1342, GNorm = 1.3591, lr_0 = 1.1909e-04
Validation auc = 0.876953
Epoch 27
Loss = 1.8200e-01, PNorm = 37.1469, GNorm = 1.7932, lr_0 = 1.1607e-04
Loss = 1.7436e-01, PNorm = 37.1568, GNorm = 1.1590, lr_0 = 1.1313e-04
Loss = 1.4737e-01, PNorm = 37.1697, GNorm = 0.6555, lr_0 = 1.1026e-04
Validation auc = 0.876077
Epoch 28
Loss = 1.1868e-01, PNorm = 37.1807, GNorm = 0.7642, lr_0 = 1.0746e-04
Loss = 1.6770e-01, PNorm = 37.1898, GNorm = 0.9152, lr_0 = 1.0473e-04
Loss = 1.7687e-01, PNorm = 37.1999, GNorm = 1.1660, lr_0 = 1.0208e-04
Validation auc = 0.875336
Epoch 29
Loss = 1.6006e-01, PNorm = 37.2104, GNorm = 2.7978, lr_0 = 1.0000e-04
Loss = 1.6464e-01, PNorm = 37.2212, GNorm = 1.4714, lr_0 = 1.0000e-04
Loss = 1.8973e-01, PNorm = 37.2316, GNorm = 2.1347, lr_0 = 1.0000e-04
Validation auc = 0.876871
Model 0 best validation auc = 0.877031 on epoch 21
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.899712
Ensemble test auc = 0.899712
Fold 9
Splitting data with seed 9
Total scaffolds = 1,025 | train scaffolds = 822 | val scaffolds = 0 | test scaffolds = 203
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=300, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 355,201
Epoch 0
Loss = 5.7355e-01, PNorm = 34.0135, GNorm = 1.3898, lr_0 = 2.5469e-04
Loss = 5.4916e-01, PNorm = 34.0176, GNorm = 1.3625, lr_0 = 3.9531e-04
Loss = 5.2713e-01, PNorm = 34.0341, GNorm = 0.1727, lr_0 = 5.3594e-04
Validation auc = 0.731387
Epoch 1
Loss = 5.6181e-01, PNorm = 34.0599, GNorm = 1.3737, lr_0 = 6.9063e-04
Loss = 5.4009e-01, PNorm = 34.0979, GNorm = 0.8545, lr_0 = 8.3125e-04
Loss = 4.9376e-01, PNorm = 34.1536, GNorm = 0.5686, lr_0 = 9.7187e-04
Validation auc = 0.761204
Epoch 2
Loss = 5.3742e-01, PNorm = 34.2259, GNorm = 1.5691, lr_0 = 9.7965e-04
Loss = 3.9386e-01, PNorm = 34.3099, GNorm = 0.8096, lr_0 = 9.5480e-04
Loss = 4.4236e-01, PNorm = 34.3557, GNorm = 0.5507, lr_0 = 9.3057e-04
Validation auc = 0.791568
Epoch 3
Loss = 4.2308e-01, PNorm = 34.4201, GNorm = 0.4710, lr_0 = 9.0463e-04
Loss = 4.2625e-01, PNorm = 34.4839, GNorm = 2.3323, lr_0 = 8.8168e-04
Loss = 3.4713e-01, PNorm = 34.5529, GNorm = 1.4637, lr_0 = 8.5931e-04
Loss = 4.2077e-01, PNorm = 34.5964, GNorm = 0.6571, lr_0 = 8.3751e-04
Validation auc = 0.827755
Epoch 4
Loss = 3.3712e-01, PNorm = 34.6475, GNorm = 1.0306, lr_0 = 8.1626e-04
Loss = 3.2588e-01, PNorm = 34.7061, GNorm = 1.6170, lr_0 = 7.9555e-04
Loss = 3.8492e-01, PNorm = 34.7481, GNorm = 0.3718, lr_0 = 7.7537e-04
Validation auc = 0.828054
Epoch 5
Loss = 3.4264e-01, PNorm = 34.8038, GNorm = 0.4273, lr_0 = 7.5570e-04
Loss = 3.2844e-01, PNorm = 34.8629, GNorm = 1.2101, lr_0 = 7.3653e-04
Loss = 3.4978e-01, PNorm = 34.9220, GNorm = 1.1866, lr_0 = 7.1784e-04
Validation auc = 0.851047
Epoch 6
Loss = 3.2186e-01, PNorm = 34.9997, GNorm = 0.7869, lr_0 = 6.9783e-04
Loss = 3.2372e-01, PNorm = 35.0719, GNorm = 0.4749, lr_0 = 6.8013e-04
Loss = 3.1195e-01, PNorm = 35.1244, GNorm = 2.0203, lr_0 = 6.6287e-04
Validation auc = 0.852341
Epoch 7
Loss = 3.0974e-01, PNorm = 35.1811, GNorm = 1.7987, lr_0 = 6.4605e-04
Loss = 3.0368e-01, PNorm = 35.2501, GNorm = 1.4095, lr_0 = 6.2966e-04
Loss = 3.7589e-01, PNorm = 35.2954, GNorm = 2.1109, lr_0 = 6.1369e-04
Loss = 3.6816e-01, PNorm = 35.3463, GNorm = 0.7726, lr_0 = 5.9812e-04
Loss = 3.9080e-01, PNorm = 35.3516, GNorm = 0.4996, lr_0 = 5.9658e-04
Validation auc = 0.845782
Epoch 8
Loss = 3.5167e-01, PNorm = 35.4028, GNorm = 0.4615, lr_0 = 5.8145e-04
Loss = 2.8388e-01, PNorm = 35.4565, GNorm = 0.9019, lr_0 = 5.6669e-04
Loss = 3.5399e-01, PNorm = 35.4984, GNorm = 0.5972, lr_0 = 5.5232e-04
Validation auc = 0.856509
Epoch 9
Loss = 2.4704e-01, PNorm = 35.5443, GNorm = 0.9954, lr_0 = 5.3830e-04
Loss = 3.2154e-01, PNorm = 35.5865, GNorm = 1.9169, lr_0 = 5.2465e-04
Loss = 2.9224e-01, PNorm = 35.6308, GNorm = 0.8374, lr_0 = 5.1133e-04
Validation auc = 0.865598
Epoch 10
Loss = 3.0247e-01, PNorm = 35.6612, GNorm = 0.8315, lr_0 = 4.9836e-04
Loss = 2.7513e-01, PNorm = 35.6949, GNorm = 1.1238, lr_0 = 4.8572e-04
Loss = 2.6106e-01, PNorm = 35.7404, GNorm = 1.6288, lr_0 = 4.7339e-04
Validation auc = 0.869175
Epoch 11
Loss = 2.2082e-01, PNorm = 35.7909, GNorm = 0.7308, lr_0 = 4.6020e-04
Loss = 2.7329e-01, PNorm = 35.8341, GNorm = 0.6021, lr_0 = 4.4852e-04
Loss = 2.6603e-01, PNorm = 35.8722, GNorm = 0.9407, lr_0 = 4.3714e-04
Loss = 2.4075e-01, PNorm = 35.9113, GNorm = 2.0187, lr_0 = 4.2605e-04
Validation auc = 0.867018
Epoch 12
Loss = 2.5492e-01, PNorm = 35.9484, GNorm = 1.0856, lr_0 = 4.1524e-04
Loss = 2.4939e-01, PNorm = 35.9858, GNorm = 0.4561, lr_0 = 4.0471e-04
Loss = 2.4741e-01, PNorm = 36.0232, GNorm = 1.5466, lr_0 = 3.9444e-04
Validation auc = 0.875294
Epoch 13
Loss = 2.4982e-01, PNorm = 36.0614, GNorm = 2.4447, lr_0 = 3.8443e-04
Loss = 2.4805e-01, PNorm = 36.0925, GNorm = 1.2654, lr_0 = 3.7468e-04
Loss = 2.5467e-01, PNorm = 36.1294, GNorm = 1.3820, lr_0 = 3.6517e-04
Validation auc = 0.876470
Epoch 14
Loss = 2.3493e-01, PNorm = 36.1666, GNorm = 0.9006, lr_0 = 3.5500e-04
Loss = 2.3090e-01, PNorm = 36.2007, GNorm = 0.9171, lr_0 = 3.4599e-04
Loss = 2.3686e-01, PNorm = 36.2300, GNorm = 2.0575, lr_0 = 3.3721e-04
Validation auc = 0.878013
Epoch 15
Loss = 2.9026e-01, PNorm = 36.2573, GNorm = 1.3134, lr_0 = 3.2866e-04
Loss = 1.9981e-01, PNorm = 36.2863, GNorm = 0.7343, lr_0 = 3.2032e-04
Loss = 1.9687e-01, PNorm = 36.3116, GNorm = 1.6622, lr_0 = 3.1219e-04
Loss = 2.5691e-01, PNorm = 36.3379, GNorm = 0.8183, lr_0 = 3.0427e-04
Validation auc = 0.875972
Epoch 16
Loss = 1.9455e-01, PNorm = 36.3669, GNorm = 1.2843, lr_0 = 2.9579e-04
Loss = 2.2575e-01, PNorm = 36.3932, GNorm = 0.6172, lr_0 = 2.8828e-04
Loss = 2.0250e-01, PNorm = 36.4198, GNorm = 0.9775, lr_0 = 2.8097e-04
Validation auc = 0.869266
Epoch 17
Loss = 1.9697e-01, PNorm = 36.4458, GNorm = 2.1296, lr_0 = 2.7384e-04
Loss = 2.1166e-01, PNorm = 36.4693, GNorm = 1.2592, lr_0 = 2.6689e-04
Loss = 1.9109e-01, PNorm = 36.4920, GNorm = 1.2560, lr_0 = 2.6012e-04
Validation auc = 0.875670
Epoch 18
Loss = 1.8643e-01, PNorm = 36.5195, GNorm = 1.2630, lr_0 = 2.5352e-04
Loss = 1.8821e-01, PNorm = 36.5462, GNorm = 1.1309, lr_0 = 2.4709e-04
Loss = 2.1482e-01, PNorm = 36.5691, GNorm = 2.0538, lr_0 = 2.4082e-04
Validation auc = 0.882305
Epoch 19
Loss = 3.6615e-01, PNorm = 36.5870, GNorm = 1.2744, lr_0 = 2.3411e-04
Loss = 1.7905e-01, PNorm = 36.6064, GNorm = 1.4056, lr_0 = 2.2817e-04
Loss = 1.6863e-01, PNorm = 36.6280, GNorm = 0.8830, lr_0 = 2.2238e-04
Loss = 2.2525e-01, PNorm = 36.6487, GNorm = 1.1407, lr_0 = 2.1674e-04
Validation auc = 0.878234
Epoch 20
Loss = 1.8261e-01, PNorm = 36.6677, GNorm = 0.5729, lr_0 = 2.1124e-04
Loss = 1.6636e-01, PNorm = 36.6873, GNorm = 2.5082, lr_0 = 2.0588e-04
Loss = 1.9284e-01, PNorm = 36.7066, GNorm = 0.6993, lr_0 = 2.0066e-04
Validation auc = 0.884596
Epoch 21
Loss = 1.7006e-01, PNorm = 36.7234, GNorm = 1.4929, lr_0 = 1.9557e-04
Loss = 1.7874e-01, PNorm = 36.7407, GNorm = 2.4642, lr_0 = 1.9060e-04
Loss = 1.8300e-01, PNorm = 36.7556, GNorm = 1.3921, lr_0 = 1.8577e-04
Validation auc = 0.880451
Epoch 22
Loss = 2.2415e-01, PNorm = 36.7748, GNorm = 3.0747, lr_0 = 1.8059e-04
Loss = 1.8420e-01, PNorm = 36.7904, GNorm = 1.5966, lr_0 = 1.7601e-04
Loss = 1.8406e-01, PNorm = 36.8065, GNorm = 3.2764, lr_0 = 1.7154e-04
Loss = 1.7007e-01, PNorm = 36.8239, GNorm = 2.2602, lr_0 = 1.6719e-04
Validation auc = 0.880731
Epoch 23
Loss = 1.8307e-01, PNorm = 36.8388, GNorm = 0.9624, lr_0 = 1.6295e-04
Loss = 1.6942e-01, PNorm = 36.8528, GNorm = 1.5294, lr_0 = 1.5882e-04
Loss = 1.9677e-01, PNorm = 36.8652, GNorm = 2.0170, lr_0 = 1.5479e-04
Validation auc = 0.883153
Epoch 24
Loss = 1.9167e-01, PNorm = 36.8796, GNorm = 1.6526, lr_0 = 1.5047e-04
Loss = 1.7906e-01, PNorm = 36.8896, GNorm = 1.4202, lr_0 = 1.4665e-04
Loss = 1.6134e-01, PNorm = 36.9037, GNorm = 1.5846, lr_0 = 1.4293e-04
Validation auc = 0.884527
Epoch 25
Loss = 2.1820e-01, PNorm = 36.9145, GNorm = 2.8235, lr_0 = 1.3931e-04
Loss = 1.5305e-01, PNorm = 36.9264, GNorm = 1.3115, lr_0 = 1.3577e-04
Loss = 1.4523e-01, PNorm = 36.9400, GNorm = 2.9751, lr_0 = 1.3233e-04
Validation auc = 0.884324
Epoch 26
Loss = 1.0589e-01, PNorm = 36.9495, GNorm = 0.5398, lr_0 = 1.2897e-04
Loss = 1.7584e-01, PNorm = 36.9614, GNorm = 0.7777, lr_0 = 1.2570e-04
Loss = 1.7186e-01, PNorm = 36.9732, GNorm = 1.1555, lr_0 = 1.2251e-04
Loss = 1.6196e-01, PNorm = 36.9816, GNorm = 0.6087, lr_0 = 1.1940e-04
Loss = 7.2826e-02, PNorm = 36.9825, GNorm = 1.8686, lr_0 = 1.1909e-04
Validation auc = 0.883706
Epoch 27
Loss = 1.8395e-01, PNorm = 36.9932, GNorm = 1.1524, lr_0 = 1.1607e-04
Loss = 1.4853e-01, PNorm = 37.0025, GNorm = 2.9369, lr_0 = 1.1313e-04
Loss = 1.5653e-01, PNorm = 37.0122, GNorm = 1.2032, lr_0 = 1.1026e-04
Validation auc = 0.884723
Epoch 28
Loss = 1.3687e-01, PNorm = 37.0222, GNorm = 1.2745, lr_0 = 1.0746e-04
Loss = 1.4577e-01, PNorm = 37.0320, GNorm = 1.0341, lr_0 = 1.0473e-04
Loss = 2.0489e-01, PNorm = 37.0415, GNorm = 3.6318, lr_0 = 1.0208e-04
Validation auc = 0.884838
Epoch 29
Loss = 1.5350e-01, PNorm = 37.0487, GNorm = 1.8702, lr_0 = 1.0000e-04
Loss = 1.7822e-01, PNorm = 37.0573, GNorm = 1.4119, lr_0 = 1.0000e-04
Loss = 1.2261e-01, PNorm = 37.0653, GNorm = 1.2145, lr_0 = 1.0000e-04
Validation auc = 0.884231
Model 0 best validation auc = 0.884838 on epoch 28
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.898943
Ensemble test auc = 0.898943
10-fold cross validation
	Seed 0 ==> test auc = 0.844660
	Seed 1 ==> test auc = 0.859605
	Seed 2 ==> test auc = 0.884451
	Seed 3 ==> test auc = 0.893417
	Seed 4 ==> test auc = 0.938451
	Seed 5 ==> test auc = 0.876687
	Seed 6 ==> test auc = 0.906706
	Seed 7 ==> test auc = 0.897564
	Seed 8 ==> test auc = 0.899712
	Seed 9 ==> test auc = 0.898943
Overall test auc = 0.890020 +/- 0.024612
Elapsed time = 1:54:20
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme="hmac-sha256" --Session.key=b"3a3b5b40-9d6a-4d9c-bdcf-9515235abaac" --shell=9002 --transport="tcp" --iopub=9004 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036paP6uCOxRzAL.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': True,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/molnet_chemprop.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': './data/chemprop_B3DB.csv',
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme="hmac-sha256" --Session.key=b"a0f851d0-52d6-44fb-9526-1a9a0aca924e" --shell=9007 --transport="tcp" --iopub=9009 --f=C:\Users\gurka\AppData\Local\Temp\tmp-90365wrP990Acsul.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': True,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/molnet_chemprop.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 1,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': './data/chemprop_B3DB.csv',
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total scaffolds = 1,025 | train scaffolds = 924 | val scaffolds = 0 | test scaffolds = 101
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 7,807 | test size = 408
With class_balance, effective train size = 796
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8107e-01, PNorm = 35.0710, GNorm = 0.9078, lr_0 = 2.5469e-04
Validation auc = 0.807140
Epoch 1
Loss = 5.2529e-01, PNorm = 35.0928, GNorm = 0.9035, lr_0 = 4.0937e-04
Loss = 4.2634e-01, PNorm = 35.1227, GNorm = 0.2634, lr_0 = 5.5000e-04
Validation auc = 0.822199
Epoch 2
Loss = 4.1222e-01, PNorm = 35.1551, GNorm = 0.5645, lr_0 = 6.9063e-04
Validation auc = 0.818672
Epoch 3
Loss = 4.2440e-01, PNorm = 35.1808, GNorm = 2.3690, lr_0 = 8.3125e-04
Loss = 4.4346e-01, PNorm = 35.2089, GNorm = 0.3607, lr_0 = 9.7187e-04
Validation auc = 0.861986
Epoch 4
Loss = 4.0672e-01, PNorm = 35.2457, GNorm = 0.3135, lr_0 = 9.7965e-04
Validation auc = 0.867270
Epoch 5
Loss = 3.7309e-01, PNorm = 35.2896, GNorm = 0.4153, lr_0 = 9.5480e-04
Loss = 3.8110e-01, PNorm = 35.3338, GNorm = 1.2823, lr_0 = 9.3057e-04
Validation auc = 0.878306
Epoch 6
Loss = 3.0901e-01, PNorm = 35.3798, GNorm = 0.2625, lr_0 = 9.0696e-04
Loss = 3.6536e-01, PNorm = 35.4277, GNorm = 0.7632, lr_0 = 8.8395e-04
Validation auc = 0.876094
Epoch 7
Loss = 3.2511e-01, PNorm = 35.4813, GNorm = 0.8412, lr_0 = 8.6152e-04
Validation auc = 0.884008
Epoch 8
Loss = 2.7578e-01, PNorm = 35.5361, GNorm = 0.9088, lr_0 = 8.3967e-04
Loss = 3.6029e-01, PNorm = 35.5867, GNorm = 1.8414, lr_0 = 8.1836e-04
Validation auc = 0.892168
Epoch 9
Loss = 3.2205e-01, PNorm = 35.6344, GNorm = 0.3623, lr_0 = 7.9760e-04
Validation auc = 0.889467
Epoch 10
Loss = 3.4697e-01, PNorm = 35.6845, GNorm = 0.5572, lr_0 = 7.7737e-04
Loss = 3.2027e-01, PNorm = 35.7380, GNorm = 0.5168, lr_0 = 7.5764e-04
Validation auc = 0.886215
Epoch 11
Loss = 3.0143e-01, PNorm = 35.7906, GNorm = 0.4235, lr_0 = 7.3842e-04
Loss = 3.0875e-01, PNorm = 35.8445, GNorm = 0.5648, lr_0 = 7.1969e-04
Validation auc = 0.895508
Epoch 12
Loss = 2.9093e-01, PNorm = 35.8946, GNorm = 0.3769, lr_0 = 7.0143e-04
Validation auc = 0.895358
Epoch 13
Loss = 2.6926e-01, PNorm = 35.9603, GNorm = 0.7401, lr_0 = 6.8188e-04
Loss = 3.0419e-01, PNorm = 36.0190, GNorm = 1.3131, lr_0 = 6.6458e-04
Validation auc = 0.885569
Epoch 14
Loss = 3.1403e-01, PNorm = 36.0705, GNorm = 1.0593, lr_0 = 6.4771e-04
Validation auc = 0.897508
Epoch 15
Loss = 2.2705e-01, PNorm = 36.1199, GNorm = 0.5505, lr_0 = 6.3128e-04
Loss = 2.6047e-01, PNorm = 36.1720, GNorm = 0.7243, lr_0 = 6.1527e-04
Validation auc = 0.896823
Epoch 16
Loss = 2.9186e-01, PNorm = 36.2209, GNorm = 0.8064, lr_0 = 5.9966e-04
Loss = 2.7694e-01, PNorm = 36.2714, GNorm = 0.5733, lr_0 = 5.8444e-04
Validation auc = 0.897779
Epoch 17
Loss = 2.9683e-01, PNorm = 36.3265, GNorm = 0.3154, lr_0 = 5.6961e-04
Validation auc = 0.896502
Epoch 18
Loss = 2.9697e-01, PNorm = 36.3831, GNorm = 1.1251, lr_0 = 5.5516e-04
Loss = 2.5506e-01, PNorm = 36.4339, GNorm = 0.9726, lr_0 = 5.4108e-04
Validation auc = 0.896925
Epoch 19
Loss = 2.7557e-01, PNorm = 36.4826, GNorm = 0.3210, lr_0 = 5.2735e-04
Validation auc = 0.899300
Epoch 20
Loss = 2.0066e-01, PNorm = 36.5332, GNorm = 1.0277, lr_0 = 5.1397e-04
Loss = 2.4477e-01, PNorm = 36.5885, GNorm = 1.1580, lr_0 = 5.0093e-04
Validation auc = 0.897851
Epoch 21
Loss = 2.2988e-01, PNorm = 36.6360, GNorm = 0.5869, lr_0 = 4.8822e-04
Loss = 2.5329e-01, PNorm = 36.6848, GNorm = 1.0933, lr_0 = 4.7583e-04
Validation auc = 0.898454
Epoch 22
Loss = 2.2670e-01, PNorm = 36.7375, GNorm = 0.9868, lr_0 = 4.6376e-04
Validation auc = 0.898323
Epoch 23
Loss = 2.1908e-01, PNorm = 36.7918, GNorm = 0.7779, lr_0 = 4.5200e-04
Loss = 2.1115e-01, PNorm = 36.8464, GNorm = 1.2115, lr_0 = 4.4053e-04
Validation auc = 0.899206
Epoch 24
Loss = 2.3253e-01, PNorm = 36.8923, GNorm = 0.5230, lr_0 = 4.2935e-04
Validation auc = 0.897154
Epoch 25
Loss = 1.4939e-01, PNorm = 36.9358, GNorm = 1.0954, lr_0 = 4.1846e-04
Loss = 1.9860e-01, PNorm = 36.9816, GNorm = 0.6358, lr_0 = 4.0784e-04
Validation auc = 0.898995
Epoch 26
Loss = 1.9404e-01, PNorm = 37.0403, GNorm = 0.8078, lr_0 = 3.9647e-04
Validation auc = 0.895844
Epoch 27
Loss = 2.2818e-01, PNorm = 37.0803, GNorm = 0.7710, lr_0 = 3.8641e-04
Loss = 2.0340e-01, PNorm = 37.1217, GNorm = 0.8579, lr_0 = 3.7661e-04
Validation auc = 0.897954
Epoch 28
Loss = 2.1206e-01, PNorm = 37.1696, GNorm = 0.4233, lr_0 = 3.6706e-04
Loss = 1.9761e-01, PNorm = 37.2167, GNorm = 1.3511, lr_0 = 3.5774e-04
Validation auc = 0.898642
Epoch 29
Loss = 2.2999e-01, PNorm = 37.2560, GNorm = 0.8203, lr_0 = 3.4867e-04
Validation auc = 0.900843
Model 0 best validation auc = 0.900843 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.854985
Ensemble test auc = 0.854985
1-fold cross validation
	Seed 0 ==> test auc = 0.854985
Overall test auc = 0.854985 +/- 0.000000
Elapsed time = 0:23:09
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme="hmac-sha256" --Session.key=b"a0f851d0-52d6-44fb-9526-1a9a0aca924e" --shell=9007 --transport="tcp" --iopub=9009 --f=C:\Users\gurka\AppData\Local\Temp\tmp-90365wrP990Acsul.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': True,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/molnet_chemprop.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 10,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': './data/chemprop_B3DB.csv',
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme="hmac-sha256" --Session.key=b"78ce7e33-618d-4d70-bde9-935ab47d3a38" --shell=9002 --transport="tcp" --iopub=9004 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036WgdJUnZ0WKJ0.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': True,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/molnet_chemprop.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 30,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 10,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total scaffolds = 1,025 | train scaffolds = 764 | val scaffolds = 123 | test scaffolds = 138
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 774
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7708e-01, PNorm = 35.0708, GNorm = 0.7273, lr_0 = 2.5469e-04
Validation auc = 0.861534
Epoch 1
Loss = 5.0486e-01, PNorm = 35.0930, GNorm = 0.7116, lr_0 = 4.0937e-04
Loss = 5.4657e-01, PNorm = 35.1182, GNorm = 1.4816, lr_0 = 5.5000e-04
Loss = 4.0673e-01, PNorm = 35.1203, GNorm = 0.7096, lr_0 = 5.6406e-04
Validation auc = 0.879050
Epoch 2
Loss = 4.5546e-01, PNorm = 35.1483, GNorm = 2.1511, lr_0 = 7.0469e-04
Validation auc = 0.915397
Epoch 3
Loss = 4.7097e-01, PNorm = 35.1837, GNorm = 0.9679, lr_0 = 8.4531e-04
Loss = 4.1481e-01, PNorm = 35.2336, GNorm = 0.4119, lr_0 = 9.8594e-04
Validation auc = 0.916782
Epoch 4
Loss = 4.0431e-01, PNorm = 35.2929, GNorm = 1.5132, lr_0 = 9.7463e-04
Validation auc = 0.914220
Epoch 5
Loss = 3.8522e-01, PNorm = 35.3457, GNorm = 0.5654, lr_0 = 9.4990e-04
Loss = 4.2492e-01, PNorm = 35.3974, GNorm = 0.8292, lr_0 = 9.2580e-04
Validation auc = 0.910897
Epoch 6
Loss = 3.6514e-01, PNorm = 35.4634, GNorm = 0.6041, lr_0 = 9.0000e-04
Validation auc = 0.924605
Epoch 7
Loss = 3.1496e-01, PNorm = 35.5239, GNorm = 1.1895, lr_0 = 8.7716e-04
Loss = 3.6111e-01, PNorm = 35.5722, GNorm = 0.4888, lr_0 = 8.5491e-04
Validation auc = 0.914705
Epoch 8
Loss = 3.1736e-01, PNorm = 35.6203, GNorm = 0.4954, lr_0 = 8.3108e-04
Validation auc = 0.926059
Epoch 9
Loss = 2.8455e-01, PNorm = 35.6808, GNorm = 0.6534, lr_0 = 8.0999e-04
Loss = 3.3993e-01, PNorm = 35.7286, GNorm = 1.1358, lr_0 = 7.8944e-04
Validation auc = 0.919274
Epoch 10
Loss = 3.1946e-01, PNorm = 35.7849, GNorm = 0.7575, lr_0 = 7.6744e-04
Loss = 2.9509e-01, PNorm = 35.8519, GNorm = 0.4835, lr_0 = 7.4797e-04
Validation auc = 0.918374
Epoch 11
Loss = 3.3841e-01, PNorm = 35.9082, GNorm = 0.5555, lr_0 = 7.2899e-04
Validation auc = 0.916782
Epoch 12
Loss = 3.3625e-01, PNorm = 35.9823, GNorm = 1.7178, lr_0 = 7.0867e-04
Loss = 3.4066e-01, PNorm = 36.0452, GNorm = 0.6074, lr_0 = 6.9069e-04
Validation auc = 0.924328
Epoch 13
Loss = 3.0686e-01, PNorm = 36.0976, GNorm = 0.8210, lr_0 = 6.7317e-04
Validation auc = 0.921421
Epoch 14
Loss = 3.9857e-01, PNorm = 36.1592, GNorm = 1.1383, lr_0 = 6.5441e-04
Loss = 2.9598e-01, PNorm = 36.2155, GNorm = 1.0250, lr_0 = 6.3780e-04
Validation auc = 0.915536
Epoch 15
Loss = 2.8544e-01, PNorm = 36.2755, GNorm = 0.6223, lr_0 = 6.2162e-04
Validation auc = 0.921421
Epoch 16
Loss = 3.0373e-01, PNorm = 36.3420, GNorm = 0.5812, lr_0 = 6.0430e-04
Loss = 2.7205e-01, PNorm = 36.4042, GNorm = 0.9582, lr_0 = 5.8896e-04
Validation auc = 0.919828
Epoch 17
Loss = 2.4479e-01, PNorm = 36.4592, GNorm = 0.3736, lr_0 = 5.7402e-04
Validation auc = 0.916505
Epoch 18
Loss = 3.6197e-01, PNorm = 36.5189, GNorm = 1.0225, lr_0 = 5.5802e-04
Loss = 2.4149e-01, PNorm = 36.5730, GNorm = 0.5263, lr_0 = 5.4386e-04
Validation auc = 0.920382
Epoch 19
Loss = 2.6389e-01, PNorm = 36.6224, GNorm = 0.8074, lr_0 = 5.3007e-04
Validation auc = 0.914220
Epoch 20
Loss = 2.3568e-01, PNorm = 36.6777, GNorm = 1.2016, lr_0 = 5.1529e-04
Loss = 2.3845e-01, PNorm = 36.7351, GNorm = 0.4906, lr_0 = 5.0222e-04
Validation auc = 0.917751
Epoch 21
Loss = 2.7996e-01, PNorm = 36.7860, GNorm = 1.6765, lr_0 = 4.8948e-04
Loss = 2.5793e-01, PNorm = 36.8373, GNorm = 0.5384, lr_0 = 4.7706e-04
Loss = 2.4037e-01, PNorm = 36.8410, GNorm = 1.4289, lr_0 = 4.7583e-04
Validation auc = 0.909790
Epoch 22
Loss = 2.3667e-01, PNorm = 36.8880, GNorm = 0.8989, lr_0 = 4.6376e-04
Validation auc = 0.910274
Epoch 23
Loss = 2.2438e-01, PNorm = 36.9363, GNorm = 1.0100, lr_0 = 4.5200e-04
Loss = 2.4690e-01, PNorm = 36.9839, GNorm = 1.6493, lr_0 = 4.4053e-04
Validation auc = 0.916644
Epoch 24
Loss = 2.1884e-01, PNorm = 37.0406, GNorm = 0.4688, lr_0 = 4.2825e-04
Validation auc = 0.907851
Epoch 25
Loss = 1.9501e-01, PNorm = 37.0895, GNorm = 0.9582, lr_0 = 4.1738e-04
Loss = 2.1625e-01, PNorm = 37.1412, GNorm = 0.7817, lr_0 = 4.0679e-04
Validation auc = 0.907505
Epoch 26
Loss = 2.0087e-01, PNorm = 37.1929, GNorm = 0.6889, lr_0 = 3.9546e-04
Validation auc = 0.910413
Epoch 27
Loss = 2.2407e-01, PNorm = 37.2414, GNorm = 0.6726, lr_0 = 3.8443e-04
Loss = 2.2782e-01, PNorm = 37.2839, GNorm = 1.3572, lr_0 = 3.7468e-04
Validation auc = 0.902659
Epoch 28
Loss = 2.0008e-01, PNorm = 37.3293, GNorm = 0.5742, lr_0 = 3.6517e-04
Validation auc = 0.908197
Epoch 29
Loss = 1.4276e-01, PNorm = 37.3835, GNorm = 0.5498, lr_0 = 3.5500e-04
Loss = 1.8137e-01, PNorm = 37.4268, GNorm = 1.1301, lr_0 = 3.4599e-04
Validation auc = 0.903420
Model 0 best validation auc = 0.926059 on epoch 8
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.928767
Ensemble test auc = 0.928767
Fold 1
Splitting data with seed 1
Total scaffolds = 1,025 | train scaffolds = 768 | val scaffolds = 132 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 762
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9210e-01, PNorm = 35.0699, GNorm = 0.7570, lr_0 = 2.5469e-04
Validation auc = 0.840480
Epoch 1
Loss = 5.1862e-01, PNorm = 35.0913, GNorm = 0.4386, lr_0 = 4.0937e-04
Loss = 5.1567e-01, PNorm = 35.1154, GNorm = 1.9380, lr_0 = 5.5000e-04
Loss = 4.7269e-01, PNorm = 35.1180, GNorm = 0.8592, lr_0 = 5.6406e-04
Validation auc = 0.862137
Epoch 2
Loss = 4.8015e-01, PNorm = 35.1451, GNorm = 0.4625, lr_0 = 7.0469e-04
Validation auc = 0.866206
Epoch 3
Loss = 4.8771e-01, PNorm = 35.1906, GNorm = 2.8453, lr_0 = 8.5938e-04
Loss = 4.1720e-01, PNorm = 35.2348, GNorm = 0.5161, lr_0 = 1.0000e-03
Loss = 3.8087e-01, PNorm = 35.2404, GNorm = 1.5332, lr_0 = 9.9743e-04
Validation auc = 0.872602
Epoch 4
Loss = 4.1287e-01, PNorm = 35.2940, GNorm = 0.5543, lr_0 = 9.7213e-04
Validation auc = 0.876017
Epoch 5
Loss = 4.2662e-01, PNorm = 35.3503, GNorm = 1.1419, lr_0 = 9.4746e-04
Loss = 3.9269e-01, PNorm = 35.4020, GNorm = 1.0231, lr_0 = 9.2343e-04
Validation auc = 0.883503
Epoch 6
Loss = 4.1541e-01, PNorm = 35.4523, GNorm = 1.2695, lr_0 = 8.9769e-04
Validation auc = 0.879142
Epoch 7
Loss = 3.7131e-01, PNorm = 35.5196, GNorm = 1.1003, lr_0 = 8.7267e-04
Loss = 3.5046e-01, PNorm = 35.5856, GNorm = 0.8896, lr_0 = 8.5053e-04
Validation auc = 0.880741
Epoch 8
Loss = 3.8872e-01, PNorm = 35.6446, GNorm = 0.4468, lr_0 = 8.2682e-04
Validation auc = 0.874927
Epoch 9
Loss = 3.2717e-01, PNorm = 35.6921, GNorm = 0.3400, lr_0 = 8.0584e-04
Loss = 3.3178e-01, PNorm = 35.7545, GNorm = 1.0003, lr_0 = 7.8540e-04
Validation auc = 0.878852
Epoch 10
Loss = 3.2289e-01, PNorm = 35.8088, GNorm = 0.3172, lr_0 = 7.6351e-04
Validation auc = 0.881686
Epoch 11
Loss = 3.0705e-01, PNorm = 35.8617, GNorm = 1.6489, lr_0 = 7.4223e-04
Loss = 3.4592e-01, PNorm = 35.9107, GNorm = 0.4274, lr_0 = 7.2339e-04
Validation auc = 0.881904
Epoch 12
Loss = 3.4798e-01, PNorm = 35.9677, GNorm = 0.6393, lr_0 = 7.0323e-04
Validation auc = 0.881686
Epoch 13
Loss = 3.0276e-01, PNorm = 36.0286, GNorm = 1.0261, lr_0 = 6.8539e-04
Loss = 2.9833e-01, PNorm = 36.0936, GNorm = 0.3353, lr_0 = 6.6800e-04
Validation auc = 0.883794
Epoch 14
Loss = 2.8992e-01, PNorm = 36.1519, GNorm = 0.4737, lr_0 = 6.4938e-04
Validation auc = 0.878052
Epoch 15
Loss = 2.7244e-01, PNorm = 36.2082, GNorm = 0.4070, lr_0 = 6.3128e-04
Loss = 2.8061e-01, PNorm = 36.2606, GNorm = 1.4588, lr_0 = 6.1527e-04
Validation auc = 0.877616
Epoch 16
Loss = 2.8102e-01, PNorm = 36.3257, GNorm = 0.9080, lr_0 = 5.9812e-04
Validation auc = 0.881977
Epoch 17
Loss = 3.4494e-01, PNorm = 36.3799, GNorm = 0.7523, lr_0 = 5.8294e-04
Loss = 2.5616e-01, PNorm = 36.4348, GNorm = 0.4095, lr_0 = 5.6815e-04
Validation auc = 0.883358
Epoch 18
Loss = 2.7002e-01, PNorm = 36.4973, GNorm = 1.6871, lr_0 = 5.5232e-04
Validation auc = 0.882049
Epoch 19
Loss = 1.5736e-01, PNorm = 36.5680, GNorm = 0.7537, lr_0 = 5.3692e-04
Loss = 2.5303e-01, PNorm = 36.6256, GNorm = 1.4191, lr_0 = 5.2330e-04
Validation auc = 0.886265
Epoch 20
Loss = 2.3237e-01, PNorm = 36.6778, GNorm = 0.4496, lr_0 = 5.0871e-04
Loss = 2.8206e-01, PNorm = 36.7257, GNorm = 1.3904, lr_0 = 4.9581e-04
Validation auc = 0.874419
Epoch 21
Loss = 2.5630e-01, PNorm = 36.7781, GNorm = 0.8404, lr_0 = 4.8323e-04
Validation auc = 0.880160
Epoch 22
Loss = 2.4103e-01, PNorm = 36.8359, GNorm = 0.6777, lr_0 = 4.6976e-04
Loss = 2.3677e-01, PNorm = 36.8883, GNorm = 0.6569, lr_0 = 4.5784e-04
Loss = 3.0860e-01, PNorm = 36.8930, GNorm = 3.3992, lr_0 = 4.5667e-04
Validation auc = 0.884375
Epoch 23
Loss = 2.6946e-01, PNorm = 36.9384, GNorm = 0.6204, lr_0 = 4.4508e-04
Validation auc = 0.883285
Epoch 24
Loss = 2.1397e-01, PNorm = 36.9892, GNorm = 0.5029, lr_0 = 4.3267e-04
Loss = 2.1605e-01, PNorm = 37.0324, GNorm = 0.5696, lr_0 = 4.2170e-04
Validation auc = 0.874564
Epoch 25
Loss = 2.1453e-01, PNorm = 37.0750, GNorm = 0.5221, lr_0 = 4.1100e-04
Validation auc = 0.880305
Epoch 26
Loss = 2.2348e-01, PNorm = 37.1286, GNorm = 0.7086, lr_0 = 3.9954e-04
Loss = 2.1704e-01, PNorm = 37.1738, GNorm = 0.6357, lr_0 = 3.8941e-04
Validation auc = 0.884666
Epoch 27
Loss = 1.8718e-01, PNorm = 37.2237, GNorm = 0.6494, lr_0 = 3.7855e-04
Validation auc = 0.877834
Epoch 28
Loss = 1.9712e-01, PNorm = 37.2635, GNorm = 1.7903, lr_0 = 3.6800e-04
Loss = 1.7342e-01, PNorm = 37.3009, GNorm = 0.7498, lr_0 = 3.5866e-04
Validation auc = 0.880160
Epoch 29
Loss = 1.9046e-01, PNorm = 37.3381, GNorm = 0.6182, lr_0 = 3.4867e-04
Validation auc = 0.882558
Model 0 best validation auc = 0.886265 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.903879
Ensemble test auc = 0.903879
Fold 2
Splitting data with seed 2
Total scaffolds = 1,025 | train scaffolds = 766 | val scaffolds = 125 | test scaffolds = 134
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 748
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8410e-01, PNorm = 35.0706, GNorm = 1.0058, lr_0 = 2.5469e-04
Validation auc = 0.860611
Epoch 1
Loss = 5.2723e-01, PNorm = 35.0922, GNorm = 0.6741, lr_0 = 4.0937e-04
Validation auc = 0.860338
Epoch 2
Loss = 4.3403e-01, PNorm = 35.1195, GNorm = 2.4570, lr_0 = 5.5000e-04
Loss = 4.6489e-01, PNorm = 35.1464, GNorm = 2.2846, lr_0 = 6.9063e-04
Validation auc = 0.845336
Epoch 3
Loss = 4.1517e-01, PNorm = 35.1787, GNorm = 0.6632, lr_0 = 8.3125e-04
Validation auc = 0.856110
Epoch 4
Loss = 4.6568e-01, PNorm = 35.2196, GNorm = 0.4393, lr_0 = 9.7187e-04
Loss = 4.1940e-01, PNorm = 35.2660, GNorm = 0.3472, lr_0 = 9.7965e-04
Validation auc = 0.855019
Epoch 5
Loss = 4.2476e-01, PNorm = 35.3045, GNorm = 0.4688, lr_0 = 9.5480e-04
Validation auc = 0.860611
Epoch 6
Loss = 2.4068e-01, PNorm = 35.3459, GNorm = 0.3486, lr_0 = 9.3057e-04
Loss = 3.8589e-01, PNorm = 35.3949, GNorm = 0.4017, lr_0 = 9.0696e-04
Validation auc = 0.868385
Epoch 7
Loss = 3.9044e-01, PNorm = 35.4408, GNorm = 0.6193, lr_0 = 8.8395e-04
Validation auc = 0.872886
Epoch 8
Loss = 3.7216e-01, PNorm = 35.4890, GNorm = 0.4825, lr_0 = 8.6152e-04
Loss = 3.8001e-01, PNorm = 35.5442, GNorm = 0.3777, lr_0 = 8.3967e-04
Validation auc = 0.870022
Epoch 9
Loss = 3.3624e-01, PNorm = 35.6086, GNorm = 1.1195, lr_0 = 8.1836e-04
Validation auc = 0.883388
Epoch 10
Loss = 3.7868e-01, PNorm = 35.6731, GNorm = 1.0353, lr_0 = 7.9760e-04
Loss = 3.1987e-01, PNorm = 35.7335, GNorm = 0.9857, lr_0 = 7.7737e-04
Validation auc = 0.870977
Epoch 11
Loss = 3.3718e-01, PNorm = 35.7876, GNorm = 0.8580, lr_0 = 7.5764e-04
Validation auc = 0.885297
Epoch 12
Loss = 3.1119e-01, PNorm = 35.8494, GNorm = 0.4380, lr_0 = 7.3842e-04
Loss = 3.1860e-01, PNorm = 35.9072, GNorm = 0.5162, lr_0 = 7.1969e-04
Validation auc = 0.869885
Epoch 13
Loss = 2.8610e-01, PNorm = 35.9709, GNorm = 0.3755, lr_0 = 7.0143e-04
Validation auc = 0.886798
Epoch 14
Loss = 2.8398e-01, PNorm = 36.0275, GNorm = 0.4917, lr_0 = 6.8363e-04
Loss = 3.1310e-01, PNorm = 36.0897, GNorm = 0.6805, lr_0 = 6.6629e-04
Validation auc = 0.890071
Epoch 15
Loss = 2.7499e-01, PNorm = 36.1551, GNorm = 0.3195, lr_0 = 6.4938e-04
Validation auc = 0.884615
Epoch 16
Loss = 2.1973e-01, PNorm = 36.2220, GNorm = 0.5076, lr_0 = 6.3291e-04
Loss = 3.1136e-01, PNorm = 36.2818, GNorm = 0.7714, lr_0 = 6.1685e-04
Validation auc = 0.885706
Epoch 17
Loss = 3.0157e-01, PNorm = 36.3520, GNorm = 1.1448, lr_0 = 6.0120e-04
Validation auc = 0.889662
Epoch 18
Loss = 3.7117e-01, PNorm = 36.4178, GNorm = 0.9789, lr_0 = 5.8595e-04
Loss = 2.6434e-01, PNorm = 36.4767, GNorm = 0.9041, lr_0 = 5.7108e-04
Validation auc = 0.882024
Epoch 19
Loss = 2.4643e-01, PNorm = 36.5345, GNorm = 0.6394, lr_0 = 5.5659e-04
Validation auc = 0.888980
Epoch 20
Loss = 2.1711e-01, PNorm = 36.5969, GNorm = 0.6051, lr_0 = 5.4247e-04
Loss = 2.5435e-01, PNorm = 36.6615, GNorm = 0.4998, lr_0 = 5.2871e-04
Validation auc = 0.893071
Epoch 21
Loss = 2.3009e-01, PNorm = 36.7160, GNorm = 0.5496, lr_0 = 5.1529e-04
Validation auc = 0.902482
Epoch 22
Loss = 2.6941e-01, PNorm = 36.7737, GNorm = 0.7187, lr_0 = 5.0222e-04
Loss = 2.1727e-01, PNorm = 36.8374, GNorm = 0.5362, lr_0 = 4.8948e-04
Validation auc = 0.895936
Epoch 23
Loss = 2.3954e-01, PNorm = 36.9048, GNorm = 1.7898, lr_0 = 4.7706e-04
Validation auc = 0.895117
Epoch 24
Loss = 2.0783e-01, PNorm = 36.9608, GNorm = 1.2293, lr_0 = 4.6495e-04
Loss = 2.6412e-01, PNorm = 37.0150, GNorm = 0.6017, lr_0 = 4.5316e-04
Validation auc = 0.907665
Epoch 25
Loss = 2.3531e-01, PNorm = 37.0697, GNorm = 1.4423, lr_0 = 4.4166e-04
Validation auc = 0.901528
Epoch 26
Loss = 2.8937e-01, PNorm = 37.1318, GNorm = 0.5535, lr_0 = 4.2935e-04
Loss = 2.2323e-01, PNorm = 37.1882, GNorm = 0.7663, lr_0 = 4.1846e-04
Validation auc = 0.903301
Epoch 27
Loss = 2.2214e-01, PNorm = 37.2349, GNorm = 0.9161, lr_0 = 4.0784e-04
Validation auc = 0.898663
Epoch 28
Loss = 1.5933e-01, PNorm = 37.2844, GNorm = 0.4876, lr_0 = 3.9749e-04
Loss = 1.9948e-01, PNorm = 37.3339, GNorm = 0.6255, lr_0 = 3.8741e-04
Validation auc = 0.904528
Epoch 29
Loss = 2.0250e-01, PNorm = 37.3856, GNorm = 1.5845, lr_0 = 3.7758e-04
Validation auc = 0.917212
Model 0 best validation auc = 0.917212 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.955724
Ensemble test auc = 0.955724
Fold 3
Splitting data with seed 3
Total scaffolds = 1,025 | train scaffolds = 835 | val scaffolds = 63 | test scaffolds = 127
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 824
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8195e-01, PNorm = 35.0697, GNorm = 0.6962, lr_0 = 2.5469e-04
Validation auc = 0.789388
Epoch 1
Loss = 4.7180e-01, PNorm = 35.0910, GNorm = 0.6856, lr_0 = 4.0937e-04
Loss = 5.1193e-01, PNorm = 35.1184, GNorm = 0.9026, lr_0 = 5.5000e-04
Validation auc = 0.843469
Epoch 2
Loss = 4.3106e-01, PNorm = 35.1404, GNorm = 0.4501, lr_0 = 7.0469e-04
Validation auc = 0.880816
Epoch 3
Loss = 3.8783e-01, PNorm = 35.1722, GNorm = 0.7876, lr_0 = 8.4531e-04
Loss = 4.2032e-01, PNorm = 35.2101, GNorm = 0.4401, lr_0 = 9.8594e-04
Validation auc = 0.881224
Epoch 4
Loss = 3.9673e-01, PNorm = 35.2629, GNorm = 0.4363, lr_0 = 9.7463e-04
Loss = 3.8963e-01, PNorm = 35.3100, GNorm = 0.3707, lr_0 = 9.4990e-04
Validation auc = 0.884286
Epoch 5
Loss = 3.9545e-01, PNorm = 35.3526, GNorm = 1.2785, lr_0 = 9.2580e-04
Validation auc = 0.886939
Epoch 6
Loss = 4.0235e-01, PNorm = 35.4035, GNorm = 1.1258, lr_0 = 9.0000e-04
Loss = 3.7258e-01, PNorm = 35.4542, GNorm = 1.3011, lr_0 = 8.7716e-04
Validation auc = 0.878980
Epoch 7
Loss = 4.0250e-01, PNorm = 35.5028, GNorm = 0.6357, lr_0 = 8.5491e-04
Loss = 3.4830e-01, PNorm = 35.5598, GNorm = 0.6677, lr_0 = 8.3322e-04
Validation auc = 0.878163
Epoch 8
Loss = 3.0133e-01, PNorm = 35.6278, GNorm = 0.5694, lr_0 = 8.0999e-04
Validation auc = 0.881429
Epoch 9
Loss = 3.4792e-01, PNorm = 35.6850, GNorm = 0.3322, lr_0 = 7.8944e-04
Loss = 3.4115e-01, PNorm = 35.7491, GNorm = 0.3031, lr_0 = 7.6942e-04
Validation auc = 0.876327
Epoch 10
Loss = 3.1786e-01, PNorm = 35.8241, GNorm = 0.5071, lr_0 = 7.4797e-04
Loss = 3.2188e-01, PNorm = 35.8987, GNorm = 0.3379, lr_0 = 7.2899e-04
Validation auc = 0.884490
Epoch 11
Loss = 2.9495e-01, PNorm = 35.9849, GNorm = 0.4485, lr_0 = 7.1050e-04
Validation auc = 0.869592
Epoch 12
Loss = 3.5849e-01, PNorm = 36.0466, GNorm = 1.8460, lr_0 = 6.9069e-04
Loss = 3.2212e-01, PNorm = 36.1036, GNorm = 0.4198, lr_0 = 6.7317e-04
Validation auc = 0.870612
Epoch 13
Loss = 2.7875e-01, PNorm = 36.1582, GNorm = 0.7984, lr_0 = 6.5609e-04
Loss = 3.1581e-01, PNorm = 36.2168, GNorm = 0.5078, lr_0 = 6.3945e-04
Loss = 3.3853e-01, PNorm = 36.2234, GNorm = 0.7794, lr_0 = 6.3780e-04
Validation auc = 0.858367
Epoch 14
Loss = 3.0897e-01, PNorm = 36.2859, GNorm = 0.6910, lr_0 = 6.2162e-04
Validation auc = 0.871633
Epoch 15
Loss = 2.5609e-01, PNorm = 36.3414, GNorm = 0.9021, lr_0 = 6.0585e-04
Loss = 2.9051e-01, PNorm = 36.3937, GNorm = 1.1061, lr_0 = 5.9048e-04
Validation auc = 0.863469
Epoch 16
Loss = 2.8874e-01, PNorm = 36.4537, GNorm = 0.5982, lr_0 = 5.7402e-04
Loss = 2.7835e-01, PNorm = 36.5079, GNorm = 0.8924, lr_0 = 5.5946e-04
Validation auc = 0.858163
Epoch 17
Loss = 2.5328e-01, PNorm = 36.5633, GNorm = 0.7617, lr_0 = 5.4526e-04
Validation auc = 0.863673
Epoch 18
Loss = 3.3355e-01, PNorm = 36.6157, GNorm = 0.3955, lr_0 = 5.3007e-04
Loss = 2.6314e-01, PNorm = 36.6729, GNorm = 0.4728, lr_0 = 5.1662e-04
Validation auc = 0.856735
Epoch 19
Loss = 2.5061e-01, PNorm = 36.7322, GNorm = 0.9203, lr_0 = 5.0351e-04
Validation auc = 0.846122
Epoch 20
Loss = 2.9945e-01, PNorm = 36.7963, GNorm = 0.5495, lr_0 = 4.8948e-04
Loss = 2.3632e-01, PNorm = 36.8366, GNorm = 1.1823, lr_0 = 4.7706e-04
Validation auc = 0.853061
Epoch 21
Loss = 2.7441e-01, PNorm = 36.8835, GNorm = 0.7951, lr_0 = 4.6495e-04
Loss = 2.5280e-01, PNorm = 36.9312, GNorm = 0.3339, lr_0 = 4.5316e-04
Validation auc = 0.855510
Epoch 22
Loss = 2.4278e-01, PNorm = 36.9799, GNorm = 0.5995, lr_0 = 4.4053e-04
Validation auc = 0.855918
Epoch 23
Loss = 1.6177e-01, PNorm = 37.0232, GNorm = 1.0769, lr_0 = 4.2935e-04
Loss = 2.3901e-01, PNorm = 37.0820, GNorm = 0.3480, lr_0 = 4.1846e-04
Validation auc = 0.851020
Epoch 24
Loss = 2.2227e-01, PNorm = 37.1370, GNorm = 0.5668, lr_0 = 4.0679e-04
Loss = 2.2908e-01, PNorm = 37.1866, GNorm = 1.0169, lr_0 = 3.9647e-04
Validation auc = 0.857347
Epoch 25
Loss = 2.1975e-01, PNorm = 37.2272, GNorm = 1.0389, lr_0 = 3.8641e-04
Validation auc = 0.855510
Epoch 26
Loss = 2.1599e-01, PNorm = 37.2694, GNorm = 0.8049, lr_0 = 3.7564e-04
Loss = 2.1524e-01, PNorm = 37.3140, GNorm = 0.7418, lr_0 = 3.6611e-04
Validation auc = 0.853469
Epoch 27
Loss = 1.8725e-01, PNorm = 37.3568, GNorm = 0.6557, lr_0 = 3.5591e-04
Loss = 1.8595e-01, PNorm = 37.4036, GNorm = 0.3032, lr_0 = 3.4688e-04
Validation auc = 0.853673
Epoch 28
Loss = 1.9537e-01, PNorm = 37.4462, GNorm = 0.4139, lr_0 = 3.3808e-04
Validation auc = 0.851429
Epoch 29
Loss = 2.1094e-01, PNorm = 37.4852, GNorm = 1.1778, lr_0 = 3.2866e-04
Loss = 2.1702e-01, PNorm = 37.5200, GNorm = 1.4952, lr_0 = 3.2032e-04
Validation auc = 0.851020
Model 0 best validation auc = 0.886939 on epoch 5
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.862450
Ensemble test auc = 0.862450
Fold 4
Splitting data with seed 4
Total scaffolds = 1,025 | train scaffolds = 822 | val scaffolds = 112 | test scaffolds = 91
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 778
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7560e-01, PNorm = 35.0702, GNorm = 0.7138, lr_0 = 2.5469e-04
Validation auc = 0.839449
Epoch 1
Loss = 5.3299e-01, PNorm = 35.0928, GNorm = 0.4347, lr_0 = 4.0937e-04
Loss = 4.8267e-01, PNorm = 35.1232, GNorm = 2.3111, lr_0 = 5.5000e-04
Validation auc = 0.874342
Epoch 2
Loss = 4.7293e-01, PNorm = 35.1497, GNorm = 0.7093, lr_0 = 6.9063e-04
Validation auc = 0.888604
Epoch 3
Loss = 3.9661e-01, PNorm = 35.1842, GNorm = 0.4857, lr_0 = 8.4531e-04
Loss = 4.3782e-01, PNorm = 35.2257, GNorm = 1.1108, lr_0 = 9.8594e-04
Validation auc = 0.897674
Epoch 4
Loss = 3.9179e-01, PNorm = 35.2680, GNorm = 0.7602, lr_0 = 9.7714e-04
Validation auc = 0.884658
Epoch 5
Loss = 4.5975e-01, PNorm = 35.3212, GNorm = 0.4117, lr_0 = 9.4990e-04
Loss = 3.6431e-01, PNorm = 35.3776, GNorm = 0.3158, lr_0 = 9.2580e-04
Validation auc = 0.891443
Epoch 6
Loss = 3.5705e-01, PNorm = 35.4403, GNorm = 1.3364, lr_0 = 9.0231e-04
Validation auc = 0.886043
Epoch 7
Loss = 4.3081e-01, PNorm = 35.4964, GNorm = 0.3859, lr_0 = 8.7716e-04
Loss = 3.4625e-01, PNorm = 35.5491, GNorm = 1.8075, lr_0 = 8.5491e-04
Validation auc = 0.891651
Epoch 8
Loss = 3.7839e-01, PNorm = 35.5961, GNorm = 0.7660, lr_0 = 8.3322e-04
Loss = 3.5529e-01, PNorm = 35.6565, GNorm = 0.7765, lr_0 = 8.1208e-04
Validation auc = 0.889643
Epoch 9
Loss = 3.4970e-01, PNorm = 35.7092, GNorm = 0.6119, lr_0 = 7.9148e-04
Validation auc = 0.891720
Epoch 10
Loss = 3.6777e-01, PNorm = 35.7676, GNorm = 0.8774, lr_0 = 7.6942e-04
Loss = 3.1017e-01, PNorm = 35.8269, GNorm = 1.2803, lr_0 = 7.4989e-04
Validation auc = 0.894281
Epoch 11
Loss = 3.4091e-01, PNorm = 35.8834, GNorm = 0.7920, lr_0 = 7.3087e-04
Validation auc = 0.887843
Epoch 12
Loss = 3.2223e-01, PNorm = 35.9405, GNorm = 0.9216, lr_0 = 7.1050e-04
Loss = 2.9448e-01, PNorm = 35.9984, GNorm = 0.8468, lr_0 = 6.9247e-04
Validation auc = 0.893520
Epoch 13
Loss = 2.9593e-01, PNorm = 36.0539, GNorm = 0.4840, lr_0 = 6.7490e-04
Validation auc = 0.889297
Epoch 14
Loss = 2.4915e-01, PNorm = 36.1101, GNorm = 0.9270, lr_0 = 6.5609e-04
Loss = 3.2981e-01, PNorm = 36.1685, GNorm = 0.5709, lr_0 = 6.3945e-04
Validation auc = 0.890543
Epoch 15
Loss = 3.0197e-01, PNorm = 36.2254, GNorm = 1.2770, lr_0 = 6.2322e-04
Validation auc = 0.892966
Epoch 16
Loss = 2.0230e-01, PNorm = 36.2895, GNorm = 0.3303, lr_0 = 6.0585e-04
Loss = 2.6956e-01, PNorm = 36.3522, GNorm = 0.5446, lr_0 = 5.9048e-04
Validation auc = 0.886320
Epoch 17
Loss = 2.6649e-01, PNorm = 36.4088, GNorm = 0.8118, lr_0 = 5.7550e-04
Loss = 2.4939e-01, PNorm = 36.4684, GNorm = 0.7264, lr_0 = 5.6090e-04
Validation auc = 0.885212
Epoch 18
Loss = 2.9204e-01, PNorm = 36.5302, GNorm = 1.3535, lr_0 = 5.4667e-04
Validation auc = 0.890889
Epoch 19
Loss = 2.6987e-01, PNorm = 36.5982, GNorm = 0.7724, lr_0 = 5.3143e-04
Loss = 2.9572e-01, PNorm = 36.6567, GNorm = 0.7205, lr_0 = 5.1795e-04
Validation auc = 0.881681
Epoch 20
Loss = 2.4634e-01, PNorm = 36.7119, GNorm = 0.4843, lr_0 = 5.0481e-04
Validation auc = 0.868388
Epoch 21
Loss = 2.5648e-01, PNorm = 36.7729, GNorm = 0.4267, lr_0 = 4.9074e-04
Loss = 2.2368e-01, PNorm = 36.8293, GNorm = 0.6796, lr_0 = 4.7829e-04
Validation auc = 0.887150
Epoch 22
Loss = 2.6304e-01, PNorm = 36.8860, GNorm = 1.1962, lr_0 = 4.6615e-04
Validation auc = 0.877596
Epoch 23
Loss = 2.5961e-01, PNorm = 36.9485, GNorm = 0.6488, lr_0 = 4.5316e-04
Loss = 2.1868e-01, PNorm = 36.9981, GNorm = 0.8692, lr_0 = 4.4166e-04
Validation auc = 0.886597
Epoch 24
Loss = 2.4165e-01, PNorm = 37.0501, GNorm = 0.6600, lr_0 = 4.3046e-04
Validation auc = 0.878842
Epoch 25
Loss = 1.6522e-01, PNorm = 37.1034, GNorm = 0.5754, lr_0 = 4.1953e-04
Loss = 2.2244e-01, PNorm = 37.1580, GNorm = 0.8428, lr_0 = 4.0889e-04
Validation auc = 0.887289
Epoch 26
Loss = 2.5440e-01, PNorm = 37.2139, GNorm = 0.6500, lr_0 = 3.9749e-04
Loss = 2.0281e-01, PNorm = 37.2568, GNorm = 0.8227, lr_0 = 3.8741e-04
Validation auc = 0.873165
Epoch 27
Loss = 2.0870e-01, PNorm = 37.3033, GNorm = 0.5421, lr_0 = 3.7758e-04
Validation auc = 0.885143
Epoch 28
Loss = 1.9077e-01, PNorm = 37.3526, GNorm = 1.2917, lr_0 = 3.6706e-04
Loss = 1.7510e-01, PNorm = 37.3995, GNorm = 0.9573, lr_0 = 3.5774e-04
Validation auc = 0.867419
Epoch 29
Loss = 2.0081e-01, PNorm = 37.4480, GNorm = 0.6366, lr_0 = 3.4867e-04
Validation auc = 0.885904
Model 0 best validation auc = 0.897674 on epoch 3
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.890246
Ensemble test auc = 0.890246
Fold 5
Splitting data with seed 5
Total scaffolds = 1,025 | train scaffolds = 811 | val scaffolds = 109 | test scaffolds = 105
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 718
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8251e-01, PNorm = 35.0696, GNorm = 0.7468, lr_0 = 2.5469e-04
Validation auc = 0.953879
Epoch 1
Loss = 5.5491e-01, PNorm = 35.0895, GNorm = 0.8420, lr_0 = 4.0937e-04
Validation auc = 0.961037
Epoch 2
Loss = 5.3409e-01, PNorm = 35.1140, GNorm = 2.0035, lr_0 = 5.6406e-04
Loss = 4.4611e-01, PNorm = 35.1433, GNorm = 1.2027, lr_0 = 7.0469e-04
Validation auc = 0.966116
Epoch 3
Loss = 4.8597e-01, PNorm = 35.1712, GNorm = 0.7184, lr_0 = 8.4531e-04
Validation auc = 0.968714
Epoch 4
Loss = 5.1828e-01, PNorm = 35.2135, GNorm = 0.4462, lr_0 = 1.0000e-03
Loss = 4.4036e-01, PNorm = 35.2600, GNorm = 0.6111, lr_0 = 9.7463e-04
Validation auc = 0.973043
Epoch 5
Loss = 4.0955e-01, PNorm = 35.3189, GNorm = 0.3528, lr_0 = 9.4746e-04
Validation auc = 0.973332
Epoch 6
Loss = 3.7937e-01, PNorm = 35.3663, GNorm = 1.0860, lr_0 = 9.2343e-04
Loss = 3.8270e-01, PNorm = 35.4239, GNorm = 0.5491, lr_0 = 9.0000e-04
Loss = 3.1108e-01, PNorm = 35.4294, GNorm = 0.9814, lr_0 = 8.9769e-04
Validation auc = 0.970907
Epoch 7
Loss = 4.2090e-01, PNorm = 35.4825, GNorm = 1.6428, lr_0 = 8.7491e-04
Validation auc = 0.977661
Epoch 8
Loss = 3.9077e-01, PNorm = 35.5411, GNorm = 0.3594, lr_0 = 8.5053e-04
Validation auc = 0.972985
Epoch 9
Loss = 3.1851e-01, PNorm = 35.6037, GNorm = 0.3165, lr_0 = 8.2895e-04
Loss = 3.6323e-01, PNorm = 35.6683, GNorm = 0.8784, lr_0 = 8.0792e-04
Validation auc = 0.967848
Epoch 10
Loss = 3.3845e-01, PNorm = 35.7338, GNorm = 0.8542, lr_0 = 7.8540e-04
Validation auc = 0.967733
Epoch 11
Loss = 3.5683e-01, PNorm = 35.7980, GNorm = 0.4587, lr_0 = 7.6351e-04
Loss = 3.3287e-01, PNorm = 35.8616, GNorm = 0.6444, lr_0 = 7.4414e-04
Validation auc = 0.967213
Epoch 12
Loss = 3.5351e-01, PNorm = 35.9304, GNorm = 1.1734, lr_0 = 7.2526e-04
Validation auc = 0.967271
Epoch 13
Loss = 2.8516e-01, PNorm = 36.0041, GNorm = 0.3876, lr_0 = 7.0504e-04
Loss = 3.2010e-01, PNorm = 36.0721, GNorm = 0.6470, lr_0 = 6.8715e-04
Validation auc = 0.963288
Epoch 14
Loss = 3.1226e-01, PNorm = 36.1322, GNorm = 0.6978, lr_0 = 6.6972e-04
Validation auc = 0.973101
Epoch 15
Loss = 3.2159e-01, PNorm = 36.2006, GNorm = 1.5000, lr_0 = 6.5105e-04
Validation auc = 0.969637
Epoch 16
Loss = 2.5924e-01, PNorm = 36.2746, GNorm = 0.4871, lr_0 = 6.3291e-04
Loss = 2.8545e-01, PNorm = 36.3421, GNorm = 0.4873, lr_0 = 6.1685e-04
Validation auc = 0.955149
Epoch 17
Loss = 2.8804e-01, PNorm = 36.4097, GNorm = 0.6089, lr_0 = 6.0120e-04
Validation auc = 0.970503
Epoch 18
Loss = 2.3155e-01, PNorm = 36.4720, GNorm = 0.7170, lr_0 = 5.8444e-04
Loss = 2.8287e-01, PNorm = 36.5308, GNorm = 1.0180, lr_0 = 5.6961e-04
Validation auc = 0.962999
Epoch 19
Loss = 2.2149e-01, PNorm = 36.6057, GNorm = 0.6644, lr_0 = 5.5374e-04
Validation auc = 0.957342
Epoch 20
Loss = 1.6694e-01, PNorm = 36.6800, GNorm = 1.1571, lr_0 = 5.3969e-04
Loss = 2.6596e-01, PNorm = 36.7411, GNorm = 0.9146, lr_0 = 5.2600e-04
Validation auc = 0.950531
Epoch 21
Loss = 2.3695e-01, PNorm = 36.7983, GNorm = 1.1062, lr_0 = 5.1133e-04
Validation auc = 0.960113
Epoch 22
Loss = 2.2629e-01, PNorm = 36.8553, GNorm = 1.0565, lr_0 = 4.9708e-04
Loss = 2.2788e-01, PNorm = 36.9082, GNorm = 0.9817, lr_0 = 4.8447e-04
Validation auc = 0.953706
Epoch 23
Loss = 2.2613e-01, PNorm = 36.9662, GNorm = 0.5965, lr_0 = 4.7218e-04
Validation auc = 0.948280
Epoch 24
Loss = 2.3365e-01, PNorm = 37.0224, GNorm = 0.8097, lr_0 = 4.5902e-04
Validation auc = 0.953417
Epoch 25
Loss = 1.4911e-01, PNorm = 37.0712, GNorm = 0.5523, lr_0 = 4.4737e-04
Loss = 2.3109e-01, PNorm = 37.1328, GNorm = 1.1131, lr_0 = 4.3602e-04
Validation auc = 0.945798
Epoch 26
Loss = 2.2861e-01, PNorm = 37.1791, GNorm = 0.5713, lr_0 = 4.2387e-04
Validation auc = 0.960748
Epoch 27
Loss = 2.0723e-01, PNorm = 37.2264, GNorm = 0.6070, lr_0 = 4.1206e-04
Loss = 2.4672e-01, PNorm = 37.2775, GNorm = 0.9446, lr_0 = 4.0160e-04
Validation auc = 0.947414
Epoch 28
Loss = 1.9554e-01, PNorm = 37.3245, GNorm = 1.7933, lr_0 = 3.9141e-04
Validation auc = 0.948568
Epoch 29
Loss = 1.9966e-01, PNorm = 37.3658, GNorm = 0.8038, lr_0 = 3.8050e-04
Loss = 1.8129e-01, PNorm = 37.4064, GNorm = 1.3905, lr_0 = 3.7085e-04
Loss = 1.4121e-01, PNorm = 37.4100, GNorm = 1.0467, lr_0 = 3.6990e-04
Validation auc = 0.946779
Model 0 best validation auc = 0.977661 on epoch 7
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.892326
Ensemble test auc = 0.892326
Fold 6
Splitting data with seed 6
Total scaffolds = 1,025 | train scaffolds = 786 | val scaffolds = 128 | test scaffolds = 111
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 748
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7485e-01, PNorm = 35.0705, GNorm = 0.8107, lr_0 = 2.5469e-04
Validation auc = 0.802353
Epoch 1
Loss = 5.2496e-01, PNorm = 35.0902, GNorm = 0.6123, lr_0 = 4.0937e-04
Validation auc = 0.848758
Epoch 2
Loss = 3.8416e-01, PNorm = 35.1188, GNorm = 0.5323, lr_0 = 5.5000e-04
Loss = 4.6366e-01, PNorm = 35.1505, GNorm = 2.2412, lr_0 = 6.9063e-04
Validation auc = 0.878693
Epoch 3
Loss = 4.8582e-01, PNorm = 35.1830, GNorm = 0.4862, lr_0 = 8.3125e-04
Validation auc = 0.885621
Epoch 4
Loss = 5.0236e-01, PNorm = 35.2252, GNorm = 1.5284, lr_0 = 9.7187e-04
Loss = 3.9210e-01, PNorm = 35.2815, GNorm = 0.8620, lr_0 = 9.7965e-04
Validation auc = 0.897255
Epoch 5
Loss = 3.8225e-01, PNorm = 35.3454, GNorm = 0.7505, lr_0 = 9.5480e-04
Validation auc = 0.887320
Epoch 6
Loss = 5.0859e-01, PNorm = 35.4089, GNorm = 1.0626, lr_0 = 9.3057e-04
Loss = 3.8351e-01, PNorm = 35.4604, GNorm = 1.1550, lr_0 = 9.0696e-04
Validation auc = 0.904575
Epoch 7
Loss = 3.6898e-01, PNorm = 35.5087, GNorm = 0.8891, lr_0 = 8.8395e-04
Validation auc = 0.902876
Epoch 8
Loss = 3.1330e-01, PNorm = 35.5653, GNorm = 0.4349, lr_0 = 8.6152e-04
Loss = 3.1232e-01, PNorm = 35.6328, GNorm = 1.7686, lr_0 = 8.3967e-04
Validation auc = 0.907974
Epoch 9
Loss = 3.6319e-01, PNorm = 35.6846, GNorm = 0.6820, lr_0 = 8.1836e-04
Validation auc = 0.900784
Epoch 10
Loss = 2.1183e-01, PNorm = 35.7386, GNorm = 0.7953, lr_0 = 7.9760e-04
Loss = 3.2645e-01, PNorm = 35.7963, GNorm = 0.2878, lr_0 = 7.7737e-04
Validation auc = 0.905229
Epoch 11
Loss = 3.4921e-01, PNorm = 35.8508, GNorm = 1.3254, lr_0 = 7.5764e-04
Validation auc = 0.906536
Epoch 12
Loss = 3.1318e-01, PNorm = 35.9007, GNorm = 0.5067, lr_0 = 7.3842e-04
Loss = 3.0668e-01, PNorm = 35.9579, GNorm = 0.6461, lr_0 = 7.1969e-04
Validation auc = 0.910065
Epoch 13
Loss = 3.2000e-01, PNorm = 36.0165, GNorm = 0.3713, lr_0 = 7.0143e-04
Validation auc = 0.912157
Epoch 14
Loss = 2.3129e-01, PNorm = 36.0771, GNorm = 0.4678, lr_0 = 6.8363e-04
Loss = 2.9771e-01, PNorm = 36.1489, GNorm = 0.9171, lr_0 = 6.6629e-04
Validation auc = 0.911111
Epoch 15
Loss = 2.8633e-01, PNorm = 36.2207, GNorm = 0.3418, lr_0 = 6.4938e-04
Validation auc = 0.903268
Epoch 16
Loss = 2.4402e-01, PNorm = 36.2820, GNorm = 0.6092, lr_0 = 6.3291e-04
Loss = 2.8962e-01, PNorm = 36.3484, GNorm = 0.9671, lr_0 = 6.1685e-04
Validation auc = 0.909412
Epoch 17
Loss = 2.8291e-01, PNorm = 36.4151, GNorm = 0.5980, lr_0 = 6.0120e-04
Validation auc = 0.913595
Epoch 18
Loss = 2.5969e-01, PNorm = 36.4742, GNorm = 0.4307, lr_0 = 5.8595e-04
Loss = 2.5992e-01, PNorm = 36.5427, GNorm = 0.3874, lr_0 = 5.7108e-04
Validation auc = 0.919739
Epoch 19
Loss = 2.3194e-01, PNorm = 36.6152, GNorm = 0.3751, lr_0 = 5.5659e-04
Validation auc = 0.910850
Epoch 20
Loss = 1.3596e-01, PNorm = 36.6869, GNorm = 0.9449, lr_0 = 5.4247e-04
Loss = 2.6864e-01, PNorm = 36.7564, GNorm = 0.4148, lr_0 = 5.2871e-04
Validation auc = 0.913987
Epoch 21
Loss = 2.9102e-01, PNorm = 36.8215, GNorm = 0.5706, lr_0 = 5.1529e-04
Validation auc = 0.916601
Epoch 22
Loss = 2.9874e-01, PNorm = 36.8832, GNorm = 1.9306, lr_0 = 5.0222e-04
Loss = 2.5240e-01, PNorm = 36.9410, GNorm = 0.9468, lr_0 = 4.8948e-04
Validation auc = 0.917516
Epoch 23
Loss = 2.8056e-01, PNorm = 36.9951, GNorm = 0.9197, lr_0 = 4.7706e-04
Validation auc = 0.909935
Epoch 24
Loss = 2.2963e-01, PNorm = 37.0463, GNorm = 0.4833, lr_0 = 4.6495e-04
Loss = 2.2430e-01, PNorm = 37.1044, GNorm = 0.8915, lr_0 = 4.5316e-04
Validation auc = 0.915817
Epoch 25
Loss = 1.8059e-01, PNorm = 37.1617, GNorm = 0.4482, lr_0 = 4.4166e-04
Validation auc = 0.916471
Epoch 26
Loss = 2.5789e-01, PNorm = 37.2215, GNorm = 0.7521, lr_0 = 4.2935e-04
Loss = 2.1579e-01, PNorm = 37.2844, GNorm = 0.7781, lr_0 = 4.1846e-04
Validation auc = 0.922222
Epoch 27
Loss = 2.2113e-01, PNorm = 37.3454, GNorm = 0.8661, lr_0 = 4.0784e-04
Validation auc = 0.913072
Epoch 28
Loss = 2.2944e-01, PNorm = 37.3963, GNorm = 0.5364, lr_0 = 3.9749e-04
Loss = 1.8979e-01, PNorm = 37.4428, GNorm = 0.5229, lr_0 = 3.8741e-04
Validation auc = 0.908235
Epoch 29
Loss = 2.2811e-01, PNorm = 37.4969, GNorm = 0.5685, lr_0 = 3.7758e-04
Validation auc = 0.924837
Model 0 best validation auc = 0.924837 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.886606
Ensemble test auc = 0.886606
Fold 7
Splitting data with seed 7
Total scaffolds = 1,025 | train scaffolds = 843 | val scaffolds = 123 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 814
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7304e-01, PNorm = 35.0703, GNorm = 0.6263, lr_0 = 2.5469e-04
Validation auc = 0.887659
Epoch 1
Loss = 5.3554e-01, PNorm = 35.0933, GNorm = 1.1034, lr_0 = 4.0937e-04
Loss = 4.5947e-01, PNorm = 35.1227, GNorm = 0.4852, lr_0 = 5.5000e-04
Validation auc = 0.896451
Epoch 2
Loss = 4.2376e-01, PNorm = 35.1608, GNorm = 2.2761, lr_0 = 7.0469e-04
Validation auc = 0.909313
Epoch 3
Loss = 3.9836e-01, PNorm = 35.1874, GNorm = 0.3809, lr_0 = 8.5938e-04
Loss = 4.4445e-01, PNorm = 35.2214, GNorm = 1.2261, lr_0 = 1.0000e-03
Validation auc = 0.913220
Epoch 4
Loss = 4.5111e-01, PNorm = 35.2670, GNorm = 0.5793, lr_0 = 9.7463e-04
Loss = 4.2478e-01, PNorm = 35.3153, GNorm = 1.1752, lr_0 = 9.4990e-04
Validation auc = 0.919733
Epoch 5
Loss = 3.8069e-01, PNorm = 35.3648, GNorm = 0.9705, lr_0 = 9.2343e-04
Validation auc = 0.923803
Epoch 6
Loss = 4.8116e-01, PNorm = 35.4138, GNorm = 1.0366, lr_0 = 8.9769e-04
Loss = 4.0016e-01, PNorm = 35.4606, GNorm = 0.9024, lr_0 = 8.7491e-04
Validation auc = 0.927711
Epoch 7
Loss = 4.1394e-01, PNorm = 35.5080, GNorm = 0.5367, lr_0 = 8.5053e-04
Loss = 3.5629e-01, PNorm = 35.5597, GNorm = 0.9072, lr_0 = 8.2895e-04
Validation auc = 0.928688
Epoch 8
Loss = 3.7207e-01, PNorm = 35.6183, GNorm = 0.9041, lr_0 = 8.0792e-04
Validation auc = 0.936991
Epoch 9
Loss = 3.8542e-01, PNorm = 35.6734, GNorm = 1.0415, lr_0 = 7.8540e-04
Loss = 3.5491e-01, PNorm = 35.7216, GNorm = 0.7165, lr_0 = 7.6547e-04
Validation auc = 0.931130
Epoch 10
Loss = 3.8968e-01, PNorm = 35.7822, GNorm = 0.9612, lr_0 = 7.4414e-04
Validation auc = 0.931130
Epoch 11
Loss = 3.0055e-01, PNorm = 35.8338, GNorm = 0.3656, lr_0 = 7.2526e-04
Loss = 3.6445e-01, PNorm = 35.8843, GNorm = 0.9773, lr_0 = 7.0686e-04
Validation auc = 0.931293
Epoch 12
Loss = 4.2658e-01, PNorm = 35.9443, GNorm = 1.5765, lr_0 = 6.8715e-04
Loss = 3.4817e-01, PNorm = 35.9967, GNorm = 0.3575, lr_0 = 6.6972e-04
Validation auc = 0.929502
Epoch 13
Loss = 3.5863e-01, PNorm = 36.0499, GNorm = 0.4539, lr_0 = 6.5105e-04
Validation auc = 0.937480
Epoch 14
Loss = 3.4950e-01, PNorm = 36.1025, GNorm = 0.7379, lr_0 = 6.3291e-04
Loss = 3.3799e-01, PNorm = 36.1507, GNorm = 1.1123, lr_0 = 6.1685e-04
Validation auc = 0.936828
Epoch 15
Loss = 3.2609e-01, PNorm = 36.1984, GNorm = 0.3541, lr_0 = 6.0120e-04
Loss = 3.3221e-01, PNorm = 36.2517, GNorm = 0.4075, lr_0 = 5.8595e-04
Loss = 3.5253e-01, PNorm = 36.2580, GNorm = 1.2201, lr_0 = 5.8444e-04
Validation auc = 0.928036
Epoch 16
Loss = 3.4086e-01, PNorm = 36.3193, GNorm = 0.5586, lr_0 = 5.6961e-04
Validation auc = 0.940573
Epoch 17
Loss = 2.6939e-01, PNorm = 36.3808, GNorm = 0.4775, lr_0 = 5.5374e-04
Loss = 3.0516e-01, PNorm = 36.4392, GNorm = 1.0254, lr_0 = 5.3969e-04
Validation auc = 0.936503
Epoch 18
Loss = 2.8823e-01, PNorm = 36.4959, GNorm = 0.9819, lr_0 = 5.2600e-04
Validation auc = 0.936828
Epoch 19
Loss = 1.7861e-01, PNorm = 36.5571, GNorm = 0.7657, lr_0 = 5.1133e-04
Loss = 2.8243e-01, PNorm = 36.6132, GNorm = 1.3378, lr_0 = 4.9836e-04
Validation auc = 0.943178
Epoch 20
Loss = 2.6881e-01, PNorm = 36.6751, GNorm = 1.5060, lr_0 = 4.8447e-04
Loss = 3.4022e-01, PNorm = 36.7326, GNorm = 1.0796, lr_0 = 4.7218e-04
Validation auc = 0.936991
Epoch 21
Loss = 2.6783e-01, PNorm = 36.7839, GNorm = 0.4634, lr_0 = 4.5902e-04
Validation auc = 0.937317
Epoch 22
Loss = 2.6396e-01, PNorm = 36.8324, GNorm = 0.5222, lr_0 = 4.4737e-04
Loss = 2.5929e-01, PNorm = 36.8842, GNorm = 2.1606, lr_0 = 4.3602e-04
Validation auc = 0.942201
Epoch 23
Loss = 2.7131e-01, PNorm = 36.9249, GNorm = 1.1706, lr_0 = 4.2387e-04
Loss = 3.2124e-01, PNorm = 36.9684, GNorm = 0.4908, lr_0 = 4.1312e-04
Loss = 2.4145e-01, PNorm = 36.9739, GNorm = 0.6926, lr_0 = 4.1206e-04
Validation auc = 0.945132
Epoch 24
Loss = 3.0088e-01, PNorm = 37.0255, GNorm = 0.3859, lr_0 = 4.0160e-04
Validation auc = 0.946760
Epoch 25
Loss = 2.8412e-01, PNorm = 37.0667, GNorm = 0.6883, lr_0 = 3.9141e-04
Loss = 2.5039e-01, PNorm = 37.1108, GNorm = 1.0102, lr_0 = 3.8148e-04
Validation auc = 0.935363
Epoch 26
Loss = 2.5708e-01, PNorm = 37.1540, GNorm = 0.7326, lr_0 = 3.7085e-04
Validation auc = 0.944969
Epoch 27
Loss = 2.5798e-01, PNorm = 37.2028, GNorm = 0.5849, lr_0 = 3.6051e-04
Loss = 2.2991e-01, PNorm = 37.2462, GNorm = 0.4456, lr_0 = 3.5137e-04
Validation auc = 0.937642
Epoch 28
Loss = 2.8638e-01, PNorm = 37.2936, GNorm = 1.2857, lr_0 = 3.4157e-04
Loss = 2.3926e-01, PNorm = 37.3319, GNorm = 0.7790, lr_0 = 3.3291e-04
Validation auc = 0.945132
Epoch 29
Loss = 2.5840e-01, PNorm = 37.3776, GNorm = 0.6399, lr_0 = 3.2446e-04
Validation auc = 0.941550
Model 0 best validation auc = 0.946760 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.951849
Ensemble test auc = 0.951849
Fold 8
Splitting data with seed 8
Total scaffolds = 1,025 | train scaffolds = 828 | val scaffolds = 80 | test scaffolds = 117
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 792
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.6601e-01, PNorm = 35.0707, GNorm = 0.7782, lr_0 = 2.5469e-04
Validation auc = 0.745499
Epoch 1
Loss = 4.7155e-01, PNorm = 35.0936, GNorm = 0.9164, lr_0 = 4.0937e-04
Loss = 4.9905e-01, PNorm = 35.1194, GNorm = 2.1609, lr_0 = 5.5000e-04
Validation auc = 0.828020
Epoch 2
Loss = 4.7221e-01, PNorm = 35.1440, GNorm = 1.5141, lr_0 = 6.9063e-04
Validation auc = 0.829707
Epoch 3
Loss = 4.5416e-01, PNorm = 35.1709, GNorm = 0.3647, lr_0 = 8.3125e-04
Loss = 4.1348e-01, PNorm = 35.2071, GNorm = 0.5457, lr_0 = 9.7187e-04
Validation auc = 0.838335
Epoch 4
Loss = 3.9295e-01, PNorm = 35.2563, GNorm = 1.0490, lr_0 = 9.7965e-04
Validation auc = 0.826425
Epoch 5
Loss = 5.1980e-01, PNorm = 35.3057, GNorm = 2.1998, lr_0 = 9.5480e-04
Loss = 4.0210e-01, PNorm = 35.3531, GNorm = 0.5083, lr_0 = 9.3057e-04
Validation auc = 0.852119
Epoch 6
Loss = 3.7226e-01, PNorm = 35.4021, GNorm = 0.3448, lr_0 = 9.0696e-04
Loss = 3.7060e-01, PNorm = 35.4569, GNorm = 0.3241, lr_0 = 8.8395e-04
Loss = 4.0777e-01, PNorm = 35.4632, GNorm = 0.4989, lr_0 = 8.8168e-04
Validation auc = 0.847337
Epoch 7
Loss = 3.6077e-01, PNorm = 35.5162, GNorm = 1.9830, lr_0 = 8.5931e-04
Validation auc = 0.846305
Epoch 8
Loss = 4.1543e-01, PNorm = 35.5711, GNorm = 0.6160, lr_0 = 8.3751e-04
Loss = 3.5086e-01, PNorm = 35.6295, GNorm = 0.3180, lr_0 = 8.1626e-04
Validation auc = 0.871155
Epoch 9
Loss = 3.2940e-01, PNorm = 35.6914, GNorm = 0.6796, lr_0 = 7.9555e-04
Validation auc = 0.848275
Epoch 10
Loss = 3.0629e-01, PNorm = 35.7469, GNorm = 0.7234, lr_0 = 7.7537e-04
Loss = 3.2806e-01, PNorm = 35.8063, GNorm = 0.9992, lr_0 = 7.5570e-04
Validation auc = 0.866748
Epoch 11
Loss = 3.4950e-01, PNorm = 35.8640, GNorm = 1.1414, lr_0 = 7.3653e-04
Loss = 3.2633e-01, PNorm = 35.9273, GNorm = 0.6686, lr_0 = 7.1784e-04
Validation auc = 0.873125
Epoch 12
Loss = 2.9709e-01, PNorm = 36.0027, GNorm = 0.9515, lr_0 = 6.9963e-04
Validation auc = 0.876313
Epoch 13
Loss = 2.7466e-01, PNorm = 36.0719, GNorm = 0.8572, lr_0 = 6.8013e-04
Loss = 3.2042e-01, PNorm = 36.1359, GNorm = 0.3921, lr_0 = 6.6287e-04
Validation auc = 0.873968
Epoch 14
Loss = 2.9879e-01, PNorm = 36.2065, GNorm = 0.4293, lr_0 = 6.4605e-04
Validation auc = 0.880251
Epoch 15
Loss = 3.1755e-01, PNorm = 36.2646, GNorm = 0.4988, lr_0 = 6.2966e-04
Loss = 2.5862e-01, PNorm = 36.3223, GNorm = 0.3588, lr_0 = 6.1369e-04
Validation auc = 0.876032
Epoch 16
Loss = 3.2306e-01, PNorm = 36.3848, GNorm = 0.9049, lr_0 = 5.9812e-04
Validation auc = 0.873593
Epoch 17
Loss = 2.9931e-01, PNorm = 36.4428, GNorm = 0.4147, lr_0 = 5.8294e-04
Loss = 2.7087e-01, PNorm = 36.5016, GNorm = 0.5690, lr_0 = 5.6815e-04
Validation auc = 0.865435
Epoch 18
Loss = 2.4120e-01, PNorm = 36.5578, GNorm = 0.6094, lr_0 = 5.5374e-04
Loss = 2.8742e-01, PNorm = 36.6213, GNorm = 1.5144, lr_0 = 5.3969e-04
Loss = 2.5499e-01, PNorm = 36.6265, GNorm = 0.9348, lr_0 = 5.3830e-04
Validation auc = 0.879314
Epoch 19
Loss = 2.4990e-01, PNorm = 36.6767, GNorm = 0.5636, lr_0 = 5.2465e-04
Validation auc = 0.878376
Epoch 20
Loss = 2.2528e-01, PNorm = 36.7308, GNorm = 0.3941, lr_0 = 5.1133e-04
Loss = 2.4766e-01, PNorm = 36.7903, GNorm = 0.6501, lr_0 = 4.9836e-04
Validation auc = 0.875750
Epoch 21
Loss = 2.4932e-01, PNorm = 36.8524, GNorm = 1.2324, lr_0 = 4.8572e-04
Validation auc = 0.889816
Epoch 22
Loss = 2.2779e-01, PNorm = 36.9007, GNorm = 0.4944, lr_0 = 4.7339e-04
Loss = 2.3400e-01, PNorm = 36.9407, GNorm = 1.2129, lr_0 = 4.6138e-04
Validation auc = 0.879032
Epoch 23
Loss = 2.2857e-01, PNorm = 36.9893, GNorm = 0.4819, lr_0 = 4.4968e-04
Loss = 2.4461e-01, PNorm = 37.0345, GNorm = 1.2474, lr_0 = 4.3827e-04
Validation auc = 0.881845
Epoch 24
Loss = 2.3798e-01, PNorm = 37.0826, GNorm = 1.7453, lr_0 = 4.2715e-04
Validation auc = 0.879126
Epoch 25
Loss = 2.9123e-01, PNorm = 37.1254, GNorm = 0.8808, lr_0 = 4.1631e-04
Loss = 2.0605e-01, PNorm = 37.1728, GNorm = 0.7076, lr_0 = 4.0575e-04
Validation auc = 0.885221
Epoch 26
Loss = 2.0974e-01, PNorm = 37.2223, GNorm = 0.3467, lr_0 = 3.9444e-04
Validation auc = 0.880439
Epoch 27
Loss = 2.6355e-01, PNorm = 37.2669, GNorm = 0.4207, lr_0 = 3.8443e-04
Loss = 2.1986e-01, PNorm = 37.3100, GNorm = 1.6546, lr_0 = 3.7468e-04
Validation auc = 0.886347
Epoch 28
Loss = 2.3830e-01, PNorm = 37.3512, GNorm = 0.9552, lr_0 = 3.6517e-04
Validation auc = 0.878938
Epoch 29
Loss = 9.6398e-02, PNorm = 37.3934, GNorm = 0.3599, lr_0 = 3.5591e-04
Loss = 2.1245e-01, PNorm = 37.4373, GNorm = 0.4464, lr_0 = 3.4688e-04
Validation auc = 0.890004
Model 0 best validation auc = 0.890004 on epoch 29
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.906486
Ensemble test auc = 0.906486
Fold 9
Splitting data with seed 9
Total scaffolds = 1,025 | train scaffolds = 761 | val scaffolds = 139 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 752
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9230e-01, PNorm = 35.0698, GNorm = 0.6988, lr_0 = 2.5469e-04
Validation auc = 0.852076
Epoch 1
Loss = 5.4669e-01, PNorm = 35.0867, GNorm = 0.4694, lr_0 = 4.0937e-04
Loss = 5.2462e-01, PNorm = 35.1077, GNorm = 1.6948, lr_0 = 5.5000e-04
Loss = 5.8890e-01, PNorm = 35.1100, GNorm = 2.4199, lr_0 = 5.6406e-04
Validation auc = 0.865958
Epoch 2
Loss = 5.0648e-01, PNorm = 35.1335, GNorm = 0.8333, lr_0 = 7.0469e-04
Validation auc = 0.887481
Epoch 3
Loss = 4.3419e-01, PNorm = 35.1675, GNorm = 0.6184, lr_0 = 8.5938e-04
Loss = 4.4155e-01, PNorm = 35.2084, GNorm = 0.6285, lr_0 = 1.0000e-03
Loss = 1.7279e-01, PNorm = 35.2135, GNorm = 0.8467, lr_0 = 9.9743e-04
Validation auc = 0.880476
Epoch 4
Loss = 4.0851e-01, PNorm = 35.2647, GNorm = 0.9785, lr_0 = 9.7213e-04
Validation auc = 0.878375
Epoch 5
Loss = 3.9541e-01, PNorm = 35.3128, GNorm = 1.0460, lr_0 = 9.4503e-04
Loss = 4.4234e-01, PNorm = 35.3565, GNorm = 0.8957, lr_0 = 9.2106e-04
Loss = 1.2517e-01, PNorm = 35.3603, GNorm = 1.1576, lr_0 = 9.1869e-04
Validation auc = 0.875764
Epoch 6
Loss = 4.0460e-01, PNorm = 35.4005, GNorm = 1.4842, lr_0 = 8.9538e-04
Validation auc = 0.884552
Epoch 7
Loss = 3.3962e-01, PNorm = 35.4403, GNorm = 0.6710, lr_0 = 8.7043e-04
Loss = 4.0554e-01, PNorm = 35.4796, GNorm = 0.5928, lr_0 = 8.4834e-04
Loss = 3.2405e-01, PNorm = 35.4837, GNorm = 2.2647, lr_0 = 8.4617e-04
Validation auc = 0.884233
Epoch 8
Loss = 3.6064e-01, PNorm = 35.5258, GNorm = 0.3783, lr_0 = 8.2470e-04
Validation auc = 0.890537
Epoch 9
Loss = 4.3256e-01, PNorm = 35.5745, GNorm = 0.4532, lr_0 = 8.0171e-04
Loss = 3.3115e-01, PNorm = 35.6232, GNorm = 0.3244, lr_0 = 7.8137e-04
Loss = 6.2498e-01, PNorm = 35.6286, GNorm = 2.7286, lr_0 = 7.7937e-04
Validation auc = 0.892320
Epoch 10
Loss = 3.1514e-01, PNorm = 35.6873, GNorm = 1.0807, lr_0 = 7.5959e-04
Validation auc = 0.885953
Epoch 11
Loss = 3.7995e-01, PNorm = 35.7463, GNorm = 0.6198, lr_0 = 7.3842e-04
Loss = 3.3945e-01, PNorm = 35.7911, GNorm = 0.4828, lr_0 = 7.1969e-04
Loss = 2.2174e-01, PNorm = 35.7965, GNorm = 1.9270, lr_0 = 7.1784e-04
Validation auc = 0.887672
Epoch 12
Loss = 3.4236e-01, PNorm = 35.8448, GNorm = 0.8832, lr_0 = 6.9963e-04
Validation auc = 0.892575
Epoch 13
Loss = 3.4918e-01, PNorm = 35.8972, GNorm = 1.2828, lr_0 = 6.8013e-04
Loss = 3.5921e-01, PNorm = 35.9419, GNorm = 0.4613, lr_0 = 6.6287e-04
Loss = 8.2161e-02, PNorm = 35.9462, GNorm = 1.1033, lr_0 = 6.6117e-04
Validation auc = 0.892320
Epoch 14
Loss = 3.6465e-01, PNorm = 35.9868, GNorm = 0.4599, lr_0 = 6.4439e-04
Validation auc = 0.891365
Epoch 15
Loss = 2.9491e-01, PNorm = 36.0350, GNorm = 0.6642, lr_0 = 6.2643e-04
Loss = 3.3170e-01, PNorm = 36.0853, GNorm = 0.3824, lr_0 = 6.1054e-04
Loss = 4.2207e-02, PNorm = 36.0901, GNorm = 0.6592, lr_0 = 6.0897e-04
Validation auc = 0.892320
Epoch 16
Loss = 3.0156e-01, PNorm = 36.1425, GNorm = 0.4993, lr_0 = 5.9352e-04
Validation auc = 0.887608
Epoch 17
Loss = 3.1240e-01, PNorm = 36.1990, GNorm = 0.9886, lr_0 = 5.7698e-04
Loss = 2.7358e-01, PNorm = 36.2548, GNorm = 0.3702, lr_0 = 5.6234e-04
Loss = 1.3465e-01, PNorm = 36.2605, GNorm = 1.1335, lr_0 = 5.6090e-04
Validation auc = 0.891493
Epoch 18
Loss = 2.8740e-01, PNorm = 36.3172, GNorm = 0.9065, lr_0 = 5.4667e-04
Validation auc = 0.892066
Epoch 19
Loss = 2.5197e-01, PNorm = 36.3829, GNorm = 0.9471, lr_0 = 5.3143e-04
Loss = 2.9547e-01, PNorm = 36.4348, GNorm = 0.7319, lr_0 = 5.1795e-04
Loss = 1.1621e-01, PNorm = 36.4407, GNorm = 1.0033, lr_0 = 5.1662e-04
Validation auc = 0.888500
Epoch 20
Loss = 3.1207e-01, PNorm = 36.4947, GNorm = 0.5702, lr_0 = 5.0351e-04
Validation auc = 0.891365
Epoch 21
Loss = 2.7179e-01, PNorm = 36.5411, GNorm = 1.2034, lr_0 = 4.8948e-04
Loss = 2.8348e-01, PNorm = 36.5851, GNorm = 0.4660, lr_0 = 4.7706e-04
Loss = 1.1847e-01, PNorm = 36.5887, GNorm = 1.5243, lr_0 = 4.7583e-04
Validation auc = 0.887863
Epoch 22
Loss = 2.9249e-01, PNorm = 36.6337, GNorm = 1.3760, lr_0 = 4.6376e-04
Validation auc = 0.899198
Epoch 23
Loss = 3.1245e-01, PNorm = 36.6740, GNorm = 0.4419, lr_0 = 4.5084e-04
Loss = 2.6418e-01, PNorm = 36.7100, GNorm = 0.5541, lr_0 = 4.3940e-04
Loss = 4.9166e-02, PNorm = 36.7139, GNorm = 1.0222, lr_0 = 4.3827e-04
Validation auc = 0.894868
Epoch 24
Loss = 2.5740e-01, PNorm = 36.7554, GNorm = 0.4982, lr_0 = 4.2715e-04
Validation auc = 0.897415
Epoch 25
Loss = 2.3066e-01, PNorm = 36.7997, GNorm = 0.6252, lr_0 = 4.1631e-04
Loss = 2.4775e-01, PNorm = 36.8487, GNorm = 0.6578, lr_0 = 4.0575e-04
Validation auc = 0.895886
Epoch 26
Loss = 2.6616e-01, PNorm = 36.8876, GNorm = 1.4899, lr_0 = 3.9444e-04
Validation auc = 0.897033
Epoch 27
Loss = 2.3938e-01, PNorm = 36.9308, GNorm = 0.7241, lr_0 = 3.8345e-04
Loss = 2.4586e-01, PNorm = 36.9668, GNorm = 0.7825, lr_0 = 3.7372e-04
Validation auc = 0.896842
Epoch 28
Loss = 2.1392e-01, PNorm = 37.0112, GNorm = 0.5111, lr_0 = 3.6330e-04
Validation auc = 0.897096
Epoch 29
Loss = 2.2142e-01, PNorm = 37.0541, GNorm = 0.4508, lr_0 = 3.5318e-04
Loss = 2.3049e-01, PNorm = 37.0973, GNorm = 1.0174, lr_0 = 3.4422e-04
Validation auc = 0.898242
Model 0 best validation auc = 0.899198 on epoch 22
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.937866
Ensemble test auc = 0.937866
10-fold cross validation
	Seed 0 ==> test auc = 0.928767
	Seed 1 ==> test auc = 0.903879
	Seed 2 ==> test auc = 0.955724
	Seed 3 ==> test auc = 0.862450
	Seed 4 ==> test auc = 0.890246
	Seed 5 ==> test auc = 0.892326
	Seed 6 ==> test auc = 0.886606
	Seed 7 ==> test auc = 0.951849
	Seed 8 ==> test auc = 0.906486
	Seed 9 ==> test auc = 0.937866
Overall test auc = 0.911620 +/- 0.029164
Elapsed time = 0:20:54
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme="hmac-sha256" --Session.key=b"78ce7e33-618d-4d70-bde9-935ab47d3a38" --shell=9002 --transport="tcp" --iopub=9004 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036WgdJUnZ0WKJ0.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': True,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/molnet_chemprop.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 100,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 10,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total scaffolds = 1,025 | train scaffolds = 764 | val scaffolds = 123 | test scaffolds = 138
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 774
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7708e-01, PNorm = 35.0708, GNorm = 0.7273, lr_0 = 2.5469e-04
Validation auc = 0.861534
Epoch 1
Loss = 5.0486e-01, PNorm = 35.0930, GNorm = 0.7116, lr_0 = 4.0937e-04
Loss = 5.4657e-01, PNorm = 35.1182, GNorm = 1.4816, lr_0 = 5.5000e-04
Loss = 4.0673e-01, PNorm = 35.1203, GNorm = 0.7096, lr_0 = 5.6406e-04
Validation auc = 0.879050
Epoch 2
Loss = 4.5546e-01, PNorm = 35.1483, GNorm = 2.1511, lr_0 = 7.0469e-04
Validation auc = 0.915397
Epoch 3
Loss = 4.7097e-01, PNorm = 35.1837, GNorm = 0.9679, lr_0 = 8.4531e-04
Loss = 4.1481e-01, PNorm = 35.2336, GNorm = 0.4119, lr_0 = 9.8594e-04
Validation auc = 0.916782
Epoch 4
Loss = 4.0431e-01, PNorm = 35.2934, GNorm = 1.5009, lr_0 = 9.9268e-04
Validation auc = 0.914151
Epoch 5
Loss = 3.8241e-01, PNorm = 35.3481, GNorm = 0.4750, lr_0 = 9.8542e-04
Loss = 4.2601e-01, PNorm = 35.4024, GNorm = 0.9342, lr_0 = 9.7821e-04
Validation auc = 0.910966
Epoch 6
Loss = 3.6428e-01, PNorm = 35.4734, GNorm = 0.5953, lr_0 = 9.7034e-04
Validation auc = 0.925021
Epoch 7
Loss = 3.2864e-01, PNorm = 35.5393, GNorm = 1.4203, lr_0 = 9.6325e-04
Loss = 3.6174e-01, PNorm = 35.5932, GNorm = 0.4218, lr_0 = 9.5620e-04
Validation auc = 0.915259
Epoch 8
Loss = 3.1729e-01, PNorm = 35.6508, GNorm = 0.4263, lr_0 = 9.4851e-04
Validation auc = 0.926682
Epoch 9
Loss = 2.8145e-01, PNorm = 35.7212, GNorm = 0.6738, lr_0 = 9.4157e-04
Loss = 3.3839e-01, PNorm = 35.7789, GNorm = 1.0535, lr_0 = 9.3468e-04
Validation auc = 0.920105
Epoch 10
Loss = 3.1683e-01, PNorm = 35.8479, GNorm = 0.5683, lr_0 = 9.2716e-04
Loss = 2.9372e-01, PNorm = 35.9318, GNorm = 0.6563, lr_0 = 9.2038e-04
Validation auc = 0.919828
Epoch 11
Loss = 3.3114e-01, PNorm = 36.0069, GNorm = 0.5441, lr_0 = 9.1365e-04
Validation auc = 0.910966
Epoch 12
Loss = 3.1499e-01, PNorm = 36.1089, GNorm = 0.9477, lr_0 = 9.0630e-04
Loss = 3.3890e-01, PNorm = 36.1927, GNorm = 0.8516, lr_0 = 8.9967e-04
Validation auc = 0.920590
Epoch 13
Loss = 3.0046e-01, PNorm = 36.2699, GNorm = 0.6667, lr_0 = 8.9309e-04
Validation auc = 0.920867
Epoch 14
Loss = 3.5578e-01, PNorm = 36.3638, GNorm = 1.4477, lr_0 = 8.8590e-04
Loss = 2.7849e-01, PNorm = 36.4528, GNorm = 0.4760, lr_0 = 8.7942e-04
Validation auc = 0.912697
Epoch 15
Loss = 2.8875e-01, PNorm = 36.5415, GNorm = 0.9831, lr_0 = 8.7299e-04
Validation auc = 0.919828
Epoch 16
Loss = 2.8486e-01, PNorm = 36.6364, GNorm = 0.5240, lr_0 = 8.6596e-04
Loss = 2.6195e-01, PNorm = 36.7327, GNorm = 0.9982, lr_0 = 8.5963e-04
Validation auc = 0.919898
Epoch 17
Loss = 2.3448e-01, PNorm = 36.8168, GNorm = 0.3799, lr_0 = 8.5334e-04
Validation auc = 0.911520
Epoch 18
Loss = 3.2186e-01, PNorm = 36.9089, GNorm = 0.5658, lr_0 = 8.4648e-04
Loss = 2.4303e-01, PNorm = 36.9942, GNorm = 0.9113, lr_0 = 8.4028e-04
Validation auc = 0.922044
Epoch 19
Loss = 2.4073e-01, PNorm = 37.0786, GNorm = 0.6888, lr_0 = 8.3414e-04
Validation auc = 0.907782
Epoch 20
Loss = 1.8862e-01, PNorm = 37.1745, GNorm = 0.7750, lr_0 = 8.2743e-04
Loss = 2.3766e-01, PNorm = 37.2714, GNorm = 1.0122, lr_0 = 8.2137e-04
Validation auc = 0.903766
Epoch 21
Loss = 2.8251e-01, PNorm = 37.3464, GNorm = 1.8292, lr_0 = 8.1536e-04
Loss = 2.5448e-01, PNorm = 37.4338, GNorm = 0.9073, lr_0 = 8.0940e-04
Loss = 2.4380e-01, PNorm = 37.4398, GNorm = 1.2180, lr_0 = 8.0881e-04
Validation auc = 0.912628
Epoch 22
Loss = 2.2836e-01, PNorm = 37.5201, GNorm = 0.8263, lr_0 = 8.0289e-04
Validation auc = 0.903074
Epoch 23
Loss = 2.2044e-01, PNorm = 37.6019, GNorm = 0.7669, lr_0 = 7.9702e-04
Loss = 2.2853e-01, PNorm = 37.6896, GNorm = 1.6166, lr_0 = 7.9119e-04
Validation auc = 0.915536
Epoch 24
Loss = 1.9791e-01, PNorm = 37.7943, GNorm = 0.4505, lr_0 = 7.8482e-04
Validation auc = 0.908751
Epoch 25
Loss = 1.7109e-01, PNorm = 37.8795, GNorm = 0.8764, lr_0 = 7.7908e-04
Loss = 2.0006e-01, PNorm = 37.9721, GNorm = 0.6759, lr_0 = 7.7338e-04
Validation auc = 0.903836
Epoch 26
Loss = 1.7784e-01, PNorm = 38.0686, GNorm = 1.2136, lr_0 = 7.6716e-04
Validation auc = 0.907851
Epoch 27
Loss = 2.0019e-01, PNorm = 38.1667, GNorm = 0.4588, lr_0 = 7.6099e-04
Loss = 2.1575e-01, PNorm = 38.2571, GNorm = 1.1297, lr_0 = 7.5542e-04
Validation auc = 0.890127
Epoch 28
Loss = 1.8322e-01, PNorm = 38.3472, GNorm = 0.4851, lr_0 = 7.4989e-04
Validation auc = 0.902520
Epoch 29
Loss = 1.2301e-01, PNorm = 38.4506, GNorm = 0.4598, lr_0 = 7.4386e-04
Loss = 1.5758e-01, PNorm = 38.5345, GNorm = 1.2868, lr_0 = 7.3842e-04
Validation auc = 0.889643
Epoch 30
Loss = 1.6940e-01, PNorm = 38.6130, GNorm = 0.9260, lr_0 = 7.3302e-04
Validation auc = 0.899335
Epoch 31
Loss = 2.6260e-01, PNorm = 38.7031, GNorm = 2.1929, lr_0 = 7.2712e-04
Loss = 1.6224e-01, PNorm = 38.7943, GNorm = 0.3474, lr_0 = 7.2180e-04
Validation auc = 0.897674
Epoch 32
Loss = 1.2365e-01, PNorm = 38.8781, GNorm = 0.5431, lr_0 = 7.1652e-04
Loss = 1.6706e-01, PNorm = 38.9618, GNorm = 0.8273, lr_0 = 7.1128e-04
Loss = 1.0189e-01, PNorm = 38.9693, GNorm = 1.0230, lr_0 = 7.1076e-04
Validation auc = 0.888120
Epoch 33
Loss = 1.4739e-01, PNorm = 39.0554, GNorm = 1.0220, lr_0 = 7.0556e-04
Validation auc = 0.883896
Epoch 34
Loss = 1.4290e-01, PNorm = 39.1348, GNorm = 0.8022, lr_0 = 7.0040e-04
Loss = 1.9848e-01, PNorm = 39.2172, GNorm = 0.4897, lr_0 = 6.9527e-04
Validation auc = 0.894420
Epoch 35
Loss = 1.4688e-01, PNorm = 39.2974, GNorm = 0.6675, lr_0 = 6.8968e-04
Validation auc = 0.887912
Epoch 36
Loss = 1.9261e-01, PNorm = 39.3817, GNorm = 0.6167, lr_0 = 6.8464e-04
Loss = 1.1286e-01, PNorm = 39.4585, GNorm = 0.4531, lr_0 = 6.7963e-04
Validation auc = 0.889504
Epoch 37
Loss = 1.5103e-01, PNorm = 39.5464, GNorm = 0.9390, lr_0 = 6.7416e-04
Validation auc = 0.890889
Epoch 38
Loss = 8.9196e-02, PNorm = 39.6251, GNorm = 0.9480, lr_0 = 6.6923e-04
Loss = 1.3557e-01, PNorm = 39.7093, GNorm = 1.0336, lr_0 = 6.6433e-04
Validation auc = 0.874758
Epoch 39
Loss = 1.4174e-01, PNorm = 39.8013, GNorm = 0.8234, lr_0 = 6.5899e-04
Validation auc = 0.875658
Epoch 40
Loss = 1.0336e-01, PNorm = 39.8815, GNorm = 0.5029, lr_0 = 6.5417e-04
Loss = 1.1074e-01, PNorm = 39.9561, GNorm = 0.3082, lr_0 = 6.4938e-04
Validation auc = 0.882581
Epoch 41
Loss = 1.2510e-01, PNorm = 40.0409, GNorm = 0.4664, lr_0 = 6.4416e-04
Loss = 1.2979e-01, PNorm = 40.1197, GNorm = 0.9161, lr_0 = 6.3945e-04
Validation auc = 0.881473
Epoch 42
Loss = 1.0199e-01, PNorm = 40.1858, GNorm = 0.9671, lr_0 = 6.3477e-04
Validation auc = 0.887012
Epoch 43
Loss = 1.2593e-01, PNorm = 40.2629, GNorm = 1.3179, lr_0 = 6.2966e-04
Loss = 1.1413e-01, PNorm = 40.3288, GNorm = 1.1534, lr_0 = 6.2506e-04
Validation auc = 0.880366
Epoch 44
Loss = 9.4373e-02, PNorm = 40.4007, GNorm = 0.6223, lr_0 = 6.2048e-04
Validation auc = 0.872750
Epoch 45
Loss = 7.8062e-02, PNorm = 40.4737, GNorm = 0.6766, lr_0 = 6.1549e-04
Loss = 1.0578e-01, PNorm = 40.5370, GNorm = 1.3977, lr_0 = 6.1099e-04
Validation auc = 0.872611
Epoch 46
Loss = 8.6481e-02, PNorm = 40.5997, GNorm = 1.5893, lr_0 = 6.0652e-04
Validation auc = 0.864165
Epoch 47
Loss = 1.3253e-01, PNorm = 40.6785, GNorm = 0.4606, lr_0 = 6.0164e-04
Loss = 1.0321e-01, PNorm = 40.7384, GNorm = 0.9631, lr_0 = 5.9724e-04
Validation auc = 0.859665
Epoch 48
Loss = 9.8734e-02, PNorm = 40.8041, GNorm = 1.0686, lr_0 = 5.9287e-04
Validation auc = 0.873511
Epoch 49
Loss = 1.1183e-01, PNorm = 40.8650, GNorm = 0.9681, lr_0 = 5.8810e-04
Loss = 8.2559e-02, PNorm = 40.9265, GNorm = 0.4744, lr_0 = 5.8380e-04
Validation auc = 0.857796
Epoch 50
Loss = 7.4849e-02, PNorm = 40.9816, GNorm = 0.7424, lr_0 = 5.7953e-04
Validation auc = 0.863611
Epoch 51
Loss = 1.2571e-01, PNorm = 41.0414, GNorm = 1.6910, lr_0 = 5.7487e-04
Loss = 1.0003e-01, PNorm = 41.0801, GNorm = 0.6025, lr_0 = 5.7066e-04
Validation auc = 0.881473
Epoch 52
Loss = 9.6320e-02, PNorm = 41.1429, GNorm = 1.3305, lr_0 = 5.6607e-04
Loss = 1.0504e-01, PNorm = 41.1988, GNorm = 0.5577, lr_0 = 5.6193e-04
Validation auc = 0.882304
Epoch 53
Loss = 7.4594e-02, PNorm = 41.2510, GNorm = 1.1889, lr_0 = 5.5782e-04
Validation auc = 0.867904
Epoch 54
Loss = 9.3009e-02, PNorm = 41.3263, GNorm = 0.3887, lr_0 = 5.5333e-04
Loss = 8.4604e-02, PNorm = 41.3713, GNorm = 0.7373, lr_0 = 5.4928e-04
Validation auc = 0.883550
Epoch 55
Loss = 8.3835e-02, PNorm = 41.4244, GNorm = 0.9457, lr_0 = 5.4526e-04
Validation auc = 0.873165
Epoch 56
Loss = 6.8622e-02, PNorm = 41.4920, GNorm = 0.8979, lr_0 = 5.4088e-04
Loss = 6.6677e-02, PNorm = 41.5454, GNorm = 0.2674, lr_0 = 5.3692e-04
Validation auc = 0.861188
Epoch 57
Loss = 6.2009e-02, PNorm = 41.5914, GNorm = 0.4423, lr_0 = 5.3299e-04
Validation auc = 0.868457
Epoch 58
Loss = 4.2396e-02, PNorm = 41.6393, GNorm = 0.1876, lr_0 = 5.2871e-04
Loss = 4.7013e-02, PNorm = 41.6841, GNorm = 0.5703, lr_0 = 5.2484e-04
Validation auc = 0.870673
Epoch 59
Loss = 5.6968e-02, PNorm = 41.7275, GNorm = 0.6843, lr_0 = 5.2100e-04
Validation auc = 0.858073
Epoch 60
Loss = 1.0620e-01, PNorm = 41.7787, GNorm = 1.1039, lr_0 = 5.1681e-04
Loss = 5.9377e-02, PNorm = 41.8189, GNorm = 0.9577, lr_0 = 5.1303e-04
Validation auc = 0.870119
Epoch 61
Loss = 6.2897e-02, PNorm = 41.8605, GNorm = 0.4962, lr_0 = 5.0927e-04
Validation auc = 0.861950
Epoch 62
Loss = 2.9399e-02, PNorm = 41.9108, GNorm = 0.6295, lr_0 = 5.0518e-04
Loss = 6.0353e-02, PNorm = 41.9552, GNorm = 0.6413, lr_0 = 5.0148e-04
Validation auc = 0.880712
Epoch 63
Loss = 5.2395e-02, PNorm = 42.0003, GNorm = 0.1767, lr_0 = 4.9781e-04
Loss = 7.4136e-02, PNorm = 42.0425, GNorm = 1.0863, lr_0 = 4.9417e-04
Loss = 5.9144e-02, PNorm = 42.0464, GNorm = 0.6084, lr_0 = 4.9381e-04
Validation auc = 0.868804
Epoch 64
Loss = 4.2292e-02, PNorm = 42.0869, GNorm = 0.5563, lr_0 = 4.9020e-04
Validation auc = 0.857380
Epoch 65
Loss = 3.6400e-02, PNorm = 42.1367, GNorm = 0.5609, lr_0 = 4.8661e-04
Loss = 5.8673e-02, PNorm = 42.1750, GNorm = 0.8110, lr_0 = 4.8305e-04
Validation auc = 0.877250
Epoch 66
Loss = 6.2548e-02, PNorm = 42.2133, GNorm = 0.4249, lr_0 = 4.7916e-04
Validation auc = 0.854957
Epoch 67
Loss = 4.4454e-02, PNorm = 42.2439, GNorm = 0.5514, lr_0 = 4.7566e-04
Loss = 4.2764e-02, PNorm = 42.2734, GNorm = 0.7674, lr_0 = 4.7218e-04
Validation auc = 0.874273
Epoch 68
Loss = 5.2437e-02, PNorm = 42.3125, GNorm = 0.4701, lr_0 = 4.6838e-04
Validation auc = 0.864857
Epoch 69
Loss = 3.4084e-02, PNorm = 42.3433, GNorm = 0.7148, lr_0 = 4.6495e-04
Loss = 6.8781e-02, PNorm = 42.3804, GNorm = 1.2633, lr_0 = 4.6155e-04
Validation auc = 0.865273
Epoch 70
Loss = 3.6478e-02, PNorm = 42.4275, GNorm = 0.4233, lr_0 = 4.5784e-04
Validation auc = 0.864580
Epoch 71
Loss = 5.8020e-02, PNorm = 42.4622, GNorm = 1.3278, lr_0 = 4.5449e-04
Loss = 5.7755e-02, PNorm = 42.5018, GNorm = 0.5209, lr_0 = 4.5117e-04
Validation auc = 0.854472
Epoch 72
Loss = 5.4139e-02, PNorm = 42.5340, GNorm = 0.3338, lr_0 = 4.4754e-04
Loss = 7.2378e-02, PNorm = 42.5623, GNorm = 2.0771, lr_0 = 4.4426e-04
Validation auc = 0.871365
Epoch 73
Loss = 4.9274e-02, PNorm = 42.6026, GNorm = 1.2802, lr_0 = 4.4101e-04
Validation auc = 0.870327
Epoch 74
Loss = 6.1956e-02, PNorm = 42.6375, GNorm = 0.6785, lr_0 = 4.3747e-04
Loss = 4.4411e-02, PNorm = 42.6688, GNorm = 0.6859, lr_0 = 4.3427e-04
Validation auc = 0.874965
Epoch 75
Loss = 4.8184e-02, PNorm = 42.6982, GNorm = 0.4625, lr_0 = 4.3109e-04
Validation auc = 0.874688
Epoch 76
Loss = 6.1994e-02, PNorm = 42.7286, GNorm = 1.4551, lr_0 = 4.2762e-04
Loss = 3.9105e-02, PNorm = 42.7603, GNorm = 1.0013, lr_0 = 4.2449e-04
Validation auc = 0.869358
Epoch 77
Loss = 4.5759e-02, PNorm = 42.7936, GNorm = 0.1249, lr_0 = 4.2108e-04
Validation auc = 0.871711
Epoch 78
Loss = 3.8466e-02, PNorm = 42.8175, GNorm = 1.1190, lr_0 = 4.1800e-04
Loss = 2.8227e-02, PNorm = 42.8447, GNorm = 0.9911, lr_0 = 4.1494e-04
Validation auc = 0.856134
Epoch 79
Loss = 8.0300e-02, PNorm = 42.8788, GNorm = 1.7255, lr_0 = 4.1160e-04
Validation auc = 0.879535
Epoch 80
Loss = 2.1012e-02, PNorm = 42.9116, GNorm = 0.5228, lr_0 = 4.0859e-04
Loss = 6.1932e-02, PNorm = 42.9505, GNorm = 1.0418, lr_0 = 4.0560e-04
Validation auc = 0.868457
Epoch 81
Loss = 2.8764e-02, PNorm = 42.9826, GNorm = 0.3537, lr_0 = 4.0234e-04
Validation auc = 0.871365
Epoch 82
Loss = 6.7306e-02, PNorm = 43.0084, GNorm = 0.5717, lr_0 = 3.9940e-04
Loss = 3.6191e-02, PNorm = 43.0329, GNorm = 0.8074, lr_0 = 3.9647e-04
Validation auc = 0.851842
Epoch 83
Loss = 4.0448e-02, PNorm = 43.0565, GNorm = 0.1867, lr_0 = 3.9328e-04
Loss = 4.5529e-02, PNorm = 43.0748, GNorm = 1.2219, lr_0 = 3.9041e-04
Validation auc = 0.871504
Epoch 84
Loss = 3.9878e-02, PNorm = 43.1015, GNorm = 0.8455, lr_0 = 3.8755e-04
Validation auc = 0.857242
Epoch 85
Loss = 2.9275e-02, PNorm = 43.1253, GNorm = 0.5517, lr_0 = 3.8443e-04
Loss = 3.5457e-02, PNorm = 43.1494, GNorm = 0.9144, lr_0 = 3.8162e-04
Validation auc = 0.866519
Epoch 86
Loss = 3.4538e-02, PNorm = 43.1774, GNorm = 0.9669, lr_0 = 3.7883e-04
Validation auc = 0.872196
Epoch 87
Loss = 2.3915e-02, PNorm = 43.2051, GNorm = 0.8032, lr_0 = 3.7578e-04
Loss = 3.4717e-02, PNorm = 43.2301, GNorm = 0.1937, lr_0 = 3.7303e-04
Validation auc = 0.872127
Epoch 88
Loss = 2.6105e-02, PNorm = 43.2573, GNorm = 0.6216, lr_0 = 3.7030e-04
Validation auc = 0.868250
Epoch 89
Loss = 3.6393e-02, PNorm = 43.2804, GNorm = 0.1570, lr_0 = 3.6733e-04
Loss = 2.0193e-02, PNorm = 43.3029, GNorm = 0.6018, lr_0 = 3.6464e-04
Validation auc = 0.863196
Epoch 90
Loss = 3.6650e-02, PNorm = 43.3161, GNorm = 0.4168, lr_0 = 3.6197e-04
Validation auc = 0.862157
Epoch 91
Loss = 6.3909e-02, PNorm = 43.3325, GNorm = 0.9415, lr_0 = 3.5906e-04
Loss = 4.3062e-02, PNorm = 43.3456, GNorm = 0.1245, lr_0 = 3.5643e-04
Validation auc = 0.866173
Epoch 92
Loss = 4.6853e-02, PNorm = 43.3668, GNorm = 0.4134, lr_0 = 3.5382e-04
Validation auc = 0.872958
Epoch 93
Loss = 4.8404e-02, PNorm = 43.3895, GNorm = 1.0267, lr_0 = 3.5098e-04
Loss = 3.5346e-02, PNorm = 43.4137, GNorm = 0.1557, lr_0 = 3.4841e-04
Validation auc = 0.867073
Epoch 94
Loss = 2.4088e-02, PNorm = 43.4350, GNorm = 0.7188, lr_0 = 3.4586e-04
Loss = 2.9499e-02, PNorm = 43.4597, GNorm = 0.3261, lr_0 = 3.4333e-04
Loss = 1.7708e-02, PNorm = 43.4620, GNorm = 0.3546, lr_0 = 3.4308e-04
Validation auc = 0.856342
Epoch 95
Loss = 4.2790e-02, PNorm = 43.4822, GNorm = 0.8243, lr_0 = 3.4057e-04
Validation auc = 0.867557
Epoch 96
Loss = 1.9447e-02, PNorm = 43.4964, GNorm = 0.3212, lr_0 = 3.3808e-04
Loss = 3.5245e-02, PNorm = 43.5110, GNorm = 0.3711, lr_0 = 3.3561e-04
Validation auc = 0.858073
Epoch 97
Loss = 2.5961e-02, PNorm = 43.5246, GNorm = 0.6781, lr_0 = 3.3291e-04
Validation auc = 0.863888
Epoch 98
Loss = 2.4511e-02, PNorm = 43.5393, GNorm = 0.3973, lr_0 = 3.3047e-04
Loss = 4.9046e-02, PNorm = 43.5590, GNorm = 0.5030, lr_0 = 3.2805e-04
Validation auc = 0.866381
Epoch 99
Loss = 4.0727e-02, PNorm = 43.5769, GNorm = 1.0369, lr_0 = 3.2541e-04
Validation auc = 0.866519
Model 0 best validation auc = 0.926682 on epoch 8
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.929177
Ensemble test auc = 0.929177
Fold 1
Splitting data with seed 1
Total scaffolds = 1,025 | train scaffolds = 768 | val scaffolds = 132 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 762
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9210e-01, PNorm = 35.0699, GNorm = 0.7570, lr_0 = 2.5469e-04
Validation auc = 0.840480
Epoch 1
Loss = 5.1862e-01, PNorm = 35.0913, GNorm = 0.4386, lr_0 = 4.0937e-04
Loss = 5.1567e-01, PNorm = 35.1154, GNorm = 1.9380, lr_0 = 5.5000e-04
Loss = 4.7269e-01, PNorm = 35.1180, GNorm = 0.8592, lr_0 = 5.6406e-04
Validation auc = 0.862137
Epoch 2
Loss = 4.8015e-01, PNorm = 35.1451, GNorm = 0.4625, lr_0 = 7.0469e-04
Validation auc = 0.866206
Epoch 3
Loss = 4.8771e-01, PNorm = 35.1906, GNorm = 2.8453, lr_0 = 8.5938e-04
Loss = 4.1720e-01, PNorm = 35.2348, GNorm = 0.5161, lr_0 = 1.0000e-03
Loss = 3.8087e-01, PNorm = 35.2404, GNorm = 1.5332, lr_0 = 9.9927e-04
Validation auc = 0.872602
Epoch 4
Loss = 4.1291e-01, PNorm = 35.2946, GNorm = 0.5704, lr_0 = 9.9196e-04
Validation auc = 0.875945
Epoch 5
Loss = 4.2701e-01, PNorm = 35.3525, GNorm = 1.1635, lr_0 = 9.8470e-04
Loss = 3.9211e-01, PNorm = 35.4071, GNorm = 0.9302, lr_0 = 9.7750e-04
Validation auc = 0.883794
Epoch 6
Loss = 4.1384e-01, PNorm = 35.4625, GNorm = 1.1434, lr_0 = 9.6963e-04
Validation auc = 0.879506
Epoch 7
Loss = 3.7072e-01, PNorm = 35.5376, GNorm = 1.1743, lr_0 = 9.6183e-04
Loss = 3.5002e-01, PNorm = 35.6111, GNorm = 0.7487, lr_0 = 9.5480e-04
Validation auc = 0.882631
Epoch 8
Loss = 3.9081e-01, PNorm = 35.6807, GNorm = 0.5518, lr_0 = 9.4712e-04
Validation auc = 0.872747
Epoch 9
Loss = 3.2664e-01, PNorm = 35.7385, GNorm = 0.3436, lr_0 = 9.4019e-04
Loss = 3.2894e-01, PNorm = 35.8144, GNorm = 0.8221, lr_0 = 9.3331e-04
Validation auc = 0.880741
Epoch 10
Loss = 3.3156e-01, PNorm = 35.8803, GNorm = 0.3426, lr_0 = 9.2580e-04
Validation auc = 0.881613
Epoch 11
Loss = 3.0813e-01, PNorm = 35.9455, GNorm = 1.6044, lr_0 = 9.1835e-04
Loss = 3.4246e-01, PNorm = 36.0047, GNorm = 0.4668, lr_0 = 9.1164e-04
Validation auc = 0.883358
Epoch 12
Loss = 3.4613e-01, PNorm = 36.0783, GNorm = 0.7212, lr_0 = 9.0430e-04
Validation auc = 0.881395
Epoch 13
Loss = 2.8942e-01, PNorm = 36.1592, GNorm = 0.8346, lr_0 = 8.9769e-04
Loss = 2.9538e-01, PNorm = 36.2503, GNorm = 0.7512, lr_0 = 8.9112e-04
Validation auc = 0.885392
Epoch 14
Loss = 2.9479e-01, PNorm = 36.3309, GNorm = 1.0458, lr_0 = 8.8395e-04
Validation auc = 0.878125
Epoch 15
Loss = 2.7503e-01, PNorm = 36.4153, GNorm = 0.4633, lr_0 = 8.7684e-04
Loss = 2.7631e-01, PNorm = 36.4948, GNorm = 1.3299, lr_0 = 8.7043e-04
Validation auc = 0.873983
Epoch 16
Loss = 2.8600e-01, PNorm = 36.5940, GNorm = 0.8571, lr_0 = 8.6342e-04
Validation auc = 0.879288
Epoch 17
Loss = 3.3518e-01, PNorm = 36.6771, GNorm = 0.7312, lr_0 = 8.5711e-04
Loss = 2.5477e-01, PNorm = 36.7608, GNorm = 0.4439, lr_0 = 8.5084e-04
Validation auc = 0.881541
Epoch 18
Loss = 2.8013e-01, PNorm = 36.8551, GNorm = 1.8242, lr_0 = 8.4399e-04
Validation auc = 0.880887
Epoch 19
Loss = 1.6671e-01, PNorm = 36.9561, GNorm = 0.9967, lr_0 = 8.3720e-04
Loss = 2.5644e-01, PNorm = 37.0403, GNorm = 1.4859, lr_0 = 8.3108e-04
Validation auc = 0.880451
Epoch 20
Loss = 2.2614e-01, PNorm = 37.1356, GNorm = 0.4205, lr_0 = 8.2439e-04
Loss = 2.7577e-01, PNorm = 37.2115, GNorm = 1.4950, lr_0 = 8.1836e-04
Validation auc = 0.874055
Epoch 21
Loss = 2.5923e-01, PNorm = 37.2967, GNorm = 0.7978, lr_0 = 8.1238e-04
Validation auc = 0.874927
Epoch 22
Loss = 2.2454e-01, PNorm = 37.3960, GNorm = 0.6161, lr_0 = 8.0584e-04
Loss = 2.2407e-01, PNorm = 37.4874, GNorm = 0.6937, lr_0 = 7.9995e-04
Loss = 3.7830e-01, PNorm = 37.4942, GNorm = 3.8750, lr_0 = 7.9936e-04
Validation auc = 0.883939
Epoch 23
Loss = 2.6791e-01, PNorm = 37.5752, GNorm = 0.4910, lr_0 = 7.9351e-04
Validation auc = 0.880305
Epoch 24
Loss = 2.0493e-01, PNorm = 37.6683, GNorm = 0.8495, lr_0 = 7.8713e-04
Loss = 2.1287e-01, PNorm = 37.7460, GNorm = 0.3700, lr_0 = 7.8137e-04
Validation auc = 0.872384
Epoch 25
Loss = 2.0990e-01, PNorm = 37.8263, GNorm = 0.6046, lr_0 = 7.7565e-04
Validation auc = 0.883212
Epoch 26
Loss = 2.0001e-01, PNorm = 37.9219, GNorm = 0.5978, lr_0 = 7.6942e-04
Loss = 2.0741e-01, PNorm = 38.0003, GNorm = 0.4820, lr_0 = 7.6379e-04
Validation auc = 0.881177
Epoch 27
Loss = 1.6785e-01, PNorm = 38.0908, GNorm = 1.1172, lr_0 = 7.5764e-04
Validation auc = 0.872456
Epoch 28
Loss = 1.8953e-01, PNorm = 38.1643, GNorm = 1.7513, lr_0 = 7.5155e-04
Loss = 1.5945e-01, PNorm = 38.2392, GNorm = 0.6361, lr_0 = 7.4605e-04
Validation auc = 0.881177
Epoch 29
Loss = 1.8109e-01, PNorm = 38.3239, GNorm = 0.2765, lr_0 = 7.4005e-04
Validation auc = 0.886846
Epoch 30
Loss = 1.9616e-01, PNorm = 38.3901, GNorm = 0.6722, lr_0 = 7.3463e-04
Loss = 1.5032e-01, PNorm = 38.4684, GNorm = 0.5776, lr_0 = 7.2926e-04
Validation auc = 0.883067
Epoch 31
Loss = 1.6227e-01, PNorm = 38.5730, GNorm = 1.2231, lr_0 = 7.2339e-04
Validation auc = 0.871003
Epoch 32
Loss = 1.4940e-01, PNorm = 38.6626, GNorm = 1.3126, lr_0 = 7.1758e-04
Loss = 1.6706e-01, PNorm = 38.7342, GNorm = 0.8233, lr_0 = 7.1233e-04
Validation auc = 0.873692
Epoch 33
Loss = 1.7599e-01, PNorm = 38.8242, GNorm = 0.6630, lr_0 = 7.0660e-04
Validation auc = 0.880015
Epoch 34
Loss = 1.9236e-01, PNorm = 38.9012, GNorm = 0.5280, lr_0 = 7.0143e-04
Loss = 1.8083e-01, PNorm = 38.9778, GNorm = 0.5989, lr_0 = 6.9630e-04
Validation auc = 0.878634
Epoch 35
Loss = 1.5571e-01, PNorm = 39.0527, GNorm = 1.4329, lr_0 = 6.9069e-04
Validation auc = 0.873038
Epoch 36
Loss = 1.5248e-01, PNorm = 39.1333, GNorm = 0.9481, lr_0 = 6.8514e-04
Loss = 1.6423e-01, PNorm = 39.2027, GNorm = 1.0037, lr_0 = 6.8013e-04
Validation auc = 0.879142
Epoch 37
Loss = 1.3486e-01, PNorm = 39.2753, GNorm = 0.4605, lr_0 = 6.7465e-04
Validation auc = 0.855887
Epoch 38
Loss = 8.0358e-02, PNorm = 39.3554, GNorm = 0.6481, lr_0 = 6.6972e-04
Loss = 1.6999e-01, PNorm = 39.4142, GNorm = 0.7046, lr_0 = 6.6482e-04
Validation auc = 0.864026
Epoch 39
Loss = 1.1496e-01, PNorm = 39.4969, GNorm = 0.6972, lr_0 = 6.5947e-04
Validation auc = 0.868532
Epoch 40
Loss = 7.5883e-02, PNorm = 39.5716, GNorm = 0.3590, lr_0 = 6.5417e-04
Loss = 1.6258e-01, PNorm = 39.6318, GNorm = 0.7441, lr_0 = 6.4938e-04
Validation auc = 0.880887
Epoch 41
Loss = 9.9751e-02, PNorm = 39.7126, GNorm = 0.4730, lr_0 = 6.4416e-04
Loss = 1.2774e-01, PNorm = 39.7794, GNorm = 1.7516, lr_0 = 6.3945e-04
Validation auc = 0.883721
Epoch 42
Loss = 1.6995e-01, PNorm = 39.8462, GNorm = 1.6789, lr_0 = 6.3477e-04
Validation auc = 0.863881
Epoch 43
Loss = 1.0968e-01, PNorm = 39.9257, GNorm = 0.3239, lr_0 = 6.2966e-04
Loss = 1.1654e-01, PNorm = 39.9971, GNorm = 0.7763, lr_0 = 6.2506e-04
Loss = 8.2971e-02, PNorm = 40.0043, GNorm = 1.5534, lr_0 = 6.2460e-04
Validation auc = 0.879433
Epoch 44
Loss = 1.0751e-01, PNorm = 40.0745, GNorm = 0.7524, lr_0 = 6.2003e-04
Validation auc = 0.880160
Epoch 45
Loss = 9.7703e-02, PNorm = 40.1485, GNorm = 0.2940, lr_0 = 6.1504e-04
Loss = 1.0909e-01, PNorm = 40.2094, GNorm = 0.8505, lr_0 = 6.1054e-04
Validation auc = 0.878634
Epoch 46
Loss = 9.9313e-02, PNorm = 40.2691, GNorm = 0.8734, lr_0 = 6.0607e-04
Validation auc = 0.886337
Epoch 47
Loss = 1.1939e-01, PNorm = 40.3259, GNorm = 0.3877, lr_0 = 6.0120e-04
Loss = 1.3437e-01, PNorm = 40.3877, GNorm = 1.2765, lr_0 = 5.9680e-04
Validation auc = 0.882776
Epoch 48
Loss = 1.1692e-01, PNorm = 40.4646, GNorm = 1.0810, lr_0 = 5.9200e-04
Validation auc = 0.884811
Epoch 49
Loss = 1.1874e-01, PNorm = 40.5231, GNorm = 1.2445, lr_0 = 5.8724e-04
Loss = 1.1325e-01, PNorm = 40.5773, GNorm = 0.9963, lr_0 = 5.8294e-04
Validation auc = 0.887137
Epoch 50
Loss = 7.5733e-02, PNorm = 40.6210, GNorm = 0.5710, lr_0 = 5.7868e-04
Validation auc = 0.885974
Epoch 51
Loss = 1.5437e-01, PNorm = 40.6728, GNorm = 1.1486, lr_0 = 5.7402e-04
Loss = 6.9064e-02, PNorm = 40.7217, GNorm = 0.7264, lr_0 = 5.6982e-04
Validation auc = 0.883358
Epoch 52
Loss = 1.0357e-01, PNorm = 40.7742, GNorm = 0.7893, lr_0 = 5.6524e-04
Validation auc = 0.880814
Epoch 53
Loss = 7.6733e-02, PNorm = 40.8370, GNorm = 0.4947, lr_0 = 5.6069e-04
Loss = 7.4320e-02, PNorm = 40.8959, GNorm = 0.4081, lr_0 = 5.5659e-04
Validation auc = 0.882049
Epoch 54
Loss = 9.5912e-02, PNorm = 40.9487, GNorm = 0.8686, lr_0 = 5.5211e-04
Validation auc = 0.877035
Epoch 55
Loss = 9.0397e-02, PNorm = 40.9924, GNorm = 0.3921, lr_0 = 5.4807e-04
Loss = 8.5320e-02, PNorm = 41.0405, GNorm = 0.7263, lr_0 = 5.4406e-04
Validation auc = 0.881468
Epoch 56
Loss = 9.6510e-02, PNorm = 41.0950, GNorm = 0.3976, lr_0 = 5.3969e-04
Validation auc = 0.887863
Epoch 57
Loss = 1.2705e-01, PNorm = 41.1440, GNorm = 0.8599, lr_0 = 5.3535e-04
Loss = 1.0963e-01, PNorm = 41.1985, GNorm = 0.3604, lr_0 = 5.3143e-04
Validation auc = 0.888299
Epoch 58
Loss = 7.9169e-02, PNorm = 41.2413, GNorm = 0.5565, lr_0 = 5.2716e-04
Validation auc = 0.889462
Epoch 59
Loss = 5.8726e-02, PNorm = 41.2903, GNorm = 0.3541, lr_0 = 5.2330e-04
Loss = 6.7182e-02, PNorm = 41.3357, GNorm = 0.9777, lr_0 = 5.1947e-04
Validation auc = 0.889608
Epoch 60
Loss = 4.5587e-02, PNorm = 41.3824, GNorm = 0.2509, lr_0 = 5.1529e-04
Validation auc = 0.883648
Epoch 61
Loss = 8.0285e-02, PNorm = 41.4362, GNorm = 1.1110, lr_0 = 5.1115e-04
Loss = 9.2245e-02, PNorm = 41.4787, GNorm = 0.7282, lr_0 = 5.0741e-04
Validation auc = 0.874201
Epoch 62
Loss = 5.8828e-02, PNorm = 41.5199, GNorm = 0.8867, lr_0 = 5.0333e-04
Loss = 7.1944e-02, PNorm = 41.5567, GNorm = 0.3035, lr_0 = 4.9964e-04
Validation auc = 0.888154
Epoch 63
Loss = 6.9538e-02, PNorm = 41.5984, GNorm = 0.5996, lr_0 = 4.9599e-04
Validation auc = 0.880741
Epoch 64
Loss = 7.4366e-02, PNorm = 41.6431, GNorm = 0.2768, lr_0 = 4.9200e-04
Loss = 5.6272e-02, PNorm = 41.6901, GNorm = 0.7174, lr_0 = 4.8840e-04
Loss = 6.0006e-02, PNorm = 41.6936, GNorm = 0.7928, lr_0 = 4.8804e-04
Validation auc = 0.884012
Epoch 65
Loss = 7.7834e-02, PNorm = 41.7318, GNorm = 1.5458, lr_0 = 4.8447e-04
Validation auc = 0.883794
Epoch 66
Loss = 6.3766e-02, PNorm = 41.7709, GNorm = 0.5873, lr_0 = 4.8057e-04
Loss = 6.0987e-02, PNorm = 41.8117, GNorm = 0.3714, lr_0 = 4.7706e-04
Validation auc = 0.877907
Epoch 67
Loss = 9.9099e-02, PNorm = 41.8575, GNorm = 0.2392, lr_0 = 4.7357e-04
Validation auc = 0.895276
Epoch 68
Loss = 6.2775e-02, PNorm = 41.9028, GNorm = 0.7305, lr_0 = 4.6976e-04
Loss = 5.6494e-02, PNorm = 41.9422, GNorm = 0.2931, lr_0 = 4.6632e-04
Validation auc = 0.884956
Epoch 69
Loss = 6.3097e-02, PNorm = 41.9831, GNorm = 0.3229, lr_0 = 4.6257e-04
Validation auc = 0.884157
Epoch 70
Loss = 5.6555e-02, PNorm = 42.0153, GNorm = 1.3427, lr_0 = 4.5885e-04
Loss = 6.6171e-02, PNorm = 42.0449, GNorm = 0.1674, lr_0 = 4.5549e-04
Validation auc = 0.889753
Epoch 71
Loss = 6.3725e-02, PNorm = 42.0833, GNorm = 0.5373, lr_0 = 4.5216e-04
Validation auc = 0.891570
Epoch 72
Loss = 8.3370e-02, PNorm = 42.1281, GNorm = 0.5454, lr_0 = 4.4852e-04
Loss = 6.5954e-02, PNorm = 42.1635, GNorm = 0.7858, lr_0 = 4.4524e-04
Validation auc = 0.895203
Epoch 73
Loss = 6.0110e-02, PNorm = 42.2005, GNorm = 0.4562, lr_0 = 4.4166e-04
Validation auc = 0.888590
Epoch 74
Loss = 6.3581e-02, PNorm = 42.2368, GNorm = 0.3719, lr_0 = 4.3811e-04
Loss = 4.0305e-02, PNorm = 42.2653, GNorm = 1.2035, lr_0 = 4.3490e-04
Validation auc = 0.887282
Epoch 75
Loss = 5.9335e-02, PNorm = 42.2952, GNorm = 0.5712, lr_0 = 4.3172e-04
Validation auc = 0.888299
Epoch 76
Loss = 2.7521e-02, PNorm = 42.3294, GNorm = 0.3527, lr_0 = 4.2825e-04
Loss = 4.6379e-02, PNorm = 42.3604, GNorm = 0.6558, lr_0 = 4.2512e-04
Validation auc = 0.884084
Epoch 77
Loss = 6.1886e-02, PNorm = 42.3981, GNorm = 0.6588, lr_0 = 4.2170e-04
Validation auc = 0.883866
Epoch 78
Loss = 5.7168e-02, PNorm = 42.4215, GNorm = 0.2649, lr_0 = 4.1830e-04
Loss = 3.8320e-02, PNorm = 42.4508, GNorm = 0.3842, lr_0 = 4.1524e-04
Validation auc = 0.879142
Epoch 79
Loss = 2.6762e-02, PNorm = 42.4847, GNorm = 0.4561, lr_0 = 4.1190e-04
Validation auc = 0.878125
Epoch 80
Loss = 6.8318e-02, PNorm = 42.5113, GNorm = 0.8649, lr_0 = 4.0889e-04
Loss = 3.4048e-02, PNorm = 42.5362, GNorm = 0.6471, lr_0 = 4.0590e-04
Validation auc = 0.877398
Epoch 81
Loss = 2.6316e-02, PNorm = 42.5623, GNorm = 0.5252, lr_0 = 4.0263e-04
Validation auc = 0.873401
Epoch 82
Loss = 2.3491e-02, PNorm = 42.5908, GNorm = 0.4154, lr_0 = 3.9940e-04
Loss = 4.5689e-02, PNorm = 42.6121, GNorm = 0.8933, lr_0 = 3.9647e-04
Validation auc = 0.885465
Epoch 83
Loss = 5.1951e-02, PNorm = 42.6350, GNorm = 0.9689, lr_0 = 3.9328e-04
Loss = 5.4797e-02, PNorm = 42.6602, GNorm = 0.0610, lr_0 = 3.9041e-04
Validation auc = 0.875727
Epoch 84
Loss = 4.4291e-02, PNorm = 42.6837, GNorm = 0.5589, lr_0 = 3.8755e-04
Validation auc = 0.891206
Epoch 85
Loss = 5.4613e-02, PNorm = 42.7113, GNorm = 0.8057, lr_0 = 3.8443e-04
Loss = 4.7657e-02, PNorm = 42.7376, GNorm = 0.7232, lr_0 = 3.8162e-04
Loss = 1.5322e-01, PNorm = 42.7401, GNorm = 2.0146, lr_0 = 3.8134e-04
Validation auc = 0.892006
Epoch 86
Loss = 4.4585e-02, PNorm = 42.7596, GNorm = 0.1898, lr_0 = 3.7855e-04
Validation auc = 0.883648
Epoch 87
Loss = 3.3658e-02, PNorm = 42.7942, GNorm = 0.3924, lr_0 = 3.7551e-04
Loss = 7.3868e-02, PNorm = 42.8207, GNorm = 1.2196, lr_0 = 3.7276e-04
Validation auc = 0.873765
Epoch 88
Loss = 4.0237e-02, PNorm = 42.8534, GNorm = 0.3664, lr_0 = 3.7003e-04
Validation auc = 0.893895
Epoch 89
Loss = 4.4381e-02, PNorm = 42.8887, GNorm = 0.2000, lr_0 = 3.6706e-04
Loss = 4.4550e-02, PNorm = 42.9166, GNorm = 0.3388, lr_0 = 3.6437e-04
Validation auc = 0.875799
Epoch 90
Loss = 3.1761e-02, PNorm = 42.9480, GNorm = 0.1924, lr_0 = 3.6144e-04
Validation auc = 0.883140
Epoch 91
Loss = 3.0815e-02, PNorm = 42.9772, GNorm = 0.4702, lr_0 = 3.5853e-04
Loss = 4.8610e-02, PNorm = 42.9984, GNorm = 1.4841, lr_0 = 3.5591e-04
Validation auc = 0.894186
Epoch 92
Loss = 4.3602e-02, PNorm = 43.0168, GNorm = 0.4524, lr_0 = 3.5331e-04
Validation auc = 0.877689
Epoch 93
Loss = 4.5530e-02, PNorm = 43.0424, GNorm = 0.7739, lr_0 = 3.5046e-04
Loss = 3.6196e-02, PNorm = 43.0653, GNorm = 0.3197, lr_0 = 3.4790e-04
Validation auc = 0.880959
Epoch 94
Loss = 3.7667e-02, PNorm = 43.0935, GNorm = 0.4774, lr_0 = 3.4510e-04
Validation auc = 0.864898
Epoch 95
Loss = 7.4394e-02, PNorm = 43.1190, GNorm = 1.2360, lr_0 = 3.4233e-04
Loss = 2.7823e-02, PNorm = 43.1371, GNorm = 0.2836, lr_0 = 3.3982e-04
Validation auc = 0.881977
Epoch 96
Loss = 3.3032e-02, PNorm = 43.1498, GNorm = 0.6305, lr_0 = 3.3733e-04
Validation auc = 0.879869
Epoch 97
Loss = 3.1110e-02, PNorm = 43.1694, GNorm = 0.5053, lr_0 = 3.3462e-04
Loss = 3.2984e-02, PNorm = 43.1868, GNorm = 0.5313, lr_0 = 3.3217e-04
Validation auc = 0.884375
Epoch 98
Loss = 3.4860e-02, PNorm = 43.2031, GNorm = 0.3157, lr_0 = 3.2950e-04
Validation auc = 0.891788
Epoch 99
Loss = 3.3490e-02, PNorm = 43.2214, GNorm = 0.4500, lr_0 = 3.2685e-04
Loss = 4.6142e-02, PNorm = 43.2360, GNorm = 0.7099, lr_0 = 3.2446e-04
Validation auc = 0.874855
Model 0 best validation auc = 0.895276 on epoch 67
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.852848
Ensemble test auc = 0.852848
Fold 2
Splitting data with seed 2
Total scaffolds = 1,025 | train scaffolds = 766 | val scaffolds = 125 | test scaffolds = 134
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 748
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8410e-01, PNorm = 35.0706, GNorm = 1.0058, lr_0 = 2.5469e-04
Validation auc = 0.860611
Epoch 1
Loss = 5.2723e-01, PNorm = 35.0922, GNorm = 0.6741, lr_0 = 4.0937e-04
Validation auc = 0.860338
Epoch 2
Loss = 4.3403e-01, PNorm = 35.1195, GNorm = 2.4570, lr_0 = 5.5000e-04
Loss = 4.6489e-01, PNorm = 35.1464, GNorm = 2.2846, lr_0 = 6.9063e-04
Validation auc = 0.845336
Epoch 3
Loss = 4.1517e-01, PNorm = 35.1787, GNorm = 0.6632, lr_0 = 8.3125e-04
Validation auc = 0.856110
Epoch 4
Loss = 4.6568e-01, PNorm = 35.2196, GNorm = 0.4393, lr_0 = 9.7187e-04
Loss = 4.1939e-01, PNorm = 35.2663, GNorm = 0.3525, lr_0 = 9.9414e-04
Validation auc = 0.854746
Epoch 5
Loss = 4.2518e-01, PNorm = 35.3059, GNorm = 0.4852, lr_0 = 9.8687e-04
Validation auc = 0.859384
Epoch 6
Loss = 2.4006e-01, PNorm = 35.3496, GNorm = 0.3213, lr_0 = 9.7965e-04
Loss = 3.8617e-01, PNorm = 35.4026, GNorm = 0.3647, lr_0 = 9.7248e-04
Validation auc = 0.869613
Epoch 7
Loss = 3.9220e-01, PNorm = 35.4520, GNorm = 0.7316, lr_0 = 9.6537e-04
Validation auc = 0.870977
Epoch 8
Loss = 3.6983e-01, PNorm = 35.5043, GNorm = 0.4004, lr_0 = 9.5831e-04
Loss = 3.7897e-01, PNorm = 35.5671, GNorm = 0.3490, lr_0 = 9.5130e-04
Validation auc = 0.870977
Epoch 9
Loss = 3.3112e-01, PNorm = 35.6400, GNorm = 0.9540, lr_0 = 9.4434e-04
Validation auc = 0.886388
Epoch 10
Loss = 3.6705e-01, PNorm = 35.7102, GNorm = 0.7486, lr_0 = 9.3743e-04
Loss = 3.1755e-01, PNorm = 35.7863, GNorm = 0.7437, lr_0 = 9.3057e-04
Validation auc = 0.872477
Epoch 11
Loss = 3.3182e-01, PNorm = 35.8565, GNorm = 0.6487, lr_0 = 9.2376e-04
Validation auc = 0.884752
Epoch 12
Loss = 3.0995e-01, PNorm = 35.9333, GNorm = 0.4789, lr_0 = 9.1701e-04
Loss = 3.1524e-01, PNorm = 36.0039, GNorm = 0.4698, lr_0 = 9.1030e-04
Validation auc = 0.874523
Epoch 13
Loss = 2.8652e-01, PNorm = 36.0836, GNorm = 0.4700, lr_0 = 9.0364e-04
Validation auc = 0.883388
Epoch 14
Loss = 2.7670e-01, PNorm = 36.1561, GNorm = 0.4478, lr_0 = 8.9703e-04
Loss = 3.0891e-01, PNorm = 36.2403, GNorm = 0.6160, lr_0 = 8.9047e-04
Validation auc = 0.895117
Epoch 15
Loss = 2.6770e-01, PNorm = 36.3329, GNorm = 0.2683, lr_0 = 8.8395e-04
Validation auc = 0.891435
Epoch 16
Loss = 2.1267e-01, PNorm = 36.4228, GNorm = 0.4994, lr_0 = 8.7749e-04
Loss = 3.0099e-01, PNorm = 36.5116, GNorm = 0.4362, lr_0 = 8.7107e-04
Validation auc = 0.890616
Epoch 17
Loss = 2.9038e-01, PNorm = 36.6186, GNorm = 0.6097, lr_0 = 8.6469e-04
Validation auc = 0.891298
Epoch 18
Loss = 3.6411e-01, PNorm = 36.7212, GNorm = 1.0660, lr_0 = 8.5837e-04
Loss = 2.5204e-01, PNorm = 36.8177, GNorm = 0.6676, lr_0 = 8.5209e-04
Validation auc = 0.869749
Epoch 19
Loss = 2.4252e-01, PNorm = 36.9169, GNorm = 0.8670, lr_0 = 8.4585e-04
Validation auc = 0.894708
Epoch 20
Loss = 1.9800e-01, PNorm = 37.0201, GNorm = 1.0525, lr_0 = 8.3967e-04
Loss = 2.5768e-01, PNorm = 37.1112, GNorm = 1.0291, lr_0 = 8.3352e-04
Validation auc = 0.898663
Epoch 21
Loss = 2.3098e-01, PNorm = 37.1899, GNorm = 0.4586, lr_0 = 8.2743e-04
Validation auc = 0.892662
Epoch 22
Loss = 2.4374e-01, PNorm = 37.2810, GNorm = 0.7208, lr_0 = 8.2137e-04
Loss = 2.1791e-01, PNorm = 37.3783, GNorm = 0.8154, lr_0 = 8.1536e-04
Validation auc = 0.904528
Epoch 23
Loss = 2.3573e-01, PNorm = 37.4827, GNorm = 1.8859, lr_0 = 8.0940e-04
Validation auc = 0.892799
Epoch 24
Loss = 2.0252e-01, PNorm = 37.5755, GNorm = 1.1181, lr_0 = 8.0348e-04
Loss = 2.5834e-01, PNorm = 37.6644, GNorm = 0.4811, lr_0 = 7.9760e-04
Validation auc = 0.914757
Epoch 25
Loss = 2.1814e-01, PNorm = 37.7512, GNorm = 0.7861, lr_0 = 7.9177e-04
Validation auc = 0.904937
Epoch 26
Loss = 2.5486e-01, PNorm = 37.8594, GNorm = 1.3952, lr_0 = 7.8540e-04
Loss = 2.0125e-01, PNorm = 37.9701, GNorm = 0.4008, lr_0 = 7.7965e-04
Validation auc = 0.903710
Epoch 27
Loss = 2.1655e-01, PNorm = 38.0690, GNorm = 1.6630, lr_0 = 7.7395e-04
Validation auc = 0.912166
Epoch 28
Loss = 1.5536e-01, PNorm = 38.1712, GNorm = 1.0755, lr_0 = 7.6829e-04
Loss = 1.8912e-01, PNorm = 38.2634, GNorm = 0.5489, lr_0 = 7.6267e-04
Validation auc = 0.907119
Epoch 29
Loss = 1.9686e-01, PNorm = 38.3548, GNorm = 1.2905, lr_0 = 7.5709e-04
Validation auc = 0.911893
Epoch 30
Loss = 1.9666e-01, PNorm = 38.4484, GNorm = 1.0610, lr_0 = 7.5155e-04
Loss = 1.5260e-01, PNorm = 38.5381, GNorm = 0.7379, lr_0 = 7.4605e-04
Validation auc = 0.911893
Epoch 31
Loss = 1.7637e-01, PNorm = 38.6231, GNorm = 0.9557, lr_0 = 7.4059e-04
Validation auc = 0.913803
Epoch 32
Loss = 2.2162e-01, PNorm = 38.7141, GNorm = 0.5132, lr_0 = 7.3517e-04
Loss = 1.6473e-01, PNorm = 38.8143, GNorm = 0.6479, lr_0 = 7.2980e-04
Validation auc = 0.917894
Epoch 33
Loss = 1.8570e-01, PNorm = 38.9073, GNorm = 0.4886, lr_0 = 7.2446e-04
Validation auc = 0.911620
Epoch 34
Loss = 1.6053e-01, PNorm = 38.9927, GNorm = 0.4309, lr_0 = 7.1916e-04
Loss = 1.5839e-01, PNorm = 39.0826, GNorm = 0.6572, lr_0 = 7.1390e-04
Validation auc = 0.905892
Epoch 35
Loss = 1.7677e-01, PNorm = 39.1642, GNorm = 0.4395, lr_0 = 7.0867e-04
Validation auc = 0.903710
Epoch 36
Loss = 1.7557e-01, PNorm = 39.2463, GNorm = 0.8371, lr_0 = 7.0349e-04
Loss = 1.4521e-01, PNorm = 39.3332, GNorm = 0.7899, lr_0 = 6.9834e-04
Validation auc = 0.920486
Epoch 37
Loss = 1.2968e-01, PNorm = 39.3902, GNorm = 0.7147, lr_0 = 6.9323e-04
Validation auc = 0.930715
Epoch 38
Loss = 1.2961e-01, PNorm = 39.4722, GNorm = 1.2076, lr_0 = 6.8816e-04
Loss = 1.6959e-01, PNorm = 39.5540, GNorm = 0.8452, lr_0 = 6.8313e-04
Validation auc = 0.908211
Epoch 39
Loss = 1.2931e-01, PNorm = 39.6367, GNorm = 1.1520, lr_0 = 6.7813e-04
Validation auc = 0.932624
Epoch 40
Loss = 1.3279e-01, PNorm = 39.7075, GNorm = 0.8475, lr_0 = 6.7317e-04
Loss = 1.2407e-01, PNorm = 39.7835, GNorm = 0.6181, lr_0 = 6.6825e-04
Validation auc = 0.911893
Epoch 41
Loss = 1.4780e-01, PNorm = 39.8691, GNorm = 0.4395, lr_0 = 6.6336e-04
Validation auc = 0.918985
Epoch 42
Loss = 9.5912e-02, PNorm = 39.9503, GNorm = 0.6115, lr_0 = 6.5850e-04
Loss = 1.3640e-01, PNorm = 40.0250, GNorm = 1.0198, lr_0 = 6.5369e-04
Validation auc = 0.929214
Epoch 43
Loss = 1.0804e-01, PNorm = 40.0877, GNorm = 0.6657, lr_0 = 6.4891e-04
Validation auc = 0.907938
Epoch 44
Loss = 1.1013e-01, PNorm = 40.1613, GNorm = 0.7862, lr_0 = 6.4416e-04
Loss = 1.0331e-01, PNorm = 40.2150, GNorm = 0.6497, lr_0 = 6.3945e-04
Validation auc = 0.915848
Epoch 45
Loss = 1.0488e-01, PNorm = 40.2816, GNorm = 0.7982, lr_0 = 6.3477e-04
Validation auc = 0.923759
Epoch 46
Loss = 1.6370e-01, PNorm = 40.3417, GNorm = 1.2962, lr_0 = 6.3012e-04
Loss = 1.3434e-01, PNorm = 40.4252, GNorm = 0.7633, lr_0 = 6.2551e-04
Validation auc = 0.919394
Epoch 47
Loss = 1.0369e-01, PNorm = 40.5011, GNorm = 0.6576, lr_0 = 6.2094e-04
Validation auc = 0.900846
Epoch 48
Loss = 1.2609e-01, PNorm = 40.5823, GNorm = 0.9162, lr_0 = 6.1640e-04
Loss = 1.0901e-01, PNorm = 40.6538, GNorm = 0.5076, lr_0 = 6.1189e-04
Validation auc = 0.919258
Epoch 49
Loss = 1.0390e-01, PNorm = 40.7169, GNorm = 0.4505, lr_0 = 6.0741e-04
Validation auc = 0.932079
Epoch 50
Loss = 7.7474e-02, PNorm = 40.7687, GNorm = 0.6083, lr_0 = 6.0297e-04
Loss = 7.3394e-02, PNorm = 40.8325, GNorm = 0.5735, lr_0 = 5.9856e-04
Validation auc = 0.913121
Epoch 51
Loss = 8.3006e-02, PNorm = 40.9048, GNorm = 1.2433, lr_0 = 5.9374e-04
Validation auc = 0.924304
Epoch 52
Loss = 8.7948e-02, PNorm = 40.9679, GNorm = 0.4855, lr_0 = 5.8940e-04
Loss = 9.8660e-02, PNorm = 41.0299, GNorm = 0.6336, lr_0 = 5.8509e-04
Validation auc = 0.922804
Epoch 53
Loss = 1.1742e-01, PNorm = 41.0853, GNorm = 0.6008, lr_0 = 5.8081e-04
Validation auc = 0.921031
Epoch 54
Loss = 8.4811e-02, PNorm = 41.1476, GNorm = 0.3978, lr_0 = 5.7656e-04
Loss = 1.1004e-01, PNorm = 41.2105, GNorm = 0.2783, lr_0 = 5.7234e-04
Validation auc = 0.921577
Epoch 55
Loss = 9.1898e-02, PNorm = 41.2658, GNorm = 0.3635, lr_0 = 5.6815e-04
Validation auc = 0.914621
Epoch 56
Loss = 8.1069e-02, PNorm = 41.3192, GNorm = 1.0375, lr_0 = 5.6400e-04
Loss = 8.3595e-02, PNorm = 41.3731, GNorm = 0.8386, lr_0 = 5.5987e-04
Validation auc = 0.930987
Epoch 57
Loss = 7.6829e-02, PNorm = 41.4212, GNorm = 0.3061, lr_0 = 5.5577e-04
Validation auc = 0.924441
Epoch 58
Loss = 5.3201e-02, PNorm = 41.4717, GNorm = 0.9699, lr_0 = 5.5171e-04
Loss = 5.2368e-02, PNorm = 41.5169, GNorm = 0.6965, lr_0 = 5.4767e-04
Validation auc = 0.921031
Epoch 59
Loss = 5.1000e-02, PNorm = 41.5642, GNorm = 0.5667, lr_0 = 5.4367e-04
Validation auc = 0.916803
Epoch 60
Loss = 7.0503e-02, PNorm = 41.6081, GNorm = 0.5009, lr_0 = 5.3969e-04
Loss = 9.2891e-02, PNorm = 41.6556, GNorm = 0.6007, lr_0 = 5.3574e-04
Validation auc = 0.908620
Epoch 61
Loss = 5.2904e-02, PNorm = 41.7015, GNorm = 1.0999, lr_0 = 5.3182e-04
Validation auc = 0.929351
Epoch 62
Loss = 4.0391e-02, PNorm = 41.7479, GNorm = 0.5749, lr_0 = 5.2793e-04
Loss = 6.6841e-02, PNorm = 41.7964, GNorm = 0.9671, lr_0 = 5.2407e-04
Validation auc = 0.927441
Epoch 63
Loss = 4.7416e-02, PNorm = 41.8482, GNorm = 0.4351, lr_0 = 5.2023e-04
Validation auc = 0.922259
Epoch 64
Loss = 6.8592e-02, PNorm = 41.8957, GNorm = 0.6406, lr_0 = 5.1643e-04
Loss = 8.9540e-02, PNorm = 41.9358, GNorm = 1.6542, lr_0 = 5.1265e-04
Validation auc = 0.923213
Epoch 65
Loss = 6.7471e-02, PNorm = 41.9812, GNorm = 0.5650, lr_0 = 5.0890e-04
Validation auc = 0.925805
Epoch 66
Loss = 2.8149e-02, PNorm = 42.0170, GNorm = 0.4705, lr_0 = 5.0518e-04
Loss = 5.3545e-02, PNorm = 42.0556, GNorm = 1.6798, lr_0 = 5.0148e-04
Validation auc = 0.923622
Epoch 67
Loss = 4.5341e-02, PNorm = 42.1027, GNorm = 0.5782, lr_0 = 4.9781e-04
Validation auc = 0.924032
Epoch 68
Loss = 9.6786e-02, PNorm = 42.1475, GNorm = 1.6422, lr_0 = 4.9417e-04
Loss = 4.5707e-02, PNorm = 42.1917, GNorm = 0.2811, lr_0 = 4.9056e-04
Validation auc = 0.927851
Epoch 69
Loss = 5.3634e-02, PNorm = 42.2300, GNorm = 0.8930, lr_0 = 4.8697e-04
Validation auc = 0.918985
Epoch 70
Loss = 6.6742e-02, PNorm = 42.2647, GNorm = 0.4532, lr_0 = 4.8341e-04
Loss = 7.2444e-02, PNorm = 42.3006, GNorm = 1.3177, lr_0 = 4.7987e-04
Validation auc = 0.928260
Epoch 71
Loss = 6.2639e-02, PNorm = 42.3457, GNorm = 0.5155, lr_0 = 4.7636e-04
Validation auc = 0.920895
Epoch 72
Loss = 4.4952e-02, PNorm = 42.3849, GNorm = 0.5745, lr_0 = 4.7287e-04
Loss = 5.5767e-02, PNorm = 42.4269, GNorm = 0.7809, lr_0 = 4.6941e-04
Validation auc = 0.928942
Epoch 73
Loss = 5.3270e-02, PNorm = 42.4688, GNorm = 0.4965, lr_0 = 4.6598e-04
Validation auc = 0.916803
Epoch 74
Loss = 6.9560e-02, PNorm = 42.5015, GNorm = 1.3634, lr_0 = 4.6257e-04
Loss = 4.4763e-02, PNorm = 42.5298, GNorm = 0.5508, lr_0 = 4.5919e-04
Validation auc = 0.929487
Epoch 75
Loss = 5.6478e-02, PNorm = 42.5613, GNorm = 0.7556, lr_0 = 4.5583e-04
Validation auc = 0.925259
Epoch 76
Loss = 3.7067e-02, PNorm = 42.6029, GNorm = 0.8178, lr_0 = 4.5216e-04
Loss = 5.6921e-02, PNorm = 42.6401, GNorm = 0.2563, lr_0 = 4.4885e-04
Validation auc = 0.918712
Epoch 77
Loss = 3.6616e-02, PNorm = 42.6704, GNorm = 0.7147, lr_0 = 4.4557e-04
Validation auc = 0.923895
Epoch 78
Loss = 5.5236e-02, PNorm = 42.7062, GNorm = 0.7877, lr_0 = 4.4231e-04
Loss = 3.8071e-02, PNorm = 42.7340, GNorm = 0.6992, lr_0 = 4.3907e-04
Validation auc = 0.918440
Epoch 79
Loss = 3.9411e-02, PNorm = 42.7670, GNorm = 0.7326, lr_0 = 4.3586e-04
Validation auc = 0.931669
Epoch 80
Loss = 4.2877e-02, PNorm = 42.7966, GNorm = 1.2155, lr_0 = 4.3267e-04
Loss = 5.4865e-02, PNorm = 42.8289, GNorm = 1.0257, lr_0 = 4.2951e-04
Validation auc = 0.921167
Epoch 81
Loss = 3.5611e-02, PNorm = 42.8594, GNorm = 1.1463, lr_0 = 4.2637e-04
Validation auc = 0.922531
Epoch 82
Loss = 6.6881e-02, PNorm = 42.8880, GNorm = 2.1442, lr_0 = 4.2325e-04
Loss = 4.9807e-02, PNorm = 42.9285, GNorm = 0.9043, lr_0 = 4.2015e-04
Validation auc = 0.921986
Epoch 83
Loss = 4.7943e-02, PNorm = 42.9591, GNorm = 0.8823, lr_0 = 4.1708e-04
Validation auc = 0.924714
Epoch 84
Loss = 4.6353e-02, PNorm = 42.9883, GNorm = 0.2990, lr_0 = 4.1403e-04
Loss = 4.2307e-02, PNorm = 43.0173, GNorm = 0.8897, lr_0 = 4.1100e-04
Validation auc = 0.922531
Epoch 85
Loss = 4.0184e-02, PNorm = 43.0460, GNorm = 0.4128, lr_0 = 4.0799e-04
Validation auc = 0.922122
Epoch 86
Loss = 2.7686e-02, PNorm = 43.0691, GNorm = 0.3062, lr_0 = 4.0501e-04
Loss = 3.7674e-02, PNorm = 43.0928, GNorm = 0.4589, lr_0 = 4.0204e-04
Validation auc = 0.920622
Epoch 87
Loss = 4.6492e-02, PNorm = 43.1195, GNorm = 0.6674, lr_0 = 3.9910e-04
Validation auc = 0.925123
Epoch 88
Loss = 6.1772e-02, PNorm = 43.1332, GNorm = 1.3830, lr_0 = 3.9618e-04
Loss = 4.4458e-02, PNorm = 43.1663, GNorm = 0.2073, lr_0 = 3.9328e-04
Validation auc = 0.910870
Epoch 89
Loss = 3.0432e-02, PNorm = 43.1879, GNorm = 0.2734, lr_0 = 3.9041e-04
Validation auc = 0.927714
Epoch 90
Loss = 4.7533e-02, PNorm = 43.2060, GNorm = 1.2659, lr_0 = 3.8755e-04
Loss = 3.9286e-02, PNorm = 43.2270, GNorm = 0.6162, lr_0 = 3.8472e-04
Validation auc = 0.926350
Epoch 91
Loss = 3.6609e-02, PNorm = 43.2453, GNorm = 0.8150, lr_0 = 3.8190e-04
Validation auc = 0.924168
Epoch 92
Loss = 2.6276e-02, PNorm = 43.2660, GNorm = 0.3786, lr_0 = 3.7911e-04
Loss = 2.7697e-02, PNorm = 43.2871, GNorm = 0.6113, lr_0 = 3.7633e-04
Validation auc = 0.924850
Epoch 93
Loss = 3.1539e-02, PNorm = 43.3064, GNorm = 0.7715, lr_0 = 3.7358e-04
Validation auc = 0.927987
Epoch 94
Loss = 4.3742e-02, PNorm = 43.3237, GNorm = 0.9909, lr_0 = 3.7085e-04
Loss = 3.7302e-02, PNorm = 43.3481, GNorm = 1.2362, lr_0 = 3.6814e-04
Validation auc = 0.921986
Epoch 95
Loss = 3.6519e-02, PNorm = 43.3712, GNorm = 1.0316, lr_0 = 3.6544e-04
Validation auc = 0.927032
Epoch 96
Loss = 2.8031e-02, PNorm = 43.3905, GNorm = 0.5364, lr_0 = 3.6277e-04
Loss = 2.0721e-02, PNorm = 43.4094, GNorm = 0.1812, lr_0 = 3.6012e-04
Validation auc = 0.929214
Epoch 97
Loss = 2.3840e-02, PNorm = 43.4306, GNorm = 0.0547, lr_0 = 3.5748e-04
Validation auc = 0.921304
Epoch 98
Loss = 1.1521e-02, PNorm = 43.4520, GNorm = 0.1104, lr_0 = 3.5487e-04
Loss = 5.7459e-02, PNorm = 43.4659, GNorm = 0.7103, lr_0 = 3.5227e-04
Validation auc = 0.922395
Epoch 99
Loss = 3.6976e-02, PNorm = 43.4887, GNorm = 0.4727, lr_0 = 3.4969e-04
Validation auc = 0.919531
Model 0 best validation auc = 0.932624 on epoch 39
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.944112
Ensemble test auc = 0.944112
Fold 3
Splitting data with seed 3
Total scaffolds = 1,025 | train scaffolds = 835 | val scaffolds = 63 | test scaffolds = 127
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 824
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8195e-01, PNorm = 35.0697, GNorm = 0.6962, lr_0 = 2.5469e-04
Validation auc = 0.789388
Epoch 1
Loss = 4.7180e-01, PNorm = 35.0910, GNorm = 0.6856, lr_0 = 4.0937e-04
Loss = 5.1193e-01, PNorm = 35.1184, GNorm = 0.9026, lr_0 = 5.5000e-04
Validation auc = 0.843469
Epoch 2
Loss = 4.3106e-01, PNorm = 35.1404, GNorm = 0.4501, lr_0 = 7.0469e-04
Validation auc = 0.880816
Epoch 3
Loss = 3.8783e-01, PNorm = 35.1722, GNorm = 0.7876, lr_0 = 8.4531e-04
Loss = 4.2032e-01, PNorm = 35.2101, GNorm = 0.4401, lr_0 = 9.8594e-04
Validation auc = 0.881224
Epoch 4
Loss = 3.9680e-01, PNorm = 35.2633, GNorm = 0.4519, lr_0 = 9.9268e-04
Loss = 3.8928e-01, PNorm = 35.3119, GNorm = 0.3329, lr_0 = 9.8542e-04
Validation auc = 0.884082
Epoch 5
Loss = 3.9247e-01, PNorm = 35.3571, GNorm = 1.1589, lr_0 = 9.7821e-04
Validation auc = 0.886531
Epoch 6
Loss = 3.9613e-01, PNorm = 35.4127, GNorm = 0.9711, lr_0 = 9.7034e-04
Loss = 3.7287e-01, PNorm = 35.4677, GNorm = 1.4749, lr_0 = 9.6325e-04
Validation auc = 0.878367
Epoch 7
Loss = 4.0596e-01, PNorm = 35.5215, GNorm = 0.8858, lr_0 = 9.5620e-04
Loss = 3.5206e-01, PNorm = 35.5862, GNorm = 0.5705, lr_0 = 9.4920e-04
Validation auc = 0.878571
Epoch 8
Loss = 2.9993e-01, PNorm = 35.6642, GNorm = 0.7530, lr_0 = 9.4157e-04
Validation auc = 0.881429
Epoch 9
Loss = 3.5170e-01, PNorm = 35.7305, GNorm = 0.4137, lr_0 = 9.3468e-04
Loss = 3.4258e-01, PNorm = 35.8078, GNorm = 0.2987, lr_0 = 9.2784e-04
Validation auc = 0.872653
Epoch 10
Loss = 3.1803e-01, PNorm = 35.8968, GNorm = 0.4857, lr_0 = 9.2038e-04
Loss = 3.2124e-01, PNorm = 35.9868, GNorm = 0.3083, lr_0 = 9.1365e-04
Validation auc = 0.878980
Epoch 11
Loss = 2.9354e-01, PNorm = 36.0974, GNorm = 0.4976, lr_0 = 9.0696e-04
Validation auc = 0.868980
Epoch 12
Loss = 3.7312e-01, PNorm = 36.1805, GNorm = 2.4405, lr_0 = 8.9967e-04
Loss = 3.2446e-01, PNorm = 36.2611, GNorm = 0.6145, lr_0 = 8.9309e-04
Validation auc = 0.870204
Epoch 13
Loss = 2.7373e-01, PNorm = 36.3347, GNorm = 0.7625, lr_0 = 8.8655e-04
Loss = 3.1681e-01, PNorm = 36.4168, GNorm = 0.4504, lr_0 = 8.8007e-04
Loss = 3.5964e-01, PNorm = 36.4256, GNorm = 0.8551, lr_0 = 8.7942e-04
Validation auc = 0.852041
Epoch 14
Loss = 3.0225e-01, PNorm = 36.5189, GNorm = 0.5338, lr_0 = 8.7299e-04
Validation auc = 0.867755
Epoch 15
Loss = 2.5584e-01, PNorm = 36.6054, GNorm = 0.7824, lr_0 = 8.6660e-04
Loss = 2.8779e-01, PNorm = 36.6884, GNorm = 1.2006, lr_0 = 8.6026e-04
Validation auc = 0.860000
Epoch 16
Loss = 2.8890e-01, PNorm = 36.7796, GNorm = 0.6783, lr_0 = 8.5334e-04
Loss = 2.7105e-01, PNorm = 36.8635, GNorm = 0.5989, lr_0 = 8.4710e-04
Validation auc = 0.853673
Epoch 17
Loss = 2.3866e-01, PNorm = 36.9530, GNorm = 0.5314, lr_0 = 8.4090e-04
Validation auc = 0.859184
Epoch 18
Loss = 3.2804e-01, PNorm = 37.0514, GNorm = 0.5730, lr_0 = 8.3414e-04
Loss = 2.5456e-01, PNorm = 37.1540, GNorm = 0.4815, lr_0 = 8.2803e-04
Validation auc = 0.852857
Epoch 19
Loss = 2.3980e-01, PNorm = 37.2661, GNorm = 0.5639, lr_0 = 8.2198e-04
Validation auc = 0.844490
Epoch 20
Loss = 2.9273e-01, PNorm = 37.3770, GNorm = 0.8153, lr_0 = 8.1536e-04
Loss = 2.2182e-01, PNorm = 37.4472, GNorm = 0.7128, lr_0 = 8.0940e-04
Validation auc = 0.850612
Epoch 21
Loss = 2.8254e-01, PNorm = 37.5393, GNorm = 1.0379, lr_0 = 8.0348e-04
Loss = 2.3895e-01, PNorm = 37.6353, GNorm = 0.6075, lr_0 = 7.9760e-04
Validation auc = 0.859388
Epoch 22
Loss = 2.2326e-01, PNorm = 37.7272, GNorm = 0.5929, lr_0 = 7.9119e-04
Validation auc = 0.850000
Epoch 23
Loss = 1.1826e-01, PNorm = 37.8131, GNorm = 0.4834, lr_0 = 7.8540e-04
Loss = 2.1881e-01, PNorm = 37.9336, GNorm = 0.5819, lr_0 = 7.7965e-04
Validation auc = 0.858571
Epoch 24
Loss = 1.9047e-01, PNorm = 38.0357, GNorm = 0.7128, lr_0 = 7.7338e-04
Loss = 2.0920e-01, PNorm = 38.1325, GNorm = 1.1571, lr_0 = 7.6772e-04
Validation auc = 0.863673
Epoch 25
Loss = 1.9693e-01, PNorm = 38.2114, GNorm = 1.1830, lr_0 = 7.6211e-04
Validation auc = 0.848776
Epoch 26
Loss = 1.9669e-01, PNorm = 38.3037, GNorm = 0.6655, lr_0 = 7.5598e-04
Loss = 2.0219e-01, PNorm = 38.3932, GNorm = 0.6683, lr_0 = 7.5045e-04
Validation auc = 0.856939
Epoch 27
Loss = 1.6096e-01, PNorm = 38.4877, GNorm = 0.6864, lr_0 = 7.4441e-04
Loss = 1.6418e-01, PNorm = 38.5896, GNorm = 0.4277, lr_0 = 7.3896e-04
Validation auc = 0.851633
Epoch 28
Loss = 1.6776e-01, PNorm = 38.6755, GNorm = 0.8080, lr_0 = 7.3356e-04
Validation auc = 0.851633
Epoch 29
Loss = 1.9460e-01, PNorm = 38.7493, GNorm = 0.7570, lr_0 = 7.2766e-04
Loss = 1.9275e-01, PNorm = 38.8330, GNorm = 0.5478, lr_0 = 7.2233e-04
Validation auc = 0.846122
Epoch 30
Loss = 1.5988e-01, PNorm = 38.9125, GNorm = 0.6053, lr_0 = 7.1705e-04
Loss = 1.4448e-01, PNorm = 38.9922, GNorm = 0.4658, lr_0 = 7.1180e-04
Loss = 1.2941e-01, PNorm = 39.0008, GNorm = 0.8035, lr_0 = 7.1128e-04
Validation auc = 0.853469
Epoch 31
Loss = 1.6523e-01, PNorm = 39.0843, GNorm = 1.4258, lr_0 = 7.0608e-04
Validation auc = 0.856939
Epoch 32
Loss = 1.8101e-01, PNorm = 39.1621, GNorm = 1.6600, lr_0 = 7.0091e-04
Loss = 1.9762e-01, PNorm = 39.2241, GNorm = 0.9221, lr_0 = 6.9578e-04
Validation auc = 0.846735
Epoch 33
Loss = 1.9471e-01, PNorm = 39.2996, GNorm = 0.6542, lr_0 = 6.9019e-04
Loss = 1.7474e-01, PNorm = 39.3758, GNorm = 0.8011, lr_0 = 6.8514e-04
Validation auc = 0.857959
Epoch 34
Loss = 1.6181e-01, PNorm = 39.4705, GNorm = 0.7284, lr_0 = 6.8013e-04
Validation auc = 0.848367
Epoch 35
Loss = 1.2335e-01, PNorm = 39.5594, GNorm = 0.7089, lr_0 = 6.7465e-04
Loss = 1.3867e-01, PNorm = 39.6508, GNorm = 0.7358, lr_0 = 6.6972e-04
Validation auc = 0.850816
Epoch 36
Loss = 1.2370e-01, PNorm = 39.7303, GNorm = 0.8770, lr_0 = 6.6482e-04
Validation auc = 0.841837
Epoch 37
Loss = 1.1895e-01, PNorm = 39.8118, GNorm = 0.5864, lr_0 = 6.5947e-04
Loss = 1.5440e-01, PNorm = 39.8819, GNorm = 0.6092, lr_0 = 6.5465e-04
Validation auc = 0.844082
Epoch 38
Loss = 1.2004e-01, PNorm = 39.9547, GNorm = 0.3798, lr_0 = 6.4986e-04
Loss = 1.2711e-01, PNorm = 40.0324, GNorm = 0.8594, lr_0 = 6.4510e-04
Validation auc = 0.847143
Epoch 39
Loss = 1.2561e-01, PNorm = 40.1214, GNorm = 0.3554, lr_0 = 6.3992e-04
Validation auc = 0.849184
Epoch 40
Loss = 6.6362e-02, PNorm = 40.2002, GNorm = 0.6750, lr_0 = 6.3523e-04
Loss = 1.1392e-01, PNorm = 40.2777, GNorm = 0.4570, lr_0 = 6.3059e-04
Validation auc = 0.838776
Epoch 41
Loss = 1.1858e-01, PNorm = 40.3575, GNorm = 0.6774, lr_0 = 6.2551e-04
Loss = 1.2942e-01, PNorm = 40.4102, GNorm = 0.9308, lr_0 = 6.2094e-04
Validation auc = 0.848367
Epoch 42
Loss = 1.2181e-01, PNorm = 40.4627, GNorm = 0.5481, lr_0 = 6.1640e-04
Validation auc = 0.826327
Epoch 43
Loss = 1.3759e-01, PNorm = 40.5305, GNorm = 1.2005, lr_0 = 6.1144e-04
Loss = 1.1177e-01, PNorm = 40.5853, GNorm = 0.4312, lr_0 = 6.0696e-04
Validation auc = 0.850408
Epoch 44
Loss = 1.2989e-01, PNorm = 40.6558, GNorm = 1.3787, lr_0 = 6.0252e-04
Loss = 1.2356e-01, PNorm = 40.7244, GNorm = 1.1910, lr_0 = 5.9812e-04
Validation auc = 0.850816
Epoch 45
Loss = 1.5541e-01, PNorm = 40.7892, GNorm = 0.6038, lr_0 = 5.9331e-04
Validation auc = 0.856735
Epoch 46
Loss = 1.3235e-01, PNorm = 40.8451, GNorm = 0.6588, lr_0 = 5.8896e-04
Loss = 8.4528e-02, PNorm = 40.8984, GNorm = 0.4974, lr_0 = 5.8466e-04
Validation auc = 0.855714
Epoch 47
Loss = 8.8109e-02, PNorm = 40.9584, GNorm = 0.6748, lr_0 = 5.7995e-04
Loss = 1.1673e-01, PNorm = 41.0203, GNorm = 0.6127, lr_0 = 5.7571e-04
Validation auc = 0.848980
Epoch 48
Loss = 7.5194e-02, PNorm = 41.0755, GNorm = 0.6501, lr_0 = 5.7150e-04
Validation auc = 0.838776
Epoch 49
Loss = 1.2043e-01, PNorm = 41.1421, GNorm = 0.6707, lr_0 = 5.6690e-04
Loss = 8.4877e-02, PNorm = 41.1938, GNorm = 0.4140, lr_0 = 5.6275e-04
Validation auc = 0.841735
Epoch 50
Loss = 9.4290e-02, PNorm = 41.2415, GNorm = 0.3958, lr_0 = 5.5864e-04
Loss = 1.1080e-01, PNorm = 41.2831, GNorm = 0.8514, lr_0 = 5.5455e-04
Loss = 9.8401e-02, PNorm = 41.2880, GNorm = 0.8088, lr_0 = 5.5414e-04
Validation auc = 0.840000
Epoch 51
Loss = 1.0272e-01, PNorm = 41.3424, GNorm = 0.8286, lr_0 = 5.5009e-04
Validation auc = 0.832347
Epoch 52
Loss = 1.1224e-01, PNorm = 41.4005, GNorm = 0.7515, lr_0 = 5.4566e-04
Loss = 8.6094e-02, PNorm = 41.4552, GNorm = 0.5889, lr_0 = 5.4167e-04
Validation auc = 0.847551
Epoch 53
Loss = 1.0675e-01, PNorm = 41.5180, GNorm = 0.4514, lr_0 = 5.3771e-04
Validation auc = 0.845306
Epoch 54
Loss = 6.3201e-02, PNorm = 41.5790, GNorm = 0.4240, lr_0 = 5.3339e-04
Loss = 6.9036e-02, PNorm = 41.6314, GNorm = 0.8514, lr_0 = 5.2948e-04
Validation auc = 0.828878
Epoch 55
Loss = 1.2516e-01, PNorm = 41.6791, GNorm = 1.5004, lr_0 = 5.2561e-04
Loss = 8.7104e-02, PNorm = 41.7252, GNorm = 0.5964, lr_0 = 5.2176e-04
Validation auc = 0.846531
Epoch 56
Loss = 8.2946e-02, PNorm = 41.7791, GNorm = 0.5346, lr_0 = 5.1757e-04
Validation auc = 0.840714
Epoch 57
Loss = 1.2808e-01, PNorm = 41.8243, GNorm = 0.7945, lr_0 = 5.1378e-04
Loss = 8.4239e-02, PNorm = 41.8758, GNorm = 0.4793, lr_0 = 5.1002e-04
Validation auc = 0.843163
Epoch 58
Loss = 7.4670e-02, PNorm = 41.9383, GNorm = 0.3732, lr_0 = 5.0592e-04
Loss = 6.2658e-02, PNorm = 41.9886, GNorm = 0.5211, lr_0 = 5.0222e-04
Validation auc = 0.845918
Epoch 59
Loss = 7.0835e-02, PNorm = 42.0396, GNorm = 1.7085, lr_0 = 4.9854e-04
Validation auc = 0.834898
Epoch 60
Loss = 6.2875e-02, PNorm = 42.0941, GNorm = 0.9616, lr_0 = 4.9453e-04
Loss = 6.0324e-02, PNorm = 42.1478, GNorm = 0.5627, lr_0 = 4.9092e-04
Validation auc = 0.833776
Epoch 61
Loss = 7.8827e-02, PNorm = 42.1962, GNorm = 0.2511, lr_0 = 4.8733e-04
Loss = 9.3067e-02, PNorm = 42.2306, GNorm = 1.7895, lr_0 = 4.8376e-04
Validation auc = 0.842143
Epoch 62
Loss = 9.2390e-02, PNorm = 42.2886, GNorm = 1.8905, lr_0 = 4.7987e-04
Validation auc = 0.839694
Epoch 63
Loss = 8.7286e-02, PNorm = 42.3318, GNorm = 0.4339, lr_0 = 4.7636e-04
Loss = 5.5153e-02, PNorm = 42.3800, GNorm = 0.5309, lr_0 = 4.7287e-04
Validation auc = 0.835612
Epoch 64
Loss = 7.3343e-02, PNorm = 42.4230, GNorm = 0.5210, lr_0 = 4.6907e-04
Loss = 6.1329e-02, PNorm = 42.4548, GNorm = 0.3059, lr_0 = 4.6564e-04
Validation auc = 0.851020
Epoch 65
Loss = 6.7882e-02, PNorm = 42.4835, GNorm = 0.4768, lr_0 = 4.6223e-04
Validation auc = 0.852857
Epoch 66
Loss = 7.5620e-02, PNorm = 42.5237, GNorm = 0.7616, lr_0 = 4.5851e-04
Loss = 6.9094e-02, PNorm = 42.5678, GNorm = 0.5209, lr_0 = 4.5516e-04
Validation auc = 0.839490
Epoch 67
Loss = 5.2346e-02, PNorm = 42.6037, GNorm = 0.3338, lr_0 = 4.5183e-04
Loss = 6.7661e-02, PNorm = 42.6468, GNorm = 0.6588, lr_0 = 4.4852e-04
Loss = 2.4907e-02, PNorm = 42.6512, GNorm = 0.3601, lr_0 = 4.4819e-04
Validation auc = 0.842959
Epoch 68
Loss = 4.7453e-02, PNorm = 42.6916, GNorm = 0.6319, lr_0 = 4.4492e-04
Validation auc = 0.847143
Epoch 69
Loss = 2.8650e-02, PNorm = 42.7299, GNorm = 0.1832, lr_0 = 4.4166e-04
Loss = 5.2034e-02, PNorm = 42.7599, GNorm = 0.6109, lr_0 = 4.3843e-04
Validation auc = 0.834082
Epoch 70
Loss = 4.3795e-02, PNorm = 42.7928, GNorm = 0.3335, lr_0 = 4.3490e-04
Loss = 5.0209e-02, PNorm = 42.8225, GNorm = 1.3735, lr_0 = 4.3172e-04
Validation auc = 0.843776
Epoch 71
Loss = 5.1612e-02, PNorm = 42.8487, GNorm = 0.6052, lr_0 = 4.2856e-04
Validation auc = 0.844286
Epoch 72
Loss = 4.4038e-02, PNorm = 42.8911, GNorm = 1.1069, lr_0 = 4.2512e-04
Loss = 6.0362e-02, PNorm = 42.9309, GNorm = 0.6096, lr_0 = 4.2201e-04
Validation auc = 0.835000
Epoch 73
Loss = 3.3456e-02, PNorm = 42.9545, GNorm = 0.4083, lr_0 = 4.1892e-04
Validation auc = 0.846122
Epoch 74
Loss = 4.5634e-02, PNorm = 42.9852, GNorm = 0.6122, lr_0 = 4.1555e-04
Loss = 4.4960e-02, PNorm = 43.0164, GNorm = 0.5190, lr_0 = 4.1251e-04
Validation auc = 0.846633
Epoch 75
Loss = 3.2429e-02, PNorm = 43.0446, GNorm = 0.3662, lr_0 = 4.0949e-04
Loss = 6.6216e-02, PNorm = 43.0777, GNorm = 1.0819, lr_0 = 4.0650e-04
Validation auc = 0.846429
Epoch 76
Loss = 5.8920e-02, PNorm = 43.1062, GNorm = 0.4513, lr_0 = 4.0323e-04
Validation auc = 0.838980
Epoch 77
Loss = 6.5127e-02, PNorm = 43.1515, GNorm = 0.4425, lr_0 = 3.9998e-04
Loss = 5.5469e-02, PNorm = 43.1900, GNorm = 0.2682, lr_0 = 3.9706e-04
Validation auc = 0.851939
Epoch 78
Loss = 3.6262e-02, PNorm = 43.2196, GNorm = 0.8003, lr_0 = 3.9415e-04
Loss = 4.6536e-02, PNorm = 43.2468, GNorm = 0.5776, lr_0 = 3.9127e-04
Validation auc = 0.845816
Epoch 79
Loss = 4.6596e-02, PNorm = 43.2750, GNorm = 0.7921, lr_0 = 3.8812e-04
Validation auc = 0.848878
Epoch 80
Loss = 2.7306e-02, PNorm = 43.2995, GNorm = 0.3246, lr_0 = 3.8528e-04
Loss = 3.9867e-02, PNorm = 43.3238, GNorm = 0.3941, lr_0 = 3.8246e-04
Validation auc = 0.854490
Epoch 81
Loss = 5.0975e-02, PNorm = 43.3452, GNorm = 0.8507, lr_0 = 3.7939e-04
Loss = 3.8498e-02, PNorm = 43.3703, GNorm = 0.4826, lr_0 = 3.7661e-04
Validation auc = 0.841633
Epoch 82
Loss = 2.9700e-02, PNorm = 43.3953, GNorm = 0.4145, lr_0 = 3.7386e-04
Validation auc = 0.847245
Epoch 83
Loss = 3.8671e-02, PNorm = 43.4205, GNorm = 0.9240, lr_0 = 3.7085e-04
Loss = 3.4624e-02, PNorm = 43.4409, GNorm = 0.9199, lr_0 = 3.6814e-04
Validation auc = 0.844184
Epoch 84
Loss = 4.1061e-02, PNorm = 43.4614, GNorm = 0.3833, lr_0 = 3.6544e-04
Loss = 4.0768e-02, PNorm = 43.4824, GNorm = 0.7842, lr_0 = 3.6277e-04
Loss = 5.0673e-03, PNorm = 43.4844, GNorm = 0.1516, lr_0 = 3.6250e-04
Validation auc = 0.851020
Epoch 85
Loss = 3.4708e-02, PNorm = 43.5050, GNorm = 0.2157, lr_0 = 3.5985e-04
Validation auc = 0.840408
Epoch 86
Loss = 1.9079e-02, PNorm = 43.5222, GNorm = 0.2239, lr_0 = 3.5722e-04
Loss = 2.3874e-02, PNorm = 43.5413, GNorm = 0.5857, lr_0 = 3.5461e-04
Validation auc = 0.843980
Epoch 87
Loss = 6.0452e-02, PNorm = 43.5583, GNorm = 0.9549, lr_0 = 3.5175e-04
Loss = 3.8425e-02, PNorm = 43.5773, GNorm = 0.3013, lr_0 = 3.4918e-04
Validation auc = 0.846122
Epoch 88
Loss = 3.7877e-02, PNorm = 43.5933, GNorm = 0.1150, lr_0 = 3.4662e-04
Validation auc = 0.845612
Epoch 89
Loss = 4.4343e-02, PNorm = 43.6095, GNorm = 0.6775, lr_0 = 3.4384e-04
Loss = 3.8604e-02, PNorm = 43.6284, GNorm = 0.8440, lr_0 = 3.4132e-04
Validation auc = 0.840408
Epoch 90
Loss = 2.2742e-02, PNorm = 43.6444, GNorm = 0.1129, lr_0 = 3.3882e-04
Validation auc = 0.843061
Epoch 91
Loss = 4.4536e-02, PNorm = 43.6637, GNorm = 0.5568, lr_0 = 3.3610e-04
Loss = 4.7059e-02, PNorm = 43.6838, GNorm = 0.7989, lr_0 = 3.3364e-04
Validation auc = 0.837551
Epoch 92
Loss = 4.0337e-02, PNorm = 43.7039, GNorm = 0.8316, lr_0 = 3.3120e-04
Loss = 3.0701e-02, PNorm = 43.7213, GNorm = 0.5635, lr_0 = 3.2878e-04
Validation auc = 0.846122
Epoch 93
Loss = 2.0841e-02, PNorm = 43.7385, GNorm = 0.3187, lr_0 = 3.2613e-04
Validation auc = 0.849898
Epoch 94
Loss = 3.1971e-02, PNorm = 43.7561, GNorm = 0.6571, lr_0 = 3.2375e-04
Loss = 3.6427e-02, PNorm = 43.7707, GNorm = 0.6486, lr_0 = 3.2138e-04
Validation auc = 0.841837
Epoch 95
Loss = 1.5900e-02, PNorm = 43.7901, GNorm = 0.4669, lr_0 = 3.1879e-04
Loss = 3.9196e-02, PNorm = 43.8062, GNorm = 0.4668, lr_0 = 3.1646e-04
Validation auc = 0.842857
Epoch 96
Loss = 4.2253e-02, PNorm = 43.8213, GNorm = 0.4917, lr_0 = 3.1414e-04
Validation auc = 0.844796
Epoch 97
Loss = 3.3166e-02, PNorm = 43.8416, GNorm = 0.4800, lr_0 = 3.1162e-04
Loss = 2.8894e-02, PNorm = 43.8597, GNorm = 0.1791, lr_0 = 3.0934e-04
Validation auc = 0.842347
Epoch 98
Loss = 1.8785e-02, PNorm = 43.8790, GNorm = 0.4568, lr_0 = 3.0708e-04
Loss = 3.5787e-02, PNorm = 43.8963, GNorm = 0.9052, lr_0 = 3.0483e-04
Validation auc = 0.838571
Epoch 99
Loss = 2.6648e-02, PNorm = 43.9168, GNorm = 0.2733, lr_0 = 3.0238e-04
Validation auc = 0.848673
Model 0 best validation auc = 0.886531 on epoch 5
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.862913
Ensemble test auc = 0.862913
Fold 4
Splitting data with seed 4
Total scaffolds = 1,025 | train scaffolds = 822 | val scaffolds = 112 | test scaffolds = 91
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 778
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7560e-01, PNorm = 35.0702, GNorm = 0.7138, lr_0 = 2.5469e-04
Validation auc = 0.839449
Epoch 1
Loss = 5.3299e-01, PNorm = 35.0928, GNorm = 0.4347, lr_0 = 4.0937e-04
Loss = 4.8267e-01, PNorm = 35.1232, GNorm = 2.3111, lr_0 = 5.5000e-04
Validation auc = 0.874342
Epoch 2
Loss = 4.7293e-01, PNorm = 35.1497, GNorm = 0.7093, lr_0 = 6.9063e-04
Validation auc = 0.888604
Epoch 3
Loss = 3.9661e-01, PNorm = 35.1842, GNorm = 0.4857, lr_0 = 8.4531e-04
Loss = 4.3782e-01, PNorm = 35.2257, GNorm = 1.1108, lr_0 = 9.8594e-04
Validation auc = 0.897674
Epoch 4
Loss = 3.9175e-01, PNorm = 35.2683, GNorm = 0.7490, lr_0 = 9.9341e-04
Validation auc = 0.884589
Epoch 5
Loss = 4.5928e-01, PNorm = 35.3231, GNorm = 0.4149, lr_0 = 9.8542e-04
Loss = 3.6437e-01, PNorm = 35.3835, GNorm = 0.3266, lr_0 = 9.7821e-04
Validation auc = 0.891651
Epoch 6
Loss = 3.6004e-01, PNorm = 35.4508, GNorm = 1.3874, lr_0 = 9.7106e-04
Validation auc = 0.886181
Epoch 7
Loss = 4.3098e-01, PNorm = 35.5135, GNorm = 0.3406, lr_0 = 9.6325e-04
Loss = 3.4827e-01, PNorm = 35.5742, GNorm = 1.7163, lr_0 = 9.5620e-04
Validation auc = 0.891581
Epoch 8
Loss = 3.7826e-01, PNorm = 35.6302, GNorm = 0.7732, lr_0 = 9.4920e-04
Loss = 3.5638e-01, PNorm = 35.7020, GNorm = 0.9324, lr_0 = 9.4226e-04
Validation auc = 0.889712
Epoch 9
Loss = 3.4970e-01, PNorm = 35.7662, GNorm = 0.6128, lr_0 = 9.3537e-04
Validation auc = 0.893451
Epoch 10
Loss = 3.6747e-01, PNorm = 35.8374, GNorm = 0.7557, lr_0 = 9.2784e-04
Loss = 3.0641e-01, PNorm = 35.9121, GNorm = 1.0074, lr_0 = 9.2106e-04
Validation auc = 0.892343
Epoch 11
Loss = 3.3242e-01, PNorm = 35.9890, GNorm = 0.9185, lr_0 = 9.1432e-04
Validation auc = 0.886735
Epoch 12
Loss = 3.1427e-01, PNorm = 36.0704, GNorm = 1.0705, lr_0 = 9.0696e-04
Loss = 2.8902e-01, PNorm = 36.1511, GNorm = 0.7203, lr_0 = 9.0033e-04
Validation auc = 0.891651
Epoch 13
Loss = 2.8894e-01, PNorm = 36.2306, GNorm = 0.4833, lr_0 = 8.9374e-04
Validation auc = 0.887635
Epoch 14
Loss = 2.4297e-01, PNorm = 36.3115, GNorm = 0.8997, lr_0 = 8.8655e-04
Loss = 3.0971e-01, PNorm = 36.4016, GNorm = 0.4833, lr_0 = 8.8007e-04
Validation auc = 0.885973
Epoch 15
Loss = 2.8057e-01, PNorm = 36.4907, GNorm = 0.5224, lr_0 = 8.7363e-04
Validation auc = 0.894212
Epoch 16
Loss = 2.0072e-01, PNorm = 36.5902, GNorm = 0.7752, lr_0 = 8.6660e-04
Loss = 2.5313e-01, PNorm = 36.6868, GNorm = 0.6626, lr_0 = 8.6026e-04
Validation auc = 0.882927
Epoch 17
Loss = 2.6231e-01, PNorm = 36.7774, GNorm = 1.5039, lr_0 = 8.5397e-04
Loss = 2.4252e-01, PNorm = 36.8665, GNorm = 0.9510, lr_0 = 8.4772e-04
Validation auc = 0.889643
Epoch 18
Loss = 2.8229e-01, PNorm = 36.9651, GNorm = 0.5420, lr_0 = 8.4152e-04
Validation auc = 0.892966
Epoch 19
Loss = 2.5942e-01, PNorm = 37.0687, GNorm = 1.4416, lr_0 = 8.3475e-04
Loss = 3.0195e-01, PNorm = 37.1636, GNorm = 0.7492, lr_0 = 8.2864e-04
Validation auc = 0.884243
Epoch 20
Loss = 2.5512e-01, PNorm = 37.2532, GNorm = 0.7621, lr_0 = 8.2258e-04
Validation auc = 0.873719
Epoch 21
Loss = 2.4229e-01, PNorm = 37.3531, GNorm = 0.5563, lr_0 = 8.1596e-04
Loss = 2.1114e-01, PNorm = 37.4468, GNorm = 0.7557, lr_0 = 8.0999e-04
Validation auc = 0.888050
Epoch 22
Loss = 2.5541e-01, PNorm = 37.5481, GNorm = 1.0208, lr_0 = 8.0407e-04
Validation auc = 0.875658
Epoch 23
Loss = 2.5943e-01, PNorm = 37.6652, GNorm = 0.8431, lr_0 = 7.9760e-04
Loss = 1.9827e-01, PNorm = 37.7618, GNorm = 0.6102, lr_0 = 7.9177e-04
Validation auc = 0.888258
Epoch 24
Loss = 2.2744e-01, PNorm = 37.8601, GNorm = 0.8907, lr_0 = 7.8597e-04
Validation auc = 0.881750
Epoch 25
Loss = 1.5275e-01, PNorm = 37.9597, GNorm = 1.4353, lr_0 = 7.8022e-04
Loss = 2.1904e-01, PNorm = 38.0575, GNorm = 1.0574, lr_0 = 7.7452e-04
Validation auc = 0.865342
Epoch 26
Loss = 2.4470e-01, PNorm = 38.1676, GNorm = 0.4601, lr_0 = 7.6829e-04
Loss = 1.8793e-01, PNorm = 38.2571, GNorm = 1.2171, lr_0 = 7.6267e-04
Validation auc = 0.883550
Epoch 27
Loss = 1.8775e-01, PNorm = 38.3498, GNorm = 0.9729, lr_0 = 7.5709e-04
Validation auc = 0.856826
Epoch 28
Loss = 1.6781e-01, PNorm = 38.4555, GNorm = 0.6335, lr_0 = 7.5100e-04
Loss = 1.6212e-01, PNorm = 38.5507, GNorm = 0.6711, lr_0 = 7.4550e-04
Validation auc = 0.887843
Epoch 29
Loss = 1.8526e-01, PNorm = 38.6499, GNorm = 0.5618, lr_0 = 7.4005e-04
Validation auc = 0.877873
Epoch 30
Loss = 1.9301e-01, PNorm = 38.7456, GNorm = 0.4765, lr_0 = 7.3410e-04
Loss = 2.1197e-01, PNorm = 38.8457, GNorm = 0.4531, lr_0 = 7.2873e-04
Validation auc = 0.891927
Epoch 31
Loss = 2.1195e-01, PNorm = 38.9278, GNorm = 1.5205, lr_0 = 7.2339e-04
Validation auc = 0.886527
Epoch 32
Loss = 1.7143e-01, PNorm = 39.0122, GNorm = 0.7034, lr_0 = 7.1758e-04
Loss = 1.7240e-01, PNorm = 39.0908, GNorm = 1.5391, lr_0 = 7.1233e-04
Validation auc = 0.876627
Epoch 33
Loss = 1.6118e-01, PNorm = 39.1789, GNorm = 0.5710, lr_0 = 7.0711e-04
Validation auc = 0.879950
Epoch 34
Loss = 1.1579e-01, PNorm = 39.2559, GNorm = 0.4823, lr_0 = 7.0194e-04
Loss = 1.4715e-01, PNorm = 39.3512, GNorm = 0.6692, lr_0 = 6.9681e-04
Validation auc = 0.878012
Epoch 35
Loss = 1.4059e-01, PNorm = 39.4459, GNorm = 0.8375, lr_0 = 6.9120e-04
Loss = 1.5679e-01, PNorm = 39.5329, GNorm = 0.4032, lr_0 = 6.8614e-04
Validation auc = 0.887843
Epoch 36
Loss = 1.4613e-01, PNorm = 39.6198, GNorm = 0.9413, lr_0 = 6.8113e-04
Validation auc = 0.887704
Epoch 37
Loss = 1.5380e-01, PNorm = 39.7247, GNorm = 0.9142, lr_0 = 6.7565e-04
Loss = 1.3954e-01, PNorm = 39.8122, GNorm = 1.3879, lr_0 = 6.7070e-04
Validation auc = 0.886458
Epoch 38
Loss = 1.4746e-01, PNorm = 39.8919, GNorm = 1.2669, lr_0 = 6.6580e-04
Validation auc = 0.878912
Epoch 39
Loss = 1.5323e-01, PNorm = 39.9586, GNorm = 0.6755, lr_0 = 6.6044e-04
Loss = 1.2815e-01, PNorm = 40.0362, GNorm = 1.2914, lr_0 = 6.5561e-04
Validation auc = 0.890958
Epoch 40
Loss = 1.5570e-01, PNorm = 40.1165, GNorm = 1.0736, lr_0 = 6.5081e-04
Validation auc = 0.886873
Epoch 41
Loss = 1.3312e-01, PNorm = 40.2074, GNorm = 1.0711, lr_0 = 6.4558e-04
Loss = 1.2193e-01, PNorm = 40.2796, GNorm = 0.2971, lr_0 = 6.4086e-04
Validation auc = 0.883135
Epoch 42
Loss = 1.0642e-01, PNorm = 40.3574, GNorm = 0.6742, lr_0 = 6.3617e-04
Validation auc = 0.886320
Epoch 43
Loss = 8.7289e-02, PNorm = 40.4257, GNorm = 0.6239, lr_0 = 6.3151e-04
Loss = 1.2023e-01, PNorm = 40.4936, GNorm = 1.2010, lr_0 = 6.2689e-04
Validation auc = 0.887704
Epoch 44
Loss = 1.0048e-01, PNorm = 40.5638, GNorm = 1.4193, lr_0 = 6.2185e-04
Loss = 1.4176e-01, PNorm = 40.6414, GNorm = 0.8808, lr_0 = 6.1730e-04
Validation auc = 0.887981
Epoch 45
Loss = 1.2045e-01, PNorm = 40.7200, GNorm = 1.8703, lr_0 = 6.1279e-04
Validation auc = 0.889504
Epoch 46
Loss = 7.4923e-02, PNorm = 40.8035, GNorm = 0.5388, lr_0 = 6.0786e-04
Loss = 1.1895e-01, PNorm = 40.8800, GNorm = 0.3737, lr_0 = 6.0341e-04
Validation auc = 0.875104
Epoch 47
Loss = 9.2860e-02, PNorm = 40.9489, GNorm = 0.3165, lr_0 = 5.9900e-04
Validation auc = 0.884866
Epoch 48
Loss = 1.4254e-01, PNorm = 41.0192, GNorm = 2.3564, lr_0 = 5.9418e-04
Loss = 9.0250e-02, PNorm = 41.0897, GNorm = 1.0923, lr_0 = 5.8983e-04
Validation auc = 0.889435
Epoch 49
Loss = 1.0781e-01, PNorm = 41.1546, GNorm = 0.9797, lr_0 = 5.8552e-04
Validation auc = 0.879050
Epoch 50
Loss = 1.2025e-01, PNorm = 41.2195, GNorm = 1.3524, lr_0 = 5.8123e-04
Loss = 1.0924e-01, PNorm = 41.2735, GNorm = 0.6536, lr_0 = 5.7698e-04
Validation auc = 0.884104
Epoch 51
Loss = 7.6325e-02, PNorm = 41.3498, GNorm = 0.9135, lr_0 = 5.7234e-04
Validation auc = 0.880089
Epoch 52
Loss = 5.9838e-02, PNorm = 41.4103, GNorm = 0.4707, lr_0 = 5.6815e-04
Loss = 1.0076e-01, PNorm = 41.4787, GNorm = 0.5439, lr_0 = 5.6400e-04
Validation auc = 0.872196
Epoch 53
Loss = 7.3075e-02, PNorm = 41.5482, GNorm = 1.0218, lr_0 = 5.5946e-04
Loss = 8.5468e-02, PNorm = 41.6014, GNorm = 0.4228, lr_0 = 5.5537e-04
Validation auc = 0.877596
Epoch 54
Loss = 8.7035e-02, PNorm = 41.6622, GNorm = 0.8265, lr_0 = 5.5130e-04
Validation auc = 0.889366
Epoch 55
Loss = 4.2357e-02, PNorm = 41.7380, GNorm = 0.3232, lr_0 = 5.4687e-04
Loss = 9.0656e-02, PNorm = 41.7839, GNorm = 1.0920, lr_0 = 5.4287e-04
Validation auc = 0.856203
Epoch 56
Loss = 7.2572e-02, PNorm = 41.8322, GNorm = 0.3265, lr_0 = 5.3890e-04
Validation auc = 0.895251
Epoch 57
Loss = 9.1241e-02, PNorm = 41.8851, GNorm = 1.0900, lr_0 = 5.3456e-04
Loss = 1.2359e-01, PNorm = 41.9484, GNorm = 1.2979, lr_0 = 5.3065e-04
Validation auc = 0.871642
Epoch 58
Loss = 7.7211e-02, PNorm = 41.9964, GNorm = 0.2426, lr_0 = 5.2677e-04
Validation auc = 0.889643
Epoch 59
Loss = 4.7403e-02, PNorm = 42.0505, GNorm = 0.5337, lr_0 = 5.2292e-04
Loss = 8.3405e-02, PNorm = 42.1029, GNorm = 0.3887, lr_0 = 5.1909e-04
Validation auc = 0.867073
Epoch 60
Loss = 8.0299e-02, PNorm = 42.1638, GNorm = 0.6105, lr_0 = 5.1491e-04
Validation auc = 0.878981
Epoch 61
Loss = 1.3236e-01, PNorm = 42.2163, GNorm = 0.6175, lr_0 = 5.1115e-04
Loss = 9.2095e-02, PNorm = 42.2676, GNorm = 0.6516, lr_0 = 5.0741e-04
Validation auc = 0.875865
Epoch 62
Loss = 6.0637e-02, PNorm = 42.3182, GNorm = 0.4942, lr_0 = 5.0333e-04
Loss = 8.5867e-02, PNorm = 42.3705, GNorm = 0.9854, lr_0 = 4.9964e-04
Validation auc = 0.887497
Epoch 63
Loss = 6.4004e-02, PNorm = 42.4123, GNorm = 1.9014, lr_0 = 4.9599e-04
Validation auc = 0.887081
Epoch 64
Loss = 5.8887e-02, PNorm = 42.4643, GNorm = 0.6535, lr_0 = 4.9200e-04
Loss = 6.9985e-02, PNorm = 42.5061, GNorm = 0.7919, lr_0 = 4.8840e-04
Validation auc = 0.889297
Epoch 65
Loss = 6.6783e-02, PNorm = 42.5538, GNorm = 0.3077, lr_0 = 4.8483e-04
Validation auc = 0.880989
Epoch 66
Loss = 6.2445e-02, PNorm = 42.6168, GNorm = 1.2706, lr_0 = 4.8093e-04
Loss = 5.4179e-02, PNorm = 42.6660, GNorm = 0.5581, lr_0 = 4.7741e-04
Validation auc = 0.884450
Epoch 67
Loss = 7.4110e-02, PNorm = 42.7126, GNorm = 0.9692, lr_0 = 4.7392e-04
Validation auc = 0.872265
Epoch 68
Loss = 8.0478e-02, PNorm = 42.7366, GNorm = 0.8847, lr_0 = 4.7045e-04
Loss = 7.7437e-02, PNorm = 42.7875, GNorm = 0.5241, lr_0 = 4.6701e-04
Validation auc = 0.884104
Epoch 69
Loss = 6.2957e-02, PNorm = 42.8309, GNorm = 1.5542, lr_0 = 4.6325e-04
Validation auc = 0.882304
Epoch 70
Loss = 1.0132e-01, PNorm = 42.8818, GNorm = 0.9521, lr_0 = 4.5986e-04
Loss = 4.6427e-02, PNorm = 42.9161, GNorm = 0.9696, lr_0 = 4.5650e-04
Validation auc = 0.881404
Epoch 71
Loss = 5.6819e-02, PNorm = 42.9524, GNorm = 0.2854, lr_0 = 4.5283e-04
Loss = 7.3959e-02, PNorm = 42.9939, GNorm = 1.4450, lr_0 = 4.4951e-04
Validation auc = 0.868319
Epoch 72
Loss = 4.9610e-02, PNorm = 43.0286, GNorm = 0.7158, lr_0 = 4.4622e-04
Validation auc = 0.871573
Epoch 73
Loss = 4.5036e-02, PNorm = 43.0660, GNorm = 0.2598, lr_0 = 4.4264e-04
Loss = 4.9240e-02, PNorm = 43.1025, GNorm = 0.4331, lr_0 = 4.3940e-04
Validation auc = 0.884866
Epoch 74
Loss = 6.0185e-02, PNorm = 43.1356, GNorm = 0.7086, lr_0 = 4.3618e-04
Validation auc = 0.860080
Epoch 75
Loss = 6.4467e-02, PNorm = 43.1751, GNorm = 0.4888, lr_0 = 4.3299e-04
Loss = 5.9863e-02, PNorm = 43.2050, GNorm = 0.5506, lr_0 = 4.2982e-04
Validation auc = 0.878842
Epoch 76
Loss = 5.0184e-02, PNorm = 43.2377, GNorm = 1.1009, lr_0 = 4.2637e-04
Validation auc = 0.887081
Epoch 77
Loss = 2.4756e-02, PNorm = 43.2677, GNorm = 0.2487, lr_0 = 4.2325e-04
Loss = 4.7847e-02, PNorm = 43.2907, GNorm = 0.9521, lr_0 = 4.2015e-04
Validation auc = 0.881196
Epoch 78
Loss = 2.3500e-02, PNorm = 43.3223, GNorm = 0.2752, lr_0 = 4.1677e-04
Validation auc = 0.877112
Epoch 79
Loss = 2.1288e-02, PNorm = 43.3535, GNorm = 0.4061, lr_0 = 4.1372e-04
Loss = 4.7645e-02, PNorm = 43.3840, GNorm = 0.6973, lr_0 = 4.1070e-04
Validation auc = 0.873788
Epoch 80
Loss = 2.5438e-02, PNorm = 43.4247, GNorm = 0.4467, lr_0 = 4.0739e-04
Loss = 4.4459e-02, PNorm = 43.4551, GNorm = 1.1354, lr_0 = 4.0441e-04
Validation auc = 0.887635
Epoch 81
Loss = 3.3554e-02, PNorm = 43.4809, GNorm = 0.2636, lr_0 = 4.0145e-04
Validation auc = 0.875173
Epoch 82
Loss = 2.4558e-02, PNorm = 43.5073, GNorm = 0.3601, lr_0 = 3.9822e-04
Loss = 3.1709e-02, PNorm = 43.5335, GNorm = 0.4936, lr_0 = 3.9531e-04
Validation auc = 0.888812
Epoch 83
Loss = 3.0951e-02, PNorm = 43.5527, GNorm = 0.1297, lr_0 = 3.9242e-04
Validation auc = 0.894558
Epoch 84
Loss = 7.3764e-02, PNorm = 43.5757, GNorm = 1.2954, lr_0 = 3.8955e-04
Loss = 5.3426e-02, PNorm = 43.6038, GNorm = 0.9948, lr_0 = 3.8670e-04
Validation auc = 0.880850
Epoch 85
Loss = 7.1082e-02, PNorm = 43.6351, GNorm = 2.6645, lr_0 = 3.8359e-04
Validation auc = 0.891443
Epoch 86
Loss = 1.7089e-02, PNorm = 43.6694, GNorm = 0.3976, lr_0 = 3.8078e-04
Loss = 4.8532e-02, PNorm = 43.6979, GNorm = 0.2610, lr_0 = 3.7800e-04
Validation auc = 0.873858
Epoch 87
Loss = 5.5682e-02, PNorm = 43.7315, GNorm = 1.2376, lr_0 = 3.7496e-04
Validation auc = 0.887081
Epoch 88
Loss = 6.1375e-02, PNorm = 43.7647, GNorm = 0.5665, lr_0 = 3.7221e-04
Loss = 3.0861e-02, PNorm = 43.7919, GNorm = 0.6262, lr_0 = 3.6949e-04
Validation auc = 0.878219
Epoch 89
Loss = 1.9124e-02, PNorm = 43.8150, GNorm = 0.2362, lr_0 = 3.6652e-04
Loss = 4.9657e-02, PNorm = 43.8351, GNorm = 0.5237, lr_0 = 3.6384e-04
Validation auc = 0.867281
Epoch 90
Loss = 2.7402e-02, PNorm = 43.8557, GNorm = 0.8140, lr_0 = 3.6117e-04
Validation auc = 0.884520
Epoch 91
Loss = 1.3004e-02, PNorm = 43.8801, GNorm = 0.1676, lr_0 = 3.5827e-04
Loss = 3.0846e-02, PNorm = 43.9051, GNorm = 1.0779, lr_0 = 3.5565e-04
Validation auc = 0.895389
Epoch 92
Loss = 3.1862e-02, PNorm = 43.9268, GNorm = 0.2648, lr_0 = 3.5305e-04
Validation auc = 0.889297
Epoch 93
Loss = 2.3088e-02, PNorm = 43.9492, GNorm = 0.4730, lr_0 = 3.5046e-04
Loss = 3.0881e-02, PNorm = 43.9721, GNorm = 0.6516, lr_0 = 3.4790e-04
Validation auc = 0.890335
Epoch 94
Loss = 4.7746e-02, PNorm = 43.9970, GNorm = 0.3254, lr_0 = 3.4510e-04
Validation auc = 0.892758
Epoch 95
Loss = 2.2168e-02, PNorm = 44.0142, GNorm = 0.2439, lr_0 = 3.4258e-04
Loss = 3.7379e-02, PNorm = 44.0341, GNorm = 0.1110, lr_0 = 3.4007e-04
Validation auc = 0.883481
Epoch 96
Loss = 3.4372e-02, PNorm = 44.0608, GNorm = 0.2756, lr_0 = 3.3733e-04
Validation auc = 0.871435
Epoch 97
Loss = 1.5946e-02, PNorm = 44.0824, GNorm = 0.3189, lr_0 = 3.3487e-04
Loss = 3.7170e-02, PNorm = 44.0985, GNorm = 0.5270, lr_0 = 3.3242e-04
Validation auc = 0.877527
Epoch 98
Loss = 4.4630e-02, PNorm = 44.1145, GNorm = 1.6226, lr_0 = 3.2974e-04
Loss = 2.5087e-02, PNorm = 44.1352, GNorm = 0.4427, lr_0 = 3.2733e-04
Validation auc = 0.889297
Epoch 99
Loss = 3.1245e-02, PNorm = 44.1494, GNorm = 0.5825, lr_0 = 3.2494e-04
Validation auc = 0.883343
Model 0 best validation auc = 0.897674 on epoch 3
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.890246
Ensemble test auc = 0.890246
Fold 5
Splitting data with seed 5
Total scaffolds = 1,025 | train scaffolds = 811 | val scaffolds = 109 | test scaffolds = 105
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 718
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8251e-01, PNorm = 35.0696, GNorm = 0.7468, lr_0 = 2.5469e-04
Validation auc = 0.953879
Epoch 1
Loss = 5.5491e-01, PNorm = 35.0895, GNorm = 0.8420, lr_0 = 4.0937e-04
Validation auc = 0.961037
Epoch 2
Loss = 5.3409e-01, PNorm = 35.1140, GNorm = 2.0035, lr_0 = 5.6406e-04
Loss = 4.4611e-01, PNorm = 35.1433, GNorm = 1.2027, lr_0 = 7.0469e-04
Validation auc = 0.966116
Epoch 3
Loss = 4.8597e-01, PNorm = 35.1712, GNorm = 0.7184, lr_0 = 8.4531e-04
Validation auc = 0.968714
Epoch 4
Loss = 5.1828e-01, PNorm = 35.2135, GNorm = 0.4462, lr_0 = 1.0000e-03
Loss = 4.4037e-01, PNorm = 35.2604, GNorm = 0.6189, lr_0 = 9.9268e-04
Validation auc = 0.972928
Epoch 5
Loss = 4.0954e-01, PNorm = 35.3214, GNorm = 0.3526, lr_0 = 9.8470e-04
Validation auc = 0.973794
Epoch 6
Loss = 3.7972e-01, PNorm = 35.3713, GNorm = 1.1252, lr_0 = 9.7750e-04
Loss = 3.8342e-01, PNorm = 35.4327, GNorm = 0.4470, lr_0 = 9.7034e-04
Loss = 3.0599e-01, PNorm = 35.4388, GNorm = 0.8601, lr_0 = 9.6963e-04
Validation auc = 0.972062
Epoch 7
Loss = 4.2119e-01, PNorm = 35.4990, GNorm = 1.9756, lr_0 = 9.6254e-04
Validation auc = 0.977892
Epoch 8
Loss = 3.9139e-01, PNorm = 35.5662, GNorm = 0.3792, lr_0 = 9.5480e-04
Validation auc = 0.974717
Epoch 9
Loss = 3.2002e-01, PNorm = 35.6335, GNorm = 0.3399, lr_0 = 9.4781e-04
Loss = 3.6442e-01, PNorm = 35.7103, GNorm = 0.9806, lr_0 = 9.4088e-04
Validation auc = 0.968079
Epoch 10
Loss = 3.3890e-01, PNorm = 35.7856, GNorm = 1.1208, lr_0 = 9.3331e-04
Validation auc = 0.967502
Epoch 11
Loss = 3.5482e-01, PNorm = 35.8661, GNorm = 0.4508, lr_0 = 9.2580e-04
Loss = 3.3270e-01, PNorm = 35.9485, GNorm = 0.6810, lr_0 = 9.1903e-04
Validation auc = 0.968541
Epoch 12
Loss = 3.5292e-01, PNorm = 36.0360, GNorm = 1.2933, lr_0 = 9.1231e-04
Validation auc = 0.968541
Epoch 13
Loss = 2.8886e-01, PNorm = 36.1270, GNorm = 0.3942, lr_0 = 9.0497e-04
Loss = 3.0740e-01, PNorm = 36.2161, GNorm = 0.3775, lr_0 = 8.9835e-04
Validation auc = 0.961325
Epoch 14
Loss = 2.9785e-01, PNorm = 36.3017, GNorm = 0.5388, lr_0 = 8.9177e-04
Validation auc = 0.966982
Epoch 15
Loss = 3.0376e-01, PNorm = 36.3996, GNorm = 1.1808, lr_0 = 8.8460e-04
Validation auc = 0.975237
Epoch 16
Loss = 2.9190e-01, PNorm = 36.5053, GNorm = 1.3563, lr_0 = 8.7749e-04
Loss = 2.9098e-01, PNorm = 36.6030, GNorm = 0.7336, lr_0 = 8.7107e-04
Validation auc = 0.958612
Epoch 17
Loss = 2.8384e-01, PNorm = 36.7013, GNorm = 0.6349, lr_0 = 8.6469e-04
Validation auc = 0.971427
Epoch 18
Loss = 2.1761e-01, PNorm = 36.8004, GNorm = 0.4896, lr_0 = 8.5774e-04
Loss = 2.7743e-01, PNorm = 36.8943, GNorm = 1.5302, lr_0 = 8.5146e-04
Validation auc = 0.962768
Epoch 19
Loss = 2.1215e-01, PNorm = 37.0073, GNorm = 0.5121, lr_0 = 8.4461e-04
Validation auc = 0.949607
Epoch 20
Loss = 1.6511e-01, PNorm = 37.1149, GNorm = 1.3541, lr_0 = 8.3843e-04
Loss = 2.5431e-01, PNorm = 37.2005, GNorm = 0.7775, lr_0 = 8.3230e-04
Validation auc = 0.950185
Epoch 21
Loss = 2.2982e-01, PNorm = 37.2954, GNorm = 0.6765, lr_0 = 8.2561e-04
Validation auc = 0.958151
Epoch 22
Loss = 2.1112e-01, PNorm = 37.3911, GNorm = 0.6769, lr_0 = 8.1896e-04
Loss = 2.1546e-01, PNorm = 37.4808, GNorm = 0.8801, lr_0 = 8.1297e-04
Validation auc = 0.953533
Epoch 23
Loss = 2.0897e-01, PNorm = 37.5815, GNorm = 0.8980, lr_0 = 8.0703e-04
Validation auc = 0.948568
Epoch 24
Loss = 2.1142e-01, PNorm = 37.6762, GNorm = 0.2940, lr_0 = 8.0053e-04
Validation auc = 0.958208
Epoch 25
Loss = 1.5558e-01, PNorm = 37.7569, GNorm = 0.5090, lr_0 = 7.9468e-04
Loss = 2.3428e-01, PNorm = 37.8518, GNorm = 0.8071, lr_0 = 7.8886e-04
Validation auc = 0.943258
Epoch 26
Loss = 2.2114e-01, PNorm = 37.9432, GNorm = 0.5236, lr_0 = 7.8252e-04
Validation auc = 0.965655
Epoch 27
Loss = 2.0023e-01, PNorm = 38.0313, GNorm = 0.4409, lr_0 = 7.7622e-04
Loss = 2.3667e-01, PNorm = 38.1211, GNorm = 0.7600, lr_0 = 7.7055e-04
Validation auc = 0.946086
Epoch 28
Loss = 1.8168e-01, PNorm = 38.2084, GNorm = 1.1121, lr_0 = 7.6491e-04
Validation auc = 0.961614
Epoch 29
Loss = 2.1114e-01, PNorm = 38.2834, GNorm = 1.4338, lr_0 = 7.5876e-04
Loss = 1.8409e-01, PNorm = 38.3634, GNorm = 1.4129, lr_0 = 7.5321e-04
Loss = 1.2451e-01, PNorm = 38.3709, GNorm = 0.7642, lr_0 = 7.5265e-04
Validation auc = 0.957458
Epoch 30
Loss = 1.5858e-01, PNorm = 38.4558, GNorm = 1.3057, lr_0 = 7.4715e-04
Validation auc = 0.923286
Epoch 31
Loss = 1.8503e-01, PNorm = 38.5430, GNorm = 0.6324, lr_0 = 7.4168e-04
Validation auc = 0.953244
Epoch 32
Loss = 1.2824e-01, PNorm = 38.6354, GNorm = 0.6998, lr_0 = 7.3571e-04
Loss = 1.8337e-01, PNorm = 38.7156, GNorm = 0.8979, lr_0 = 7.3033e-04
Validation auc = 0.932752
Epoch 33
Loss = 2.0822e-01, PNorm = 38.8090, GNorm = 0.4176, lr_0 = 7.2446e-04
Validation auc = 0.935177
Epoch 34
Loss = 1.6562e-01, PNorm = 38.8860, GNorm = 0.8226, lr_0 = 7.1916e-04
Loss = 1.7131e-01, PNorm = 38.9635, GNorm = 0.9061, lr_0 = 7.1390e-04
Validation auc = 0.957400
Epoch 35
Loss = 1.4457e-01, PNorm = 39.0573, GNorm = 0.4029, lr_0 = 7.0815e-04
Validation auc = 0.938582
Epoch 36
Loss = 1.1319e-01, PNorm = 39.1494, GNorm = 0.6747, lr_0 = 7.0246e-04
Loss = 1.1884e-01, PNorm = 39.2243, GNorm = 0.3669, lr_0 = 6.9732e-04
Validation auc = 0.938986
Epoch 37
Loss = 1.3366e-01, PNorm = 39.2860, GNorm = 1.0776, lr_0 = 6.9222e-04
Validation auc = 0.911164
Epoch 38
Loss = 1.6350e-01, PNorm = 39.3549, GNorm = 0.4214, lr_0 = 6.8665e-04
Loss = 1.3776e-01, PNorm = 39.4167, GNorm = 1.3496, lr_0 = 6.8163e-04
Validation auc = 0.951628
Epoch 39
Loss = 1.2930e-01, PNorm = 39.4854, GNorm = 0.6494, lr_0 = 6.7664e-04
Validation auc = 0.942565
Epoch 40
Loss = 1.4186e-01, PNorm = 39.5587, GNorm = 1.2655, lr_0 = 6.7120e-04
Validation auc = 0.932637
Epoch 41
Loss = 1.1461e-01, PNorm = 39.6364, GNorm = 0.9293, lr_0 = 6.6580e-04
Loss = 1.4148e-01, PNorm = 39.7163, GNorm = 1.3113, lr_0 = 6.6093e-04
Validation auc = 0.962480
Epoch 42
Loss = 1.2638e-01, PNorm = 39.7857, GNorm = 0.5067, lr_0 = 6.5609e-04
Validation auc = 0.938178
Epoch 43
Loss = 1.3280e-01, PNorm = 39.8554, GNorm = 0.7900, lr_0 = 6.5081e-04
Loss = 1.1971e-01, PNorm = 39.9178, GNorm = 1.0151, lr_0 = 6.4605e-04
Validation auc = 0.950877
Epoch 44
Loss = 1.1952e-01, PNorm = 39.9729, GNorm = 0.9404, lr_0 = 6.4086e-04
Validation auc = 0.944355
Epoch 45
Loss = 1.1290e-01, PNorm = 40.0295, GNorm = 0.9825, lr_0 = 6.3617e-04
Loss = 9.8240e-02, PNorm = 40.0963, GNorm = 0.6886, lr_0 = 6.3151e-04
Loss = 1.0921e-01, PNorm = 40.1027, GNorm = 1.4911, lr_0 = 6.3105e-04
Validation auc = 0.950589
Epoch 46
Loss = 1.0376e-01, PNorm = 40.1654, GNorm = 0.7167, lr_0 = 6.2643e-04
Validation auc = 0.941411
Epoch 47
Loss = 1.1530e-01, PNorm = 40.2358, GNorm = 1.4124, lr_0 = 6.2139e-04
Validation auc = 0.960286
Epoch 48
Loss = 9.7630e-02, PNorm = 40.2920, GNorm = 0.7086, lr_0 = 6.1685e-04
Loss = 1.2134e-01, PNorm = 40.3522, GNorm = 0.3860, lr_0 = 6.1234e-04
Validation auc = 0.936331
Epoch 49
Loss = 9.8392e-02, PNorm = 40.4219, GNorm = 0.5697, lr_0 = 6.0741e-04
Validation auc = 0.943893
Epoch 50
Loss = 4.9410e-02, PNorm = 40.4815, GNorm = 0.1693, lr_0 = 6.0297e-04
Loss = 9.7840e-02, PNorm = 40.5409, GNorm = 0.2180, lr_0 = 5.9856e-04
Validation auc = 0.945509
Epoch 51
Loss = 9.4826e-02, PNorm = 40.6054, GNorm = 0.6036, lr_0 = 5.9374e-04
Validation auc = 0.962018
Epoch 52
Loss = 1.0755e-01, PNorm = 40.6616, GNorm = 0.8539, lr_0 = 5.8896e-04
Loss = 9.4991e-02, PNorm = 40.7185, GNorm = 0.6813, lr_0 = 5.8466e-04
Validation auc = 0.941873
Epoch 53
Loss = 1.0524e-01, PNorm = 40.7755, GNorm = 0.5653, lr_0 = 5.8038e-04
Validation auc = 0.950589
Epoch 54
Loss = 7.8791e-02, PNorm = 40.8363, GNorm = 0.7598, lr_0 = 5.7571e-04
Validation auc = 0.949492
Epoch 55
Loss = 4.5198e-02, PNorm = 40.8904, GNorm = 0.5643, lr_0 = 5.7108e-04
Loss = 5.9639e-02, PNorm = 40.9375, GNorm = 0.6041, lr_0 = 5.6690e-04
Validation auc = 0.950127
Epoch 56
Loss = 1.0573e-01, PNorm = 40.9894, GNorm = 0.7409, lr_0 = 5.6275e-04
Validation auc = 0.940314
Epoch 57
Loss = 7.9726e-02, PNorm = 41.0413, GNorm = 0.6960, lr_0 = 5.5823e-04
Loss = 8.5413e-02, PNorm = 41.0918, GNorm = 0.7242, lr_0 = 5.5414e-04
Validation auc = 0.927499
Epoch 58
Loss = 6.3550e-02, PNorm = 41.1493, GNorm = 0.6654, lr_0 = 5.4969e-04
Validation auc = 0.954110
Epoch 59
Loss = 7.5486e-02, PNorm = 41.1997, GNorm = 0.9976, lr_0 = 5.4566e-04
Loss = 7.7130e-02, PNorm = 41.2514, GNorm = 1.2226, lr_0 = 5.4167e-04
Validation auc = 0.921785
Epoch 60
Loss = 6.6013e-02, PNorm = 41.3040, GNorm = 0.3950, lr_0 = 5.3732e-04
Validation auc = 0.942854
Epoch 61
Loss = 9.0269e-02, PNorm = 41.3654, GNorm = 0.6553, lr_0 = 5.3299e-04
Loss = 8.5365e-02, PNorm = 41.4134, GNorm = 0.6966, lr_0 = 5.2909e-04
Validation auc = 0.946837
Epoch 62
Loss = 8.0927e-02, PNorm = 41.4696, GNorm = 0.7196, lr_0 = 5.2522e-04
Validation auc = 0.935638
Epoch 63
Loss = 7.7603e-02, PNorm = 41.5254, GNorm = 1.8283, lr_0 = 5.2100e-04
Validation auc = 0.944932
Epoch 64
Loss = 5.9797e-02, PNorm = 41.5754, GNorm = 0.7155, lr_0 = 5.1719e-04
Loss = 5.1208e-02, PNorm = 41.6192, GNorm = 0.4272, lr_0 = 5.1340e-04
Validation auc = 0.954052
Epoch 65
Loss = 5.7457e-02, PNorm = 41.6577, GNorm = 0.4290, lr_0 = 5.0927e-04
Validation auc = 0.948568
Epoch 66
Loss = 8.7244e-02, PNorm = 41.6965, GNorm = 1.1867, lr_0 = 5.0518e-04
Loss = 4.4302e-02, PNorm = 41.7370, GNorm = 1.0928, lr_0 = 5.0148e-04
Validation auc = 0.947760
Epoch 67
Loss = 5.8831e-02, PNorm = 41.7810, GNorm = 0.9011, lr_0 = 4.9781e-04
Validation auc = 0.931540
Epoch 68
Loss = 5.3797e-02, PNorm = 41.8301, GNorm = 0.7261, lr_0 = 4.9381e-04
Loss = 6.0394e-02, PNorm = 41.8759, GNorm = 1.0978, lr_0 = 4.9020e-04
Loss = 1.6703e-01, PNorm = 41.8799, GNorm = 1.7504, lr_0 = 4.8984e-04
Validation auc = 0.944239
Epoch 69
Loss = 4.7924e-02, PNorm = 41.9183, GNorm = 0.5617, lr_0 = 4.8625e-04
Validation auc = 0.952436
Epoch 70
Loss = 6.9595e-02, PNorm = 41.9576, GNorm = 1.1753, lr_0 = 4.8270e-04
Validation auc = 0.939737
Epoch 71
Loss = 1.2140e-01, PNorm = 42.0091, GNorm = 1.1185, lr_0 = 4.7881e-04
Loss = 5.2859e-02, PNorm = 42.0412, GNorm = 0.2737, lr_0 = 4.7531e-04
Validation auc = 0.945163
Epoch 72
Loss = 3.5088e-02, PNorm = 42.0791, GNorm = 0.4986, lr_0 = 4.7149e-04
Validation auc = 0.941007
Epoch 73
Loss = 5.3539e-02, PNorm = 42.1136, GNorm = 0.7609, lr_0 = 4.6804e-04
Loss = 6.0971e-02, PNorm = 42.1476, GNorm = 1.3775, lr_0 = 4.6461e-04
Validation auc = 0.950647
Epoch 74
Loss = 7.8606e-02, PNorm = 42.1881, GNorm = 0.8184, lr_0 = 4.6088e-04
Validation auc = 0.943547
Epoch 75
Loss = 3.0874e-02, PNorm = 42.2131, GNorm = 0.4710, lr_0 = 4.5750e-04
Loss = 3.6494e-02, PNorm = 42.2395, GNorm = 0.1953, lr_0 = 4.5416e-04
Validation auc = 0.938005
Epoch 76
Loss = 7.1626e-02, PNorm = 42.2713, GNorm = 1.1674, lr_0 = 4.5050e-04
Validation auc = 0.939044
Epoch 77
Loss = 6.3362e-02, PNorm = 42.3083, GNorm = 0.6483, lr_0 = 4.4688e-04
Loss = 5.6106e-02, PNorm = 42.3435, GNorm = 0.6972, lr_0 = 4.4361e-04
Validation auc = 0.936620
Epoch 78
Loss = 7.0836e-02, PNorm = 42.3806, GNorm = 0.7096, lr_0 = 4.4037e-04
Validation auc = 0.943893
Epoch 79
Loss = 4.2502e-02, PNorm = 42.4202, GNorm = 0.3680, lr_0 = 4.3682e-04
Validation auc = 0.935638
Epoch 80
Loss = 5.4452e-02, PNorm = 42.4564, GNorm = 0.8483, lr_0 = 4.3331e-04
Loss = 4.1949e-02, PNorm = 42.4842, GNorm = 0.3158, lr_0 = 4.3014e-04
Validation auc = 0.946202
Epoch 81
Loss = 4.3222e-02, PNorm = 42.5093, GNorm = 0.9634, lr_0 = 4.2699e-04
Validation auc = 0.944297
Epoch 82
Loss = 6.7169e-02, PNorm = 42.5435, GNorm = 1.1242, lr_0 = 4.2356e-04
Loss = 5.5536e-02, PNorm = 42.5805, GNorm = 0.6062, lr_0 = 4.2046e-04
Validation auc = 0.943085
Epoch 83
Loss = 5.2352e-02, PNorm = 42.6153, GNorm = 0.3217, lr_0 = 4.1708e-04
Validation auc = 0.943720
Epoch 84
Loss = 6.2202e-02, PNorm = 42.6452, GNorm = 0.1133, lr_0 = 4.1403e-04
Loss = 7.3377e-02, PNorm = 42.6856, GNorm = 1.1763, lr_0 = 4.1100e-04
Loss = 4.3340e-02, PNorm = 42.6891, GNorm = 0.5570, lr_0 = 4.1070e-04
Validation auc = 0.952263
Epoch 85
Loss = 4.3443e-02, PNorm = 42.7224, GNorm = 0.4412, lr_0 = 4.0769e-04
Validation auc = 0.946260
Epoch 86
Loss = 5.7975e-02, PNorm = 42.7540, GNorm = 0.3447, lr_0 = 4.0441e-04
Validation auc = 0.948799
Epoch 87
Loss = 3.4218e-02, PNorm = 42.7803, GNorm = 0.6718, lr_0 = 4.0145e-04
Loss = 5.6100e-02, PNorm = 42.8134, GNorm = 0.7068, lr_0 = 3.9852e-04
Validation auc = 0.935581
Epoch 88
Loss = 5.2355e-02, PNorm = 42.8469, GNorm = 0.8574, lr_0 = 3.9531e-04
Validation auc = 0.945509
Epoch 89
Loss = 3.8426e-02, PNorm = 42.8742, GNorm = 0.1911, lr_0 = 3.9242e-04
Loss = 4.3039e-02, PNorm = 42.9045, GNorm = 2.8960, lr_0 = 3.8955e-04
Validation auc = 0.946317
Epoch 90
Loss = 4.6641e-02, PNorm = 42.9338, GNorm = 0.4248, lr_0 = 3.8641e-04
Validation auc = 0.961845
Epoch 91
Loss = 3.2698e-02, PNorm = 42.9610, GNorm = 0.4416, lr_0 = 3.8331e-04
Loss = 2.9143e-02, PNorm = 42.9833, GNorm = 0.3268, lr_0 = 3.8050e-04
Validation auc = 0.954803
Epoch 92
Loss = 4.9348e-02, PNorm = 43.0058, GNorm = 1.0084, lr_0 = 3.7772e-04
Validation auc = 0.949723
Epoch 93
Loss = 3.6107e-02, PNorm = 43.0273, GNorm = 0.1690, lr_0 = 3.7468e-04
Validation auc = 0.952725
Epoch 94
Loss = 2.7690e-02, PNorm = 43.0511, GNorm = 0.3110, lr_0 = 3.7167e-04
Loss = 4.0481e-02, PNorm = 43.0760, GNorm = 0.2115, lr_0 = 3.6895e-04
Validation auc = 0.939390
Epoch 95
Loss = 2.7909e-02, PNorm = 43.1018, GNorm = 0.5972, lr_0 = 3.6625e-04
Validation auc = 0.939044
Epoch 96
Loss = 2.1279e-02, PNorm = 43.1218, GNorm = 0.6888, lr_0 = 3.6330e-04
Loss = 2.6268e-02, PNorm = 43.1394, GNorm = 0.2159, lr_0 = 3.6064e-04
Validation auc = 0.942508
Epoch 97
Loss = 4.9061e-02, PNorm = 43.1590, GNorm = 0.8906, lr_0 = 3.5774e-04
Validation auc = 0.944759
Epoch 98
Loss = 2.0058e-02, PNorm = 43.1757, GNorm = 0.6186, lr_0 = 3.5513e-04
Loss = 3.1012e-02, PNorm = 43.1937, GNorm = 0.0533, lr_0 = 3.5253e-04
Validation auc = 0.951455
Epoch 99
Loss = 5.5385e-02, PNorm = 43.2148, GNorm = 1.0427, lr_0 = 3.4969e-04
Validation auc = 0.932695
Model 0 best validation auc = 0.977892 on epoch 7
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.893487
Ensemble test auc = 0.893487
Fold 6
Splitting data with seed 6
Total scaffolds = 1,025 | train scaffolds = 786 | val scaffolds = 128 | test scaffolds = 111
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 748
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7485e-01, PNorm = 35.0705, GNorm = 0.8107, lr_0 = 2.5469e-04
Validation auc = 0.802353
Epoch 1
Loss = 5.2496e-01, PNorm = 35.0902, GNorm = 0.6123, lr_0 = 4.0937e-04
Validation auc = 0.848758
Epoch 2
Loss = 3.8416e-01, PNorm = 35.1188, GNorm = 0.5323, lr_0 = 5.5000e-04
Loss = 4.6366e-01, PNorm = 35.1505, GNorm = 2.2412, lr_0 = 6.9063e-04
Validation auc = 0.878693
Epoch 3
Loss = 4.8582e-01, PNorm = 35.1830, GNorm = 0.4862, lr_0 = 8.3125e-04
Validation auc = 0.885621
Epoch 4
Loss = 5.0236e-01, PNorm = 35.2252, GNorm = 1.5284, lr_0 = 9.7187e-04
Loss = 3.9211e-01, PNorm = 35.2819, GNorm = 0.8617, lr_0 = 9.9414e-04
Validation auc = 0.897386
Epoch 5
Loss = 3.8243e-01, PNorm = 35.3470, GNorm = 0.8088, lr_0 = 9.8687e-04
Validation auc = 0.885490
Epoch 6
Loss = 5.1080e-01, PNorm = 35.4134, GNorm = 0.9713, lr_0 = 9.7965e-04
Loss = 3.8375e-01, PNorm = 35.4680, GNorm = 1.0312, lr_0 = 9.7248e-04
Validation auc = 0.903007
Epoch 7
Loss = 3.6604e-01, PNorm = 35.5210, GNorm = 0.7803, lr_0 = 9.6537e-04
Validation auc = 0.903268
Epoch 8
Loss = 3.1210e-01, PNorm = 35.5859, GNorm = 0.4567, lr_0 = 9.5831e-04
Loss = 3.0827e-01, PNorm = 35.6625, GNorm = 2.0937, lr_0 = 9.5130e-04
Validation auc = 0.909150
Epoch 9
Loss = 3.5422e-01, PNorm = 35.7245, GNorm = 0.4958, lr_0 = 9.4434e-04
Validation auc = 0.900915
Epoch 10
Loss = 2.1893e-01, PNorm = 35.7907, GNorm = 0.9521, lr_0 = 9.3743e-04
Loss = 3.2970e-01, PNorm = 35.8643, GNorm = 0.4194, lr_0 = 9.3057e-04
Validation auc = 0.903791
Epoch 11
Loss = 3.4349e-01, PNorm = 35.9357, GNorm = 1.0892, lr_0 = 9.2376e-04
Validation auc = 0.907712
Epoch 12
Loss = 3.1680e-01, PNorm = 36.0004, GNorm = 0.5408, lr_0 = 9.1701e-04
Loss = 3.0299e-01, PNorm = 36.0767, GNorm = 0.5356, lr_0 = 9.1030e-04
Validation auc = 0.911111
Epoch 13
Loss = 3.1503e-01, PNorm = 36.1570, GNorm = 0.3956, lr_0 = 9.0364e-04
Validation auc = 0.913464
Epoch 14
Loss = 2.3617e-01, PNorm = 36.2439, GNorm = 0.6577, lr_0 = 8.9703e-04
Loss = 2.8697e-01, PNorm = 36.3464, GNorm = 0.8669, lr_0 = 8.9047e-04
Validation auc = 0.913203
Epoch 15
Loss = 2.8667e-01, PNorm = 36.4383, GNorm = 0.4044, lr_0 = 8.8395e-04
Validation auc = 0.903922
Epoch 16
Loss = 2.3716e-01, PNorm = 36.5222, GNorm = 0.4209, lr_0 = 8.7749e-04
Loss = 2.7952e-01, PNorm = 36.6091, GNorm = 1.1016, lr_0 = 8.7107e-04
Validation auc = 0.918039
Epoch 17
Loss = 2.8713e-01, PNorm = 36.7063, GNorm = 0.5398, lr_0 = 8.6469e-04
Validation auc = 0.912680
Epoch 18
Loss = 2.5668e-01, PNorm = 36.7840, GNorm = 0.4444, lr_0 = 8.5837e-04
Loss = 2.5771e-01, PNorm = 36.8783, GNorm = 0.7379, lr_0 = 8.5209e-04
Validation auc = 0.913987
Epoch 19
Loss = 2.1821e-01, PNorm = 36.9883, GNorm = 0.6744, lr_0 = 8.4585e-04
Validation auc = 0.914510
Epoch 20
Loss = 1.2156e-01, PNorm = 37.0959, GNorm = 0.7619, lr_0 = 8.3967e-04
Loss = 2.6530e-01, PNorm = 37.1959, GNorm = 0.4749, lr_0 = 8.3352e-04
Validation auc = 0.911373
Epoch 21
Loss = 2.7787e-01, PNorm = 37.2974, GNorm = 0.6293, lr_0 = 8.2743e-04
Validation auc = 0.918170
Epoch 22
Loss = 2.5566e-01, PNorm = 37.4008, GNorm = 0.9836, lr_0 = 8.2137e-04
Loss = 2.4115e-01, PNorm = 37.5020, GNorm = 0.4957, lr_0 = 8.1536e-04
Validation auc = 0.919216
Epoch 23
Loss = 2.6059e-01, PNorm = 37.6050, GNorm = 1.3548, lr_0 = 8.0940e-04
Validation auc = 0.914510
Epoch 24
Loss = 2.3161e-01, PNorm = 37.6926, GNorm = 0.7209, lr_0 = 8.0348e-04
Loss = 2.1966e-01, PNorm = 37.7839, GNorm = 0.4445, lr_0 = 7.9760e-04
Validation auc = 0.913333
Epoch 25
Loss = 1.7925e-01, PNorm = 37.8762, GNorm = 0.4143, lr_0 = 7.9177e-04
Validation auc = 0.919608
Epoch 26
Loss = 2.5870e-01, PNorm = 37.9754, GNorm = 0.8326, lr_0 = 7.8540e-04
Loss = 1.9916e-01, PNorm = 38.0906, GNorm = 0.5617, lr_0 = 7.7965e-04
Validation auc = 0.920000
Epoch 27
Loss = 1.9682e-01, PNorm = 38.2026, GNorm = 0.4265, lr_0 = 7.7395e-04
Validation auc = 0.912157
Epoch 28
Loss = 2.0427e-01, PNorm = 38.3026, GNorm = 0.7138, lr_0 = 7.6829e-04
Loss = 1.6988e-01, PNorm = 38.3883, GNorm = 0.5381, lr_0 = 7.6267e-04
Validation auc = 0.910327
Epoch 29
Loss = 2.0535e-01, PNorm = 38.5004, GNorm = 0.3503, lr_0 = 7.5709e-04
Validation auc = 0.923399
Epoch 30
Loss = 1.5246e-01, PNorm = 38.6016, GNorm = 0.3803, lr_0 = 7.5155e-04
Loss = 1.8212e-01, PNorm = 38.7033, GNorm = 0.8496, lr_0 = 7.4605e-04
Validation auc = 0.917647
Epoch 31
Loss = 1.3760e-01, PNorm = 38.7981, GNorm = 0.5452, lr_0 = 7.4059e-04
Validation auc = 0.908627
Epoch 32
Loss = 1.5850e-01, PNorm = 38.8921, GNorm = 1.3490, lr_0 = 7.3517e-04
Loss = 1.6601e-01, PNorm = 38.9782, GNorm = 0.9160, lr_0 = 7.2980e-04
Validation auc = 0.923922
Epoch 33
Loss = 1.8109e-01, PNorm = 39.0725, GNorm = 0.4020, lr_0 = 7.2446e-04
Validation auc = 0.921176
Epoch 34
Loss = 2.0188e-01, PNorm = 39.1627, GNorm = 1.0355, lr_0 = 7.1916e-04
Loss = 1.4334e-01, PNorm = 39.2622, GNorm = 0.6282, lr_0 = 7.1390e-04
Validation auc = 0.918562
Epoch 35
Loss = 1.2992e-01, PNorm = 39.3501, GNorm = 0.6313, lr_0 = 7.0867e-04
Validation auc = 0.908366
Epoch 36
Loss = 1.5929e-01, PNorm = 39.4416, GNorm = 1.0125, lr_0 = 7.0349e-04
Loss = 1.4042e-01, PNorm = 39.5157, GNorm = 1.4575, lr_0 = 6.9834e-04
Validation auc = 0.922353
Epoch 37
Loss = 1.3439e-01, PNorm = 39.6133, GNorm = 0.6533, lr_0 = 6.9323e-04
Validation auc = 0.909804
Epoch 38
Loss = 1.3443e-01, PNorm = 39.6850, GNorm = 0.4318, lr_0 = 6.8816e-04
Loss = 1.4379e-01, PNorm = 39.7719, GNorm = 0.5871, lr_0 = 6.8313e-04
Validation auc = 0.912026
Epoch 39
Loss = 9.2262e-02, PNorm = 39.8565, GNorm = 0.4834, lr_0 = 6.7813e-04
Validation auc = 0.909804
Epoch 40
Loss = 1.3792e-01, PNorm = 39.9410, GNorm = 1.0482, lr_0 = 6.7317e-04
Loss = 1.3965e-01, PNorm = 40.0186, GNorm = 0.7333, lr_0 = 6.6825e-04
Validation auc = 0.922353
Epoch 41
Loss = 1.2859e-01, PNorm = 40.1047, GNorm = 0.9266, lr_0 = 6.6336e-04
Validation auc = 0.904706
Epoch 42
Loss = 1.3746e-01, PNorm = 40.1833, GNorm = 1.1038, lr_0 = 6.5850e-04
Loss = 1.2105e-01, PNorm = 40.2599, GNorm = 3.4102, lr_0 = 6.5369e-04
Validation auc = 0.925359
Epoch 43
Loss = 1.4459e-01, PNorm = 40.3326, GNorm = 1.1935, lr_0 = 6.4891e-04
Validation auc = 0.915948
Epoch 44
Loss = 1.0350e-01, PNorm = 40.4061, GNorm = 0.8643, lr_0 = 6.4416e-04
Loss = 1.1132e-01, PNorm = 40.4775, GNorm = 0.7642, lr_0 = 6.3945e-04
Validation auc = 0.915033
Epoch 45
Loss = 1.1242e-01, PNorm = 40.5565, GNorm = 1.1976, lr_0 = 6.3477e-04
Validation auc = 0.921176
Epoch 46
Loss = 1.1048e-01, PNorm = 40.6285, GNorm = 1.0387, lr_0 = 6.3012e-04
Loss = 1.0553e-01, PNorm = 40.6948, GNorm = 1.3130, lr_0 = 6.2551e-04
Validation auc = 0.917516
Epoch 47
Loss = 8.2432e-02, PNorm = 40.7742, GNorm = 0.6311, lr_0 = 6.2094e-04
Validation auc = 0.914641
Epoch 48
Loss = 9.7182e-02, PNorm = 40.8435, GNorm = 0.8369, lr_0 = 6.1640e-04
Loss = 1.0803e-01, PNorm = 40.9030, GNorm = 0.8228, lr_0 = 6.1189e-04
Validation auc = 0.912418
Epoch 49
Loss = 7.5309e-02, PNorm = 40.9732, GNorm = 0.4150, lr_0 = 6.0741e-04
Validation auc = 0.919477
Epoch 50
Loss = 6.7878e-02, PNorm = 41.0390, GNorm = 0.9525, lr_0 = 6.0297e-04
Loss = 9.9526e-02, PNorm = 41.1046, GNorm = 0.6369, lr_0 = 5.9856e-04
Validation auc = 0.916732
Epoch 51
Loss = 8.7158e-02, PNorm = 41.1801, GNorm = 0.4395, lr_0 = 5.9374e-04
Validation auc = 0.911503
Epoch 52
Loss = 8.4339e-02, PNorm = 41.2451, GNorm = 1.4010, lr_0 = 5.8940e-04
Loss = 1.0285e-01, PNorm = 41.3134, GNorm = 2.4193, lr_0 = 5.8509e-04
Validation auc = 0.906667
Epoch 53
Loss = 1.5194e-01, PNorm = 41.3747, GNorm = 3.0677, lr_0 = 5.8081e-04
Validation auc = 0.918954
Epoch 54
Loss = 8.5327e-02, PNorm = 41.4399, GNorm = 0.3295, lr_0 = 5.7656e-04
Loss = 1.0983e-01, PNorm = 41.4959, GNorm = 0.5316, lr_0 = 5.7234e-04
Validation auc = 0.915033
Epoch 55
Loss = 6.4511e-02, PNorm = 41.5511, GNorm = 0.5271, lr_0 = 5.6815e-04
Validation auc = 0.919869
Epoch 56
Loss = 9.4290e-02, PNorm = 41.6091, GNorm = 0.8195, lr_0 = 5.6400e-04
Loss = 7.8588e-02, PNorm = 41.6565, GNorm = 0.5752, lr_0 = 5.5987e-04
Validation auc = 0.913987
Epoch 57
Loss = 6.4802e-02, PNorm = 41.7047, GNorm = 0.5028, lr_0 = 5.5577e-04
Validation auc = 0.917647
Epoch 58
Loss = 2.8096e-02, PNorm = 41.7514, GNorm = 0.2302, lr_0 = 5.5171e-04
Loss = 6.7619e-02, PNorm = 41.7986, GNorm = 0.2996, lr_0 = 5.4767e-04
Validation auc = 0.915294
Epoch 59
Loss = 5.5863e-02, PNorm = 41.8458, GNorm = 0.3368, lr_0 = 5.4367e-04
Validation auc = 0.914902
Epoch 60
Loss = 3.7862e-02, PNorm = 41.8954, GNorm = 0.3118, lr_0 = 5.3969e-04
Loss = 5.7999e-02, PNorm = 41.9298, GNorm = 0.8412, lr_0 = 5.3574e-04
Validation auc = 0.920261
Epoch 61
Loss = 5.2796e-02, PNorm = 41.9672, GNorm = 0.2337, lr_0 = 5.3182e-04
Validation auc = 0.920915
Epoch 62
Loss = 5.1683e-02, PNorm = 42.0135, GNorm = 0.6179, lr_0 = 5.2793e-04
Loss = 6.3977e-02, PNorm = 42.0624, GNorm = 0.9809, lr_0 = 5.2407e-04
Validation auc = 0.906275
Epoch 63
Loss = 6.3034e-02, PNorm = 42.1169, GNorm = 0.5035, lr_0 = 5.2023e-04
Validation auc = 0.910327
Epoch 64
Loss = 2.6869e-02, PNorm = 42.1531, GNorm = 0.5155, lr_0 = 5.1643e-04
Loss = 6.6461e-02, PNorm = 42.1842, GNorm = 0.1099, lr_0 = 5.1265e-04
Validation auc = 0.917124
Epoch 65
Loss = 6.5582e-02, PNorm = 42.2262, GNorm = 0.2251, lr_0 = 5.0890e-04
Validation auc = 0.910458
Epoch 66
Loss = 3.4187e-02, PNorm = 42.2685, GNorm = 0.3604, lr_0 = 5.0518e-04
Loss = 7.6992e-02, PNorm = 42.3153, GNorm = 0.4108, lr_0 = 5.0148e-04
Validation auc = 0.918824
Epoch 67
Loss = 6.9869e-02, PNorm = 42.3559, GNorm = 0.8508, lr_0 = 4.9781e-04
Validation auc = 0.901961
Epoch 68
Loss = 7.1440e-02, PNorm = 42.3998, GNorm = 0.6608, lr_0 = 4.9417e-04
Loss = 6.6284e-02, PNorm = 42.4431, GNorm = 0.5801, lr_0 = 4.9056e-04
Validation auc = 0.914510
Epoch 69
Loss = 4.7965e-02, PNorm = 42.4832, GNorm = 0.3201, lr_0 = 4.8697e-04
Validation auc = 0.902614
Epoch 70
Loss = 3.8302e-02, PNorm = 42.5192, GNorm = 0.7041, lr_0 = 4.8341e-04
Loss = 6.6646e-02, PNorm = 42.5618, GNorm = 0.3635, lr_0 = 4.7987e-04
Validation auc = 0.911765
Epoch 71
Loss = 5.5664e-02, PNorm = 42.6027, GNorm = 0.6493, lr_0 = 4.7636e-04
Validation auc = 0.909673
Epoch 72
Loss = 4.6394e-02, PNorm = 42.6434, GNorm = 0.9063, lr_0 = 4.7287e-04
Loss = 5.5073e-02, PNorm = 42.6819, GNorm = 0.7507, lr_0 = 4.6941e-04
Validation auc = 0.909935
Epoch 73
Loss = 5.5340e-02, PNorm = 42.7255, GNorm = 0.1640, lr_0 = 4.6598e-04
Validation auc = 0.914902
Epoch 74
Loss = 5.7918e-02, PNorm = 42.7612, GNorm = 0.4685, lr_0 = 4.6257e-04
Loss = 3.5825e-02, PNorm = 42.7938, GNorm = 0.3365, lr_0 = 4.5919e-04
Validation auc = 0.919869
Epoch 75
Loss = 3.2953e-02, PNorm = 42.8253, GNorm = 0.3988, lr_0 = 4.5583e-04
Validation auc = 0.919477
Epoch 76
Loss = 5.1738e-02, PNorm = 42.8703, GNorm = 1.3549, lr_0 = 4.5216e-04
Loss = 8.9231e-02, PNorm = 42.9128, GNorm = 1.5010, lr_0 = 4.4885e-04
Validation auc = 0.908627
Epoch 77
Loss = 5.1144e-02, PNorm = 42.9501, GNorm = 0.6921, lr_0 = 4.4557e-04
Validation auc = 0.908366
Epoch 78
Loss = 2.3672e-02, PNorm = 42.9834, GNorm = 0.4931, lr_0 = 4.4231e-04
Loss = 5.7941e-02, PNorm = 43.0279, GNorm = 0.6548, lr_0 = 4.3907e-04
Validation auc = 0.915163
Epoch 79
Loss = 5.5624e-02, PNorm = 43.0588, GNorm = 0.9124, lr_0 = 4.3586e-04
Validation auc = 0.918693
Epoch 80
Loss = 5.7527e-02, PNorm = 43.0821, GNorm = 0.2435, lr_0 = 4.3267e-04
Loss = 5.6390e-02, PNorm = 43.1103, GNorm = 1.3556, lr_0 = 4.2951e-04
Validation auc = 0.911895
Epoch 81
Loss = 3.7501e-02, PNorm = 43.1369, GNorm = 0.5165, lr_0 = 4.2637e-04
Validation auc = 0.918170
Epoch 82
Loss = 4.7010e-02, PNorm = 43.1627, GNorm = 0.4125, lr_0 = 4.2325e-04
Loss = 3.2056e-02, PNorm = 43.1874, GNorm = 0.4472, lr_0 = 4.2015e-04
Validation auc = 0.918301
Epoch 83
Loss = 4.4628e-02, PNorm = 43.2151, GNorm = 0.5184, lr_0 = 4.1708e-04
Validation auc = 0.910915
Epoch 84
Loss = 3.6245e-02, PNorm = 43.2365, GNorm = 0.3973, lr_0 = 4.1403e-04
Loss = 4.2504e-02, PNorm = 43.2622, GNorm = 0.4621, lr_0 = 4.1100e-04
Validation auc = 0.916209
Epoch 85
Loss = 4.5736e-02, PNorm = 43.2926, GNorm = 0.8413, lr_0 = 4.0799e-04
Validation auc = 0.909412
Epoch 86
Loss = 4.2904e-02, PNorm = 43.3150, GNorm = 0.7208, lr_0 = 4.0501e-04
Loss = 4.1676e-02, PNorm = 43.3417, GNorm = 0.4510, lr_0 = 4.0204e-04
Validation auc = 0.915948
Epoch 87
Loss = 3.0886e-02, PNorm = 43.3745, GNorm = 1.3082, lr_0 = 3.9910e-04
Validation auc = 0.914641
Epoch 88
Loss = 4.2887e-02, PNorm = 43.4056, GNorm = 0.6100, lr_0 = 3.9618e-04
Loss = 3.5503e-02, PNorm = 43.4341, GNorm = 0.7794, lr_0 = 3.9328e-04
Validation auc = 0.908497
Epoch 89
Loss = 3.7704e-02, PNorm = 43.4635, GNorm = 0.5205, lr_0 = 3.9041e-04
Validation auc = 0.913856
Epoch 90
Loss = 5.0950e-02, PNorm = 43.4827, GNorm = 1.2569, lr_0 = 3.8755e-04
Loss = 3.9458e-02, PNorm = 43.5110, GNorm = 0.6801, lr_0 = 3.8472e-04
Validation auc = 0.915948
Epoch 91
Loss = 4.1553e-02, PNorm = 43.5447, GNorm = 0.4505, lr_0 = 3.8190e-04
Validation auc = 0.914510
Epoch 92
Loss = 3.3969e-02, PNorm = 43.5621, GNorm = 1.2591, lr_0 = 3.7911e-04
Loss = 2.9876e-02, PNorm = 43.5829, GNorm = 0.1422, lr_0 = 3.7633e-04
Validation auc = 0.909281
Epoch 93
Loss = 6.1909e-02, PNorm = 43.6131, GNorm = 0.8445, lr_0 = 3.7358e-04
Validation auc = 0.919085
Epoch 94
Loss = 1.9002e-02, PNorm = 43.6356, GNorm = 0.2432, lr_0 = 3.7085e-04
Loss = 4.8398e-02, PNorm = 43.6619, GNorm = 0.2122, lr_0 = 3.6814e-04
Validation auc = 0.908105
Epoch 95
Loss = 3.7438e-02, PNorm = 43.6852, GNorm = 1.2530, lr_0 = 3.6544e-04
Validation auc = 0.900392
Epoch 96
Loss = 4.7943e-02, PNorm = 43.7110, GNorm = 0.5840, lr_0 = 3.6277e-04
Loss = 2.7367e-02, PNorm = 43.7328, GNorm = 0.2656, lr_0 = 3.6012e-04
Validation auc = 0.912810
Epoch 97
Loss = 2.9463e-02, PNorm = 43.7563, GNorm = 1.2030, lr_0 = 3.5748e-04
Validation auc = 0.907190
Epoch 98
Loss = 2.6860e-02, PNorm = 43.7748, GNorm = 0.2519, lr_0 = 3.5487e-04
Loss = 2.9004e-02, PNorm = 43.7959, GNorm = 0.4187, lr_0 = 3.5227e-04
Validation auc = 0.916863
Epoch 99
Loss = 2.4257e-02, PNorm = 43.8136, GNorm = 0.2330, lr_0 = 3.4969e-04
Validation auc = 0.916209
Model 0 best validation auc = 0.925359 on epoch 42
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.881697
Ensemble test auc = 0.881697
Fold 7
Splitting data with seed 7
Total scaffolds = 1,025 | train scaffolds = 843 | val scaffolds = 123 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 814
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7304e-01, PNorm = 35.0703, GNorm = 0.6263, lr_0 = 2.5469e-04
Validation auc = 0.887659
Epoch 1
Loss = 5.3554e-01, PNorm = 35.0933, GNorm = 1.1034, lr_0 = 4.0937e-04
Loss = 4.5947e-01, PNorm = 35.1227, GNorm = 0.4852, lr_0 = 5.5000e-04
Validation auc = 0.896451
Epoch 2
Loss = 4.2376e-01, PNorm = 35.1608, GNorm = 2.2761, lr_0 = 7.0469e-04
Validation auc = 0.909313
Epoch 3
Loss = 3.9836e-01, PNorm = 35.1874, GNorm = 0.3809, lr_0 = 8.5938e-04
Loss = 4.4445e-01, PNorm = 35.2214, GNorm = 1.2261, lr_0 = 1.0000e-03
Validation auc = 0.913058
Epoch 4
Loss = 4.5130e-01, PNorm = 35.2674, GNorm = 0.5864, lr_0 = 9.9268e-04
Loss = 4.2513e-01, PNorm = 35.3170, GNorm = 1.2103, lr_0 = 9.8542e-04
Validation auc = 0.920221
Epoch 5
Loss = 3.8105e-01, PNorm = 35.3683, GNorm = 1.0316, lr_0 = 9.7750e-04
Validation auc = 0.923966
Epoch 6
Loss = 4.8154e-01, PNorm = 35.4214, GNorm = 0.9399, lr_0 = 9.6963e-04
Loss = 4.0193e-01, PNorm = 35.4739, GNorm = 0.7741, lr_0 = 9.6254e-04
Validation auc = 0.927060
Epoch 7
Loss = 4.1183e-01, PNorm = 35.5280, GNorm = 0.4836, lr_0 = 9.5480e-04
Loss = 3.5629e-01, PNorm = 35.5865, GNorm = 0.9158, lr_0 = 9.4781e-04
Validation auc = 0.928362
Epoch 8
Loss = 3.7127e-01, PNorm = 35.6524, GNorm = 0.7667, lr_0 = 9.4088e-04
Validation auc = 0.936340
Epoch 9
Loss = 3.8460e-01, PNorm = 35.7164, GNorm = 1.1331, lr_0 = 9.3331e-04
Loss = 3.5908e-01, PNorm = 35.7748, GNorm = 0.5671, lr_0 = 9.2648e-04
Validation auc = 0.931944
Epoch 10
Loss = 3.9291e-01, PNorm = 35.8471, GNorm = 1.0867, lr_0 = 9.1903e-04
Validation auc = 0.931944
Epoch 11
Loss = 2.9756e-01, PNorm = 35.9102, GNorm = 0.3658, lr_0 = 9.1231e-04
Loss = 3.6326e-01, PNorm = 35.9746, GNorm = 0.8525, lr_0 = 9.0563e-04
Validation auc = 0.932432
Epoch 12
Loss = 4.3001e-01, PNorm = 36.0528, GNorm = 1.7597, lr_0 = 8.9835e-04
Loss = 3.4848e-01, PNorm = 36.1317, GNorm = 0.6142, lr_0 = 8.9177e-04
Validation auc = 0.929502
Epoch 13
Loss = 3.6058e-01, PNorm = 36.2097, GNorm = 0.5824, lr_0 = 8.8460e-04
Validation auc = 0.937154
Epoch 14
Loss = 3.4951e-01, PNorm = 36.2875, GNorm = 0.7756, lr_0 = 8.7749e-04
Loss = 3.3917e-01, PNorm = 36.3534, GNorm = 1.0872, lr_0 = 8.7107e-04
Validation auc = 0.938945
Epoch 15
Loss = 3.2730e-01, PNorm = 36.4188, GNorm = 0.4238, lr_0 = 8.6469e-04
Loss = 3.2738e-01, PNorm = 36.4983, GNorm = 0.3671, lr_0 = 8.5837e-04
Loss = 3.5462e-01, PNorm = 36.5073, GNorm = 1.3153, lr_0 = 8.5774e-04
Validation auc = 0.930641
Epoch 16
Loss = 3.2850e-01, PNorm = 36.6053, GNorm = 0.4911, lr_0 = 8.5146e-04
Validation auc = 0.944806
Epoch 17
Loss = 2.6902e-01, PNorm = 36.7066, GNorm = 0.4601, lr_0 = 8.4461e-04
Loss = 2.9505e-01, PNorm = 36.7971, GNorm = 0.8109, lr_0 = 8.3843e-04
Validation auc = 0.935200
Epoch 18
Loss = 2.9511e-01, PNorm = 36.8868, GNorm = 1.0400, lr_0 = 8.3230e-04
Validation auc = 0.937968
Epoch 19
Loss = 1.6987e-01, PNorm = 36.9797, GNorm = 0.6141, lr_0 = 8.2561e-04
Loss = 2.8283e-01, PNorm = 37.0723, GNorm = 0.7766, lr_0 = 8.1957e-04
Validation auc = 0.941224
Epoch 20
Loss = 2.5738e-01, PNorm = 37.1703, GNorm = 1.0704, lr_0 = 8.1297e-04
Loss = 3.1516e-01, PNorm = 37.2760, GNorm = 0.6429, lr_0 = 8.0703e-04
Validation auc = 0.941713
Epoch 21
Loss = 2.4887e-01, PNorm = 37.3779, GNorm = 0.3669, lr_0 = 8.0053e-04
Validation auc = 0.943667
Epoch 22
Loss = 2.3373e-01, PNorm = 37.4686, GNorm = 0.6840, lr_0 = 7.9468e-04
Loss = 2.3654e-01, PNorm = 37.5673, GNorm = 0.8542, lr_0 = 7.8886e-04
Validation auc = 0.943667
Epoch 23
Loss = 2.4818e-01, PNorm = 37.6635, GNorm = 0.9099, lr_0 = 7.8252e-04
Loss = 2.9542e-01, PNorm = 37.7564, GNorm = 0.5932, lr_0 = 7.7679e-04
Loss = 2.0209e-01, PNorm = 37.7666, GNorm = 0.6737, lr_0 = 7.7622e-04
Validation auc = 0.936666
Epoch 24
Loss = 2.7904e-01, PNorm = 37.8657, GNorm = 0.4238, lr_0 = 7.7055e-04
Validation auc = 0.958971
Epoch 25
Loss = 2.8722e-01, PNorm = 37.9618, GNorm = 0.5041, lr_0 = 7.6491e-04
Loss = 2.3205e-01, PNorm = 38.0571, GNorm = 0.8790, lr_0 = 7.5931e-04
Validation auc = 0.941224
Epoch 26
Loss = 2.2570e-01, PNorm = 38.1474, GNorm = 0.4707, lr_0 = 7.5321e-04
Validation auc = 0.948063
Epoch 27
Loss = 1.9711e-01, PNorm = 38.2513, GNorm = 0.4931, lr_0 = 7.4715e-04
Loss = 1.9980e-01, PNorm = 38.3473, GNorm = 0.6947, lr_0 = 7.4168e-04
Validation auc = 0.947900
Epoch 28
Loss = 2.6857e-01, PNorm = 38.4443, GNorm = 1.3542, lr_0 = 7.3571e-04
Loss = 2.0910e-01, PNorm = 38.5266, GNorm = 0.3522, lr_0 = 7.3033e-04
Validation auc = 0.949039
Epoch 29
Loss = 2.2496e-01, PNorm = 38.6258, GNorm = 0.6596, lr_0 = 7.2499e-04
Validation auc = 0.951807
Epoch 30
Loss = 1.1736e-01, PNorm = 38.7230, GNorm = 0.3940, lr_0 = 7.1916e-04
Loss = 1.9448e-01, PNorm = 38.8240, GNorm = 0.4492, lr_0 = 7.1390e-04
Validation auc = 0.949853
Epoch 31
Loss = 2.2874e-01, PNorm = 38.9097, GNorm = 1.2890, lr_0 = 7.0815e-04
Loss = 1.7952e-01, PNorm = 39.0022, GNorm = 0.6681, lr_0 = 7.0297e-04
Loss = 6.8760e-02, PNorm = 39.0115, GNorm = 0.6803, lr_0 = 7.0246e-04
Validation auc = 0.944155
Epoch 32
Loss = 1.8617e-01, PNorm = 39.0906, GNorm = 0.9421, lr_0 = 6.9732e-04
Validation auc = 0.954249
Epoch 33
Loss = 2.2704e-01, PNorm = 39.1709, GNorm = 1.4603, lr_0 = 6.9222e-04
Loss = 1.7436e-01, PNorm = 39.2592, GNorm = 0.5820, lr_0 = 6.8715e-04
Validation auc = 0.945132
Epoch 34
Loss = 1.8604e-01, PNorm = 39.3601, GNorm = 0.9800, lr_0 = 6.8163e-04
Validation auc = 0.954901
Epoch 35
Loss = 1.0931e-01, PNorm = 39.4607, GNorm = 0.4842, lr_0 = 6.7614e-04
Loss = 1.6163e-01, PNorm = 39.5519, GNorm = 1.1337, lr_0 = 6.7120e-04
Validation auc = 0.948225
Epoch 36
Loss = 1.5262e-01, PNorm = 39.6148, GNorm = 0.8545, lr_0 = 6.6629e-04
Loss = 1.8249e-01, PNorm = 39.6837, GNorm = 0.9841, lr_0 = 6.6141e-04
Validation auc = 0.944318
Epoch 37
Loss = 1.5460e-01, PNorm = 39.7629, GNorm = 0.5098, lr_0 = 6.5609e-04
Validation auc = 0.954412
Epoch 38
Loss = 1.4168e-01, PNorm = 39.8521, GNorm = 1.2674, lr_0 = 6.5081e-04
Loss = 1.5451e-01, PNorm = 39.9398, GNorm = 0.6636, lr_0 = 6.4605e-04
Validation auc = 0.933084
Epoch 39
Loss = 1.7739e-01, PNorm = 40.0278, GNorm = 0.9719, lr_0 = 6.4086e-04
Loss = 1.5277e-01, PNorm = 40.1069, GNorm = 0.5368, lr_0 = 6.3617e-04
Validation auc = 0.947411
Epoch 40
Loss = 1.5385e-01, PNorm = 40.1920, GNorm = 0.9758, lr_0 = 6.3151e-04
Validation auc = 0.953110
Epoch 41
Loss = 1.4606e-01, PNorm = 40.2607, GNorm = 0.9206, lr_0 = 6.2643e-04
Loss = 1.3842e-01, PNorm = 40.3389, GNorm = 0.8464, lr_0 = 6.2185e-04
Validation auc = 0.941876
Epoch 42
Loss = 1.4520e-01, PNorm = 40.4222, GNorm = 1.4470, lr_0 = 6.1685e-04
Loss = 1.1834e-01, PNorm = 40.4942, GNorm = 1.0073, lr_0 = 6.1234e-04
Validation auc = 0.950993
Epoch 43
Loss = 1.5895e-01, PNorm = 40.5671, GNorm = 1.0842, lr_0 = 6.0786e-04
Validation auc = 0.944969
Epoch 44
Loss = 9.9702e-02, PNorm = 40.6418, GNorm = 1.5046, lr_0 = 6.0297e-04
Loss = 1.2227e-01, PNorm = 40.7131, GNorm = 0.7311, lr_0 = 5.9856e-04
Validation auc = 0.943341
Epoch 45
Loss = 1.2117e-01, PNorm = 40.7935, GNorm = 0.7917, lr_0 = 5.9374e-04
Validation auc = 0.934223
Epoch 46
Loss = 8.8155e-02, PNorm = 40.8784, GNorm = 0.3836, lr_0 = 5.8896e-04
Loss = 1.2695e-01, PNorm = 40.9398, GNorm = 0.4533, lr_0 = 5.8466e-04
Validation auc = 0.933084
Epoch 47
Loss = 1.3678e-01, PNorm = 40.9955, GNorm = 2.0446, lr_0 = 5.8038e-04
Loss = 1.3036e-01, PNorm = 41.0580, GNorm = 0.9214, lr_0 = 5.7613e-04
Validation auc = 0.945132
Epoch 48
Loss = 1.0800e-01, PNorm = 41.1294, GNorm = 1.3349, lr_0 = 5.7150e-04
Validation auc = 0.945295
Epoch 49
Loss = 1.4365e-01, PNorm = 41.2025, GNorm = 0.9287, lr_0 = 5.6690e-04
Loss = 1.0054e-01, PNorm = 41.2671, GNorm = 0.6192, lr_0 = 5.6275e-04
Validation auc = 0.936991
Epoch 50
Loss = 9.0814e-02, PNorm = 41.3219, GNorm = 0.4787, lr_0 = 5.5864e-04
Loss = 1.0569e-01, PNorm = 41.3818, GNorm = 1.1245, lr_0 = 5.5455e-04
Loss = 5.4829e-02, PNorm = 41.3874, GNorm = 0.6406, lr_0 = 5.5414e-04
Validation auc = 0.931130
Epoch 51
Loss = 9.9551e-02, PNorm = 41.4382, GNorm = 1.2571, lr_0 = 5.5009e-04
Validation auc = 0.949365
Epoch 52
Loss = 7.4617e-02, PNorm = 41.5028, GNorm = 0.6245, lr_0 = 5.4566e-04
Loss = 1.1749e-01, PNorm = 41.5606, GNorm = 0.6668, lr_0 = 5.4167e-04
Validation auc = 0.936666
Epoch 53
Loss = 9.0507e-02, PNorm = 41.6321, GNorm = 0.5681, lr_0 = 5.3732e-04
Validation auc = 0.943667
Epoch 54
Loss = 5.6295e-02, PNorm = 41.6869, GNorm = 0.6991, lr_0 = 5.3339e-04
Loss = 7.8472e-02, PNorm = 41.7519, GNorm = 0.7840, lr_0 = 5.2948e-04
Validation auc = 0.938619
Epoch 55
Loss = 1.0087e-01, PNorm = 41.8076, GNorm = 1.0620, lr_0 = 5.2522e-04
Loss = 8.7990e-02, PNorm = 41.8596, GNorm = 0.6542, lr_0 = 5.2138e-04
Validation auc = 0.951970
Epoch 56
Loss = 8.3500e-02, PNorm = 41.9179, GNorm = 1.0603, lr_0 = 5.1719e-04
Validation auc = 0.931293
Epoch 57
Loss = 8.1012e-02, PNorm = 41.9679, GNorm = 0.1398, lr_0 = 5.1303e-04
Loss = 6.1543e-02, PNorm = 42.0115, GNorm = 0.7655, lr_0 = 5.0927e-04
Validation auc = 0.940573
Epoch 58
Loss = 7.0291e-02, PNorm = 42.0653, GNorm = 0.6428, lr_0 = 5.0555e-04
Loss = 7.8666e-02, PNorm = 42.1062, GNorm = 1.1486, lr_0 = 5.0185e-04
Loss = 4.4994e-02, PNorm = 42.1107, GNorm = 0.4828, lr_0 = 5.0148e-04
Validation auc = 0.929827
Epoch 59
Loss = 6.1568e-02, PNorm = 42.1506, GNorm = 0.7177, lr_0 = 4.9781e-04
Validation auc = 0.929013
Epoch 60
Loss = 5.0929e-02, PNorm = 42.2009, GNorm = 0.7830, lr_0 = 4.9381e-04
Loss = 6.7134e-02, PNorm = 42.2462, GNorm = 0.4972, lr_0 = 4.9020e-04
Validation auc = 0.938131
Epoch 61
Loss = 5.1358e-02, PNorm = 42.2905, GNorm = 0.7706, lr_0 = 4.8661e-04
Validation auc = 0.939271
Epoch 62
Loss = 3.4390e-02, PNorm = 42.3253, GNorm = 0.3795, lr_0 = 4.8270e-04
Loss = 8.3018e-02, PNorm = 42.3660, GNorm = 0.3375, lr_0 = 4.7916e-04
Validation auc = 0.933246
Epoch 63
Loss = 4.4461e-02, PNorm = 42.4207, GNorm = 0.9425, lr_0 = 4.7531e-04
Loss = 5.4017e-02, PNorm = 42.4620, GNorm = 0.4419, lr_0 = 4.7183e-04
Validation auc = 0.938294
Epoch 64
Loss = 6.2073e-02, PNorm = 42.5125, GNorm = 1.1176, lr_0 = 4.6804e-04
Validation auc = 0.947248
Epoch 65
Loss = 5.2316e-02, PNorm = 42.5457, GNorm = 0.5079, lr_0 = 4.6461e-04
Loss = 6.6192e-02, PNorm = 42.5933, GNorm = 0.4423, lr_0 = 4.6121e-04
Validation auc = 0.923641
Epoch 66
Loss = 7.5089e-02, PNorm = 42.6456, GNorm = 0.6376, lr_0 = 4.5750e-04
Loss = 7.2520e-02, PNorm = 42.6784, GNorm = 0.4989, lr_0 = 4.5416e-04
Loss = 4.5496e-02, PNorm = 42.6823, GNorm = 0.9459, lr_0 = 4.5382e-04
Validation auc = 0.937642
Epoch 67
Loss = 5.5514e-02, PNorm = 42.7263, GNorm = 0.4513, lr_0 = 4.5050e-04
Validation auc = 0.928362
Epoch 68
Loss = 6.6975e-02, PNorm = 42.7703, GNorm = 0.7811, lr_0 = 4.4721e-04
Loss = 7.6652e-02, PNorm = 42.7984, GNorm = 1.6472, lr_0 = 4.4394e-04
Validation auc = 0.954087
Epoch 69
Loss = 7.0544e-02, PNorm = 42.8459, GNorm = 0.5076, lr_0 = 4.4037e-04
Validation auc = 0.939433
Epoch 70
Loss = 7.6792e-02, PNorm = 42.8893, GNorm = 1.1101, lr_0 = 4.3682e-04
Loss = 6.5280e-02, PNorm = 42.9318, GNorm = 0.1921, lr_0 = 4.3363e-04
Validation auc = 0.938457
Epoch 71
Loss = 5.6228e-02, PNorm = 42.9667, GNorm = 0.4561, lr_0 = 4.3014e-04
Loss = 5.9726e-02, PNorm = 43.0016, GNorm = 1.1735, lr_0 = 4.2699e-04
Validation auc = 0.932107
Epoch 72
Loss = 6.5810e-02, PNorm = 43.0348, GNorm = 0.7027, lr_0 = 4.2387e-04
Validation auc = 0.936014
Epoch 73
Loss = 6.6018e-02, PNorm = 43.0682, GNorm = 1.0363, lr_0 = 4.2046e-04
Loss = 6.3270e-02, PNorm = 43.1036, GNorm = 1.6868, lr_0 = 4.1738e-04
Validation auc = 0.936177
Epoch 74
Loss = 3.1198e-02, PNorm = 43.1413, GNorm = 0.6668, lr_0 = 4.1403e-04
Loss = 4.6004e-02, PNorm = 43.1760, GNorm = 0.6101, lr_0 = 4.1100e-04
Validation auc = 0.933409
Epoch 75
Loss = 4.0481e-02, PNorm = 43.2057, GNorm = 0.5770, lr_0 = 4.0799e-04
Validation auc = 0.933898
Epoch 76
Loss = 4.0732e-02, PNorm = 43.2404, GNorm = 0.2851, lr_0 = 4.0471e-04
Loss = 5.1009e-02, PNorm = 43.2723, GNorm = 0.5099, lr_0 = 4.0175e-04
Validation auc = 0.929013
Epoch 77
Loss = 2.7589e-02, PNorm = 43.3024, GNorm = 0.2053, lr_0 = 3.9852e-04
Validation auc = 0.922175
Epoch 78
Loss = 1.6151e-02, PNorm = 43.3350, GNorm = 0.2292, lr_0 = 3.9531e-04
Loss = 4.2232e-02, PNorm = 43.3592, GNorm = 1.6931, lr_0 = 3.9242e-04
Validation auc = 0.933572
Epoch 79
Loss = 3.9386e-02, PNorm = 43.3852, GNorm = 0.7850, lr_0 = 3.8955e-04
Loss = 3.2332e-02, PNorm = 43.4153, GNorm = 0.4291, lr_0 = 3.8670e-04
Validation auc = 0.923966
Epoch 80
Loss = 5.8887e-02, PNorm = 43.4489, GNorm = 1.5933, lr_0 = 3.8359e-04
Validation auc = 0.931618
Epoch 81
Loss = 3.6380e-02, PNorm = 43.4675, GNorm = 0.4421, lr_0 = 3.8050e-04
Loss = 5.6658e-02, PNorm = 43.4942, GNorm = 0.5085, lr_0 = 3.7772e-04
Validation auc = 0.918756
Epoch 82
Loss = 5.9575e-02, PNorm = 43.5286, GNorm = 0.5116, lr_0 = 3.7468e-04
Loss = 3.0662e-02, PNorm = 43.5524, GNorm = 0.6279, lr_0 = 3.7194e-04
Validation auc = 0.932270
Epoch 83
Loss = 4.1899e-02, PNorm = 43.5802, GNorm = 0.3879, lr_0 = 3.6922e-04
Validation auc = 0.915174
Epoch 84
Loss = 5.5936e-02, PNorm = 43.6147, GNorm = 0.2194, lr_0 = 3.6625e-04
Loss = 3.4783e-02, PNorm = 43.6430, GNorm = 0.5280, lr_0 = 3.6357e-04
Validation auc = 0.932595
Epoch 85
Loss = 3.5934e-02, PNorm = 43.6651, GNorm = 0.6069, lr_0 = 3.6064e-04
Loss = 5.9339e-02, PNorm = 43.6900, GNorm = 0.4053, lr_0 = 3.5801e-04
Validation auc = 0.927385
Epoch 86
Loss = 3.9304e-02, PNorm = 43.7172, GNorm = 0.5752, lr_0 = 3.5539e-04
Validation auc = 0.919977
Epoch 87
Loss = 4.4273e-02, PNorm = 43.7445, GNorm = 0.8509, lr_0 = 3.5253e-04
Loss = 3.9889e-02, PNorm = 43.7693, GNorm = 1.1319, lr_0 = 3.4995e-04
Validation auc = 0.930479
Epoch 88
Loss = 6.4925e-02, PNorm = 43.7989, GNorm = 1.6949, lr_0 = 3.4713e-04
Validation auc = 0.925106
Epoch 89
Loss = 3.4232e-02, PNorm = 43.8299, GNorm = 0.6407, lr_0 = 3.4434e-04
Loss = 3.6501e-02, PNorm = 43.8557, GNorm = 0.2202, lr_0 = 3.4182e-04
Validation auc = 0.931130
Epoch 90
Loss = 4.2310e-02, PNorm = 43.8771, GNorm = 0.3280, lr_0 = 3.3932e-04
Loss = 3.0903e-02, PNorm = 43.8970, GNorm = 0.2054, lr_0 = 3.3684e-04
Validation auc = 0.922175
Epoch 91
Loss = 3.7802e-02, PNorm = 43.9154, GNorm = 0.4713, lr_0 = 3.3413e-04
Validation auc = 0.926083
Epoch 92
Loss = 4.4607e-02, PNorm = 43.9418, GNorm = 1.4999, lr_0 = 3.3144e-04
Loss = 3.1699e-02, PNorm = 43.9629, GNorm = 0.1865, lr_0 = 3.2902e-04
Validation auc = 0.921687
Epoch 93
Loss = 2.8378e-02, PNorm = 43.9817, GNorm = 0.9026, lr_0 = 3.2661e-04
Loss = 2.9098e-02, PNorm = 43.9990, GNorm = 0.1499, lr_0 = 3.2422e-04
Loss = 1.1640e-02, PNorm = 44.0007, GNorm = 0.3389, lr_0 = 3.2398e-04
Validation auc = 0.930804
Epoch 94
Loss = 1.7307e-02, PNorm = 44.0219, GNorm = 0.1697, lr_0 = 3.2161e-04
Validation auc = 0.929583
Epoch 95
Loss = 3.0630e-02, PNorm = 44.0370, GNorm = 0.1970, lr_0 = 3.1903e-04
Loss = 4.1058e-02, PNorm = 44.0530, GNorm = 0.5264, lr_0 = 3.1669e-04
Validation auc = 0.933246
Epoch 96
Loss = 3.3434e-02, PNorm = 44.0736, GNorm = 0.6361, lr_0 = 3.1414e-04
Validation auc = 0.915418
Epoch 97
Loss = 1.5976e-02, PNorm = 44.0909, GNorm = 0.2457, lr_0 = 3.1185e-04
Loss = 2.1811e-02, PNorm = 44.1070, GNorm = 0.5031, lr_0 = 3.0957e-04
Validation auc = 0.929990
Epoch 98
Loss = 2.3680e-02, PNorm = 44.1264, GNorm = 0.7037, lr_0 = 3.0708e-04
Loss = 2.3091e-02, PNorm = 44.1412, GNorm = 0.2024, lr_0 = 3.0483e-04
Validation auc = 0.922989
Epoch 99
Loss = 2.7419e-02, PNorm = 44.1568, GNorm = 0.1630, lr_0 = 3.0238e-04
Validation auc = 0.936991
Model 0 best validation auc = 0.958971 on epoch 24
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.941933
Ensemble test auc = 0.941933
Fold 8
Splitting data with seed 8
Total scaffolds = 1,025 | train scaffolds = 828 | val scaffolds = 80 | test scaffolds = 117
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 792
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.6601e-01, PNorm = 35.0707, GNorm = 0.7782, lr_0 = 2.5469e-04
Validation auc = 0.745499
Epoch 1
Loss = 4.7155e-01, PNorm = 35.0936, GNorm = 0.9164, lr_0 = 4.0937e-04
Loss = 4.9905e-01, PNorm = 35.1194, GNorm = 2.1609, lr_0 = 5.5000e-04
Validation auc = 0.828020
Epoch 2
Loss = 4.7221e-01, PNorm = 35.1440, GNorm = 1.5141, lr_0 = 6.9063e-04
Validation auc = 0.829801
Epoch 3
Loss = 4.5416e-01, PNorm = 35.1709, GNorm = 0.3647, lr_0 = 8.3125e-04
Loss = 4.1348e-01, PNorm = 35.2071, GNorm = 0.5457, lr_0 = 9.7187e-04
Validation auc = 0.838335
Epoch 4
Loss = 3.9296e-01, PNorm = 35.2566, GNorm = 1.0680, lr_0 = 9.9414e-04
Validation auc = 0.826707
Epoch 5
Loss = 5.2523e-01, PNorm = 35.3073, GNorm = 2.2141, lr_0 = 9.8687e-04
Loss = 4.0296e-01, PNorm = 35.3576, GNorm = 0.5449, lr_0 = 9.7965e-04
Validation auc = 0.851932
Epoch 6
Loss = 3.7198e-01, PNorm = 35.4106, GNorm = 0.3945, lr_0 = 9.7248e-04
Loss = 3.7131e-01, PNorm = 35.4700, GNorm = 0.3611, lr_0 = 9.6537e-04
Loss = 4.0710e-01, PNorm = 35.4768, GNorm = 0.4566, lr_0 = 9.6466e-04
Validation auc = 0.850056
Epoch 7
Loss = 3.5934e-01, PNorm = 35.5350, GNorm = 2.0629, lr_0 = 9.5760e-04
Validation auc = 0.844242
Epoch 8
Loss = 4.2805e-01, PNorm = 35.5978, GNorm = 0.6824, lr_0 = 9.5060e-04
Loss = 3.5073e-01, PNorm = 35.6645, GNorm = 0.4779, lr_0 = 9.4365e-04
Validation auc = 0.867686
Epoch 9
Loss = 3.3056e-01, PNorm = 35.7360, GNorm = 0.7183, lr_0 = 9.3674e-04
Validation auc = 0.851744
Epoch 10
Loss = 3.1652e-01, PNorm = 35.7999, GNorm = 0.8099, lr_0 = 9.2989e-04
Loss = 3.3164e-01, PNorm = 35.8696, GNorm = 0.8787, lr_0 = 9.2309e-04
Validation auc = 0.865341
Epoch 11
Loss = 3.5108e-01, PNorm = 35.9397, GNorm = 1.1241, lr_0 = 9.1633e-04
Loss = 3.2785e-01, PNorm = 36.0141, GNorm = 0.6129, lr_0 = 9.0963e-04
Validation auc = 0.876032
Epoch 12
Loss = 2.9477e-01, PNorm = 36.1062, GNorm = 0.8307, lr_0 = 9.0298e-04
Validation auc = 0.878188
Epoch 13
Loss = 2.6998e-01, PNorm = 36.1955, GNorm = 0.7339, lr_0 = 8.9571e-04
Loss = 3.1644e-01, PNorm = 36.2781, GNorm = 0.5248, lr_0 = 8.8916e-04
Validation auc = 0.875844
Epoch 14
Loss = 2.9170e-01, PNorm = 36.3755, GNorm = 0.4671, lr_0 = 8.8265e-04
Validation auc = 0.878376
Epoch 15
Loss = 3.0435e-01, PNorm = 36.4579, GNorm = 0.3650, lr_0 = 8.7620e-04
Loss = 2.6979e-01, PNorm = 36.5419, GNorm = 0.4065, lr_0 = 8.6979e-04
Validation auc = 0.878001
Epoch 16
Loss = 3.1730e-01, PNorm = 36.6329, GNorm = 0.7138, lr_0 = 8.6342e-04
Validation auc = 0.874719
Epoch 17
Loss = 2.9182e-01, PNorm = 36.7232, GNorm = 0.4339, lr_0 = 8.5711e-04
Loss = 2.6303e-01, PNorm = 36.8148, GNorm = 0.5783, lr_0 = 8.5084e-04
Validation auc = 0.871343
Epoch 18
Loss = 2.3972e-01, PNorm = 36.9028, GNorm = 0.7958, lr_0 = 8.4461e-04
Loss = 2.7587e-01, PNorm = 37.0037, GNorm = 1.2273, lr_0 = 8.3843e-04
Loss = 2.4339e-01, PNorm = 37.0124, GNorm = 0.8802, lr_0 = 8.3782e-04
Validation auc = 0.882314
Epoch 19
Loss = 2.4398e-01, PNorm = 37.0996, GNorm = 2.0242, lr_0 = 8.3169e-04
Validation auc = 0.881658
Epoch 20
Loss = 2.2599e-01, PNorm = 37.1867, GNorm = 0.3544, lr_0 = 8.2561e-04
Loss = 2.4438e-01, PNorm = 37.2759, GNorm = 0.5163, lr_0 = 8.1957e-04
Validation auc = 0.871249
Epoch 21
Loss = 2.4207e-01, PNorm = 37.3792, GNorm = 0.7293, lr_0 = 8.1357e-04
Validation auc = 0.895443
Epoch 22
Loss = 2.2770e-01, PNorm = 37.4677, GNorm = 0.8090, lr_0 = 8.0762e-04
Loss = 2.1670e-01, PNorm = 37.5405, GNorm = 1.0358, lr_0 = 8.0171e-04
Validation auc = 0.877626
Epoch 23
Loss = 2.0790e-01, PNorm = 37.6258, GNorm = 0.6459, lr_0 = 7.9585e-04
Loss = 2.4259e-01, PNorm = 37.6955, GNorm = 1.0739, lr_0 = 7.9002e-04
Validation auc = 0.885128
Epoch 24
Loss = 2.3000e-01, PNorm = 37.7787, GNorm = 1.7629, lr_0 = 7.8424e-04
Validation auc = 0.870874
Epoch 25
Loss = 3.1529e-01, PNorm = 37.8620, GNorm = 1.0597, lr_0 = 7.7851e-04
Loss = 1.9287e-01, PNorm = 37.9562, GNorm = 0.5877, lr_0 = 7.7281e-04
Validation auc = 0.878001
Epoch 26
Loss = 1.8839e-01, PNorm = 38.0540, GNorm = 0.3228, lr_0 = 7.6660e-04
Validation auc = 0.872468
Epoch 27
Loss = 2.4812e-01, PNorm = 38.1412, GNorm = 0.6926, lr_0 = 7.6099e-04
Loss = 1.8976e-01, PNorm = 38.2263, GNorm = 1.0591, lr_0 = 7.5542e-04
Validation auc = 0.882877
Epoch 28
Loss = 2.2270e-01, PNorm = 38.3148, GNorm = 0.8172, lr_0 = 7.4989e-04
Validation auc = 0.880064
Epoch 29
Loss = 8.2479e-02, PNorm = 38.4034, GNorm = 0.3298, lr_0 = 7.4441e-04
Loss = 1.9194e-01, PNorm = 38.5006, GNorm = 0.3978, lr_0 = 7.3896e-04
Validation auc = 0.890941
Epoch 30
Loss = 2.0681e-01, PNorm = 38.5943, GNorm = 0.7400, lr_0 = 7.3356e-04
Loss = 1.7507e-01, PNorm = 38.6875, GNorm = 0.4887, lr_0 = 7.2819e-04
Validation auc = 0.876875
Epoch 31
Loss = 1.7542e-01, PNorm = 38.7751, GNorm = 0.4749, lr_0 = 7.2286e-04
Validation auc = 0.867592
Epoch 32
Loss = 1.2512e-01, PNorm = 38.8697, GNorm = 0.6053, lr_0 = 7.1705e-04
Loss = 1.6340e-01, PNorm = 38.9580, GNorm = 0.4380, lr_0 = 7.1180e-04
Validation auc = 0.866373
Epoch 33
Loss = 1.6797e-01, PNorm = 39.0573, GNorm = 0.5013, lr_0 = 7.0660e-04
Validation auc = 0.887284
Epoch 34
Loss = 1.6300e-01, PNorm = 39.1476, GNorm = 0.8588, lr_0 = 7.0143e-04
Loss = 1.5634e-01, PNorm = 39.2456, GNorm = 0.5073, lr_0 = 6.9630e-04
Validation auc = 0.872937
Epoch 35
Loss = 1.5453e-01, PNorm = 39.3380, GNorm = 1.2959, lr_0 = 6.9120e-04
Loss = 1.3160e-01, PNorm = 39.4194, GNorm = 0.5659, lr_0 = 6.8614e-04
Validation auc = 0.892911
Epoch 36
Loss = 1.3456e-01, PNorm = 39.5118, GNorm = 1.1328, lr_0 = 6.8113e-04
Validation auc = 0.878751
Epoch 37
Loss = 1.4739e-01, PNorm = 39.5972, GNorm = 1.0042, lr_0 = 6.7614e-04
Loss = 1.4706e-01, PNorm = 39.6792, GNorm = 1.2906, lr_0 = 6.7120e-04
Validation auc = 0.885221
Epoch 38
Loss = 1.6497e-01, PNorm = 39.7746, GNorm = 0.6536, lr_0 = 6.6580e-04
Validation auc = 0.882596
Epoch 39
Loss = 1.2692e-01, PNorm = 39.8538, GNorm = 1.1496, lr_0 = 6.6093e-04
Loss = 1.3175e-01, PNorm = 39.9431, GNorm = 1.0980, lr_0 = 6.5609e-04
Validation auc = 0.896662
Epoch 40
Loss = 1.2819e-01, PNorm = 40.0255, GNorm = 1.0089, lr_0 = 6.5129e-04
Validation auc = 0.883440
Epoch 41
Loss = 9.9509e-02, PNorm = 40.1035, GNorm = 0.6953, lr_0 = 6.4653e-04
Loss = 1.1034e-01, PNorm = 40.1741, GNorm = 0.3808, lr_0 = 6.4180e-04
Validation auc = 0.880251
Epoch 42
Loss = 1.0528e-01, PNorm = 40.2350, GNorm = 0.7414, lr_0 = 6.3710e-04
Loss = 1.1048e-01, PNorm = 40.3148, GNorm = 0.3763, lr_0 = 6.3244e-04
Validation auc = 0.880439
Epoch 43
Loss = 8.3324e-02, PNorm = 40.3858, GNorm = 0.3827, lr_0 = 6.2781e-04
Validation auc = 0.869186
Epoch 44
Loss = 9.3424e-02, PNorm = 40.4644, GNorm = 0.4835, lr_0 = 6.2276e-04
Loss = 1.0854e-01, PNorm = 40.5351, GNorm = 0.9898, lr_0 = 6.1821e-04
Validation auc = 0.871999
Epoch 45
Loss = 1.4600e-01, PNorm = 40.5945, GNorm = 0.6109, lr_0 = 6.1369e-04
Validation auc = 0.874156
Epoch 46
Loss = 1.0346e-01, PNorm = 40.6631, GNorm = 0.6373, lr_0 = 6.0920e-04
Loss = 9.5177e-02, PNorm = 40.7409, GNorm = 0.5948, lr_0 = 6.0474e-04
Validation auc = 0.873687
Epoch 47
Loss = 1.1184e-01, PNorm = 40.8073, GNorm = 0.5183, lr_0 = 6.0032e-04
Loss = 9.6432e-02, PNorm = 40.8804, GNorm = 0.7255, lr_0 = 5.9592e-04
Validation auc = 0.857464
Epoch 48
Loss = 8.7430e-02, PNorm = 40.9464, GNorm = 1.1392, lr_0 = 5.9157e-04
Validation auc = 0.878001
Epoch 49
Loss = 7.2416e-02, PNorm = 41.0115, GNorm = 1.2938, lr_0 = 5.8724e-04
Loss = 8.5287e-02, PNorm = 41.0798, GNorm = 0.3714, lr_0 = 5.8294e-04
Validation auc = 0.863372
Epoch 50
Loss = 8.1803e-02, PNorm = 41.1423, GNorm = 0.9284, lr_0 = 5.7868e-04
Validation auc = 0.862716
Epoch 51
Loss = 1.0129e-01, PNorm = 41.2069, GNorm = 1.2815, lr_0 = 5.7402e-04
Loss = 7.8670e-02, PNorm = 41.2654, GNorm = 0.5719, lr_0 = 5.6982e-04
Validation auc = 0.853713
Epoch 52
Loss = 1.0614e-01, PNorm = 41.3196, GNorm = 0.9327, lr_0 = 5.6565e-04
Validation auc = 0.879220
Epoch 53
Loss = 6.3106e-02, PNorm = 41.3713, GNorm = 0.4583, lr_0 = 5.6152e-04
Loss = 8.7047e-02, PNorm = 41.4328, GNorm = 0.8991, lr_0 = 5.5741e-04
Validation auc = 0.844242
Epoch 54
Loss = 6.5257e-02, PNorm = 41.4940, GNorm = 0.1636, lr_0 = 5.5333e-04
Loss = 8.3341e-02, PNorm = 41.5548, GNorm = 0.7028, lr_0 = 5.4928e-04
Validation auc = 0.864685
Epoch 55
Loss = 6.4178e-02, PNorm = 41.6164, GNorm = 0.5031, lr_0 = 5.4526e-04
Validation auc = 0.870686
Epoch 56
Loss = 4.4698e-02, PNorm = 41.6691, GNorm = 0.7884, lr_0 = 5.4128e-04
Loss = 7.2050e-02, PNorm = 41.7258, GNorm = 0.6149, lr_0 = 5.3732e-04
Validation auc = 0.861684
Epoch 57
Loss = 7.6043e-02, PNorm = 41.7824, GNorm = 0.3918, lr_0 = 5.3299e-04
Validation auc = 0.863935
Epoch 58
Loss = 5.1105e-02, PNorm = 41.8340, GNorm = 0.3434, lr_0 = 5.2909e-04
Loss = 5.5295e-02, PNorm = 41.8895, GNorm = 0.6324, lr_0 = 5.2522e-04
Validation auc = 0.875375
Epoch 59
Loss = 6.1190e-02, PNorm = 41.9464, GNorm = 0.5184, lr_0 = 5.2138e-04
Loss = 8.7889e-02, PNorm = 42.0001, GNorm = 1.7652, lr_0 = 5.1757e-04
Validation auc = 0.855214
Epoch 60
Loss = 7.4881e-02, PNorm = 42.0598, GNorm = 0.7697, lr_0 = 5.1378e-04
Validation auc = 0.869374
Epoch 61
Loss = 4.4689e-02, PNorm = 42.1108, GNorm = 0.3391, lr_0 = 5.1002e-04
Loss = 6.5040e-02, PNorm = 42.1602, GNorm = 0.5496, lr_0 = 5.0629e-04
Validation auc = 0.847712
Epoch 62
Loss = 6.4028e-02, PNorm = 42.2062, GNorm = 0.3997, lr_0 = 5.0259e-04
Validation auc = 0.859246
Epoch 63
Loss = 5.4224e-02, PNorm = 42.2437, GNorm = 0.9025, lr_0 = 4.9854e-04
Loss = 7.1833e-02, PNorm = 42.2858, GNorm = 1.1641, lr_0 = 4.9490e-04
Validation auc = 0.842273
Epoch 64
Loss = 5.0710e-02, PNorm = 42.3260, GNorm = 0.3849, lr_0 = 4.9128e-04
Validation auc = 0.866935
Epoch 65
Loss = 4.6109e-02, PNorm = 42.3626, GNorm = 0.4846, lr_0 = 4.8768e-04
Loss = 6.1128e-02, PNorm = 42.4137, GNorm = 0.3220, lr_0 = 4.8412e-04
Validation auc = 0.853620
Epoch 66
Loss = 6.6657e-02, PNorm = 42.4494, GNorm = 0.3945, lr_0 = 4.8057e-04
Loss = 6.1154e-02, PNorm = 42.4809, GNorm = 0.6523, lr_0 = 4.7706e-04
Validation auc = 0.858496
Epoch 67
Loss = 5.2052e-02, PNorm = 42.5149, GNorm = 0.3018, lr_0 = 4.7357e-04
Validation auc = 0.861403
Epoch 68
Loss = 4.6604e-02, PNorm = 42.5484, GNorm = 0.8077, lr_0 = 4.7010e-04
Loss = 6.0609e-02, PNorm = 42.5827, GNorm = 0.1906, lr_0 = 4.6666e-04
Validation auc = 0.882408
Epoch 69
Loss = 5.2479e-02, PNorm = 42.6271, GNorm = 0.3311, lr_0 = 4.6291e-04
Validation auc = 0.864497
Epoch 70
Loss = 9.3252e-02, PNorm = 42.6741, GNorm = 0.4232, lr_0 = 4.5952e-04
Loss = 5.1359e-02, PNorm = 42.7219, GNorm = 0.5068, lr_0 = 4.5616e-04
Validation auc = 0.844899
Epoch 71
Loss = 8.9101e-02, PNorm = 42.7663, GNorm = 0.8276, lr_0 = 4.5283e-04
Loss = 4.4406e-02, PNorm = 42.7997, GNorm = 0.6504, lr_0 = 4.4951e-04
Validation auc = 0.852776
Epoch 72
Loss = 4.4065e-02, PNorm = 42.8354, GNorm = 0.3885, lr_0 = 4.4622e-04
Validation auc = 0.863091
Epoch 73
Loss = 4.6484e-02, PNorm = 42.8655, GNorm = 0.3492, lr_0 = 4.4296e-04
Loss = 5.8429e-02, PNorm = 42.8929, GNorm = 0.6956, lr_0 = 4.3972e-04
Validation auc = 0.843680
Epoch 74
Loss = 3.5384e-02, PNorm = 42.9150, GNorm = 0.5162, lr_0 = 4.3650e-04
Validation auc = 0.861215
Epoch 75
Loss = 3.4730e-02, PNorm = 42.9402, GNorm = 0.1719, lr_0 = 4.3331e-04
Loss = 5.2590e-02, PNorm = 42.9735, GNorm = 0.7435, lr_0 = 4.3014e-04
Validation auc = 0.886159
Epoch 76
Loss = 4.7730e-02, PNorm = 43.0025, GNorm = 0.9073, lr_0 = 4.2668e-04
Validation auc = 0.863091
Epoch 77
Loss = 2.7189e-02, PNorm = 43.0273, GNorm = 0.2832, lr_0 = 4.2356e-04
Loss = 4.6920e-02, PNorm = 43.0540, GNorm = 0.3482, lr_0 = 4.2046e-04
Validation auc = 0.856527
Epoch 78
Loss = 3.5459e-02, PNorm = 43.0839, GNorm = 0.6693, lr_0 = 4.1738e-04
Loss = 3.0595e-02, PNorm = 43.1043, GNorm = 0.4223, lr_0 = 4.1433e-04
Validation auc = 0.877626
Epoch 79
Loss = 4.0225e-02, PNorm = 43.1346, GNorm = 1.2041, lr_0 = 4.1130e-04
Validation auc = 0.866935
Epoch 80
Loss = 4.9061e-02, PNorm = 43.1656, GNorm = 0.8537, lr_0 = 4.0829e-04
Loss = 5.8011e-02, PNorm = 43.1893, GNorm = 0.9040, lr_0 = 4.0530e-04
Validation auc = 0.867029
Epoch 81
Loss = 6.1319e-02, PNorm = 43.2182, GNorm = 1.2572, lr_0 = 4.0234e-04
Validation auc = 0.878657
Epoch 82
Loss = 2.9074e-02, PNorm = 43.2500, GNorm = 0.7792, lr_0 = 3.9910e-04
Loss = 4.7942e-02, PNorm = 43.2832, GNorm = 0.4229, lr_0 = 3.9618e-04
Validation auc = 0.873593
Epoch 83
Loss = 3.2848e-02, PNorm = 43.3142, GNorm = 0.4009, lr_0 = 3.9328e-04
Loss = 3.5017e-02, PNorm = 43.3398, GNorm = 0.3203, lr_0 = 3.9041e-04
Validation auc = 0.871999
Epoch 84
Loss = 3.0219e-02, PNorm = 43.3652, GNorm = 0.8108, lr_0 = 3.8755e-04
Validation auc = 0.868530
Epoch 85
Loss = 2.5809e-02, PNorm = 43.3875, GNorm = 0.7025, lr_0 = 3.8472e-04
Loss = 3.7408e-02, PNorm = 43.4125, GNorm = 0.6034, lr_0 = 3.8190e-04
Validation auc = 0.853245
Epoch 86
Loss = 3.1761e-02, PNorm = 43.4324, GNorm = 1.1362, lr_0 = 3.7911e-04
Validation auc = 0.858496
Epoch 87
Loss = 4.4836e-02, PNorm = 43.4628, GNorm = 0.6364, lr_0 = 3.7633e-04
Loss = 3.8507e-02, PNorm = 43.4923, GNorm = 0.3026, lr_0 = 3.7358e-04
Validation auc = 0.848462
Epoch 88
Loss = 3.7704e-02, PNorm = 43.5158, GNorm = 0.3370, lr_0 = 3.7058e-04
Validation auc = 0.879501
Epoch 89
Loss = 6.2205e-02, PNorm = 43.5465, GNorm = 0.4902, lr_0 = 3.6787e-04
Loss = 4.1763e-02, PNorm = 43.5761, GNorm = 0.7364, lr_0 = 3.6517e-04
Validation auc = 0.864310
Epoch 90
Loss = 4.9596e-02, PNorm = 43.5989, GNorm = 0.3301, lr_0 = 3.6250e-04
Loss = 3.6461e-02, PNorm = 43.6203, GNorm = 0.5118, lr_0 = 3.5985e-04
Validation auc = 0.872187
Epoch 91
Loss = 4.6699e-02, PNorm = 43.6480, GNorm = 1.1276, lr_0 = 3.5722e-04
Validation auc = 0.864685
Epoch 92
Loss = 4.3594e-02, PNorm = 43.6684, GNorm = 0.5851, lr_0 = 3.5461e-04
Loss = 3.2354e-02, PNorm = 43.6881, GNorm = 0.0997, lr_0 = 3.5201e-04
Validation auc = 0.848181
Epoch 93
Loss = 3.8305e-02, PNorm = 43.7068, GNorm = 0.4881, lr_0 = 3.4944e-04
Validation auc = 0.874062
Epoch 94
Loss = 3.0435e-02, PNorm = 43.7208, GNorm = 0.9959, lr_0 = 3.4662e-04
Loss = 3.2629e-02, PNorm = 43.7382, GNorm = 0.2142, lr_0 = 3.4409e-04
Validation auc = 0.849869
Epoch 95
Loss = 3.0599e-02, PNorm = 43.7582, GNorm = 0.3325, lr_0 = 3.4157e-04
Loss = 3.1117e-02, PNorm = 43.7743, GNorm = 1.0331, lr_0 = 3.3907e-04
Validation auc = 0.865998
Epoch 96
Loss = 1.6782e-02, PNorm = 43.7926, GNorm = 0.7071, lr_0 = 3.3659e-04
Validation auc = 0.846212
Epoch 97
Loss = 3.0050e-02, PNorm = 43.8164, GNorm = 0.4447, lr_0 = 3.3413e-04
Loss = 4.3210e-02, PNorm = 43.8369, GNorm = 0.8950, lr_0 = 3.3169e-04
Validation auc = 0.860840
Epoch 98
Loss = 5.6336e-02, PNorm = 43.8531, GNorm = 0.7228, lr_0 = 3.2926e-04
Validation auc = 0.860371
Epoch 99
Loss = 1.3565e-02, PNorm = 43.8701, GNorm = 0.1133, lr_0 = 3.2685e-04
Loss = 2.2541e-02, PNorm = 43.8897, GNorm = 0.3862, lr_0 = 3.2446e-04
Validation auc = 0.857839
Model 0 best validation auc = 0.896662 on epoch 39
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.920437
Ensemble test auc = 0.920437
Fold 9
Splitting data with seed 9
Total scaffolds = 1,025 | train scaffolds = 761 | val scaffolds = 139 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 752
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9230e-01, PNorm = 35.0698, GNorm = 0.6988, lr_0 = 2.5469e-04
Validation auc = 0.852076
Epoch 1
Loss = 5.4669e-01, PNorm = 35.0867, GNorm = 0.4694, lr_0 = 4.0937e-04
Loss = 5.2462e-01, PNorm = 35.1077, GNorm = 1.6948, lr_0 = 5.5000e-04
Loss = 5.8890e-01, PNorm = 35.1100, GNorm = 2.4199, lr_0 = 5.6406e-04
Validation auc = 0.865830
Epoch 2
Loss = 5.0648e-01, PNorm = 35.1335, GNorm = 0.8333, lr_0 = 7.0469e-04
Validation auc = 0.887481
Epoch 3
Loss = 4.3419e-01, PNorm = 35.1675, GNorm = 0.6184, lr_0 = 8.5938e-04
Loss = 4.4155e-01, PNorm = 35.2084, GNorm = 0.6285, lr_0 = 1.0000e-03
Loss = 1.7279e-01, PNorm = 35.2135, GNorm = 0.8469, lr_0 = 9.9927e-04
Validation auc = 0.880476
Epoch 4
Loss = 4.0852e-01, PNorm = 35.2653, GNorm = 0.9722, lr_0 = 9.9196e-04
Validation auc = 0.878311
Epoch 5
Loss = 3.9547e-01, PNorm = 35.3155, GNorm = 1.1341, lr_0 = 9.8398e-04
Loss = 4.4342e-01, PNorm = 35.3620, GNorm = 0.9043, lr_0 = 9.7678e-04
Loss = 1.3059e-01, PNorm = 35.3662, GNorm = 1.2030, lr_0 = 9.7606e-04
Validation auc = 0.875637
Epoch 6
Loss = 4.0499e-01, PNorm = 35.4105, GNorm = 1.4932, lr_0 = 9.6892e-04
Validation auc = 0.884424
Epoch 7
Loss = 3.4002e-01, PNorm = 35.4539, GNorm = 0.6197, lr_0 = 9.6113e-04
Loss = 4.0471e-01, PNorm = 35.4974, GNorm = 0.5768, lr_0 = 9.5410e-04
Loss = 3.2170e-01, PNorm = 35.5020, GNorm = 2.1819, lr_0 = 9.5340e-04
Validation auc = 0.885698
Epoch 8
Loss = 3.5817e-01, PNorm = 35.5514, GNorm = 0.3364, lr_0 = 9.4642e-04
Validation auc = 0.890346
Epoch 9
Loss = 4.3407e-01, PNorm = 35.6080, GNorm = 0.3836, lr_0 = 9.3881e-04
Loss = 3.2853e-01, PNorm = 35.6684, GNorm = 0.3207, lr_0 = 9.3194e-04
Loss = 5.9043e-01, PNorm = 35.6750, GNorm = 2.3705, lr_0 = 9.3126e-04
Validation auc = 0.892320
Epoch 10
Loss = 3.0974e-01, PNorm = 35.7461, GNorm = 0.7453, lr_0 = 9.2444e-04
Validation auc = 0.888118
Epoch 11
Loss = 3.8143e-01, PNorm = 35.8271, GNorm = 0.5924, lr_0 = 9.1701e-04
Loss = 3.3799e-01, PNorm = 35.8864, GNorm = 0.4423, lr_0 = 9.1030e-04
Loss = 2.5617e-01, PNorm = 35.8937, GNorm = 2.3325, lr_0 = 9.0963e-04
Validation auc = 0.886971
Epoch 12
Loss = 3.4912e-01, PNorm = 35.9572, GNorm = 1.1431, lr_0 = 9.0298e-04
Validation auc = 0.892002
Epoch 13
Loss = 3.5116e-01, PNorm = 36.0241, GNorm = 0.8687, lr_0 = 8.9571e-04
Loss = 3.5584e-01, PNorm = 36.0875, GNorm = 0.4276, lr_0 = 8.8916e-04
Loss = 8.4405e-02, PNorm = 36.0937, GNorm = 0.9992, lr_0 = 8.8851e-04
Validation auc = 0.892702
Epoch 14
Loss = 3.6305e-01, PNorm = 36.1519, GNorm = 0.5361, lr_0 = 8.8201e-04
Validation auc = 0.891493
Epoch 15
Loss = 2.9596e-01, PNorm = 36.2229, GNorm = 0.8233, lr_0 = 8.7491e-04
Loss = 3.2396e-01, PNorm = 36.2985, GNorm = 0.4163, lr_0 = 8.6851e-04
Loss = 3.7882e-02, PNorm = 36.3056, GNorm = 0.5505, lr_0 = 8.6787e-04
Validation auc = 0.893339
Epoch 16
Loss = 2.8947e-01, PNorm = 36.3843, GNorm = 0.5810, lr_0 = 8.6152e-04
Validation auc = 0.882005
Epoch 17
Loss = 3.1794e-01, PNorm = 36.4631, GNorm = 1.3454, lr_0 = 8.5459e-04
Loss = 2.6738e-01, PNorm = 36.5474, GNorm = 0.4314, lr_0 = 8.4834e-04
Loss = 1.2591e-01, PNorm = 36.5560, GNorm = 1.0912, lr_0 = 8.4772e-04
Validation auc = 0.890983
Epoch 18
Loss = 2.8117e-01, PNorm = 36.6421, GNorm = 0.9253, lr_0 = 8.4152e-04
Validation auc = 0.891302
Epoch 19
Loss = 2.3656e-01, PNorm = 36.7469, GNorm = 0.9887, lr_0 = 8.3475e-04
Loss = 2.7596e-01, PNorm = 36.8349, GNorm = 1.1832, lr_0 = 8.2864e-04
Loss = 1.1045e-01, PNorm = 36.8454, GNorm = 0.9092, lr_0 = 8.2803e-04
Validation auc = 0.887608
Epoch 20
Loss = 2.8749e-01, PNorm = 36.9490, GNorm = 0.4705, lr_0 = 8.2198e-04
Validation auc = 0.891684
Epoch 21
Loss = 2.7423e-01, PNorm = 37.0329, GNorm = 1.1740, lr_0 = 8.1536e-04
Loss = 3.3304e-01, PNorm = 37.1094, GNorm = 0.8039, lr_0 = 8.0940e-04
Loss = 1.3142e-01, PNorm = 37.1167, GNorm = 1.4862, lr_0 = 8.0881e-04
Validation auc = 0.889200
Epoch 22
Loss = 2.9299e-01, PNorm = 37.1970, GNorm = 1.0934, lr_0 = 8.0289e-04
Validation auc = 0.897797
Epoch 23
Loss = 3.1708e-01, PNorm = 37.2699, GNorm = 0.4311, lr_0 = 7.9643e-04
Loss = 2.5623e-01, PNorm = 37.3355, GNorm = 0.5532, lr_0 = 7.9060e-04
Loss = 5.2410e-02, PNorm = 37.3422, GNorm = 1.0435, lr_0 = 7.9002e-04
Validation auc = 0.900599
Epoch 24
Loss = 2.5450e-01, PNorm = 37.4108, GNorm = 0.4384, lr_0 = 7.8424e-04
Validation auc = 0.895950
Epoch 25
Loss = 2.1738e-01, PNorm = 37.4880, GNorm = 0.6432, lr_0 = 7.7851e-04
Loss = 2.3564e-01, PNorm = 37.5667, GNorm = 0.5476, lr_0 = 7.7281e-04
Validation auc = 0.898242
Epoch 26
Loss = 2.3563e-01, PNorm = 37.6476, GNorm = 0.7489, lr_0 = 7.6660e-04
Validation auc = 0.895313
Epoch 27
Loss = 2.1406e-01, PNorm = 37.7322, GNorm = 1.1511, lr_0 = 7.6043e-04
Loss = 2.4077e-01, PNorm = 37.7981, GNorm = 1.5714, lr_0 = 7.5487e-04
Validation auc = 0.901299
Epoch 28
Loss = 1.9707e-01, PNorm = 37.8821, GNorm = 0.5700, lr_0 = 7.4879e-04
Validation auc = 0.898561
Epoch 29
Loss = 2.0556e-01, PNorm = 37.9659, GNorm = 0.4285, lr_0 = 7.4277e-04
Loss = 2.0828e-01, PNorm = 38.0443, GNorm = 0.9310, lr_0 = 7.3734e-04
Validation auc = 0.899325
Epoch 30
Loss = 2.0771e-01, PNorm = 38.1226, GNorm = 0.8322, lr_0 = 7.3141e-04
Validation auc = 0.892830
Epoch 31
Loss = 1.7555e-01, PNorm = 38.1965, GNorm = 0.5394, lr_0 = 7.2552e-04
Loss = 2.0529e-01, PNorm = 38.2636, GNorm = 0.7274, lr_0 = 7.2021e-04
Validation auc = 0.903273
Epoch 32
Loss = 2.2556e-01, PNorm = 38.3358, GNorm = 0.6036, lr_0 = 7.1442e-04
Validation auc = 0.906075
Epoch 33
Loss = 2.5725e-01, PNorm = 38.4177, GNorm = 0.3256, lr_0 = 7.0867e-04
Loss = 1.9652e-01, PNorm = 38.4879, GNorm = 0.3751, lr_0 = 7.0349e-04
Validation auc = 0.905565
Epoch 34
Loss = 1.5904e-01, PNorm = 38.5785, GNorm = 0.3989, lr_0 = 6.9783e-04
Validation auc = 0.893467
Epoch 35
Loss = 1.8032e-01, PNorm = 38.6620, GNorm = 0.7633, lr_0 = 6.9222e-04
Loss = 1.7733e-01, PNorm = 38.7307, GNorm = 0.6716, lr_0 = 6.8715e-04
Validation auc = 0.897988
Epoch 36
Loss = 1.5318e-01, PNorm = 38.8191, GNorm = 0.5424, lr_0 = 6.8163e-04
Validation auc = 0.898943
Epoch 37
Loss = 1.7161e-01, PNorm = 38.8913, GNorm = 0.9317, lr_0 = 6.7614e-04
Loss = 2.1028e-01, PNorm = 38.9530, GNorm = 0.6432, lr_0 = 6.7120e-04
Validation auc = 0.895504
Epoch 38
Loss = 1.9436e-01, PNorm = 39.0206, GNorm = 1.5022, lr_0 = 6.6580e-04
Validation auc = 0.899134
Epoch 39
Loss = 1.9343e-01, PNorm = 39.0812, GNorm = 0.4958, lr_0 = 6.6044e-04
Loss = 1.3148e-01, PNorm = 39.1470, GNorm = 0.5456, lr_0 = 6.5561e-04
Validation auc = 0.899580
Epoch 40
Loss = 1.7578e-01, PNorm = 39.2203, GNorm = 0.6074, lr_0 = 6.5034e-04
Validation auc = 0.905056
Epoch 41
Loss = 1.4373e-01, PNorm = 39.2912, GNorm = 1.0177, lr_0 = 6.4510e-04
Loss = 1.6140e-01, PNorm = 39.3582, GNorm = 0.5320, lr_0 = 6.4039e-04
Validation auc = 0.905183
Epoch 42
Loss = 1.6771e-01, PNorm = 39.4322, GNorm = 1.0087, lr_0 = 6.3523e-04
Validation auc = 0.902573
Epoch 43
Loss = 1.2177e-01, PNorm = 39.5029, GNorm = 1.1133, lr_0 = 6.3012e-04
Loss = 1.9465e-01, PNorm = 39.5693, GNorm = 1.3574, lr_0 = 6.2551e-04
Validation auc = 0.899198
Epoch 44
Loss = 1.4522e-01, PNorm = 39.6344, GNorm = 1.6261, lr_0 = 6.2048e-04
Validation auc = 0.903400
Epoch 45
Loss = 1.2423e-01, PNorm = 39.7014, GNorm = 0.6775, lr_0 = 6.1549e-04
Loss = 1.4610e-01, PNorm = 39.7564, GNorm = 0.9906, lr_0 = 6.1099e-04
Validation auc = 0.903018
Epoch 46
Loss = 1.4285e-01, PNorm = 39.8084, GNorm = 0.7340, lr_0 = 6.0607e-04
Validation auc = 0.897287
Epoch 47
Loss = 1.2187e-01, PNorm = 39.8645, GNorm = 0.7953, lr_0 = 6.0120e-04
Loss = 1.1584e-01, PNorm = 39.9131, GNorm = 0.4536, lr_0 = 5.9680e-04
Validation auc = 0.895632
Epoch 48
Loss = 1.2432e-01, PNorm = 39.9657, GNorm = 0.6644, lr_0 = 5.9200e-04
Validation auc = 0.900726
Epoch 49
Loss = 1.2003e-01, PNorm = 40.0275, GNorm = 0.3440, lr_0 = 5.8724e-04
Loss = 8.8272e-02, PNorm = 40.0858, GNorm = 0.6855, lr_0 = 5.8294e-04
Validation auc = 0.894868
Epoch 50
Loss = 1.0571e-01, PNorm = 40.1434, GNorm = 0.6457, lr_0 = 5.7868e-04
Validation auc = 0.896778
Epoch 51
Loss = 9.5551e-02, PNorm = 40.1927, GNorm = 0.3726, lr_0 = 5.7402e-04
Loss = 1.1229e-01, PNorm = 40.2408, GNorm = 0.3644, lr_0 = 5.6982e-04
Validation auc = 0.897160
Epoch 52
Loss = 9.7133e-02, PNorm = 40.3096, GNorm = 0.8648, lr_0 = 5.6524e-04
Validation auc = 0.893276
Epoch 53
Loss = 1.6737e-01, PNorm = 40.3743, GNorm = 2.0568, lr_0 = 5.6069e-04
Loss = 1.5044e-01, PNorm = 40.4248, GNorm = 2.0078, lr_0 = 5.5659e-04
Validation auc = 0.899452
Epoch 54
Loss = 1.7537e-01, PNorm = 40.4982, GNorm = 1.6479, lr_0 = 5.5211e-04
Validation auc = 0.901426
Epoch 55
Loss = 1.1731e-01, PNorm = 40.5616, GNorm = 0.7051, lr_0 = 5.4767e-04
Loss = 1.0459e-01, PNorm = 40.6118, GNorm = 0.8668, lr_0 = 5.4367e-04
Validation auc = 0.905374
Epoch 56
Loss = 1.1747e-01, PNorm = 40.6671, GNorm = 0.7081, lr_0 = 5.3929e-04
Validation auc = 0.901108
Epoch 57
Loss = 1.0201e-01, PNorm = 40.7130, GNorm = 1.2338, lr_0 = 5.3495e-04
Loss = 1.0965e-01, PNorm = 40.7512, GNorm = 0.6690, lr_0 = 5.3104e-04
Validation auc = 0.903528
Epoch 58
Loss = 6.9568e-02, PNorm = 40.8079, GNorm = 0.6694, lr_0 = 5.2677e-04
Validation auc = 0.902636
Epoch 59
Loss = 9.4348e-02, PNorm = 40.8680, GNorm = 0.9334, lr_0 = 5.2253e-04
Loss = 8.0630e-02, PNorm = 40.9160, GNorm = 0.4348, lr_0 = 5.1871e-04
Validation auc = 0.897988
Epoch 60
Loss = 8.5371e-02, PNorm = 40.9665, GNorm = 0.3563, lr_0 = 5.1454e-04
Validation auc = 0.899707
Epoch 61
Loss = 9.9973e-02, PNorm = 41.0134, GNorm = 0.6493, lr_0 = 5.1040e-04
Loss = 7.8223e-02, PNorm = 41.0552, GNorm = 1.0939, lr_0 = 5.0666e-04
Validation auc = 0.901426
Epoch 62
Loss = 7.6790e-02, PNorm = 41.0972, GNorm = 0.2743, lr_0 = 5.0259e-04
Validation auc = 0.899962
Epoch 63
Loss = 7.4280e-02, PNorm = 41.1386, GNorm = 0.3780, lr_0 = 4.9854e-04
Loss = 7.4662e-02, PNorm = 41.1837, GNorm = 0.6284, lr_0 = 4.9490e-04
Validation auc = 0.895950
Epoch 64
Loss = 6.8911e-02, PNorm = 41.2251, GNorm = 0.5113, lr_0 = 4.9092e-04
Validation auc = 0.898434
Epoch 65
Loss = 7.1821e-02, PNorm = 41.2711, GNorm = 0.7624, lr_0 = 4.8697e-04
Loss = 6.3575e-02, PNorm = 41.3174, GNorm = 0.7149, lr_0 = 4.8341e-04
Validation auc = 0.901363
Epoch 66
Loss = 8.6490e-02, PNorm = 41.3654, GNorm = 1.4705, lr_0 = 4.7952e-04
Validation auc = 0.897542
Epoch 67
Loss = 7.4176e-02, PNorm = 41.4106, GNorm = 0.4757, lr_0 = 4.7566e-04
Loss = 5.9954e-02, PNorm = 41.4479, GNorm = 0.7711, lr_0 = 4.7218e-04
Validation auc = 0.900153
Epoch 68
Loss = 7.0190e-02, PNorm = 41.4879, GNorm = 0.6992, lr_0 = 4.6838e-04
Validation auc = 0.898051
Epoch 69
Loss = 4.6996e-02, PNorm = 41.5300, GNorm = 0.4159, lr_0 = 4.6461e-04
Loss = 7.4078e-02, PNorm = 41.5748, GNorm = 0.5692, lr_0 = 4.6121e-04
Validation auc = 0.896905
Epoch 70
Loss = 6.4861e-02, PNorm = 41.6110, GNorm = 0.5549, lr_0 = 4.5750e-04
Validation auc = 0.900471
Epoch 71
Loss = 8.9094e-02, PNorm = 41.6549, GNorm = 1.5301, lr_0 = 4.5382e-04
Loss = 1.0959e-01, PNorm = 41.6924, GNorm = 0.7478, lr_0 = 4.5050e-04
Validation auc = 0.891429
Epoch 72
Loss = 2.8332e-01, PNorm = 41.7428, GNorm = 4.4560, lr_0 = 4.4688e-04
Validation auc = 0.899580
Epoch 73
Loss = 1.5155e-01, PNorm = 41.7989, GNorm = 1.0510, lr_0 = 4.4329e-04
Loss = 1.1628e-01, PNorm = 41.8397, GNorm = 0.7682, lr_0 = 4.4004e-04
Validation auc = 0.906584
Epoch 74
Loss = 1.0290e-01, PNorm = 41.8834, GNorm = 0.7664, lr_0 = 4.3650e-04
Validation auc = 0.903337
Epoch 75
Loss = 5.7757e-02, PNorm = 41.9205, GNorm = 0.3067, lr_0 = 4.3331e-04
Loss = 1.2417e-01, PNorm = 41.9530, GNorm = 1.4248, lr_0 = 4.3014e-04
Validation auc = 0.901235
Epoch 76
Loss = 1.0355e-01, PNorm = 41.9874, GNorm = 0.8628, lr_0 = 4.2668e-04
Validation auc = 0.900853
Epoch 77
Loss = 4.6637e-02, PNorm = 42.0199, GNorm = 0.2155, lr_0 = 4.2325e-04
Loss = 6.7657e-02, PNorm = 42.0457, GNorm = 0.3551, lr_0 = 4.2015e-04
Validation auc = 0.900217
Epoch 78
Loss = 7.8628e-02, PNorm = 42.0773, GNorm = 0.8594, lr_0 = 4.1677e-04
Validation auc = 0.894103
Epoch 79
Loss = 5.0451e-02, PNorm = 42.1106, GNorm = 0.6302, lr_0 = 4.1342e-04
Loss = 6.9401e-02, PNorm = 42.1390, GNorm = 0.4034, lr_0 = 4.1039e-04
Validation auc = 0.899516
Epoch 80
Loss = 6.0383e-02, PNorm = 42.1632, GNorm = 0.6341, lr_0 = 4.0709e-04
Validation auc = 0.899962
Epoch 81
Loss = 3.4302e-02, PNorm = 42.1899, GNorm = 0.3758, lr_0 = 4.0382e-04
Loss = 5.5928e-02, PNorm = 42.2150, GNorm = 0.7037, lr_0 = 4.0086e-04
Validation auc = 0.900535
Epoch 82
Loss = 1.3240e-01, PNorm = 42.2400, GNorm = 1.0719, lr_0 = 3.9764e-04
Validation auc = 0.898497
Epoch 83
Loss = 5.0947e-02, PNorm = 42.2704, GNorm = 0.4886, lr_0 = 3.9444e-04
Loss = 4.9111e-02, PNorm = 42.3016, GNorm = 0.4876, lr_0 = 3.9156e-04
Validation auc = 0.904929
Epoch 84
Loss = 5.4173e-02, PNorm = 42.3310, GNorm = 0.4818, lr_0 = 3.8841e-04
Validation auc = 0.902700
Epoch 85
Loss = 3.5143e-02, PNorm = 42.3584, GNorm = 0.2308, lr_0 = 3.8528e-04
Loss = 4.1245e-02, PNorm = 42.3820, GNorm = 0.4215, lr_0 = 3.8246e-04
Validation auc = 0.902827
Epoch 86
Loss = 4.4333e-02, PNorm = 42.4112, GNorm = 0.1242, lr_0 = 3.7939e-04
Validation auc = 0.903209
Epoch 87
Loss = 2.6693e-02, PNorm = 42.4397, GNorm = 0.4103, lr_0 = 3.7633e-04
Loss = 7.1771e-02, PNorm = 42.4695, GNorm = 1.5879, lr_0 = 3.7358e-04
Validation auc = 0.899452
Epoch 88
Loss = 6.5415e-02, PNorm = 42.4926, GNorm = 0.8679, lr_0 = 3.7058e-04
Validation auc = 0.906075
Epoch 89
Loss = 3.4877e-02, PNorm = 42.5096, GNorm = 0.1627, lr_0 = 3.6760e-04
Loss = 5.7081e-02, PNorm = 42.5318, GNorm = 0.5703, lr_0 = 3.6491e-04
Validation auc = 0.898625
Epoch 90
Loss = 5.4243e-02, PNorm = 42.5560, GNorm = 0.1697, lr_0 = 3.6197e-04
Validation auc = 0.900280
Epoch 91
Loss = 2.7223e-02, PNorm = 42.5805, GNorm = 0.1676, lr_0 = 3.5906e-04
Loss = 4.2666e-02, PNorm = 42.6032, GNorm = 0.3823, lr_0 = 3.5643e-04
Validation auc = 0.896141
Epoch 92
Loss = 5.2877e-02, PNorm = 42.6274, GNorm = 0.5288, lr_0 = 3.5357e-04
Validation auc = 0.892766
Epoch 93
Loss = 2.1536e-02, PNorm = 42.6457, GNorm = 0.2810, lr_0 = 3.5072e-04
Loss = 4.7115e-02, PNorm = 42.6614, GNorm = 0.7177, lr_0 = 3.4816e-04
Validation auc = 0.901681
Epoch 94
Loss = 1.9367e-02, PNorm = 42.6827, GNorm = 0.2255, lr_0 = 3.4535e-04
Validation auc = 0.905629
Epoch 95
Loss = 4.0812e-02, PNorm = 42.6998, GNorm = 1.0384, lr_0 = 3.4258e-04
Loss = 3.7922e-02, PNorm = 42.7196, GNorm = 0.3945, lr_0 = 3.4007e-04
Validation auc = 0.904738
Epoch 96
Loss = 4.7710e-02, PNorm = 42.7449, GNorm = 1.4657, lr_0 = 3.3733e-04
Validation auc = 0.898816
Epoch 97
Loss = 7.3115e-02, PNorm = 42.7696, GNorm = 0.9508, lr_0 = 3.3462e-04
Loss = 4.4363e-02, PNorm = 42.7903, GNorm = 0.6235, lr_0 = 3.3217e-04
Validation auc = 0.896969
Epoch 98
Loss = 2.6966e-02, PNorm = 42.8131, GNorm = 0.2842, lr_0 = 3.2950e-04
Validation auc = 0.903082
Epoch 99
Loss = 6.4292e-02, PNorm = 42.8333, GNorm = 2.2539, lr_0 = 3.2685e-04
Loss = 6.6205e-02, PNorm = 42.8630, GNorm = 0.8240, lr_0 = 3.2446e-04
Validation auc = 0.901363
Model 0 best validation auc = 0.906584 on epoch 73
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.917494
Ensemble test auc = 0.917494
10-fold cross validation
	Seed 0 ==> test auc = 0.929177
	Seed 1 ==> test auc = 0.852848
	Seed 2 ==> test auc = 0.944112
	Seed 3 ==> test auc = 0.862913
	Seed 4 ==> test auc = 0.890246
	Seed 5 ==> test auc = 0.893487
	Seed 6 ==> test auc = 0.881697
	Seed 7 ==> test auc = 0.941933
	Seed 8 ==> test auc = 0.920437
	Seed 9 ==> test auc = 0.917494
Overall test auc = 0.903435 +/- 0.030385
Elapsed time = 16:49:39
Command line
python C:\Users\gurka\miniconda3\envs\chemprop\lib\site-packages\ipykernel_launcher.py --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme="hmac-sha256" --Session.key=b"78ce7e33-618d-4d70-bde9-935ab47d3a38" --shell=9002 --transport="tcp" --iopub=9004 --f=C:\Users\gurka\AppData\Local\Temp\tmp-9036WgdJUnZ0WKJ0.json
Args
{'activation': 'ReLU',
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'batch_size': 50,
 'bias': False,
 'bond_feature_scaling': True,
 'bond_features_path': None,
 'bond_features_size': 0,
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': True,
 'config_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': './data/molnet_chemprop.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 20,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': ['rdkit_2d_normalized'],
 'features_only': False,
 'features_path': None,
 'features_scaling': False,
 'features_size': None,
 'ffn_hidden_size': 300,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'log_frequency': 10,
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'auc',
 'metrics': ['auc'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_atom_descriptor_scaling': False,
 'no_bond_features_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': True,
 'num_folds': 30,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'pytorch_seed': 0,
 'quiet': True,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'resume_experiment': False,
 'save_dir': './data/chemprop_checkpoints/',
 'save_preds': False,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_features_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_features_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'split_sizes': (0.8, 0.1, 0.1),
 'split_type': 'scaffold_balanced',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['BBB+/BBB-'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': True,
 'val_fold_index': None,
 'warmup_epochs': 2.0}
Loading data
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total scaffolds = 1,025 | train scaffolds = 764 | val scaffolds = 123 | test scaffolds = 138
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 774
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7708e-01, PNorm = 35.0708, GNorm = 0.7273, lr_0 = 2.5469e-04
Validation auc = 0.861534
Epoch 1
Loss = 5.0486e-01, PNorm = 35.0930, GNorm = 0.7116, lr_0 = 4.0937e-04
Loss = 5.4657e-01, PNorm = 35.1182, GNorm = 1.4816, lr_0 = 5.5000e-04
Loss = 4.0673e-01, PNorm = 35.1203, GNorm = 0.7096, lr_0 = 5.6406e-04
Validation auc = 0.879050
Epoch 2
Loss = 4.5546e-01, PNorm = 35.1483, GNorm = 2.1511, lr_0 = 7.0469e-04
Validation auc = 0.915397
Epoch 3
Loss = 4.7097e-01, PNorm = 35.1837, GNorm = 0.9679, lr_0 = 8.4531e-04
Loss = 4.1481e-01, PNorm = 35.2336, GNorm = 0.4119, lr_0 = 9.8594e-04
Validation auc = 0.916782
Epoch 4
Loss = 4.0433e-01, PNorm = 35.2925, GNorm = 1.5233, lr_0 = 9.6081e-04
Validation auc = 0.914082
Epoch 5
Loss = 3.8692e-01, PNorm = 35.3440, GNorm = 0.6099, lr_0 = 9.2316e-04
Loss = 4.2400e-01, PNorm = 35.3938, GNorm = 0.7854, lr_0 = 8.8699e-04
Validation auc = 0.911105
Epoch 6
Loss = 3.6551e-01, PNorm = 35.4559, GNorm = 0.5927, lr_0 = 8.4883e-04
Validation auc = 0.923844
Epoch 7
Loss = 3.0481e-01, PNorm = 35.5115, GNorm = 0.9399, lr_0 = 8.1556e-04
Loss = 3.5997e-01, PNorm = 35.5571, GNorm = 0.6062, lr_0 = 7.8361e-04
Validation auc = 0.914013
Epoch 8
Loss = 3.1905e-01, PNorm = 35.6007, GNorm = 0.4946, lr_0 = 7.4989e-04
Validation auc = 0.926821
Epoch 9
Loss = 2.8993e-01, PNorm = 35.6539, GNorm = 0.7410, lr_0 = 7.2051e-04
Loss = 3.4127e-01, PNorm = 35.6972, GNorm = 1.0058, lr_0 = 6.9227e-04
Validation auc = 0.917890
Epoch 10
Loss = 3.2062e-01, PNorm = 35.7466, GNorm = 0.9256, lr_0 = 6.6249e-04
Loss = 2.9076e-01, PNorm = 35.8080, GNorm = 0.4870, lr_0 = 6.3653e-04
Validation auc = 0.921213
Epoch 11
Loss = 3.3875e-01, PNorm = 35.8590, GNorm = 0.4562, lr_0 = 6.1159e-04
Validation auc = 0.916367
Epoch 12
Loss = 3.3895e-01, PNorm = 35.9206, GNorm = 1.7567, lr_0 = 5.8528e-04
Loss = 3.3472e-01, PNorm = 35.9744, GNorm = 0.6555, lr_0 = 5.6234e-04
Validation auc = 0.924259
Epoch 13
Loss = 2.9872e-01, PNorm = 36.0217, GNorm = 0.6420, lr_0 = 5.4030e-04
Validation auc = 0.923705
Epoch 14
Loss = 3.8538e-01, PNorm = 36.0707, GNorm = 1.2351, lr_0 = 5.1706e-04
Loss = 2.9239e-01, PNorm = 36.1157, GNorm = 0.7626, lr_0 = 4.9680e-04
Validation auc = 0.913944
Epoch 15
Loss = 2.9310e-01, PNorm = 36.1600, GNorm = 0.6353, lr_0 = 4.7733e-04
Validation auc = 0.922182
Epoch 16
Loss = 3.1045e-01, PNorm = 36.2087, GNorm = 0.6354, lr_0 = 4.5680e-04
Loss = 2.7377e-01, PNorm = 36.2551, GNorm = 0.9135, lr_0 = 4.3890e-04
Validation auc = 0.919690
Epoch 17
Loss = 2.4998e-01, PNorm = 36.2945, GNorm = 0.5166, lr_0 = 4.2170e-04
Validation auc = 0.916228
Epoch 18
Loss = 3.8084e-01, PNorm = 36.3364, GNorm = 1.3704, lr_0 = 4.0356e-04
Loss = 2.4529e-01, PNorm = 36.3753, GNorm = 0.5310, lr_0 = 3.8774e-04
Validation auc = 0.919274
Epoch 19
Loss = 2.6160e-01, PNorm = 36.4098, GNorm = 0.6660, lr_0 = 3.7255e-04
Validation auc = 0.917544
Model 0 best validation auc = 0.926821 on epoch 8
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.928630
Ensemble test auc = 0.928630
Fold 1
Splitting data with seed 1
Total scaffolds = 1,025 | train scaffolds = 768 | val scaffolds = 132 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 762
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9210e-01, PNorm = 35.0699, GNorm = 0.7570, lr_0 = 2.5469e-04
Validation auc = 0.840480
Epoch 1
Loss = 5.1862e-01, PNorm = 35.0913, GNorm = 0.4386, lr_0 = 4.0937e-04
Loss = 5.1567e-01, PNorm = 35.1154, GNorm = 1.9380, lr_0 = 5.5000e-04
Loss = 4.7269e-01, PNorm = 35.1180, GNorm = 0.8592, lr_0 = 5.6406e-04
Validation auc = 0.862137
Epoch 2
Loss = 4.8015e-01, PNorm = 35.1451, GNorm = 0.4625, lr_0 = 7.0469e-04
Validation auc = 0.866206
Epoch 3
Loss = 4.8771e-01, PNorm = 35.1906, GNorm = 2.8453, lr_0 = 8.5938e-04
Loss = 4.1720e-01, PNorm = 35.2348, GNorm = 0.5161, lr_0 = 1.0000e-03
Loss = 3.8087e-01, PNorm = 35.2404, GNorm = 1.5332, lr_0 = 9.9601e-04
Validation auc = 0.872602
Epoch 4
Loss = 4.1284e-01, PNorm = 35.2936, GNorm = 0.5415, lr_0 = 9.5698e-04
Validation auc = 0.875945
Epoch 5
Loss = 4.2637e-01, PNorm = 35.3484, GNorm = 1.1317, lr_0 = 9.1948e-04
Loss = 3.9282e-01, PNorm = 35.3977, GNorm = 1.0903, lr_0 = 8.8345e-04
Validation auc = 0.883358
Epoch 6
Loss = 4.1695e-01, PNorm = 35.4455, GNorm = 1.4030, lr_0 = 8.4544e-04
Validation auc = 0.878997
Epoch 7
Loss = 3.6803e-01, PNorm = 35.5076, GNorm = 0.9557, lr_0 = 8.0907e-04
Loss = 3.4870e-01, PNorm = 35.5678, GNorm = 0.9078, lr_0 = 7.7737e-04
Validation auc = 0.879942
Epoch 8
Loss = 3.8711e-01, PNorm = 35.6204, GNorm = 0.4317, lr_0 = 7.4392e-04
Validation auc = 0.876090
Epoch 9
Loss = 3.2807e-01, PNorm = 35.6637, GNorm = 0.3850, lr_0 = 7.1477e-04
Loss = 3.3023e-01, PNorm = 35.7177, GNorm = 1.0647, lr_0 = 6.8676e-04
Validation auc = 0.879724
Epoch 10
Loss = 3.1994e-01, PNorm = 35.7671, GNorm = 0.4218, lr_0 = 6.5722e-04
Validation auc = 0.881613
Epoch 11
Loss = 3.0276e-01, PNorm = 35.8150, GNorm = 1.5223, lr_0 = 6.2894e-04
Loss = 3.4390e-01, PNorm = 35.8582, GNorm = 0.4550, lr_0 = 6.0430e-04
Validation auc = 0.882994
Epoch 12
Loss = 3.4908e-01, PNorm = 35.9056, GNorm = 0.7304, lr_0 = 5.7830e-04
Validation auc = 0.880378
Epoch 13
Loss = 3.0053e-01, PNorm = 35.9567, GNorm = 0.9892, lr_0 = 5.5564e-04
Loss = 2.9809e-01, PNorm = 36.0105, GNorm = 0.3248, lr_0 = 5.3386e-04
Validation auc = 0.884302
Epoch 14
Loss = 2.9116e-01, PNorm = 36.0573, GNorm = 0.4304, lr_0 = 5.1090e-04
Validation auc = 0.878561
Epoch 15
Loss = 2.7192e-01, PNorm = 36.1015, GNorm = 0.3582, lr_0 = 4.8892e-04
Loss = 2.8133e-01, PNorm = 36.1412, GNorm = 1.2954, lr_0 = 4.6976e-04
Validation auc = 0.879942
Epoch 16
Loss = 2.7811e-01, PNorm = 36.1887, GNorm = 0.9739, lr_0 = 4.4955e-04
Validation auc = 0.879869
Epoch 17
Loss = 3.5022e-01, PNorm = 36.2300, GNorm = 0.8018, lr_0 = 4.3193e-04
Loss = 2.5752e-01, PNorm = 36.2702, GNorm = 0.4532, lr_0 = 4.1501e-04
Validation auc = 0.884302
Epoch 18
Loss = 2.6902e-01, PNorm = 36.3140, GNorm = 1.6152, lr_0 = 3.9715e-04
Validation auc = 0.880087
Epoch 19
Loss = 1.5511e-01, PNorm = 36.3623, GNorm = 0.5958, lr_0 = 3.8007e-04
Loss = 2.5772e-01, PNorm = 36.4025, GNorm = 1.4257, lr_0 = 3.6517e-04
Validation auc = 0.885102
Model 0 best validation auc = 0.885102 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.907636
Ensemble test auc = 0.907636
Fold 2
Splitting data with seed 2
Total scaffolds = 1,025 | train scaffolds = 766 | val scaffolds = 125 | test scaffolds = 134
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 748
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8410e-01, PNorm = 35.0706, GNorm = 1.0058, lr_0 = 2.5469e-04
Validation auc = 0.860611
Epoch 1
Loss = 5.2723e-01, PNorm = 35.0922, GNorm = 0.6741, lr_0 = 4.0937e-04
Validation auc = 0.860338
Epoch 2
Loss = 4.3403e-01, PNorm = 35.1195, GNorm = 2.4570, lr_0 = 5.5000e-04
Loss = 4.6489e-01, PNorm = 35.1464, GNorm = 2.2846, lr_0 = 6.9063e-04
Validation auc = 0.845336
Epoch 3
Loss = 4.1517e-01, PNorm = 35.1787, GNorm = 0.6632, lr_0 = 8.3125e-04
Validation auc = 0.856110
Epoch 4
Loss = 4.6568e-01, PNorm = 35.2196, GNorm = 0.4393, lr_0 = 9.7187e-04
Loss = 4.1941e-01, PNorm = 35.2658, GNorm = 0.3428, lr_0 = 9.6853e-04
Validation auc = 0.854746
Epoch 5
Loss = 4.2431e-01, PNorm = 35.3033, GNorm = 0.4568, lr_0 = 9.3057e-04
Validation auc = 0.860884
Epoch 6
Loss = 2.4185e-01, PNorm = 35.3433, GNorm = 0.3772, lr_0 = 8.9411e-04
Loss = 3.8531e-01, PNorm = 35.3902, GNorm = 0.4417, lr_0 = 8.5907e-04
Validation auc = 0.867294
Epoch 7
Loss = 3.8944e-01, PNorm = 35.4331, GNorm = 0.5706, lr_0 = 8.2540e-04
Validation auc = 0.872750
Epoch 8
Loss = 3.7241e-01, PNorm = 35.4771, GNorm = 0.5134, lr_0 = 7.9306e-04
Loss = 3.8028e-01, PNorm = 35.5267, GNorm = 0.3943, lr_0 = 7.6198e-04
Validation auc = 0.870295
Epoch 9
Loss = 3.3930e-01, PNorm = 35.5830, GNorm = 1.2405, lr_0 = 7.3212e-04
Validation auc = 0.882024
Epoch 10
Loss = 3.8092e-01, PNorm = 35.6400, GNorm = 1.0963, lr_0 = 7.0343e-04
Loss = 3.2259e-01, PNorm = 35.6896, GNorm = 1.1386, lr_0 = 6.7587e-04
Validation auc = 0.870431
Epoch 11
Loss = 3.4546e-01, PNorm = 35.7332, GNorm = 1.0169, lr_0 = 6.4938e-04
Validation auc = 0.885297
Epoch 12
Loss = 3.1439e-01, PNorm = 35.7834, GNorm = 0.3530, lr_0 = 6.2393e-04
Loss = 3.2292e-01, PNorm = 35.8298, GNorm = 0.6906, lr_0 = 5.9948e-04
Validation auc = 0.872068
Epoch 13
Loss = 2.8578e-01, PNorm = 35.8821, GNorm = 0.4527, lr_0 = 5.7599e-04
Validation auc = 0.888843
Epoch 14
Loss = 2.8587e-01, PNorm = 35.9309, GNorm = 0.6505, lr_0 = 5.5342e-04
Loss = 3.1467e-01, PNorm = 35.9791, GNorm = 0.9721, lr_0 = 5.3173e-04
Validation auc = 0.886934
Epoch 15
Loss = 2.8202e-01, PNorm = 36.0271, GNorm = 0.6150, lr_0 = 5.1090e-04
Validation auc = 0.888434
Epoch 16
Loss = 2.1872e-01, PNorm = 36.0773, GNorm = 0.3992, lr_0 = 4.9088e-04
Loss = 3.1525e-01, PNorm = 36.1225, GNorm = 1.0125, lr_0 = 4.7164e-04
Validation auc = 0.884343
Epoch 17
Loss = 3.0409e-01, PNorm = 36.1760, GNorm = 1.3000, lr_0 = 4.5316e-04
Validation auc = 0.888707
Epoch 18
Loss = 3.7937e-01, PNorm = 36.2244, GNorm = 1.1171, lr_0 = 4.3540e-04
Loss = 2.6954e-01, PNorm = 36.2659, GNorm = 0.9249, lr_0 = 4.1834e-04
Validation auc = 0.884479
Epoch 19
Loss = 2.5377e-01, PNorm = 36.3069, GNorm = 0.9491, lr_0 = 4.0195e-04
Validation auc = 0.885706
Model 0 best validation auc = 0.888843 on epoch 13
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.943526
Ensemble test auc = 0.943526
Fold 3
Splitting data with seed 3
Total scaffolds = 1,025 | train scaffolds = 835 | val scaffolds = 63 | test scaffolds = 127
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 824
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8195e-01, PNorm = 35.0697, GNorm = 0.6962, lr_0 = 2.5469e-04
Validation auc = 0.789388
Epoch 1
Loss = 4.7180e-01, PNorm = 35.0910, GNorm = 0.6856, lr_0 = 4.0937e-04
Loss = 5.1193e-01, PNorm = 35.1184, GNorm = 0.9026, lr_0 = 5.5000e-04
Validation auc = 0.843469
Epoch 2
Loss = 4.3106e-01, PNorm = 35.1404, GNorm = 0.4501, lr_0 = 7.0469e-04
Validation auc = 0.880816
Epoch 3
Loss = 3.8783e-01, PNorm = 35.1722, GNorm = 0.7876, lr_0 = 8.4531e-04
Loss = 4.2032e-01, PNorm = 35.2101, GNorm = 0.4401, lr_0 = 9.8594e-04
Validation auc = 0.881224
Epoch 4
Loss = 3.9668e-01, PNorm = 35.2626, GNorm = 0.4268, lr_0 = 9.6081e-04
Loss = 3.9043e-01, PNorm = 35.3086, GNorm = 0.4316, lr_0 = 9.2316e-04
Validation auc = 0.884082
Epoch 5
Loss = 3.9968e-01, PNorm = 35.3491, GNorm = 1.4472, lr_0 = 8.8699e-04
Validation auc = 0.886939
Epoch 6
Loss = 4.0749e-01, PNorm = 35.3971, GNorm = 1.2132, lr_0 = 8.4883e-04
Loss = 3.7197e-01, PNorm = 35.4448, GNorm = 1.0020, lr_0 = 8.1556e-04
Validation auc = 0.877959
Epoch 7
Loss = 3.9704e-01, PNorm = 35.4907, GNorm = 0.4784, lr_0 = 7.8361e-04
Loss = 3.4534e-01, PNorm = 35.5423, GNorm = 0.7174, lr_0 = 7.5290e-04
Validation auc = 0.880000
Epoch 8
Loss = 3.0024e-01, PNorm = 35.6021, GNorm = 0.5706, lr_0 = 7.2051e-04
Validation auc = 0.884490
Epoch 9
Loss = 3.4822e-01, PNorm = 35.6513, GNorm = 0.3036, lr_0 = 6.9227e-04
Loss = 3.3973e-01, PNorm = 35.7076, GNorm = 0.3072, lr_0 = 6.6515e-04
Validation auc = 0.879184
Epoch 10
Loss = 3.1575e-01, PNorm = 35.7707, GNorm = 0.5729, lr_0 = 6.3653e-04
Loss = 3.2315e-01, PNorm = 35.8320, GNorm = 0.3435, lr_0 = 6.1159e-04
Validation auc = 0.888367
Epoch 11
Loss = 2.9971e-01, PNorm = 35.9005, GNorm = 0.4474, lr_0 = 5.8762e-04
Validation auc = 0.872449
Epoch 12
Loss = 3.4984e-01, PNorm = 35.9523, GNorm = 0.9388, lr_0 = 5.6234e-04
Loss = 3.2264e-01, PNorm = 35.9975, GNorm = 0.3941, lr_0 = 5.4030e-04
Validation auc = 0.872653
Epoch 13
Loss = 2.7988e-01, PNorm = 36.0410, GNorm = 0.8160, lr_0 = 5.1913e-04
Loss = 3.2014e-01, PNorm = 36.0847, GNorm = 0.5236, lr_0 = 4.9879e-04
Loss = 3.3944e-01, PNorm = 36.0894, GNorm = 0.7034, lr_0 = 4.9680e-04
Validation auc = 0.866735
Epoch 14
Loss = 3.1624e-01, PNorm = 36.1367, GNorm = 0.5165, lr_0 = 4.7733e-04
Validation auc = 0.877959
Epoch 15
Loss = 2.5526e-01, PNorm = 36.1781, GNorm = 0.7807, lr_0 = 4.5863e-04
Loss = 2.9250e-01, PNorm = 36.2198, GNorm = 0.9189, lr_0 = 4.4065e-04
Validation auc = 0.870816
Epoch 16
Loss = 2.9560e-01, PNorm = 36.2675, GNorm = 0.6867, lr_0 = 4.2170e-04
Loss = 2.8956e-01, PNorm = 36.3062, GNorm = 1.8120, lr_0 = 4.0517e-04
Validation auc = 0.869592
Epoch 17
Loss = 2.6651e-01, PNorm = 36.3468, GNorm = 0.9460, lr_0 = 3.8929e-04
Validation auc = 0.866531
Epoch 18
Loss = 3.2079e-01, PNorm = 36.3821, GNorm = 0.3099, lr_0 = 3.7255e-04
Loss = 2.7374e-01, PNorm = 36.4160, GNorm = 0.5207, lr_0 = 3.5795e-04
Validation auc = 0.862653
Epoch 19
Loss = 2.5834e-01, PNorm = 36.4577, GNorm = 0.8563, lr_0 = 3.4392e-04
Validation auc = 0.854286
Model 0 best validation auc = 0.888367 on epoch 10
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.882607
Ensemble test auc = 0.882607
Fold 4
Splitting data with seed 4
Total scaffolds = 1,025 | train scaffolds = 822 | val scaffolds = 112 | test scaffolds = 91
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 778
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7560e-01, PNorm = 35.0702, GNorm = 0.7138, lr_0 = 2.5469e-04
Validation auc = 0.839449
Epoch 1
Loss = 5.3299e-01, PNorm = 35.0928, GNorm = 0.4347, lr_0 = 4.0937e-04
Loss = 4.8267e-01, PNorm = 35.1232, GNorm = 2.3111, lr_0 = 5.5000e-04
Validation auc = 0.874342
Epoch 2
Loss = 4.7293e-01, PNorm = 35.1497, GNorm = 0.7093, lr_0 = 6.9063e-04
Validation auc = 0.888604
Epoch 3
Loss = 3.9661e-01, PNorm = 35.1842, GNorm = 0.4857, lr_0 = 8.4531e-04
Loss = 4.3782e-01, PNorm = 35.2257, GNorm = 1.1108, lr_0 = 9.8594e-04
Validation auc = 0.897674
Epoch 4
Loss = 3.9182e-01, PNorm = 35.2678, GNorm = 0.7722, lr_0 = 9.6466e-04
Validation auc = 0.884589
Epoch 5
Loss = 4.6003e-01, PNorm = 35.3198, GNorm = 0.4110, lr_0 = 9.2316e-04
Loss = 3.6402e-01, PNorm = 35.3740, GNorm = 0.3105, lr_0 = 8.8699e-04
Validation auc = 0.892551
Epoch 6
Loss = 3.5624e-01, PNorm = 35.4337, GNorm = 1.3582, lr_0 = 8.5223e-04
Validation auc = 0.886250
Epoch 7
Loss = 4.3016e-01, PNorm = 35.4872, GNorm = 0.3762, lr_0 = 8.1556e-04
Loss = 3.4543e-01, PNorm = 35.5345, GNorm = 1.8041, lr_0 = 7.8361e-04
Validation auc = 0.892551
Epoch 8
Loss = 3.7609e-01, PNorm = 35.5780, GNorm = 0.7335, lr_0 = 7.5290e-04
Loss = 3.5234e-01, PNorm = 35.6329, GNorm = 0.7667, lr_0 = 7.2339e-04
Validation auc = 0.888950
Epoch 9
Loss = 3.4841e-01, PNorm = 35.6807, GNorm = 0.6098, lr_0 = 6.9505e-04
Validation auc = 0.891443
Epoch 10
Loss = 3.6792e-01, PNorm = 35.7321, GNorm = 0.8887, lr_0 = 6.6515e-04
Loss = 3.1149e-01, PNorm = 35.7830, GNorm = 1.5626, lr_0 = 6.3908e-04
Validation auc = 0.894074
Epoch 11
Loss = 3.4156e-01, PNorm = 35.8321, GNorm = 0.6361, lr_0 = 6.1404e-04
Validation auc = 0.887566
Epoch 12
Loss = 3.2922e-01, PNorm = 35.8789, GNorm = 0.9814, lr_0 = 5.8762e-04
Loss = 2.9806e-01, PNorm = 35.9269, GNorm = 1.0252, lr_0 = 5.6459e-04
Validation auc = 0.893520
Epoch 13
Loss = 3.0069e-01, PNorm = 35.9702, GNorm = 0.4671, lr_0 = 5.4247e-04
Validation auc = 0.888050
Epoch 14
Loss = 2.5532e-01, PNorm = 36.0145, GNorm = 0.3464, lr_0 = 5.1913e-04
Loss = 3.2382e-01, PNorm = 36.0598, GNorm = 0.6357, lr_0 = 4.9879e-04
Validation auc = 0.890197
Epoch 15
Loss = 3.0058e-01, PNorm = 36.1037, GNorm = 1.6908, lr_0 = 4.7924e-04
Validation auc = 0.892551
Epoch 16
Loss = 2.0860e-01, PNorm = 36.1509, GNorm = 0.3329, lr_0 = 4.5863e-04
Loss = 2.7378e-01, PNorm = 36.1962, GNorm = 0.4964, lr_0 = 4.4065e-04
Validation auc = 0.890750
Epoch 17
Loss = 2.7223e-01, PNorm = 36.2386, GNorm = 0.7846, lr_0 = 4.2339e-04
Loss = 2.5343e-01, PNorm = 36.2821, GNorm = 0.6719, lr_0 = 4.0679e-04
Validation auc = 0.889504
Epoch 18
Loss = 2.9512e-01, PNorm = 36.3262, GNorm = 1.2480, lr_0 = 3.9085e-04
Validation auc = 0.889989
Epoch 19
Loss = 2.6149e-01, PNorm = 36.3722, GNorm = 0.9679, lr_0 = 3.7404e-04
Loss = 2.8819e-01, PNorm = 36.4131, GNorm = 0.8105, lr_0 = 3.5938e-04
Validation auc = 0.888673
Model 0 best validation auc = 0.897674 on epoch 3
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.890246
Ensemble test auc = 0.890246
Fold 5
Splitting data with seed 5
Total scaffolds = 1,025 | train scaffolds = 811 | val scaffolds = 109 | test scaffolds = 105
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 718
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8251e-01, PNorm = 35.0696, GNorm = 0.7468, lr_0 = 2.5469e-04
Validation auc = 0.953879
Epoch 1
Loss = 5.5491e-01, PNorm = 35.0895, GNorm = 0.8420, lr_0 = 4.0937e-04
Validation auc = 0.961037
Epoch 2
Loss = 5.3409e-01, PNorm = 35.1140, GNorm = 2.0035, lr_0 = 5.6406e-04
Loss = 4.4611e-01, PNorm = 35.1433, GNorm = 1.2027, lr_0 = 7.0469e-04
Validation auc = 0.966116
Epoch 3
Loss = 4.8597e-01, PNorm = 35.1712, GNorm = 0.7184, lr_0 = 8.4531e-04
Validation auc = 0.968714
Epoch 4
Loss = 5.1828e-01, PNorm = 35.2135, GNorm = 0.4462, lr_0 = 1.0000e-03
Loss = 4.4034e-01, PNorm = 35.2596, GNorm = 0.6051, lr_0 = 9.6081e-04
Validation auc = 0.973159
Epoch 5
Loss = 4.0962e-01, PNorm = 35.3172, GNorm = 0.3505, lr_0 = 9.1948e-04
Validation auc = 0.973101
Epoch 6
Loss = 3.7916e-01, PNorm = 35.3629, GNorm = 1.0582, lr_0 = 8.8345e-04
Loss = 3.8311e-01, PNorm = 35.4168, GNorm = 0.6875, lr_0 = 8.4883e-04
Loss = 3.1707e-01, PNorm = 35.4219, GNorm = 1.1064, lr_0 = 8.4544e-04
Validation auc = 0.971485
Epoch 7
Loss = 4.2100e-01, PNorm = 35.4699, GNorm = 1.4589, lr_0 = 8.1231e-04
Validation auc = 0.977430
Epoch 8
Loss = 3.9085e-01, PNorm = 35.5220, GNorm = 0.3649, lr_0 = 7.7737e-04
Validation auc = 0.972350
Epoch 9
Loss = 3.2301e-01, PNorm = 35.5796, GNorm = 0.4119, lr_0 = 7.4690e-04
Loss = 3.6364e-01, PNorm = 35.6398, GNorm = 0.6918, lr_0 = 7.1763e-04
Validation auc = 0.969291
Epoch 10
Loss = 3.3893e-01, PNorm = 35.6998, GNorm = 0.8503, lr_0 = 6.8676e-04
Validation auc = 0.970330
Epoch 11
Loss = 3.5699e-01, PNorm = 35.7572, GNorm = 0.4252, lr_0 = 6.5722e-04
Loss = 3.3548e-01, PNorm = 35.8125, GNorm = 0.6119, lr_0 = 6.3146e-04
Validation auc = 0.969349
Epoch 12
Loss = 3.5559e-01, PNorm = 35.8727, GNorm = 1.0016, lr_0 = 6.0672e-04
Validation auc = 0.965020
Epoch 13
Loss = 2.8587e-01, PNorm = 35.9371, GNorm = 0.4548, lr_0 = 5.8062e-04
Loss = 3.3202e-01, PNorm = 35.9927, GNorm = 1.0943, lr_0 = 5.5786e-04
Validation auc = 0.965943
Epoch 14
Loss = 3.2017e-01, PNorm = 36.0432, GNorm = 0.9272, lr_0 = 5.3600e-04
Validation auc = 0.973216
Epoch 15
Loss = 3.1454e-01, PNorm = 36.0998, GNorm = 1.2192, lr_0 = 5.1294e-04
Validation auc = 0.967559
Epoch 16
Loss = 2.6467e-01, PNorm = 36.1632, GNorm = 0.6561, lr_0 = 4.9088e-04
Loss = 2.9299e-01, PNorm = 36.2179, GNorm = 0.7019, lr_0 = 4.7164e-04
Validation auc = 0.958035
Epoch 17
Loss = 2.9919e-01, PNorm = 36.2709, GNorm = 0.6181, lr_0 = 4.5316e-04
Validation auc = 0.972120
Epoch 18
Loss = 2.4120e-01, PNorm = 36.3198, GNorm = 0.8205, lr_0 = 4.3366e-04
Loss = 2.8671e-01, PNorm = 36.3665, GNorm = 0.7435, lr_0 = 4.1667e-04
Validation auc = 0.967329
Epoch 19
Loss = 2.3640e-01, PNorm = 36.4217, GNorm = 0.4304, lr_0 = 3.9874e-04
Validation auc = 0.956246
Model 0 best validation auc = 0.977430 on epoch 7
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.892559
Ensemble test auc = 0.892559
Fold 6
Splitting data with seed 6
Total scaffolds = 1,025 | train scaffolds = 786 | val scaffolds = 128 | test scaffolds = 111
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 748
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7485e-01, PNorm = 35.0705, GNorm = 0.8107, lr_0 = 2.5469e-04
Validation auc = 0.802353
Epoch 1
Loss = 5.2496e-01, PNorm = 35.0902, GNorm = 0.6123, lr_0 = 4.0937e-04
Validation auc = 0.848758
Epoch 2
Loss = 3.8416e-01, PNorm = 35.1188, GNorm = 0.5323, lr_0 = 5.5000e-04
Loss = 4.6366e-01, PNorm = 35.1505, GNorm = 2.2412, lr_0 = 6.9063e-04
Validation auc = 0.878693
Epoch 3
Loss = 4.8582e-01, PNorm = 35.1830, GNorm = 0.4862, lr_0 = 8.3125e-04
Validation auc = 0.885621
Epoch 4
Loss = 5.0236e-01, PNorm = 35.2252, GNorm = 1.5284, lr_0 = 9.7187e-04
Loss = 3.9209e-01, PNorm = 35.2813, GNorm = 0.8578, lr_0 = 9.6853e-04
Validation auc = 0.897386
Epoch 5
Loss = 3.8210e-01, PNorm = 35.3438, GNorm = 0.6972, lr_0 = 9.3057e-04
Validation auc = 0.888366
Epoch 6
Loss = 5.0783e-01, PNorm = 35.4048, GNorm = 1.1817, lr_0 = 8.9411e-04
Loss = 3.8277e-01, PNorm = 35.4527, GNorm = 1.2153, lr_0 = 8.5907e-04
Validation auc = 0.904314
Epoch 7
Loss = 3.6884e-01, PNorm = 35.4965, GNorm = 0.9016, lr_0 = 8.2540e-04
Validation auc = 0.902092
Epoch 8
Loss = 3.1286e-01, PNorm = 35.5479, GNorm = 0.4619, lr_0 = 7.9306e-04
Loss = 3.1493e-01, PNorm = 35.6066, GNorm = 1.5053, lr_0 = 7.6198e-04
Validation auc = 0.906928
Epoch 9
Loss = 3.6401e-01, PNorm = 35.6506, GNorm = 0.4689, lr_0 = 7.3212e-04
Validation auc = 0.901438
Epoch 10
Loss = 2.0093e-01, PNorm = 35.6972, GNorm = 0.5306, lr_0 = 7.0343e-04
Loss = 3.2762e-01, PNorm = 35.7460, GNorm = 0.2956, lr_0 = 6.7587e-04
Validation auc = 0.906013
Epoch 11
Loss = 3.5019e-01, PNorm = 35.7915, GNorm = 1.4332, lr_0 = 6.4938e-04
Validation auc = 0.905621
Epoch 12
Loss = 3.0662e-01, PNorm = 35.8342, GNorm = 0.3459, lr_0 = 6.2393e-04
Loss = 3.1309e-01, PNorm = 35.8808, GNorm = 1.0413, lr_0 = 5.9948e-04
Validation auc = 0.908497
Epoch 13
Loss = 3.2388e-01, PNorm = 35.9261, GNorm = 0.3415, lr_0 = 5.7599e-04
Validation auc = 0.908627
Epoch 14
Loss = 2.5956e-01, PNorm = 35.9718, GNorm = 0.9614, lr_0 = 5.5342e-04
Loss = 2.9553e-01, PNorm = 36.0291, GNorm = 0.3009, lr_0 = 5.3173e-04
Validation auc = 0.914641
Epoch 15
Loss = 2.9529e-01, PNorm = 36.0839, GNorm = 0.5652, lr_0 = 5.1090e-04
Validation auc = 0.903399
Epoch 16
Loss = 2.3209e-01, PNorm = 36.1268, GNorm = 0.4595, lr_0 = 4.9088e-04
Loss = 3.0834e-01, PNorm = 36.1749, GNorm = 0.4314, lr_0 = 4.7164e-04
Validation auc = 0.907320
Epoch 17
Loss = 2.8241e-01, PNorm = 36.2217, GNorm = 0.6976, lr_0 = 4.5316e-04
Validation auc = 0.908889
Epoch 18
Loss = 2.8528e-01, PNorm = 36.2605, GNorm = 0.9632, lr_0 = 4.3540e-04
Loss = 2.6966e-01, PNorm = 36.3067, GNorm = 0.3209, lr_0 = 4.1834e-04
Validation auc = 0.913333
Epoch 19
Loss = 2.4319e-01, PNorm = 36.3577, GNorm = 0.5014, lr_0 = 4.0195e-04
Validation auc = 0.909673
Model 0 best validation auc = 0.914641 on epoch 14
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.870606
Ensemble test auc = 0.870606
Fold 7
Splitting data with seed 7
Total scaffolds = 1,025 | train scaffolds = 843 | val scaffolds = 123 | test scaffolds = 59
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 814
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7304e-01, PNorm = 35.0703, GNorm = 0.6263, lr_0 = 2.5469e-04
Validation auc = 0.887659
Epoch 1
Loss = 5.3554e-01, PNorm = 35.0933, GNorm = 1.1034, lr_0 = 4.0937e-04
Loss = 4.5947e-01, PNorm = 35.1227, GNorm = 0.4852, lr_0 = 5.5000e-04
Validation auc = 0.896451
Epoch 2
Loss = 4.2376e-01, PNorm = 35.1608, GNorm = 2.2761, lr_0 = 7.0469e-04
Validation auc = 0.909313
Epoch 3
Loss = 3.9836e-01, PNorm = 35.1874, GNorm = 0.3809, lr_0 = 8.5938e-04
Loss = 4.4445e-01, PNorm = 35.2214, GNorm = 1.2261, lr_0 = 1.0000e-03
Validation auc = 0.913220
Epoch 4
Loss = 4.5090e-01, PNorm = 35.2666, GNorm = 0.5771, lr_0 = 9.6081e-04
Loss = 4.2486e-01, PNorm = 35.3137, GNorm = 1.1855, lr_0 = 9.2316e-04
Validation auc = 0.919896
Epoch 5
Loss = 3.8056e-01, PNorm = 35.3612, GNorm = 0.9522, lr_0 = 8.8345e-04
Validation auc = 0.923641
Epoch 6
Loss = 4.8818e-01, PNorm = 35.4057, GNorm = 1.2102, lr_0 = 8.4544e-04
Loss = 4.0040e-01, PNorm = 35.4479, GNorm = 1.0697, lr_0 = 8.1231e-04
Validation auc = 0.926734
Epoch 7
Loss = 4.1679e-01, PNorm = 35.4917, GNorm = 0.5942, lr_0 = 7.7737e-04
Loss = 3.5840e-01, PNorm = 35.5366, GNorm = 0.7788, lr_0 = 7.4690e-04
Validation auc = 0.927874
Epoch 8
Loss = 3.7226e-01, PNorm = 35.5865, GNorm = 0.6241, lr_0 = 7.1763e-04
Validation auc = 0.931781
Epoch 9
Loss = 3.8011e-01, PNorm = 35.6341, GNorm = 0.7668, lr_0 = 6.8676e-04
Loss = 3.5165e-01, PNorm = 35.6743, GNorm = 0.7871, lr_0 = 6.5985e-04
Validation auc = 0.928362
Epoch 10
Loss = 3.8817e-01, PNorm = 35.7238, GNorm = 0.9218, lr_0 = 6.3146e-04
Validation auc = 0.928525
Epoch 11
Loss = 3.0091e-01, PNorm = 35.7682, GNorm = 0.3956, lr_0 = 6.0672e-04
Loss = 3.6712e-01, PNorm = 35.8103, GNorm = 1.1628, lr_0 = 5.8294e-04
Validation auc = 0.929339
Epoch 12
Loss = 4.1779e-01, PNorm = 35.8579, GNorm = 1.2701, lr_0 = 5.5786e-04
Loss = 3.4085e-01, PNorm = 35.8968, GNorm = 0.3455, lr_0 = 5.3600e-04
Validation auc = 0.929665
Epoch 13
Loss = 3.5830e-01, PNorm = 35.9403, GNorm = 0.5056, lr_0 = 5.1294e-04
Validation auc = 0.936991
Epoch 14
Loss = 3.5468e-01, PNorm = 35.9819, GNorm = 0.9676, lr_0 = 4.9088e-04
Loss = 3.4064e-01, PNorm = 36.0187, GNorm = 1.0810, lr_0 = 4.7164e-04
Validation auc = 0.936340
Epoch 15
Loss = 3.2827e-01, PNorm = 36.0562, GNorm = 0.7558, lr_0 = 4.5316e-04
Loss = 3.4325e-01, PNorm = 36.0960, GNorm = 0.6103, lr_0 = 4.3540e-04
Loss = 3.6845e-01, PNorm = 36.1010, GNorm = 1.3771, lr_0 = 4.3366e-04
Validation auc = 0.930316
Epoch 16
Loss = 3.4593e-01, PNorm = 36.1427, GNorm = 0.6451, lr_0 = 4.1667e-04
Validation auc = 0.937805
Epoch 17
Loss = 2.7173e-01, PNorm = 36.1923, GNorm = 0.4186, lr_0 = 3.9874e-04
Loss = 3.0983e-01, PNorm = 36.2349, GNorm = 0.6749, lr_0 = 3.8312e-04
Validation auc = 0.937317
Epoch 18
Loss = 2.8350e-01, PNorm = 36.2753, GNorm = 0.6538, lr_0 = 3.6811e-04
Validation auc = 0.932270
Epoch 19
Loss = 1.8408e-01, PNorm = 36.3199, GNorm = 0.7840, lr_0 = 3.5227e-04
Loss = 2.8841e-01, PNorm = 36.3568, GNorm = 1.3642, lr_0 = 3.3847e-04
Validation auc = 0.941224
Model 0 best validation auc = 0.941224 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.947479
Ensemble test auc = 0.947479
Fold 8
Splitting data with seed 8
Total scaffolds = 1,025 | train scaffolds = 828 | val scaffolds = 80 | test scaffolds = 117
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 792
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.6601e-01, PNorm = 35.0707, GNorm = 0.7782, lr_0 = 2.5469e-04
Validation auc = 0.745499
Epoch 1
Loss = 4.7155e-01, PNorm = 35.0936, GNorm = 0.9164, lr_0 = 4.0937e-04
Loss = 4.9905e-01, PNorm = 35.1194, GNorm = 2.1609, lr_0 = 5.5000e-04
Validation auc = 0.828020
Epoch 2
Loss = 4.7221e-01, PNorm = 35.1440, GNorm = 1.5141, lr_0 = 6.9063e-04
Validation auc = 0.829707
Epoch 3
Loss = 4.5416e-01, PNorm = 35.1709, GNorm = 0.3647, lr_0 = 8.3125e-04
Loss = 4.1348e-01, PNorm = 35.2071, GNorm = 0.5457, lr_0 = 9.7187e-04
Validation auc = 0.838428
Epoch 4
Loss = 3.9286e-01, PNorm = 35.2561, GNorm = 1.0254, lr_0 = 9.6853e-04
Validation auc = 0.827363
Epoch 5
Loss = 5.1394e-01, PNorm = 35.3046, GNorm = 2.1677, lr_0 = 9.3057e-04
Loss = 4.0227e-01, PNorm = 35.3508, GNorm = 0.4911, lr_0 = 8.9411e-04
Validation auc = 0.851932
Epoch 6
Loss = 3.7181e-01, PNorm = 35.3971, GNorm = 0.3078, lr_0 = 8.5907e-04
Loss = 3.7094e-01, PNorm = 35.4478, GNorm = 0.3329, lr_0 = 8.2540e-04
Loss = 4.0894e-01, PNorm = 35.4536, GNorm = 0.5604, lr_0 = 8.2211e-04
Validation auc = 0.847618
Epoch 7
Loss = 3.6263e-01, PNorm = 35.5007, GNorm = 1.8692, lr_0 = 7.8990e-04
Validation auc = 0.846680
Epoch 8
Loss = 4.1297e-01, PNorm = 35.5482, GNorm = 0.5542, lr_0 = 7.5894e-04
Loss = 3.5215e-01, PNorm = 35.5983, GNorm = 0.3255, lr_0 = 7.2920e-04
Validation auc = 0.872187
Epoch 9
Loss = 3.2859e-01, PNorm = 35.6511, GNorm = 0.5750, lr_0 = 7.0063e-04
Validation auc = 0.850806
Epoch 10
Loss = 2.9831e-01, PNorm = 35.7009, GNorm = 0.5284, lr_0 = 6.7317e-04
Loss = 3.2502e-01, PNorm = 35.7518, GNorm = 1.1141, lr_0 = 6.4679e-04
Validation auc = 0.869467
Epoch 11
Loss = 3.4715e-01, PNorm = 35.7995, GNorm = 1.0549, lr_0 = 6.2145e-04
Loss = 3.2615e-01, PNorm = 35.8504, GNorm = 0.6443, lr_0 = 5.9709e-04
Validation auc = 0.873500
Epoch 12
Loss = 2.9829e-01, PNorm = 35.9123, GNorm = 0.9581, lr_0 = 5.7369e-04
Validation auc = 0.878282
Epoch 13
Loss = 2.7795e-01, PNorm = 35.9653, GNorm = 0.8160, lr_0 = 5.4901e-04
Loss = 3.2329e-01, PNorm = 36.0177, GNorm = 0.3945, lr_0 = 5.2750e-04
Validation auc = 0.873593
Epoch 14
Loss = 3.0029e-01, PNorm = 36.0734, GNorm = 0.5453, lr_0 = 5.0683e-04
Validation auc = 0.878470
Epoch 15
Loss = 3.2177e-01, PNorm = 36.1201, GNorm = 0.5851, lr_0 = 4.8697e-04
Loss = 2.5737e-01, PNorm = 36.1662, GNorm = 0.3747, lr_0 = 4.6788e-04
Validation auc = 0.877626
Epoch 16
Loss = 3.2404e-01, PNorm = 36.2130, GNorm = 0.9334, lr_0 = 4.4955e-04
Validation auc = 0.874625
Epoch 17
Loss = 3.0028e-01, PNorm = 36.2548, GNorm = 0.3925, lr_0 = 4.3193e-04
Loss = 2.7752e-01, PNorm = 36.2967, GNorm = 0.6694, lr_0 = 4.1501e-04
Validation auc = 0.864872
Epoch 18
Loss = 2.4435e-01, PNorm = 36.3360, GNorm = 0.4282, lr_0 = 3.9874e-04
Loss = 2.9922e-01, PNorm = 36.3802, GNorm = 1.7977, lr_0 = 3.8312e-04
Loss = 2.4608e-01, PNorm = 36.3840, GNorm = 0.7206, lr_0 = 3.8159e-04
Validation auc = 0.875000
Epoch 19
Loss = 2.5786e-01, PNorm = 36.4167, GNorm = 0.3607, lr_0 = 3.6664e-04
Validation auc = 0.876969
Model 0 best validation auc = 0.878470 on epoch 14
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.903720
Ensemble test auc = 0.903720
Fold 9
Splitting data with seed 9
Total scaffolds = 1,025 | train scaffolds = 761 | val scaffolds = 139 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 752
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9230e-01, PNorm = 35.0698, GNorm = 0.6988, lr_0 = 2.5469e-04
Validation auc = 0.852076
Epoch 1
Loss = 5.4669e-01, PNorm = 35.0867, GNorm = 0.4694, lr_0 = 4.0937e-04
Loss = 5.2462e-01, PNorm = 35.1077, GNorm = 1.6948, lr_0 = 5.5000e-04
Loss = 5.8890e-01, PNorm = 35.1100, GNorm = 2.4199, lr_0 = 5.6406e-04
Validation auc = 0.865830
Epoch 2
Loss = 5.0648e-01, PNorm = 35.1335, GNorm = 0.8333, lr_0 = 7.0469e-04
Validation auc = 0.887481
Epoch 3
Loss = 4.3419e-01, PNorm = 35.1675, GNorm = 0.6184, lr_0 = 8.5938e-04
Loss = 4.4155e-01, PNorm = 35.2084, GNorm = 0.6285, lr_0 = 1.0000e-03
Loss = 1.7279e-01, PNorm = 35.2135, GNorm = 0.8469, lr_0 = 9.9601e-04
Validation auc = 0.880413
Epoch 4
Loss = 4.0845e-01, PNorm = 35.2643, GNorm = 0.9795, lr_0 = 9.5698e-04
Validation auc = 0.878630
Epoch 5
Loss = 3.9520e-01, PNorm = 35.3111, GNorm = 0.9654, lr_0 = 9.1581e-04
Loss = 4.4123e-01, PNorm = 35.3529, GNorm = 0.8656, lr_0 = 8.7992e-04
Loss = 1.2212e-01, PNorm = 35.3565, GNorm = 1.1489, lr_0 = 8.7641e-04
Validation auc = 0.875764
Epoch 6
Loss = 4.0473e-01, PNorm = 35.3946, GNorm = 1.4879, lr_0 = 8.4207e-04
Validation auc = 0.884042
Epoch 7
Loss = 3.3968e-01, PNorm = 35.4319, GNorm = 0.6907, lr_0 = 8.0584e-04
Loss = 4.0588e-01, PNorm = 35.4686, GNorm = 0.5631, lr_0 = 7.7426e-04
Loss = 3.2048e-01, PNorm = 35.4724, GNorm = 2.1991, lr_0 = 7.7117e-04
Validation auc = 0.884424
Epoch 8
Loss = 3.6163e-01, PNorm = 35.5108, GNorm = 0.4470, lr_0 = 7.4095e-04
Validation auc = 0.889073
Epoch 9
Loss = 4.3420e-01, PNorm = 35.5524, GNorm = 0.4981, lr_0 = 7.0908e-04
Loss = 3.3236e-01, PNorm = 35.5941, GNorm = 0.3166, lr_0 = 6.8129e-04
Loss = 6.3094e-01, PNorm = 35.5986, GNorm = 2.7038, lr_0 = 6.7857e-04
Validation auc = 0.893212
Epoch 10
Loss = 3.1444e-01, PNorm = 35.6475, GNorm = 1.1133, lr_0 = 6.5198e-04
Validation auc = 0.886971
Epoch 11
Loss = 3.7970e-01, PNorm = 35.6977, GNorm = 0.8455, lr_0 = 6.2393e-04
Loss = 3.4059e-01, PNorm = 35.7316, GNorm = 0.5437, lr_0 = 5.9948e-04
Loss = 2.1933e-01, PNorm = 35.7358, GNorm = 1.9697, lr_0 = 5.9709e-04
Validation auc = 0.887354
Epoch 12
Loss = 3.4032e-01, PNorm = 35.7732, GNorm = 0.8045, lr_0 = 5.7369e-04
Validation auc = 0.893467
Epoch 13
Loss = 3.5088e-01, PNorm = 35.8152, GNorm = 1.2665, lr_0 = 5.4901e-04
Loss = 3.5956e-01, PNorm = 35.8498, GNorm = 0.4749, lr_0 = 5.2750e-04
Loss = 8.7149e-02, PNorm = 35.8531, GNorm = 1.2115, lr_0 = 5.2540e-04
Validation auc = 0.892384
Epoch 14
Loss = 3.6981e-01, PNorm = 35.8829, GNorm = 0.3597, lr_0 = 5.0481e-04
Validation auc = 0.890728
Epoch 15
Loss = 2.9604e-01, PNorm = 35.9185, GNorm = 0.6417, lr_0 = 4.8309e-04
Loss = 3.3785e-01, PNorm = 35.9554, GNorm = 0.5141, lr_0 = 4.6416e-04
Loss = 5.1414e-02, PNorm = 35.9588, GNorm = 0.8846, lr_0 = 4.6231e-04
Validation auc = 0.892193
Epoch 16
Loss = 3.1095e-01, PNorm = 35.9967, GNorm = 0.4127, lr_0 = 4.4419e-04
Validation auc = 0.890983
Epoch 17
Loss = 3.0211e-01, PNorm = 36.0368, GNorm = 0.5948, lr_0 = 4.2508e-04
Loss = 2.7835e-01, PNorm = 36.0770, GNorm = 0.3563, lr_0 = 4.0842e-04
Loss = 1.6385e-01, PNorm = 36.0812, GNorm = 1.4043, lr_0 = 4.0679e-04
Validation auc = 0.890665
Epoch 18
Loss = 3.0024e-01, PNorm = 36.1194, GNorm = 0.7451, lr_0 = 3.9085e-04
Validation auc = 0.892320
Epoch 19
Loss = 2.7554e-01, PNorm = 36.1600, GNorm = 0.4707, lr_0 = 3.7404e-04
Loss = 3.0919e-01, PNorm = 36.1915, GNorm = 0.3832, lr_0 = 3.5938e-04
Loss = 1.4756e-01, PNorm = 36.1949, GNorm = 1.3379, lr_0 = 3.5795e-04
Validation auc = 0.892957
Model 0 best validation auc = 0.893467 on epoch 12
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.930991
Ensemble test auc = 0.930991
Fold 10
Splitting data with seed 10
Total scaffolds = 1,025 | train scaffolds = 789 | val scaffolds = 110 | test scaffolds = 126
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 702
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8117e-01, PNorm = 35.0705, GNorm = 0.8525, lr_0 = 2.5469e-04
Validation auc = 0.944292
Epoch 1
Loss = 5.1201e-01, PNorm = 35.0884, GNorm = 0.7088, lr_0 = 4.0937e-04
Validation auc = 0.953786
Epoch 2
Loss = 6.6086e-01, PNorm = 35.1115, GNorm = 5.9771, lr_0 = 5.6406e-04
Loss = 5.5189e-01, PNorm = 35.1219, GNorm = 0.3395, lr_0 = 7.0469e-04
Validation auc = 0.963166
Epoch 3
Loss = 4.9017e-01, PNorm = 35.1491, GNorm = 0.6980, lr_0 = 8.5938e-04
Validation auc = 0.973233
Epoch 4
Loss = 4.4559e-01, PNorm = 35.1896, GNorm = 0.4450, lr_0 = 9.9601e-04
Loss = 4.5101e-01, PNorm = 35.2270, GNorm = 1.0258, lr_0 = 9.5698e-04
Loss = 6.5702e-01, PNorm = 35.2299, GNorm = 3.6831, lr_0 = 9.5316e-04
Validation auc = 0.967056
Epoch 5
Loss = 4.2974e-01, PNorm = 35.2634, GNorm = 0.4625, lr_0 = 9.1581e-04
Validation auc = 0.960993
Epoch 6
Loss = 4.1591e-01, PNorm = 35.3020, GNorm = 0.5589, lr_0 = 8.7641e-04
Validation auc = 0.966598
Epoch 7
Loss = 3.8293e-01, PNorm = 35.3416, GNorm = 0.3259, lr_0 = 8.3871e-04
Loss = 3.9422e-01, PNorm = 35.3831, GNorm = 0.5320, lr_0 = 8.0584e-04
Validation auc = 0.961222
Epoch 8
Loss = 3.9542e-01, PNorm = 35.4187, GNorm = 0.6563, lr_0 = 7.7117e-04
Validation auc = 0.967742
Epoch 9
Loss = 3.7331e-01, PNorm = 35.4531, GNorm = 0.7208, lr_0 = 7.3800e-04
Loss = 3.9239e-01, PNorm = 35.4875, GNorm = 0.3442, lr_0 = 7.0908e-04
Loss = 1.4476e+00, PNorm = 35.4897, GNorm = 7.1438, lr_0 = 7.0625e-04
Validation auc = 0.965569
Epoch 10
Loss = 3.9303e-01, PNorm = 35.5238, GNorm = 1.0592, lr_0 = 6.7857e-04
Validation auc = 0.959735
Epoch 11
Loss = 3.6853e-01, PNorm = 35.5616, GNorm = 0.3837, lr_0 = 6.4938e-04
Validation auc = 0.968771
Epoch 12
Loss = 3.5931e-01, PNorm = 35.6030, GNorm = 0.8860, lr_0 = 6.2145e-04
Loss = 3.9633e-01, PNorm = 35.6372, GNorm = 0.3778, lr_0 = 5.9709e-04
Validation auc = 0.968428
Epoch 13
Loss = 3.4630e-01, PNorm = 35.6637, GNorm = 0.2918, lr_0 = 5.7141e-04
Validation auc = 0.968657
Epoch 14
Loss = 3.7015e-01, PNorm = 35.6921, GNorm = 1.1905, lr_0 = 5.4682e-04
Loss = 3.6803e-01, PNorm = 35.7194, GNorm = 0.9143, lr_0 = 5.2540e-04
Loss = 2.6707e-01, PNorm = 35.7216, GNorm = 1.6636, lr_0 = 5.2330e-04
Validation auc = 0.969687
Epoch 15
Loss = 3.4903e-01, PNorm = 35.7491, GNorm = 0.6366, lr_0 = 5.0279e-04
Validation auc = 0.968085
Epoch 16
Loss = 3.2867e-01, PNorm = 35.7845, GNorm = 0.5708, lr_0 = 4.8116e-04
Validation auc = 0.967971
Epoch 17
Loss = 3.3175e-01, PNorm = 35.8183, GNorm = 0.4435, lr_0 = 4.6046e-04
Loss = 3.3544e-01, PNorm = 35.8459, GNorm = 0.7065, lr_0 = 4.4242e-04
Validation auc = 0.970030
Epoch 18
Loss = 3.4102e-01, PNorm = 35.8741, GNorm = 0.5165, lr_0 = 4.2339e-04
Validation auc = 0.972318
Epoch 19
Loss = 2.9876e-01, PNorm = 35.8985, GNorm = 0.6126, lr_0 = 4.0517e-04
Loss = 3.6856e-01, PNorm = 35.9211, GNorm = 0.3669, lr_0 = 3.8929e-04
Loss = 1.3636e-02, PNorm = 35.9235, GNorm = 0.1469, lr_0 = 3.8774e-04
Validation auc = 0.973004
Model 0 best validation auc = 0.973233 on epoch 3
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.795291
Ensemble test auc = 0.795291
Fold 11
Splitting data with seed 11
Total scaffolds = 1,025 | train scaffolds = 872 | val scaffolds = 67 | test scaffolds = 86
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 828
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7685e-01, PNorm = 35.0703, GNorm = 0.6356, lr_0 = 2.5469e-04
Validation auc = 0.764462
Epoch 1
Loss = 5.2665e-01, PNorm = 35.0930, GNorm = 0.5696, lr_0 = 4.0937e-04
Loss = 4.5546e-01, PNorm = 35.1239, GNorm = 0.7869, lr_0 = 5.5000e-04
Validation auc = 0.843809
Epoch 2
Loss = 4.7645e-01, PNorm = 35.1503, GNorm = 3.0583, lr_0 = 6.9063e-04
Validation auc = 0.878518
Epoch 3
Loss = 3.9108e-01, PNorm = 35.1765, GNorm = 0.7109, lr_0 = 8.4531e-04
Loss = 4.1670e-01, PNorm = 35.2119, GNorm = 1.9865, lr_0 = 9.8594e-04
Validation auc = 0.885397
Epoch 4
Loss = 5.0296e-01, PNorm = 35.2539, GNorm = 1.3348, lr_0 = 9.6466e-04
Loss = 3.8698e-01, PNorm = 35.2995, GNorm = 0.4214, lr_0 = 9.2686e-04
Validation auc = 0.893840
Epoch 5
Loss = 3.6632e-01, PNorm = 35.3570, GNorm = 0.4303, lr_0 = 8.8699e-04
Validation auc = 0.897905
Epoch 6
Loss = 5.0570e-01, PNorm = 35.4065, GNorm = 0.8660, lr_0 = 8.5223e-04
Loss = 3.5351e-01, PNorm = 35.4581, GNorm = 1.3999, lr_0 = 8.1883e-04
Validation auc = 0.913618
Epoch 7
Loss = 3.2101e-01, PNorm = 35.5124, GNorm = 1.1117, lr_0 = 7.8361e-04
Loss = 3.4994e-01, PNorm = 35.5697, GNorm = 0.5277, lr_0 = 7.5290e-04
Validation auc = 0.908224
Epoch 8
Loss = 3.6357e-01, PNorm = 35.6187, GNorm = 0.5112, lr_0 = 7.2339e-04
Validation auc = 0.909631
Epoch 9
Loss = 2.8685e-01, PNorm = 35.6798, GNorm = 0.3835, lr_0 = 6.9505e-04
Loss = 3.5309e-01, PNorm = 35.7386, GNorm = 0.5009, lr_0 = 6.6781e-04
Validation auc = 0.914947
Epoch 10
Loss = 3.3927e-01, PNorm = 35.8014, GNorm = 0.8212, lr_0 = 6.3908e-04
Loss = 2.9776e-01, PNorm = 35.8591, GNorm = 0.4313, lr_0 = 6.1404e-04
Validation auc = 0.911820
Epoch 11
Loss = 2.8627e-01, PNorm = 35.9156, GNorm = 1.0563, lr_0 = 5.8997e-04
Validation auc = 0.911820
Epoch 12
Loss = 2.9131e-01, PNorm = 35.9790, GNorm = 0.5102, lr_0 = 5.6459e-04
Loss = 2.9662e-01, PNorm = 36.0379, GNorm = 0.7671, lr_0 = 5.4247e-04
Validation auc = 0.896029
Epoch 13
Loss = 3.0714e-01, PNorm = 36.0958, GNorm = 0.7567, lr_0 = 5.2121e-04
Loss = 3.1735e-01, PNorm = 36.1394, GNorm = 1.1666, lr_0 = 5.0079e-04
Validation auc = 0.906035
Epoch 14
Loss = 2.8453e-01, PNorm = 36.1916, GNorm = 0.4005, lr_0 = 4.7924e-04
Validation auc = 0.899468
Epoch 15
Loss = 3.2166e-01, PNorm = 36.2467, GNorm = 0.4220, lr_0 = 4.6046e-04
Loss = 2.7179e-01, PNorm = 36.3023, GNorm = 0.4988, lr_0 = 4.4242e-04
Validation auc = 0.902595
Epoch 16
Loss = 2.9237e-01, PNorm = 36.3520, GNorm = 1.0322, lr_0 = 4.2339e-04
Loss = 3.0332e-01, PNorm = 36.4016, GNorm = 0.6213, lr_0 = 4.0679e-04
Validation auc = 0.898139
Epoch 17
Loss = 2.3955e-01, PNorm = 36.4447, GNorm = 0.6300, lr_0 = 3.9085e-04
Validation auc = 0.901110
Epoch 18
Loss = 2.4721e-01, PNorm = 36.4903, GNorm = 1.1654, lr_0 = 3.7554e-04
Loss = 2.9425e-01, PNorm = 36.5354, GNorm = 0.7689, lr_0 = 3.6082e-04
Validation auc = 0.898687
Epoch 19
Loss = 2.8666e-01, PNorm = 36.5818, GNorm = 0.5562, lr_0 = 3.4530e-04
Loss = 2.6012e-01, PNorm = 36.6223, GNorm = 0.5350, lr_0 = 3.3177e-04
Validation auc = 0.898452
Model 0 best validation auc = 0.914947 on epoch 9
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.894284
Ensemble test auc = 0.894284
Fold 12
Splitting data with seed 12
Total scaffolds = 1,025 | train scaffolds = 862 | val scaffolds = 100 | test scaffolds = 63
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 770
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.9343e-01, PNorm = 35.0690, GNorm = 0.9172, lr_0 = 2.5469e-04
Validation auc = 0.916715
Epoch 1
Loss = 5.3700e-01, PNorm = 35.0873, GNorm = 0.6494, lr_0 = 4.0937e-04
Loss = 5.0338e-01, PNorm = 35.1116, GNorm = 0.6677, lr_0 = 5.5000e-04
Loss = 4.2294e-01, PNorm = 35.1141, GNorm = 0.7392, lr_0 = 5.6406e-04
Validation auc = 0.932994
Epoch 2
Loss = 4.5937e-01, PNorm = 35.1458, GNorm = 1.1284, lr_0 = 7.0469e-04
Validation auc = 0.934448
Epoch 3
Loss = 5.0571e-01, PNorm = 35.1785, GNorm = 0.6088, lr_0 = 8.4531e-04
Loss = 4.5165e-01, PNorm = 35.2127, GNorm = 1.0836, lr_0 = 9.8594e-04
Validation auc = 0.934012
Epoch 4
Loss = 4.3338e-01, PNorm = 35.2680, GNorm = 1.3002, lr_0 = 9.6081e-04
Validation auc = 0.939099
Epoch 5
Loss = 4.1901e-01, PNorm = 35.3140, GNorm = 1.1825, lr_0 = 9.2316e-04
Loss = 3.8931e-01, PNorm = 35.3645, GNorm = 0.4462, lr_0 = 8.8699e-04
Validation auc = 0.936483
Epoch 6
Loss = 3.9850e-01, PNorm = 35.4249, GNorm = 0.3704, lr_0 = 8.4883e-04
Validation auc = 0.940988
Epoch 7
Loss = 3.8655e-01, PNorm = 35.4775, GNorm = 1.0608, lr_0 = 8.1231e-04
Loss = 3.4123e-01, PNorm = 35.5339, GNorm = 1.3259, lr_0 = 7.8048e-04
Validation auc = 0.938372
Epoch 8
Loss = 3.5553e-01, PNorm = 35.5932, GNorm = 1.6356, lr_0 = 7.4989e-04
Validation auc = 0.937645
Epoch 9
Loss = 3.1688e-01, PNorm = 35.6539, GNorm = 1.4787, lr_0 = 7.1763e-04
Loss = 4.2468e-01, PNorm = 35.7048, GNorm = 1.6387, lr_0 = 6.8951e-04
Validation auc = 0.937209
Epoch 10
Loss = 3.7449e-01, PNorm = 35.7493, GNorm = 0.4388, lr_0 = 6.6249e-04
Validation auc = 0.939244
Epoch 11
Loss = 2.7020e-01, PNorm = 35.8054, GNorm = 0.4247, lr_0 = 6.3399e-04
Loss = 3.4237e-01, PNorm = 35.8599, GNorm = 0.6677, lr_0 = 6.0915e-04
Validation auc = 0.938953
Epoch 12
Loss = 3.4401e-01, PNorm = 35.9130, GNorm = 0.8341, lr_0 = 5.8294e-04
Loss = 3.1683e-01, PNorm = 35.9631, GNorm = 0.6299, lr_0 = 5.6010e-04
Validation auc = 0.940116
Epoch 13
Loss = 3.0532e-01, PNorm = 36.0151, GNorm = 0.6278, lr_0 = 5.3815e-04
Validation auc = 0.941570
Epoch 14
Loss = 3.4739e-01, PNorm = 36.0596, GNorm = 0.8678, lr_0 = 5.1500e-04
Loss = 3.0902e-01, PNorm = 36.1013, GNorm = 0.8934, lr_0 = 4.9482e-04
Validation auc = 0.943895
Epoch 15
Loss = 2.7551e-01, PNorm = 36.1408, GNorm = 0.4194, lr_0 = 4.7543e-04
Validation auc = 0.943605
Epoch 16
Loss = 3.0019e-01, PNorm = 36.1889, GNorm = 1.3632, lr_0 = 4.5497e-04
Loss = 2.7117e-01, PNorm = 36.2257, GNorm = 0.3589, lr_0 = 4.3714e-04
Validation auc = 0.943314
Epoch 17
Loss = 2.9007e-01, PNorm = 36.2760, GNorm = 0.7223, lr_0 = 4.1834e-04
Validation auc = 0.948547
Epoch 18
Loss = 2.9435e-01, PNorm = 36.3125, GNorm = 0.7880, lr_0 = 4.0195e-04
Loss = 2.8660e-01, PNorm = 36.3536, GNorm = 0.6471, lr_0 = 3.8619e-04
Validation auc = 0.948983
Epoch 19
Loss = 3.0199e-01, PNorm = 36.4010, GNorm = 1.4437, lr_0 = 3.6958e-04
Validation auc = 0.948837
Model 0 best validation auc = 0.948983 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.936275
Ensemble test auc = 0.936275
Fold 13
Splitting data with seed 13
Total scaffolds = 1,025 | train scaffolds = 760 | val scaffolds = 122 | test scaffolds = 143
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 778
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7947e-01, PNorm = 35.0706, GNorm = 0.7367, lr_0 = 2.5469e-04
Validation auc = 0.789521
Epoch 1
Loss = 5.5428e-01, PNorm = 35.0911, GNorm = 0.4450, lr_0 = 4.0937e-04
Loss = 4.8332e-01, PNorm = 35.1163, GNorm = 0.6628, lr_0 = 5.5000e-04
Validation auc = 0.825655
Epoch 2
Loss = 4.8379e-01, PNorm = 35.1456, GNorm = 0.6524, lr_0 = 6.9063e-04
Validation auc = 0.828064
Epoch 3
Loss = 4.2678e-01, PNorm = 35.1874, GNorm = 0.4407, lr_0 = 8.4531e-04
Loss = 4.2403e-01, PNorm = 35.2259, GNorm = 1.1955, lr_0 = 9.8594e-04
Validation auc = 0.863896
Epoch 4
Loss = 4.6620e-01, PNorm = 35.2702, GNorm = 1.1266, lr_0 = 9.6466e-04
Validation auc = 0.861036
Epoch 5
Loss = 4.1240e-01, PNorm = 35.3167, GNorm = 0.4728, lr_0 = 9.2316e-04
Loss = 4.3083e-01, PNorm = 35.3581, GNorm = 1.2302, lr_0 = 8.8699e-04
Validation auc = 0.875188
Epoch 6
Loss = 3.4820e-01, PNorm = 35.4046, GNorm = 0.5260, lr_0 = 8.5223e-04
Validation auc = 0.858175
Epoch 7
Loss = 3.8788e-01, PNorm = 35.4561, GNorm = 0.5025, lr_0 = 8.1556e-04
Loss = 3.6552e-01, PNorm = 35.5034, GNorm = 0.4531, lr_0 = 7.8361e-04
Validation auc = 0.872026
Epoch 8
Loss = 3.5068e-01, PNorm = 35.5516, GNorm = 0.4859, lr_0 = 7.5290e-04
Loss = 3.4142e-01, PNorm = 35.6035, GNorm = 0.5240, lr_0 = 7.2339e-04
Validation auc = 0.884673
Epoch 9
Loss = 3.5350e-01, PNorm = 35.6506, GNorm = 0.3281, lr_0 = 6.9505e-04
Validation auc = 0.893104
Epoch 10
Loss = 3.1594e-01, PNorm = 35.7035, GNorm = 0.4235, lr_0 = 6.6515e-04
Loss = 3.5018e-01, PNorm = 35.7501, GNorm = 1.0589, lr_0 = 6.3908e-04
Validation auc = 0.886329
Epoch 11
Loss = 3.4242e-01, PNorm = 35.7939, GNorm = 0.6263, lr_0 = 6.1404e-04
Validation auc = 0.877296
Epoch 12
Loss = 3.2308e-01, PNorm = 35.8513, GNorm = 0.7173, lr_0 = 5.8762e-04
Loss = 3.0599e-01, PNorm = 35.9030, GNorm = 0.6167, lr_0 = 5.6459e-04
Validation auc = 0.890545
Epoch 13
Loss = 3.1002e-01, PNorm = 35.9505, GNorm = 0.4709, lr_0 = 5.4247e-04
Validation auc = 0.893104
Epoch 14
Loss = 2.9451e-01, PNorm = 36.0011, GNorm = 0.7183, lr_0 = 5.1913e-04
Loss = 2.9205e-01, PNorm = 36.0531, GNorm = 0.4610, lr_0 = 4.9879e-04
Validation auc = 0.879404
Epoch 15
Loss = 3.0238e-01, PNorm = 36.1007, GNorm = 0.4020, lr_0 = 4.7924e-04
Validation auc = 0.894911
Epoch 16
Loss = 2.2493e-01, PNorm = 36.1486, GNorm = 0.7478, lr_0 = 4.5863e-04
Loss = 3.2578e-01, PNorm = 36.1886, GNorm = 0.4339, lr_0 = 4.4065e-04
Validation auc = 0.876242
Epoch 17
Loss = 3.0244e-01, PNorm = 36.2314, GNorm = 0.5583, lr_0 = 4.2339e-04
Loss = 2.6307e-01, PNorm = 36.2740, GNorm = 0.5845, lr_0 = 4.0679e-04
Validation auc = 0.880458
Epoch 18
Loss = 2.7464e-01, PNorm = 36.3133, GNorm = 0.9363, lr_0 = 3.9085e-04
Validation auc = 0.888889
Epoch 19
Loss = 2.5094e-01, PNorm = 36.3518, GNorm = 1.5617, lr_0 = 3.7404e-04
Loss = 2.7179e-01, PNorm = 36.3832, GNorm = 0.7638, lr_0 = 3.5938e-04
Validation auc = 0.890997
Model 0 best validation auc = 0.894911 on epoch 15
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.930272
Ensemble test auc = 0.930272
Fold 14
Splitting data with seed 14
Total scaffolds = 1,025 | train scaffolds = 828 | val scaffolds = 72 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 758
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7414e-01, PNorm = 35.0698, GNorm = 0.5696, lr_0 = 2.5469e-04
Validation auc = 0.582942
Epoch 1
Loss = 5.3306e-01, PNorm = 35.0919, GNorm = 1.5615, lr_0 = 4.0937e-04
Loss = 4.8940e-01, PNorm = 35.1157, GNorm = 0.4243, lr_0 = 5.5000e-04
Loss = 8.2608e-01, PNorm = 35.1176, GNorm = 2.7176, lr_0 = 5.6406e-04
Validation auc = 0.635397
Epoch 2
Loss = 4.9709e-01, PNorm = 35.1350, GNorm = 2.0382, lr_0 = 7.0469e-04
Validation auc = 0.644465
Epoch 3
Loss = 4.1565e-01, PNorm = 35.1643, GNorm = 0.7845, lr_0 = 8.5938e-04
Loss = 4.1879e-01, PNorm = 35.2087, GNorm = 0.5991, lr_0 = 1.0000e-03
Loss = 1.0166e+00, PNorm = 35.2122, GNorm = 1.5446, lr_0 = 9.9601e-04
Validation auc = 0.765947
Epoch 4
Loss = 4.1044e-01, PNorm = 35.2496, GNorm = 0.9520, lr_0 = 9.5698e-04
Validation auc = 0.747186
Epoch 5
Loss = 3.4115e-01, PNorm = 35.2993, GNorm = 0.6305, lr_0 = 9.1581e-04
Loss = 4.2663e-01, PNorm = 35.3396, GNorm = 0.9050, lr_0 = 8.7992e-04
Loss = 2.4761e-01, PNorm = 35.3436, GNorm = 0.7210, lr_0 = 8.7641e-04
Validation auc = 0.826454
Epoch 6
Loss = 3.8352e-01, PNorm = 35.3802, GNorm = 0.8370, lr_0 = 8.4207e-04
Validation auc = 0.810741
Epoch 7
Loss = 3.5273e-01, PNorm = 35.4223, GNorm = 1.1687, lr_0 = 8.0907e-04
Loss = 3.7936e-01, PNorm = 35.4675, GNorm = 0.6870, lr_0 = 7.7737e-04
Validation auc = 0.830206
Epoch 8
Loss = 3.6743e-01, PNorm = 35.5169, GNorm = 0.5394, lr_0 = 7.4392e-04
Validation auc = 0.801517
Epoch 9
Loss = 3.2392e-01, PNorm = 35.5684, GNorm = 0.5495, lr_0 = 7.1192e-04
Loss = 3.5604e-01, PNorm = 35.6167, GNorm = 0.3193, lr_0 = 6.8402e-04
Validation auc = 0.838806
Epoch 10
Loss = 3.3868e-01, PNorm = 35.6746, GNorm = 0.6371, lr_0 = 6.5459e-04
Validation auc = 0.848734
Epoch 11
Loss = 3.3389e-01, PNorm = 35.7197, GNorm = 0.6539, lr_0 = 6.2643e-04
Loss = 3.6257e-01, PNorm = 35.7695, GNorm = 0.2930, lr_0 = 6.0189e-04
Validation auc = 0.835991
Epoch 12
Loss = 3.7012e-01, PNorm = 35.8191, GNorm = 0.4877, lr_0 = 5.7599e-04
Validation auc = 0.824265
Epoch 13
Loss = 2.8140e-01, PNorm = 35.8618, GNorm = 0.3496, lr_0 = 5.5342e-04
Loss = 3.2471e-01, PNorm = 35.9053, GNorm = 0.8750, lr_0 = 5.3173e-04
Validation auc = 0.844121
Epoch 14
Loss = 3.4159e-01, PNorm = 35.9400, GNorm = 0.3985, lr_0 = 5.0886e-04
Validation auc = 0.838024
Epoch 15
Loss = 3.6210e-01, PNorm = 35.9794, GNorm = 1.2181, lr_0 = 4.8697e-04
Loss = 3.6086e-01, PNorm = 36.0168, GNorm = 0.8236, lr_0 = 4.6788e-04
Validation auc = 0.846623
Epoch 16
Loss = 3.1754e-01, PNorm = 36.0590, GNorm = 0.7609, lr_0 = 4.4776e-04
Validation auc = 0.847483
Epoch 17
Loss = 3.6092e-01, PNorm = 36.1008, GNorm = 0.9902, lr_0 = 4.2849e-04
Loss = 2.9390e-01, PNorm = 36.1487, GNorm = 0.7331, lr_0 = 4.1170e-04
Validation auc = 0.851782
Epoch 18
Loss = 2.8918e-01, PNorm = 36.1968, GNorm = 1.4835, lr_0 = 3.9399e-04
Validation auc = 0.861163
Epoch 19
Loss = 2.3924e-01, PNorm = 36.2377, GNorm = 0.3949, lr_0 = 3.7855e-04
Loss = 2.9068e-01, PNorm = 36.2746, GNorm = 0.3945, lr_0 = 3.6372e-04
Validation auc = 0.847483
Model 0 best validation auc = 0.861163 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.950706
Ensemble test auc = 0.950706
Fold 15
Splitting data with seed 15
Total scaffolds = 1,025 | train scaffolds = 830 | val scaffolds = 123 | test scaffolds = 72
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 780
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8237e-01, PNorm = 35.0693, GNorm = 1.0093, lr_0 = 2.5469e-04
Validation auc = 0.882924
Epoch 1
Loss = 5.0211e-01, PNorm = 35.0902, GNorm = 1.1149, lr_0 = 4.0937e-04
Loss = 5.1049e-01, PNorm = 35.1158, GNorm = 1.4658, lr_0 = 5.5000e-04
Validation auc = 0.895516
Epoch 2
Loss = 4.5727e-01, PNorm = 35.1428, GNorm = 0.6436, lr_0 = 6.9063e-04
Validation auc = 0.917690
Epoch 3
Loss = 4.4487e-01, PNorm = 35.1772, GNorm = 0.5151, lr_0 = 8.4531e-04
Loss = 4.1952e-01, PNorm = 35.2200, GNorm = 0.5894, lr_0 = 9.8594e-04
Validation auc = 0.833231
Epoch 4
Loss = 4.0972e-01, PNorm = 35.2738, GNorm = 1.8788, lr_0 = 9.6466e-04
Validation auc = 0.866400
Epoch 5
Loss = 4.1875e-01, PNorm = 35.3155, GNorm = 1.0828, lr_0 = 9.2686e-04
Loss = 3.9793e-01, PNorm = 35.3585, GNorm = 0.8247, lr_0 = 8.9054e-04
Validation auc = 0.882494
Epoch 6
Loss = 3.5179e-01, PNorm = 35.4096, GNorm = 0.6394, lr_0 = 8.5223e-04
Validation auc = 0.877457
Epoch 7
Loss = 3.3255e-01, PNorm = 35.4583, GNorm = 0.4685, lr_0 = 8.1883e-04
Loss = 3.7104e-01, PNorm = 35.5030, GNorm = 0.7133, lr_0 = 7.8674e-04
Validation auc = 0.871929
Epoch 8
Loss = 3.3694e-01, PNorm = 35.5558, GNorm = 0.5442, lr_0 = 7.5290e-04
Loss = 3.5896e-01, PNorm = 35.6075, GNorm = 2.0211, lr_0 = 7.2339e-04
Validation auc = 0.904484
Epoch 9
Loss = 3.6663e-01, PNorm = 35.6594, GNorm = 0.4813, lr_0 = 6.9505e-04
Validation auc = 0.882371
Epoch 10
Loss = 3.6318e-01, PNorm = 35.7150, GNorm = 0.6159, lr_0 = 6.6781e-04
Loss = 3.5191e-01, PNorm = 35.7648, GNorm = 1.8197, lr_0 = 6.4164e-04
Validation auc = 0.903747
Epoch 11
Loss = 3.6193e-01, PNorm = 35.8147, GNorm = 1.0080, lr_0 = 6.1404e-04
Validation auc = 0.881757
Epoch 12
Loss = 2.6833e-01, PNorm = 35.8659, GNorm = 0.4154, lr_0 = 5.8997e-04
Loss = 3.3341e-01, PNorm = 35.9172, GNorm = 0.5193, lr_0 = 5.6686e-04
Validation auc = 0.890725
Epoch 13
Loss = 3.0753e-01, PNorm = 35.9818, GNorm = 0.4135, lr_0 = 5.4247e-04
Validation auc = 0.894533
Epoch 14
Loss = 3.1104e-01, PNorm = 36.0320, GNorm = 0.5919, lr_0 = 5.2121e-04
Loss = 2.9783e-01, PNorm = 36.0828, GNorm = 0.9304, lr_0 = 5.0079e-04
Validation auc = 0.893428
Epoch 15
Loss = 3.0556e-01, PNorm = 36.1332, GNorm = 0.7884, lr_0 = 4.8116e-04
Validation auc = 0.896130
Epoch 16
Loss = 4.5046e-01, PNorm = 36.1888, GNorm = 1.5997, lr_0 = 4.6046e-04
Loss = 3.2600e-01, PNorm = 36.2288, GNorm = 1.1175, lr_0 = 4.4242e-04
Validation auc = 0.905344
Epoch 17
Loss = 3.2873e-01, PNorm = 36.2678, GNorm = 0.4464, lr_0 = 4.2508e-04
Loss = 2.9163e-01, PNorm = 36.3117, GNorm = 1.0529, lr_0 = 4.0842e-04
Loss = 4.0438e-01, PNorm = 36.3165, GNorm = 1.0319, lr_0 = 4.0679e-04
Validation auc = 0.892813
Epoch 18
Loss = 2.6151e-01, PNorm = 36.3662, GNorm = 0.7005, lr_0 = 3.9085e-04
Validation auc = 0.902273
Epoch 19
Loss = 3.0084e-01, PNorm = 36.4130, GNorm = 1.3264, lr_0 = 3.7554e-04
Loss = 2.5929e-01, PNorm = 36.4546, GNorm = 1.0364, lr_0 = 3.6082e-04
Validation auc = 0.919349
Model 0 best validation auc = 0.919349 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.919849
Ensemble test auc = 0.919849
Fold 16
Splitting data with seed 16
Total scaffolds = 1,025 | train scaffolds = 846 | val scaffolds = 66 | test scaffolds = 113
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 792
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8537e-01, PNorm = 35.0697, GNorm = 0.6488, lr_0 = 2.5469e-04
Validation auc = 0.809345
Epoch 1
Loss = 5.0703e-01, PNorm = 35.0915, GNorm = 0.4756, lr_0 = 4.0937e-04
Loss = 4.9440e-01, PNorm = 35.1177, GNorm = 2.4122, lr_0 = 5.5000e-04
Validation auc = 0.855585
Epoch 2
Loss = 4.6537e-01, PNorm = 35.1434, GNorm = 0.6853, lr_0 = 6.9063e-04
Validation auc = 0.873982
Epoch 3
Loss = 4.4312e-01, PNorm = 35.1828, GNorm = 0.5872, lr_0 = 8.3125e-04
Loss = 4.2377e-01, PNorm = 35.2237, GNorm = 0.8397, lr_0 = 9.7187e-04
Validation auc = 0.883914
Epoch 4
Loss = 3.9276e-01, PNorm = 35.2716, GNorm = 1.2873, lr_0 = 9.6853e-04
Validation auc = 0.898079
Epoch 5
Loss = 4.6398e-01, PNorm = 35.3238, GNorm = 0.5045, lr_0 = 9.3057e-04
Loss = 3.8126e-01, PNorm = 35.3782, GNorm = 1.1121, lr_0 = 8.9411e-04
Validation auc = 0.886356
Epoch 6
Loss = 3.4943e-01, PNorm = 35.4389, GNorm = 1.2245, lr_0 = 8.5907e-04
Loss = 3.8782e-01, PNorm = 35.5048, GNorm = 1.3336, lr_0 = 8.2540e-04
Loss = 3.8075e-01, PNorm = 35.5092, GNorm = 0.5412, lr_0 = 8.2211e-04
Validation auc = 0.878216
Epoch 7
Loss = 3.6227e-01, PNorm = 35.5670, GNorm = 1.0760, lr_0 = 7.8990e-04
Validation auc = 0.870563
Epoch 8
Loss = 3.1865e-01, PNorm = 35.6273, GNorm = 0.5971, lr_0 = 7.5894e-04
Loss = 3.1387e-01, PNorm = 35.6919, GNorm = 0.5089, lr_0 = 7.2920e-04
Validation auc = 0.880821
Epoch 9
Loss = 2.9650e-01, PNorm = 35.7586, GNorm = 0.5767, lr_0 = 7.0063e-04
Validation auc = 0.879518
Epoch 10
Loss = 2.7570e-01, PNorm = 35.8096, GNorm = 0.5029, lr_0 = 6.7317e-04
Loss = 3.3341e-01, PNorm = 35.8715, GNorm = 0.8518, lr_0 = 6.4679e-04
Validation auc = 0.882774
Epoch 11
Loss = 3.1539e-01, PNorm = 35.9361, GNorm = 0.5332, lr_0 = 6.2145e-04
Loss = 2.8261e-01, PNorm = 36.0012, GNorm = 0.9218, lr_0 = 5.9709e-04
Validation auc = 0.883751
Epoch 12
Loss = 3.1294e-01, PNorm = 36.0633, GNorm = 0.9046, lr_0 = 5.7369e-04
Validation auc = 0.879192
Epoch 13
Loss = 2.9919e-01, PNorm = 36.1248, GNorm = 0.7328, lr_0 = 5.4901e-04
Loss = 3.3027e-01, PNorm = 36.1794, GNorm = 1.4607, lr_0 = 5.2750e-04
Validation auc = 0.858352
Epoch 14
Loss = 2.9825e-01, PNorm = 36.2297, GNorm = 0.6447, lr_0 = 5.0683e-04
Validation auc = 0.862585
Epoch 15
Loss = 3.2461e-01, PNorm = 36.2743, GNorm = 1.1875, lr_0 = 4.8697e-04
Loss = 2.7677e-01, PNorm = 36.3179, GNorm = 0.5356, lr_0 = 4.6788e-04
Validation auc = 0.869424
Epoch 16
Loss = 3.1259e-01, PNorm = 36.3585, GNorm = 1.5183, lr_0 = 4.4955e-04
Validation auc = 0.872029
Epoch 17
Loss = 1.9600e-01, PNorm = 36.4057, GNorm = 0.3281, lr_0 = 4.3193e-04
Loss = 2.7508e-01, PNorm = 36.4524, GNorm = 1.6812, lr_0 = 4.1501e-04
Validation auc = 0.875122
Epoch 18
Loss = 2.4650e-01, PNorm = 36.5054, GNorm = 0.5313, lr_0 = 3.9874e-04
Loss = 2.4918e-01, PNorm = 36.5524, GNorm = 0.5563, lr_0 = 3.8312e-04
Loss = 3.9391e-01, PNorm = 36.5569, GNorm = 0.9348, lr_0 = 3.8159e-04
Validation auc = 0.881146
Epoch 19
Loss = 2.5840e-01, PNorm = 36.5933, GNorm = 1.7687, lr_0 = 3.6664e-04
Validation auc = 0.867633
Model 0 best validation auc = 0.898079 on epoch 4
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.877632
Ensemble test auc = 0.877632
Fold 17
Splitting data with seed 17
Total scaffolds = 1,025 | train scaffolds = 794 | val scaffolds = 110 | test scaffolds = 121
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 764
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8590e-01, PNorm = 35.0697, GNorm = 0.6076, lr_0 = 2.5469e-04
Validation auc = 0.936790
Epoch 1
Loss = 5.4767e-01, PNorm = 35.0893, GNorm = 0.6638, lr_0 = 4.0937e-04
Loss = 4.8314e-01, PNorm = 35.1158, GNorm = 1.2820, lr_0 = 5.5000e-04
Loss = 2.6150e-01, PNorm = 35.1192, GNorm = 0.6769, lr_0 = 5.6406e-04
Validation auc = 0.925852
Epoch 2
Loss = 4.2897e-01, PNorm = 35.1543, GNorm = 2.3917, lr_0 = 7.0469e-04
Validation auc = 0.939698
Epoch 3
Loss = 4.8524e-01, PNorm = 35.1860, GNorm = 0.7929, lr_0 = 8.5938e-04
Loss = 4.3186e-01, PNorm = 35.2213, GNorm = 1.3057, lr_0 = 1.0000e-03
Validation auc = 0.940944
Epoch 4
Loss = 4.3371e-01, PNorm = 35.2671, GNorm = 0.3819, lr_0 = 9.6081e-04
Validation auc = 0.931390
Epoch 5
Loss = 3.7316e-01, PNorm = 35.3211, GNorm = 0.3717, lr_0 = 9.1948e-04
Loss = 3.8289e-01, PNorm = 35.3759, GNorm = 1.1680, lr_0 = 8.8345e-04
Validation auc = 0.926405
Epoch 6
Loss = 3.8253e-01, PNorm = 35.4330, GNorm = 0.7734, lr_0 = 8.4544e-04
Validation auc = 0.935683
Epoch 7
Loss = 3.3387e-01, PNorm = 35.4790, GNorm = 0.3584, lr_0 = 8.0907e-04
Loss = 3.7382e-01, PNorm = 35.5235, GNorm = 0.2786, lr_0 = 7.7737e-04
Validation auc = 0.935544
Epoch 8
Loss = 3.4217e-01, PNorm = 35.5709, GNorm = 1.6087, lr_0 = 7.4690e-04
Validation auc = 0.935960
Epoch 9
Loss = 3.2293e-01, PNorm = 35.6253, GNorm = 0.5181, lr_0 = 7.1477e-04
Loss = 3.3878e-01, PNorm = 35.6783, GNorm = 0.4022, lr_0 = 6.8676e-04
Validation auc = 0.933052
Epoch 10
Loss = 3.4370e-01, PNorm = 35.7317, GNorm = 0.4394, lr_0 = 6.5722e-04
Validation auc = 0.939490
Epoch 11
Loss = 3.2088e-01, PNorm = 35.7839, GNorm = 0.4514, lr_0 = 6.3146e-04
Loss = 3.1411e-01, PNorm = 35.8358, GNorm = 0.5984, lr_0 = 6.0672e-04
Validation auc = 0.940252
Epoch 12
Loss = 2.8488e-01, PNorm = 35.8930, GNorm = 0.7595, lr_0 = 5.8062e-04
Validation auc = 0.929313
Epoch 13
Loss = 2.5794e-01, PNorm = 35.9503, GNorm = 0.9813, lr_0 = 5.5564e-04
Loss = 3.4388e-01, PNorm = 35.9983, GNorm = 0.4351, lr_0 = 5.3386e-04
Validation auc = 0.932636
Epoch 14
Loss = 3.6598e-01, PNorm = 36.0473, GNorm = 1.0561, lr_0 = 5.1090e-04
Validation auc = 0.930144
Epoch 15
Loss = 2.5508e-01, PNorm = 36.0908, GNorm = 0.4825, lr_0 = 4.9088e-04
Loss = 3.1348e-01, PNorm = 36.1361, GNorm = 0.9448, lr_0 = 4.7164e-04
Validation auc = 0.932913
Epoch 16
Loss = 2.9437e-01, PNorm = 36.1864, GNorm = 0.7437, lr_0 = 4.5135e-04
Validation auc = 0.928759
Epoch 17
Loss = 2.1806e-01, PNorm = 36.2358, GNorm = 1.4659, lr_0 = 4.3193e-04
Loss = 3.1604e-01, PNorm = 36.2768, GNorm = 0.7006, lr_0 = 4.1501e-04
Validation auc = 0.928067
Epoch 18
Loss = 3.1712e-01, PNorm = 36.3170, GNorm = 0.7775, lr_0 = 3.9874e-04
Loss = 2.6361e-01, PNorm = 36.3585, GNorm = 0.7046, lr_0 = 3.8312e-04
Loss = 2.7504e-01, PNorm = 36.3627, GNorm = 0.9018, lr_0 = 3.8159e-04
Validation auc = 0.931252
Epoch 19
Loss = 2.6399e-01, PNorm = 36.4007, GNorm = 0.7189, lr_0 = 3.6664e-04
Validation auc = 0.922528
Model 0 best validation auc = 0.940944 on epoch 3
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.871467
Ensemble test auc = 0.871467
Fold 18
Splitting data with seed 18
Total scaffolds = 1,025 | train scaffolds = 825 | val scaffolds = 67 | test scaffolds = 133
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 776
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7444e-01, PNorm = 35.0707, GNorm = 0.6606, lr_0 = 2.5469e-04
Validation auc = 0.800159
Epoch 1
Loss = 5.2723e-01, PNorm = 35.0937, GNorm = 1.8075, lr_0 = 4.0937e-04
Loss = 5.0658e-01, PNorm = 35.1167, GNorm = 2.0580, lr_0 = 5.5000e-04
Validation auc = 0.845481
Epoch 2
Loss = 4.7766e-01, PNorm = 35.1383, GNorm = 0.7864, lr_0 = 6.9063e-04
Validation auc = 0.890869
Epoch 3
Loss = 4.0387e-01, PNorm = 35.1726, GNorm = 1.1323, lr_0 = 8.4531e-04
Loss = 4.3459e-01, PNorm = 35.2140, GNorm = 0.3983, lr_0 = 9.8594e-04
Validation auc = 0.923072
Epoch 4
Loss = 3.8706e-01, PNorm = 35.2602, GNorm = 1.1036, lr_0 = 9.6466e-04
Validation auc = 0.922475
Epoch 5
Loss = 3.6321e-01, PNorm = 35.3224, GNorm = 0.6503, lr_0 = 9.2316e-04
Loss = 3.9055e-01, PNorm = 35.3717, GNorm = 0.3186, lr_0 = 8.8699e-04
Validation auc = 0.918434
Epoch 6
Loss = 3.7973e-01, PNorm = 35.4245, GNorm = 0.9491, lr_0 = 8.5223e-04
Validation auc = 0.940962
Epoch 7
Loss = 3.4737e-01, PNorm = 35.4819, GNorm = 0.6677, lr_0 = 8.1556e-04
Loss = 3.5667e-01, PNorm = 35.5411, GNorm = 0.3528, lr_0 = 7.8361e-04
Validation auc = 0.935529
Epoch 8
Loss = 3.5209e-01, PNorm = 35.6027, GNorm = 0.7050, lr_0 = 7.5290e-04
Validation auc = 0.940830
Epoch 9
Loss = 3.2730e-01, PNorm = 35.6655, GNorm = 0.7520, lr_0 = 7.2051e-04
Loss = 3.4510e-01, PNorm = 35.7164, GNorm = 0.6141, lr_0 = 6.9227e-04
Validation auc = 0.941890
Epoch 10
Loss = 2.9289e-01, PNorm = 35.7782, GNorm = 0.3877, lr_0 = 6.6515e-04
Loss = 3.7895e-01, PNorm = 35.8329, GNorm = 1.3078, lr_0 = 6.3908e-04
Loss = 4.4496e-01, PNorm = 35.8383, GNorm = 1.0358, lr_0 = 6.3653e-04
Validation auc = 0.952359
Epoch 11
Loss = 3.2644e-01, PNorm = 35.8848, GNorm = 0.5116, lr_0 = 6.1159e-04
Validation auc = 0.946660
Epoch 12
Loss = 3.0849e-01, PNorm = 35.9358, GNorm = 0.6597, lr_0 = 5.8762e-04
Loss = 3.3199e-01, PNorm = 35.9866, GNorm = 0.4656, lr_0 = 5.6459e-04
Validation auc = 0.949443
Epoch 13
Loss = 3.0313e-01, PNorm = 36.0532, GNorm = 0.7010, lr_0 = 5.4030e-04
Validation auc = 0.956202
Epoch 14
Loss = 3.2789e-01, PNorm = 36.1095, GNorm = 0.4962, lr_0 = 5.1913e-04
Loss = 3.0755e-01, PNorm = 36.1687, GNorm = 1.5232, lr_0 = 4.9879e-04
Validation auc = 0.943082
Epoch 15
Loss = 3.3362e-01, PNorm = 36.2304, GNorm = 0.8597, lr_0 = 4.7733e-04
Validation auc = 0.951100
Epoch 16
Loss = 3.1319e-01, PNorm = 36.2895, GNorm = 0.4880, lr_0 = 4.5863e-04
Loss = 3.0517e-01, PNorm = 36.3511, GNorm = 0.9750, lr_0 = 4.4065e-04
Validation auc = 0.941227
Epoch 17
Loss = 2.6706e-01, PNorm = 36.4024, GNorm = 0.7262, lr_0 = 4.2170e-04
Validation auc = 0.950239
Epoch 18
Loss = 2.4530e-01, PNorm = 36.4497, GNorm = 0.4150, lr_0 = 4.0517e-04
Loss = 2.9897e-01, PNorm = 36.4941, GNorm = 1.0996, lr_0 = 3.8929e-04
Validation auc = 0.943347
Epoch 19
Loss = 2.6518e-01, PNorm = 36.5527, GNorm = 1.5747, lr_0 = 3.7255e-04
Loss = 2.8626e-01, PNorm = 36.5902, GNorm = 0.4638, lr_0 = 3.5795e-04
Validation auc = 0.943347
Model 0 best validation auc = 0.956202 on epoch 13
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.888110
Ensemble test auc = 0.888110
Fold 19
Splitting data with seed 19
Total scaffolds = 1,025 | train scaffolds = 786 | val scaffolds = 107 | test scaffolds = 132
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 754
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7452e-01, PNorm = 35.0711, GNorm = 0.7516, lr_0 = 2.5469e-04
Validation auc = 0.690327
Epoch 1
Loss = 4.9937e-01, PNorm = 35.0911, GNorm = 0.4484, lr_0 = 4.0937e-04
Loss = 4.8084e-01, PNorm = 35.1165, GNorm = 0.7776, lr_0 = 5.5000e-04
Loss = 4.7036e-01, PNorm = 35.1187, GNorm = 2.3485, lr_0 = 5.6406e-04
Validation auc = 0.722941
Epoch 2
Loss = 4.3799e-01, PNorm = 35.1437, GNorm = 1.4368, lr_0 = 7.0469e-04
Validation auc = 0.752026
Epoch 3
Loss = 5.6814e-01, PNorm = 35.1695, GNorm = 1.0747, lr_0 = 8.5938e-04
Loss = 4.6484e-01, PNorm = 35.1986, GNorm = 1.0521, lr_0 = 1.0000e-03
Loss = 5.5426e-01, PNorm = 35.2025, GNorm = 1.9970, lr_0 = 9.9601e-04
Validation auc = 0.773987
Epoch 4
Loss = 4.2382e-01, PNorm = 35.2450, GNorm = 0.4367, lr_0 = 9.5698e-04
Validation auc = 0.793987
Epoch 5
Loss = 3.8363e-01, PNorm = 35.2930, GNorm = 0.4138, lr_0 = 9.1581e-04
Loss = 3.7897e-01, PNorm = 35.3308, GNorm = 0.3671, lr_0 = 8.7992e-04
Loss = 2.0302e-01, PNorm = 35.3343, GNorm = 0.6876, lr_0 = 8.7641e-04
Validation auc = 0.789739
Epoch 6
Loss = 3.4822e-01, PNorm = 35.3703, GNorm = 0.2832, lr_0 = 8.4207e-04
Validation auc = 0.798105
Epoch 7
Loss = 3.8002e-01, PNorm = 35.4098, GNorm = 0.6505, lr_0 = 8.0584e-04
Loss = 3.4209e-01, PNorm = 35.4458, GNorm = 0.3427, lr_0 = 7.7426e-04
Loss = 6.4806e-01, PNorm = 35.4489, GNorm = 2.0534, lr_0 = 7.7117e-04
Validation auc = 0.824967
Epoch 8
Loss = 3.6462e-01, PNorm = 35.4799, GNorm = 1.3008, lr_0 = 7.4095e-04
Validation auc = 0.819020
Epoch 9
Loss = 3.6460e-01, PNorm = 35.5155, GNorm = 0.4616, lr_0 = 7.0908e-04
Loss = 3.4514e-01, PNorm = 35.5481, GNorm = 0.3126, lr_0 = 6.8129e-04
Loss = 1.0759e-01, PNorm = 35.5510, GNorm = 0.5109, lr_0 = 6.7857e-04
Validation auc = 0.831307
Epoch 10
Loss = 3.5239e-01, PNorm = 35.5813, GNorm = 0.5287, lr_0 = 6.5198e-04
Validation auc = 0.841307
Epoch 11
Loss = 2.9992e-01, PNorm = 35.6281, GNorm = 0.2796, lr_0 = 6.2393e-04
Loss = 3.3219e-01, PNorm = 35.6695, GNorm = 0.4823, lr_0 = 5.9948e-04
Loss = 2.6238e-01, PNorm = 35.6728, GNorm = 2.4293, lr_0 = 5.9709e-04
Validation auc = 0.848693
Epoch 12
Loss = 3.1714e-01, PNorm = 35.7037, GNorm = 0.3369, lr_0 = 5.7369e-04
Validation auc = 0.848039
Epoch 13
Loss = 3.7508e-01, PNorm = 35.7352, GNorm = 0.6927, lr_0 = 5.5121e-04
Loss = 3.1673e-01, PNorm = 35.7682, GNorm = 0.4006, lr_0 = 5.2961e-04
Validation auc = 0.855098
Epoch 14
Loss = 3.0539e-01, PNorm = 35.8099, GNorm = 0.8776, lr_0 = 5.0683e-04
Validation auc = 0.852876
Epoch 15
Loss = 3.0161e-01, PNorm = 35.8534, GNorm = 0.9841, lr_0 = 4.8502e-04
Loss = 3.1902e-01, PNorm = 35.8914, GNorm = 0.9968, lr_0 = 4.6602e-04
Validation auc = 0.846340
Epoch 16
Loss = 3.0909e-01, PNorm = 35.9326, GNorm = 0.7378, lr_0 = 4.4597e-04
Validation auc = 0.853660
Epoch 17
Loss = 2.6431e-01, PNorm = 35.9636, GNorm = 1.1695, lr_0 = 4.2678e-04
Loss = 3.5104e-01, PNorm = 35.9924, GNorm = 0.9726, lr_0 = 4.1006e-04
Validation auc = 0.852222
Epoch 18
Loss = 3.0083e-01, PNorm = 36.0256, GNorm = 1.0445, lr_0 = 3.9242e-04
Validation auc = 0.860850
Epoch 19
Loss = 2.3320e-01, PNorm = 36.0614, GNorm = 0.3336, lr_0 = 3.7554e-04
Loss = 2.8995e-01, PNorm = 36.0966, GNorm = 0.4755, lr_0 = 3.6082e-04
Validation auc = 0.854118
Model 0 best validation auc = 0.860850 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.905920
Ensemble test auc = 0.905920
Fold 20
Splitting data with seed 20
Total scaffolds = 1,025 | train scaffolds = 792 | val scaffolds = 131 | test scaffolds = 102
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 770
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7905e-01, PNorm = 35.0702, GNorm = 0.7154, lr_0 = 2.5469e-04
Validation auc = 0.835182
Epoch 1
Loss = 5.2339e-01, PNorm = 35.0915, GNorm = 1.2176, lr_0 = 4.0937e-04
Loss = 5.1144e-01, PNorm = 35.1196, GNorm = 0.6093, lr_0 = 5.5000e-04
Loss = 5.0021e-01, PNorm = 35.1220, GNorm = 1.1978, lr_0 = 5.6406e-04
Validation auc = 0.898920
Epoch 2
Loss = 4.6616e-01, PNorm = 35.1495, GNorm = 2.0088, lr_0 = 7.0469e-04
Validation auc = 0.902765
Epoch 3
Loss = 4.7926e-01, PNorm = 35.1826, GNorm = 0.5999, lr_0 = 8.4531e-04
Loss = 4.2372e-01, PNorm = 35.2214, GNorm = 1.9827, lr_0 = 9.8594e-04
Validation auc = 0.889899
Epoch 4
Loss = 4.0288e-01, PNorm = 35.2751, GNorm = 1.8717, lr_0 = 9.6081e-04
Validation auc = 0.891896
Epoch 5
Loss = 3.7991e-01, PNorm = 35.3216, GNorm = 0.7289, lr_0 = 9.2316e-04
Loss = 3.6354e-01, PNorm = 35.3759, GNorm = 0.4363, lr_0 = 8.8699e-04
Validation auc = 0.890195
Epoch 6
Loss = 3.5753e-01, PNorm = 35.4291, GNorm = 0.4513, lr_0 = 8.4883e-04
Validation auc = 0.889604
Epoch 7
Loss = 4.1689e-01, PNorm = 35.4876, GNorm = 0.7383, lr_0 = 8.1231e-04
Loss = 3.6667e-01, PNorm = 35.5385, GNorm = 1.1651, lr_0 = 7.8048e-04
Validation auc = 0.887311
Epoch 8
Loss = 3.4780e-01, PNorm = 35.5906, GNorm = 1.6139, lr_0 = 7.4989e-04
Validation auc = 0.905649
Epoch 9
Loss = 3.5134e-01, PNorm = 35.6543, GNorm = 0.4067, lr_0 = 7.1763e-04
Loss = 3.4298e-01, PNorm = 35.7118, GNorm = 0.4991, lr_0 = 6.8951e-04
Validation auc = 0.898033
Epoch 10
Loss = 3.4696e-01, PNorm = 35.7652, GNorm = 0.7035, lr_0 = 6.6249e-04
Validation auc = 0.905723
Epoch 11
Loss = 2.7429e-01, PNorm = 35.8207, GNorm = 0.6159, lr_0 = 6.3399e-04
Loss = 3.3487e-01, PNorm = 35.8733, GNorm = 1.0936, lr_0 = 6.0915e-04
Validation auc = 0.900030
Epoch 12
Loss = 3.0056e-01, PNorm = 35.9310, GNorm = 0.7961, lr_0 = 5.8294e-04
Loss = 3.1067e-01, PNorm = 35.9835, GNorm = 0.5981, lr_0 = 5.6010e-04
Validation auc = 0.901434
Epoch 13
Loss = 2.9312e-01, PNorm = 36.0323, GNorm = 0.5915, lr_0 = 5.3815e-04
Validation auc = 0.909568
Epoch 14
Loss = 3.2717e-01, PNorm = 36.0901, GNorm = 1.3410, lr_0 = 5.1500e-04
Loss = 2.8707e-01, PNorm = 36.1398, GNorm = 1.2729, lr_0 = 4.9482e-04
Validation auc = 0.902470
Epoch 15
Loss = 2.9615e-01, PNorm = 36.1895, GNorm = 0.5118, lr_0 = 4.7543e-04
Validation auc = 0.912674
Epoch 16
Loss = 2.4212e-01, PNorm = 36.2435, GNorm = 0.9842, lr_0 = 4.5497e-04
Loss = 2.9329e-01, PNorm = 36.2981, GNorm = 0.7052, lr_0 = 4.3714e-04
Validation auc = 0.910308
Epoch 17
Loss = 2.7149e-01, PNorm = 36.3556, GNorm = 0.5536, lr_0 = 4.1834e-04
Validation auc = 0.911934
Epoch 18
Loss = 2.1632e-01, PNorm = 36.3960, GNorm = 0.5727, lr_0 = 4.0195e-04
Loss = 2.7645e-01, PNorm = 36.4370, GNorm = 1.2834, lr_0 = 3.8619e-04
Validation auc = 0.911491
Epoch 19
Loss = 2.6770e-01, PNorm = 36.4845, GNorm = 0.9002, lr_0 = 3.6958e-04
Validation auc = 0.913857
Model 0 best validation auc = 0.913857 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.921946
Ensemble test auc = 0.921946
Fold 21
Splitting data with seed 21
Total scaffolds = 1,025 | train scaffolds = 790 | val scaffolds = 124 | test scaffolds = 111
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 736
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7878e-01, PNorm = 35.0710, GNorm = 0.7778, lr_0 = 2.5469e-04
Validation auc = 0.812049
Epoch 1
Loss = 5.4962e-01, PNorm = 35.0918, GNorm = 0.8409, lr_0 = 4.0937e-04
Validation auc = 0.834365
Epoch 2
Loss = 4.6700e-01, PNorm = 35.1201, GNorm = 2.4975, lr_0 = 5.5000e-04
Loss = 4.9643e-01, PNorm = 35.1445, GNorm = 0.5205, lr_0 = 6.9063e-04
Validation auc = 0.851651
Epoch 3
Loss = 4.5000e-01, PNorm = 35.1792, GNorm = 0.6529, lr_0 = 8.3125e-04
Validation auc = 0.863132
Epoch 4
Loss = 4.7686e-01, PNorm = 35.2228, GNorm = 1.3079, lr_0 = 9.8594e-04
Loss = 4.0884e-01, PNorm = 35.2789, GNorm = 0.6005, lr_0 = 9.6466e-04
Validation auc = 0.867260
Epoch 5
Loss = 3.8708e-01, PNorm = 35.3424, GNorm = 0.3734, lr_0 = 9.2686e-04
Validation auc = 0.875903
Epoch 6
Loss = 2.7614e-01, PNorm = 35.4012, GNorm = 0.3847, lr_0 = 8.9054e-04
Loss = 4.2093e-01, PNorm = 35.4566, GNorm = 1.1635, lr_0 = 8.5564e-04
Validation auc = 0.881063
Epoch 7
Loss = 3.6780e-01, PNorm = 35.5109, GNorm = 0.5760, lr_0 = 8.2211e-04
Validation auc = 0.878354
Epoch 8
Loss = 2.7260e-01, PNorm = 35.5791, GNorm = 0.4283, lr_0 = 7.8674e-04
Loss = 3.6509e-01, PNorm = 35.6409, GNorm = 0.8126, lr_0 = 7.5591e-04
Validation auc = 0.880289
Epoch 9
Loss = 3.4767e-01, PNorm = 35.7014, GNorm = 0.5090, lr_0 = 7.2629e-04
Validation auc = 0.881966
Epoch 10
Loss = 3.8064e-01, PNorm = 35.7607, GNorm = 0.4323, lr_0 = 6.9783e-04
Loss = 3.2388e-01, PNorm = 35.8175, GNorm = 0.3338, lr_0 = 6.7048e-04
Validation auc = 0.888545
Epoch 11
Loss = 3.3747e-01, PNorm = 35.8825, GNorm = 1.1926, lr_0 = 6.4164e-04
Validation auc = 0.887900
Epoch 12
Loss = 3.2016e-01, PNorm = 35.9422, GNorm = 0.8298, lr_0 = 6.1650e-04
Loss = 2.8534e-01, PNorm = 36.0028, GNorm = 0.7347, lr_0 = 5.9234e-04
Validation auc = 0.894221
Epoch 13
Loss = 3.2031e-01, PNorm = 36.0624, GNorm = 1.5162, lr_0 = 5.6913e-04
Validation auc = 0.891383
Epoch 14
Loss = 2.9266e-01, PNorm = 36.1130, GNorm = 0.6489, lr_0 = 5.4682e-04
Loss = 2.8385e-01, PNorm = 36.1704, GNorm = 0.4240, lr_0 = 5.2540e-04
Loss = 5.4674e-01, PNorm = 36.1758, GNorm = 1.4468, lr_0 = 5.2330e-04
Validation auc = 0.892673
Epoch 15
Loss = 2.5024e-01, PNorm = 36.2292, GNorm = 0.9713, lr_0 = 5.0279e-04
Validation auc = 0.898091
Epoch 16
Loss = 2.7347e-01, PNorm = 36.2824, GNorm = 0.8711, lr_0 = 4.8309e-04
Loss = 2.7160e-01, PNorm = 36.3312, GNorm = 0.6160, lr_0 = 4.6416e-04
Validation auc = 0.892157
Epoch 17
Loss = 2.6921e-01, PNorm = 36.3745, GNorm = 1.1263, lr_0 = 4.4597e-04
Validation auc = 0.897317
Epoch 18
Loss = 2.4838e-01, PNorm = 36.4269, GNorm = 1.3700, lr_0 = 4.2678e-04
Validation auc = 0.901574
Epoch 19
Loss = 2.3754e-01, PNorm = 36.4739, GNorm = 0.5311, lr_0 = 4.1006e-04
Loss = 2.7779e-01, PNorm = 36.5146, GNorm = 1.6604, lr_0 = 3.9399e-04
Validation auc = 0.901703
Model 0 best validation auc = 0.901703 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.928851
Ensemble test auc = 0.928851
Fold 22
Splitting data with seed 22
Total scaffolds = 1,025 | train scaffolds = 808 | val scaffolds = 139 | test scaffolds = 78
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 828
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.5983e-01, PNorm = 35.0719, GNorm = 0.7316, lr_0 = 2.5469e-04
Validation auc = 0.762273
Epoch 1
Loss = 4.9951e-01, PNorm = 35.0934, GNorm = 0.4816, lr_0 = 4.0937e-04
Loss = 4.5946e-01, PNorm = 35.1189, GNorm = 1.0798, lr_0 = 5.5000e-04
Validation auc = 0.826220
Epoch 2
Loss = 4.3623e-01, PNorm = 35.1480, GNorm = 1.0673, lr_0 = 6.9063e-04
Validation auc = 0.824031
Epoch 3
Loss = 5.0786e-01, PNorm = 35.1828, GNorm = 0.4647, lr_0 = 8.4531e-04
Loss = 3.8923e-01, PNorm = 35.2270, GNorm = 2.0437, lr_0 = 9.8594e-04
Validation auc = 0.834115
Epoch 4
Loss = 4.0846e-01, PNorm = 35.2742, GNorm = 2.0569, lr_0 = 9.6466e-04
Loss = 4.1542e-01, PNorm = 35.3179, GNorm = 0.4045, lr_0 = 9.2686e-04
Validation auc = 0.826689
Epoch 5
Loss = 3.4451e-01, PNorm = 35.3606, GNorm = 0.4102, lr_0 = 8.8699e-04
Validation auc = 0.832473
Epoch 6
Loss = 2.4270e-01, PNorm = 35.4057, GNorm = 0.9485, lr_0 = 8.5223e-04
Loss = 3.6658e-01, PNorm = 35.4537, GNorm = 0.8452, lr_0 = 8.1883e-04
Validation auc = 0.837867
Epoch 7
Loss = 3.4251e-01, PNorm = 35.5090, GNorm = 1.3502, lr_0 = 7.8361e-04
Loss = 3.6487e-01, PNorm = 35.5599, GNorm = 0.3322, lr_0 = 7.5290e-04
Validation auc = 0.832630
Epoch 8
Loss = 3.2714e-01, PNorm = 35.6100, GNorm = 0.5570, lr_0 = 7.2339e-04
Validation auc = 0.839978
Epoch 9
Loss = 2.7070e-01, PNorm = 35.6595, GNorm = 0.3564, lr_0 = 6.9505e-04
Loss = 3.3363e-01, PNorm = 35.7072, GNorm = 0.3978, lr_0 = 6.6781e-04
Validation auc = 0.845919
Epoch 10
Loss = 2.9797e-01, PNorm = 35.7583, GNorm = 0.2791, lr_0 = 6.3908e-04
Loss = 3.3308e-01, PNorm = 35.8001, GNorm = 1.3953, lr_0 = 6.1404e-04
Validation auc = 0.830050
Epoch 11
Loss = 2.8713e-01, PNorm = 35.8373, GNorm = 0.4080, lr_0 = 5.8997e-04
Validation auc = 0.845841
Epoch 12
Loss = 2.8094e-01, PNorm = 35.8884, GNorm = 0.8448, lr_0 = 5.6459e-04
Loss = 2.8972e-01, PNorm = 35.9415, GNorm = 1.0196, lr_0 = 5.4247e-04
Validation auc = 0.844903
Epoch 13
Loss = 2.3391e-01, PNorm = 35.9806, GNorm = 0.4452, lr_0 = 5.2121e-04
Loss = 2.8161e-01, PNorm = 36.0258, GNorm = 1.4786, lr_0 = 5.0079e-04
Validation auc = 0.846779
Epoch 14
Loss = 2.5761e-01, PNorm = 36.0663, GNorm = 0.9320, lr_0 = 4.7924e-04
Validation auc = 0.851861
Epoch 15
Loss = 3.3414e-01, PNorm = 36.1137, GNorm = 0.8371, lr_0 = 4.6046e-04
Loss = 2.6133e-01, PNorm = 36.1600, GNorm = 0.4886, lr_0 = 4.4242e-04
Validation auc = 0.839587
Epoch 16
Loss = 2.3312e-01, PNorm = 36.2047, GNorm = 2.1440, lr_0 = 4.2339e-04
Loss = 3.4109e-01, PNorm = 36.2342, GNorm = 1.8975, lr_0 = 4.0679e-04
Validation auc = 0.854831
Epoch 17
Loss = 2.6660e-01, PNorm = 36.2590, GNorm = 1.0778, lr_0 = 3.9085e-04
Validation auc = 0.844981
Epoch 18
Loss = 2.9895e-01, PNorm = 36.2963, GNorm = 0.4785, lr_0 = 3.7554e-04
Loss = 2.4492e-01, PNorm = 36.3379, GNorm = 0.9026, lr_0 = 3.6082e-04
Validation auc = 0.848734
Epoch 19
Loss = 2.6462e-01, PNorm = 36.3789, GNorm = 0.5103, lr_0 = 3.4530e-04
Loss = 2.3535e-01, PNorm = 36.4140, GNorm = 0.5170, lr_0 = 3.3177e-04
Validation auc = 0.844199
Model 0 best validation auc = 0.854831 on epoch 16
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.870864
Ensemble test auc = 0.870864
Fold 23
Splitting data with seed 23
Total scaffolds = 1,025 | train scaffolds = 778 | val scaffolds = 121 | test scaffolds = 126
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 790
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7115e-01, PNorm = 35.0704, GNorm = 0.5611, lr_0 = 2.5469e-04
Validation auc = 0.756759
Epoch 1
Loss = 4.9206e-01, PNorm = 35.0915, GNorm = 0.5630, lr_0 = 4.0937e-04
Loss = 4.6223e-01, PNorm = 35.1240, GNorm = 0.5167, lr_0 = 5.5000e-04
Validation auc = 0.727035
Epoch 2
Loss = 4.1162e-01, PNorm = 35.1556, GNorm = 1.0891, lr_0 = 6.9063e-04
Validation auc = 0.795858
Epoch 3
Loss = 3.9918e-01, PNorm = 35.1923, GNorm = 1.3443, lr_0 = 8.3125e-04
Loss = 4.2869e-01, PNorm = 35.2242, GNorm = 1.0650, lr_0 = 9.7187e-04
Validation auc = 0.807195
Epoch 4
Loss = 3.9462e-01, PNorm = 35.2740, GNorm = 0.4002, lr_0 = 9.6853e-04
Validation auc = 0.776744
Epoch 5
Loss = 4.3095e-01, PNorm = 35.3243, GNorm = 0.4276, lr_0 = 9.3057e-04
Loss = 3.6316e-01, PNorm = 35.3745, GNorm = 0.6258, lr_0 = 8.9411e-04
Validation auc = 0.841206
Epoch 6
Loss = 3.3610e-01, PNorm = 35.4300, GNorm = 0.9713, lr_0 = 8.5564e-04
Loss = 3.3413e-01, PNorm = 35.4748, GNorm = 0.9742, lr_0 = 8.2211e-04
Validation auc = 0.805451
Epoch 7
Loss = 3.3385e-01, PNorm = 35.5163, GNorm = 1.2077, lr_0 = 7.8990e-04
Validation auc = 0.842006
Epoch 8
Loss = 2.8418e-01, PNorm = 35.5636, GNorm = 1.0024, lr_0 = 7.5894e-04
Loss = 3.6992e-01, PNorm = 35.6113, GNorm = 0.5574, lr_0 = 7.2920e-04
Validation auc = 0.878052
Epoch 9
Loss = 3.1520e-01, PNorm = 35.6507, GNorm = 0.3039, lr_0 = 7.0063e-04
Validation auc = 0.823183
Epoch 10
Loss = 3.7800e-01, PNorm = 35.6948, GNorm = 1.3617, lr_0 = 6.7317e-04
Loss = 2.9978e-01, PNorm = 35.7416, GNorm = 0.3482, lr_0 = 6.4679e-04
Validation auc = 0.875073
Epoch 11
Loss = 3.3657e-01, PNorm = 35.7949, GNorm = 0.8175, lr_0 = 6.1897e-04
Validation auc = 0.851090
Epoch 12
Loss = 2.5766e-01, PNorm = 35.8470, GNorm = 0.4433, lr_0 = 5.9471e-04
Loss = 3.0990e-01, PNorm = 35.8945, GNorm = 0.6243, lr_0 = 5.7141e-04
Validation auc = 0.871221
Epoch 13
Loss = 2.7670e-01, PNorm = 35.9412, GNorm = 1.0710, lr_0 = 5.4901e-04
Loss = 2.8800e-01, PNorm = 35.9902, GNorm = 0.6603, lr_0 = 5.2750e-04
Validation auc = 0.866352
Epoch 14
Loss = 2.9584e-01, PNorm = 36.0331, GNorm = 0.4545, lr_0 = 5.0683e-04
Validation auc = 0.877834
Epoch 15
Loss = 2.5612e-01, PNorm = 36.0769, GNorm = 0.8290, lr_0 = 4.8697e-04
Loss = 2.8199e-01, PNorm = 36.1164, GNorm = 0.4802, lr_0 = 4.6788e-04
Validation auc = 0.872602
Epoch 16
Loss = 2.9520e-01, PNorm = 36.1569, GNorm = 0.5194, lr_0 = 4.4776e-04
Validation auc = 0.884230
Epoch 17
Loss = 3.0558e-01, PNorm = 36.1981, GNorm = 0.4598, lr_0 = 4.3021e-04
Loss = 2.4775e-01, PNorm = 36.2418, GNorm = 0.5293, lr_0 = 4.1335e-04
Validation auc = 0.899855
Epoch 18
Loss = 2.3822e-01, PNorm = 36.2881, GNorm = 0.6411, lr_0 = 3.9715e-04
Loss = 2.2922e-01, PNorm = 36.3348, GNorm = 1.0430, lr_0 = 3.8159e-04
Validation auc = 0.878270
Epoch 19
Loss = 2.3410e-01, PNorm = 36.3798, GNorm = 0.7475, lr_0 = 3.6664e-04
Validation auc = 0.902544
Model 0 best validation auc = 0.902544 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.865779
Ensemble test auc = 0.865779
Fold 24
Splitting data with seed 24
Total scaffolds = 1,025 | train scaffolds = 806 | val scaffolds = 105 | test scaffolds = 114
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 738
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8082e-01, PNorm = 35.0698, GNorm = 0.6998, lr_0 = 2.5469e-04
Validation auc = 0.894819
Epoch 1
Loss = 5.2185e-01, PNorm = 35.0901, GNorm = 0.5442, lr_0 = 4.0937e-04
Validation auc = 0.869187
Epoch 2
Loss = 5.4730e-01, PNorm = 35.1182, GNorm = 2.4694, lr_0 = 5.5000e-04
Loss = 4.7263e-01, PNorm = 35.1421, GNorm = 0.6843, lr_0 = 6.9063e-04
Validation auc = 0.910015
Epoch 3
Loss = 4.0767e-01, PNorm = 35.1782, GNorm = 0.6094, lr_0 = 8.3125e-04
Validation auc = 0.920560
Epoch 4
Loss = 4.2692e-01, PNorm = 35.2187, GNorm = 1.9874, lr_0 = 9.7187e-04
Loss = 4.2605e-01, PNorm = 35.2623, GNorm = 0.4373, lr_0 = 9.6853e-04
Validation auc = 0.919262
Epoch 5
Loss = 4.2043e-01, PNorm = 35.3255, GNorm = 0.7989, lr_0 = 9.2686e-04
Validation auc = 0.931592
Epoch 6
Loss = 4.5459e-01, PNorm = 35.3768, GNorm = 1.2219, lr_0 = 8.9054e-04
Loss = 3.8080e-01, PNorm = 35.4288, GNorm = 0.8808, lr_0 = 8.5564e-04
Validation auc = 0.930835
Epoch 7
Loss = 3.5694e-01, PNorm = 35.4734, GNorm = 1.0555, lr_0 = 8.2211e-04
Validation auc = 0.938081
Epoch 8
Loss = 4.4234e-01, PNorm = 35.5238, GNorm = 0.6585, lr_0 = 7.8990e-04
Loss = 3.2654e-01, PNorm = 35.5775, GNorm = 0.4706, lr_0 = 7.5894e-04
Validation auc = 0.936567
Epoch 9
Loss = 3.8219e-01, PNorm = 35.6314, GNorm = 0.7853, lr_0 = 7.2629e-04
Validation auc = 0.928996
Epoch 10
Loss = 2.7072e-01, PNorm = 35.6781, GNorm = 0.4424, lr_0 = 6.9783e-04
Loss = 3.2726e-01, PNorm = 35.7285, GNorm = 0.5168, lr_0 = 6.7048e-04
Validation auc = 0.937000
Epoch 11
Loss = 3.4131e-01, PNorm = 35.7793, GNorm = 1.7633, lr_0 = 6.4421e-04
Validation auc = 0.944841
Epoch 12
Loss = 3.1220e-01, PNorm = 35.8209, GNorm = 0.7891, lr_0 = 6.1897e-04
Loss = 3.0468e-01, PNorm = 35.8656, GNorm = 0.6306, lr_0 = 5.9471e-04
Validation auc = 0.933971
Epoch 13
Loss = 3.6457e-01, PNorm = 35.9155, GNorm = 1.1934, lr_0 = 5.6913e-04
Validation auc = 0.947491
Epoch 14
Loss = 3.3452e-01, PNorm = 35.9593, GNorm = 0.4789, lr_0 = 5.4682e-04
Loss = 3.2551e-01, PNorm = 36.0051, GNorm = 1.1619, lr_0 = 5.2540e-04
Validation auc = 0.945111
Epoch 15
Loss = 2.9435e-01, PNorm = 36.0481, GNorm = 0.6022, lr_0 = 5.0481e-04
Validation auc = 0.943327
Epoch 16
Loss = 3.2488e-01, PNorm = 36.0962, GNorm = 0.5437, lr_0 = 4.8502e-04
Loss = 3.0615e-01, PNorm = 36.1409, GNorm = 0.4021, lr_0 = 4.6602e-04
Loss = 3.7554e-01, PNorm = 36.1447, GNorm = 0.6746, lr_0 = 4.6416e-04
Validation auc = 0.943597
Epoch 17
Loss = 2.7380e-01, PNorm = 36.1885, GNorm = 0.8454, lr_0 = 4.4597e-04
Validation auc = 0.945760
Epoch 18
Loss = 3.4228e-01, PNorm = 36.2214, GNorm = 0.8534, lr_0 = 4.2849e-04
Loss = 2.8258e-01, PNorm = 36.2542, GNorm = 0.6210, lr_0 = 4.1170e-04
Validation auc = 0.943273
Epoch 19
Loss = 2.6526e-01, PNorm = 36.2903, GNorm = 0.9130, lr_0 = 3.9557e-04
Validation auc = 0.947274
Model 0 best validation auc = 0.947491 on epoch 13
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.902960
Ensemble test auc = 0.902960
Fold 25
Splitting data with seed 25
Total scaffolds = 1,025 | train scaffolds = 797 | val scaffolds = 127 | test scaffolds = 101
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 744
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7971e-01, PNorm = 35.0698, GNorm = 0.9126, lr_0 = 2.5469e-04
Validation auc = 0.833668
Epoch 1
Loss = 5.2889e-01, PNorm = 35.0901, GNorm = 0.9481, lr_0 = 4.0937e-04
Validation auc = 0.864939
Epoch 2
Loss = 5.0118e-01, PNorm = 35.1169, GNorm = 0.4301, lr_0 = 5.5000e-04
Loss = 4.5982e-01, PNorm = 35.1475, GNorm = 0.6107, lr_0 = 6.9063e-04
Validation auc = 0.882553
Epoch 3
Loss = 5.0140e-01, PNorm = 35.1804, GNorm = 1.8909, lr_0 = 8.3125e-04
Validation auc = 0.891249
Epoch 4
Loss = 4.3445e-01, PNorm = 35.2280, GNorm = 1.0104, lr_0 = 9.7187e-04
Loss = 4.4996e-01, PNorm = 35.2790, GNorm = 1.4961, lr_0 = 9.6853e-04
Validation auc = 0.894147
Epoch 5
Loss = 3.8196e-01, PNorm = 35.3338, GNorm = 0.4348, lr_0 = 9.3057e-04
Validation auc = 0.891472
Epoch 6
Loss = 4.1417e-01, PNorm = 35.3894, GNorm = 0.6889, lr_0 = 8.9411e-04
Loss = 3.5550e-01, PNorm = 35.4482, GNorm = 0.6651, lr_0 = 8.5907e-04
Validation auc = 0.902564
Epoch 7
Loss = 3.5373e-01, PNorm = 35.5034, GNorm = 0.5948, lr_0 = 8.2540e-04
Validation auc = 0.905518
Epoch 8
Loss = 4.5677e-01, PNorm = 35.5492, GNorm = 0.6873, lr_0 = 7.9306e-04
Loss = 3.7876e-01, PNorm = 35.6018, GNorm = 0.8188, lr_0 = 7.6198e-04
Validation auc = 0.908863
Epoch 9
Loss = 3.9595e-01, PNorm = 35.6563, GNorm = 0.9268, lr_0 = 7.2920e-04
Validation auc = 0.909532
Epoch 10
Loss = 3.3954e-01, PNorm = 35.7054, GNorm = 0.6708, lr_0 = 7.0063e-04
Loss = 3.4328e-01, PNorm = 35.7513, GNorm = 0.4130, lr_0 = 6.7317e-04
Validation auc = 0.909755
Epoch 11
Loss = 3.4235e-01, PNorm = 35.7962, GNorm = 1.1335, lr_0 = 6.4679e-04
Validation auc = 0.907191
Epoch 12
Loss = 3.1115e-01, PNorm = 35.8475, GNorm = 0.3525, lr_0 = 6.2145e-04
Loss = 3.6110e-01, PNorm = 35.8930, GNorm = 1.1805, lr_0 = 5.9709e-04
Validation auc = 0.913768
Epoch 13
Loss = 3.0715e-01, PNorm = 35.9412, GNorm = 0.6855, lr_0 = 5.7369e-04
Validation auc = 0.915106
Epoch 14
Loss = 2.6870e-01, PNorm = 35.9908, GNorm = 0.6928, lr_0 = 5.5121e-04
Loss = 3.5006e-01, PNorm = 36.0401, GNorm = 0.7595, lr_0 = 5.2961e-04
Validation auc = 0.911650
Epoch 15
Loss = 3.3448e-01, PNorm = 36.0780, GNorm = 0.4320, lr_0 = 5.0886e-04
Validation auc = 0.912430
Epoch 16
Loss = 3.1468e-01, PNorm = 36.1210, GNorm = 0.4439, lr_0 = 4.8892e-04
Loss = 3.2143e-01, PNorm = 36.1641, GNorm = 0.4559, lr_0 = 4.6976e-04
Validation auc = 0.910981
Epoch 17
Loss = 3.3330e-01, PNorm = 36.2115, GNorm = 1.0565, lr_0 = 4.4955e-04
Validation auc = 0.918896
Epoch 18
Loss = 2.5075e-01, PNorm = 36.2542, GNorm = 0.7030, lr_0 = 4.3193e-04
Loss = 2.9627e-01, PNorm = 36.2964, GNorm = 0.5275, lr_0 = 4.1501e-04
Validation auc = 0.918785
Epoch 19
Loss = 2.9294e-01, PNorm = 36.3433, GNorm = 0.5574, lr_0 = 3.9874e-04
Validation auc = 0.922910
Model 0 best validation auc = 0.922910 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.946100
Ensemble test auc = 0.946100
Fold 26
Splitting data with seed 26
Total scaffolds = 1,025 | train scaffolds = 835 | val scaffolds = 105 | test scaffolds = 85
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 794
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7867e-01, PNorm = 35.0706, GNorm = 0.8267, lr_0 = 2.5469e-04
Validation auc = 0.932245
Epoch 1
Loss = 5.2876e-01, PNorm = 35.0924, GNorm = 0.4416, lr_0 = 4.0937e-04
Loss = 4.7272e-01, PNorm = 35.1212, GNorm = 2.2602, lr_0 = 5.5000e-04
Validation auc = 0.939592
Epoch 2
Loss = 4.8184e-01, PNorm = 35.1448, GNorm = 0.8087, lr_0 = 6.9063e-04
Validation auc = 0.937347
Epoch 3
Loss = 4.8559e-01, PNorm = 35.1770, GNorm = 1.9261, lr_0 = 8.3125e-04
Loss = 4.3065e-01, PNorm = 35.2154, GNorm = 0.7087, lr_0 = 9.7187e-04
Validation auc = 0.938776
Epoch 4
Loss = 3.9890e-01, PNorm = 35.2662, GNorm = 1.7567, lr_0 = 9.6853e-04
Validation auc = 0.945918
Epoch 5
Loss = 4.2012e-01, PNorm = 35.3148, GNorm = 1.2106, lr_0 = 9.3057e-04
Loss = 4.0152e-01, PNorm = 35.3641, GNorm = 0.5008, lr_0 = 8.9411e-04
Validation auc = 0.948163
Epoch 6
Loss = 3.8478e-01, PNorm = 35.4163, GNorm = 0.6527, lr_0 = 8.5907e-04
Loss = 3.5537e-01, PNorm = 35.4705, GNorm = 0.3535, lr_0 = 8.2540e-04
Validation auc = 0.945918
Epoch 7
Loss = 3.7580e-01, PNorm = 35.5264, GNorm = 0.5596, lr_0 = 7.9306e-04
Validation auc = 0.951224
Epoch 8
Loss = 3.3312e-01, PNorm = 35.5743, GNorm = 0.3954, lr_0 = 7.6198e-04
Loss = 3.6486e-01, PNorm = 35.6281, GNorm = 0.8375, lr_0 = 7.3212e-04
Validation auc = 0.948571
Epoch 9
Loss = 3.5292e-01, PNorm = 35.6835, GNorm = 0.4572, lr_0 = 7.0063e-04
Validation auc = 0.950408
Epoch 10
Loss = 3.0436e-01, PNorm = 35.7376, GNorm = 0.7938, lr_0 = 6.7317e-04
Loss = 3.3111e-01, PNorm = 35.7932, GNorm = 0.9825, lr_0 = 6.4679e-04
Validation auc = 0.946735
Epoch 11
Loss = 3.2035e-01, PNorm = 35.8443, GNorm = 0.6653, lr_0 = 6.2145e-04
Loss = 3.2145e-01, PNorm = 35.8973, GNorm = 0.4785, lr_0 = 5.9709e-04
Validation auc = 0.946327
Epoch 12
Loss = 3.2522e-01, PNorm = 35.9499, GNorm = 0.6424, lr_0 = 5.7369e-04
Validation auc = 0.945510
Epoch 13
Loss = 2.9753e-01, PNorm = 36.0007, GNorm = 0.8051, lr_0 = 5.5121e-04
Loss = 2.9129e-01, PNorm = 36.0471, GNorm = 1.4913, lr_0 = 5.2961e-04
Validation auc = 0.943878
Epoch 14
Loss = 3.1579e-01, PNorm = 36.0973, GNorm = 0.9132, lr_0 = 5.0886e-04
Validation auc = 0.943265
Epoch 15
Loss = 3.4743e-01, PNorm = 36.1467, GNorm = 0.8711, lr_0 = 4.8892e-04
Loss = 2.9660e-01, PNorm = 36.1934, GNorm = 0.6871, lr_0 = 4.6976e-04
Validation auc = 0.939184
Epoch 16
Loss = 3.5055e-01, PNorm = 36.2334, GNorm = 1.0918, lr_0 = 4.5135e-04
Validation auc = 0.936531
Epoch 17
Loss = 2.7694e-01, PNorm = 36.2834, GNorm = 0.5227, lr_0 = 4.3193e-04
Loss = 3.0822e-01, PNorm = 36.3308, GNorm = 0.6814, lr_0 = 4.1501e-04
Validation auc = 0.943061
Epoch 18
Loss = 2.6566e-01, PNorm = 36.3764, GNorm = 0.4603, lr_0 = 3.9874e-04
Loss = 3.0850e-01, PNorm = 36.4187, GNorm = 1.0919, lr_0 = 3.8312e-04
Validation auc = 0.941837
Epoch 19
Loss = 2.5075e-01, PNorm = 36.4674, GNorm = 0.6825, lr_0 = 3.6811e-04
Validation auc = 0.934490
Model 0 best validation auc = 0.951224 on epoch 7
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.900540
Ensemble test auc = 0.900540
Fold 27
Splitting data with seed 27
Total scaffolds = 1,025 | train scaffolds = 806 | val scaffolds = 114 | test scaffolds = 105
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 778
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.8813e-01, PNorm = 35.0695, GNorm = 0.8528, lr_0 = 2.5469e-04
Validation auc = 0.862919
Epoch 1
Loss = 5.1384e-01, PNorm = 35.0900, GNorm = 0.6302, lr_0 = 4.0937e-04
Loss = 5.2249e-01, PNorm = 35.1156, GNorm = 2.0975, lr_0 = 5.5000e-04
Validation auc = 0.879258
Epoch 2
Loss = 4.7101e-01, PNorm = 35.1401, GNorm = 1.3689, lr_0 = 6.9063e-04
Validation auc = 0.890197
Epoch 3
Loss = 4.3085e-01, PNorm = 35.1755, GNorm = 0.4106, lr_0 = 8.4531e-04
Loss = 4.4552e-01, PNorm = 35.2221, GNorm = 0.5388, lr_0 = 9.8594e-04
Validation auc = 0.893104
Epoch 4
Loss = 4.2874e-01, PNorm = 35.2661, GNorm = 0.4385, lr_0 = 9.6466e-04
Validation auc = 0.892274
Epoch 5
Loss = 4.0323e-01, PNorm = 35.3281, GNorm = 0.8202, lr_0 = 9.2316e-04
Loss = 3.7416e-01, PNorm = 35.3868, GNorm = 0.5843, lr_0 = 8.8699e-04
Validation auc = 0.892274
Epoch 6
Loss = 3.7426e-01, PNorm = 35.4372, GNorm = 0.3979, lr_0 = 8.5223e-04
Validation auc = 0.886873
Epoch 7
Loss = 2.7464e-01, PNorm = 35.4979, GNorm = 1.2080, lr_0 = 8.1556e-04
Loss = 3.9683e-01, PNorm = 35.5485, GNorm = 0.7318, lr_0 = 7.8361e-04
Validation auc = 0.888535
Epoch 8
Loss = 3.6972e-01, PNorm = 35.5994, GNorm = 0.5878, lr_0 = 7.5290e-04
Loss = 3.4646e-01, PNorm = 35.6508, GNorm = 1.3573, lr_0 = 7.2339e-04
Validation auc = 0.886873
Epoch 9
Loss = 3.4694e-01, PNorm = 35.7043, GNorm = 2.0703, lr_0 = 6.9505e-04
Validation auc = 0.888535
Epoch 10
Loss = 3.4783e-01, PNorm = 35.7667, GNorm = 0.6391, lr_0 = 6.6515e-04
Loss = 3.5393e-01, PNorm = 35.8177, GNorm = 0.5230, lr_0 = 6.3908e-04
Validation auc = 0.888120
Epoch 11
Loss = 2.7755e-01, PNorm = 35.8780, GNorm = 0.8565, lr_0 = 6.1404e-04
Validation auc = 0.888258
Epoch 12
Loss = 3.2814e-01, PNorm = 35.9318, GNorm = 0.7333, lr_0 = 5.8762e-04
Loss = 3.1545e-01, PNorm = 35.9772, GNorm = 0.8978, lr_0 = 5.6459e-04
Validation auc = 0.892827
Epoch 13
Loss = 3.0269e-01, PNorm = 36.0245, GNorm = 1.1933, lr_0 = 5.4247e-04
Validation auc = 0.891027
Epoch 14
Loss = 2.8983e-01, PNorm = 36.0752, GNorm = 0.6971, lr_0 = 5.1913e-04
Loss = 3.4026e-01, PNorm = 36.1163, GNorm = 0.5823, lr_0 = 4.9879e-04
Validation auc = 0.893797
Epoch 15
Loss = 2.8671e-01, PNorm = 36.1607, GNorm = 0.4999, lr_0 = 4.7924e-04
Validation auc = 0.892412
Epoch 16
Loss = 2.7733e-01, PNorm = 36.2117, GNorm = 0.4525, lr_0 = 4.5863e-04
Loss = 2.8708e-01, PNorm = 36.2590, GNorm = 0.6941, lr_0 = 4.4065e-04
Validation auc = 0.895320
Epoch 17
Loss = 2.6889e-01, PNorm = 36.2935, GNorm = 0.4067, lr_0 = 4.2339e-04
Loss = 3.0766e-01, PNorm = 36.3339, GNorm = 0.7814, lr_0 = 4.0679e-04
Validation auc = 0.893381
Epoch 18
Loss = 2.6287e-01, PNorm = 36.3777, GNorm = 0.6280, lr_0 = 3.9085e-04
Validation auc = 0.894904
Epoch 19
Loss = 3.0903e-01, PNorm = 36.4173, GNorm = 0.5918, lr_0 = 3.7404e-04
Loss = 2.7359e-01, PNorm = 36.4597, GNorm = 0.3669, lr_0 = 3.5938e-04
Validation auc = 0.898920
Model 0 best validation auc = 0.898920 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.923984
Ensemble test auc = 0.923984
Fold 28
Splitting data with seed 28
Total scaffolds = 1,025 | train scaffolds = 769 | val scaffolds = 131 | test scaffolds = 125
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 728
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7395e-01, PNorm = 35.0699, GNorm = 0.6776, lr_0 = 2.5469e-04
Validation auc = 0.819579
Epoch 1
Loss = 5.1380e-01, PNorm = 35.0912, GNorm = 0.4592, lr_0 = 4.0937e-04
Validation auc = 0.848332
Epoch 2
Loss = 3.8984e-01, PNorm = 35.1167, GNorm = 1.1892, lr_0 = 5.5000e-04
Loss = 4.9053e-01, PNorm = 35.1386, GNorm = 0.5552, lr_0 = 6.9063e-04
Validation auc = 0.883011
Epoch 3
Loss = 4.3649e-01, PNorm = 35.1710, GNorm = 1.0489, lr_0 = 8.4531e-04
Validation auc = 0.864629
Epoch 4
Loss = 4.5004e-01, PNorm = 35.2099, GNorm = 1.0969, lr_0 = 9.8594e-04
Loss = 4.0198e-01, PNorm = 35.2560, GNorm = 0.8992, lr_0 = 9.6466e-04
Validation auc = 0.879225
Epoch 5
Loss = 3.9391e-01, PNorm = 35.3072, GNorm = 0.5904, lr_0 = 9.2316e-04
Validation auc = 0.883505
Epoch 6
Loss = 4.1935e-01, PNorm = 35.3430, GNorm = 0.5871, lr_0 = 8.8699e-04
Loss = 3.7461e-01, PNorm = 35.3884, GNorm = 1.0781, lr_0 = 8.5223e-04
Validation auc = 0.883725
Epoch 7
Loss = 3.8605e-01, PNorm = 35.4380, GNorm = 0.5225, lr_0 = 8.1556e-04
Validation auc = 0.877195
Epoch 8
Loss = 3.6824e-01, PNorm = 35.4840, GNorm = 0.4759, lr_0 = 7.8361e-04
Loss = 3.4604e-01, PNorm = 35.5375, GNorm = 0.4171, lr_0 = 7.5290e-04
Validation auc = 0.911820
Epoch 9
Loss = 3.1962e-01, PNorm = 35.5920, GNorm = 0.7107, lr_0 = 7.2339e-04
Validation auc = 0.892724
Epoch 10
Loss = 3.5230e-01, PNorm = 35.6525, GNorm = 0.4726, lr_0 = 6.9227e-04
Loss = 3.5194e-01, PNorm = 35.7056, GNorm = 1.1628, lr_0 = 6.6515e-04
Validation auc = 0.908198
Epoch 11
Loss = 3.1402e-01, PNorm = 35.7626, GNorm = 1.2416, lr_0 = 6.3908e-04
Validation auc = 0.870500
Epoch 12
Loss = 3.0910e-01, PNorm = 35.8203, GNorm = 1.0026, lr_0 = 6.1159e-04
Validation auc = 0.888554
Epoch 13
Loss = 3.1629e-01, PNorm = 35.8613, GNorm = 0.4502, lr_0 = 5.8762e-04
Loss = 3.2926e-01, PNorm = 35.9133, GNorm = 0.3571, lr_0 = 5.6459e-04
Validation auc = 0.909076
Epoch 14
Loss = 2.7446e-01, PNorm = 35.9693, GNorm = 0.6284, lr_0 = 5.4030e-04
Validation auc = 0.909076
Epoch 15
Loss = 2.3615e-01, PNorm = 36.0160, GNorm = 0.8905, lr_0 = 5.1913e-04
Loss = 3.1136e-01, PNorm = 36.0609, GNorm = 0.3716, lr_0 = 4.9879e-04
Validation auc = 0.915990
Epoch 16
Loss = 3.0913e-01, PNorm = 36.1070, GNorm = 0.6598, lr_0 = 4.7733e-04
Validation auc = 0.898705
Epoch 17
Loss = 3.6217e-01, PNorm = 36.1489, GNorm = 0.6764, lr_0 = 4.5863e-04
Loss = 2.8984e-01, PNorm = 36.1877, GNorm = 0.6260, lr_0 = 4.4065e-04
Validation auc = 0.907320
Epoch 18
Loss = 2.7707e-01, PNorm = 36.2315, GNorm = 0.8568, lr_0 = 4.2339e-04
Validation auc = 0.921916
Epoch 19
Loss = 2.3060e-01, PNorm = 36.2799, GNorm = 1.3637, lr_0 = 4.0517e-04
Loss = 3.0058e-01, PNorm = 36.3157, GNorm = 0.5924, lr_0 = 3.8929e-04
Validation auc = 0.907978
Model 0 best validation auc = 0.921916 on epoch 18
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.900345
Ensemble test auc = 0.900345
Fold 29
Splitting data with seed 29
Total scaffolds = 1,025 | train scaffolds = 788 | val scaffolds = 116 | test scaffolds = 121
Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:
Scaffold 0
Task 0: count = 137 | target average = 0.729927


Scaffold 1
Task 0: count = 99 | target average = 0.929293


Scaffold 2
Task 0: count = 76 | target average = 0.947368


Scaffold 3
Task 0: count = 26 | target average = 1.000000


Scaffold 4
Task 0: count = 26 | target average = 1.000000


Scaffold 5
Task 0: count = 24 | target average = 0.666667


Scaffold 6
Task 0: count = 21 | target average = 0.952381


Scaffold 7
Task 0: count = 18 | target average = 1.000000


Scaffold 8
Task 0: count = 17 | target average = 0.294118


Scaffold 9
Task 0: count = 16 | target average = 0.750000


Class sizes
BBB+/BBB- 0: 23.49%, 1: 76.51%
Total size = 2,039 | train size = 1,631 | val size = 203 | test size = 205
With class_balance, effective train size = 786
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout_layer): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=300, bias=False)
        (W_h): Linear(in_features=300, out_features=300, bias=False)
        (W_o): Linear(in_features=433, out_features=300, bias=True)
      )
    )
  )
  (ffn): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=500, out_features=300, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=300, out_features=1, bias=True)
  )
)
Number of parameters = 415,201
Epoch 0
Loss = 6.7038e-01, PNorm = 35.0709, GNorm = 0.6647, lr_0 = 2.5469e-04
Validation auc = 0.782438
Epoch 1
Loss = 5.1445e-01, PNorm = 35.0923, GNorm = 0.6212, lr_0 = 4.0937e-04
Loss = 4.8499e-01, PNorm = 35.1203, GNorm = 1.5881, lr_0 = 5.5000e-04
Validation auc = 0.828673
Epoch 2
Loss = 4.8151e-01, PNorm = 35.1457, GNorm = 2.6294, lr_0 = 6.9063e-04
Validation auc = 0.830135
Epoch 3
Loss = 4.3604e-01, PNorm = 35.1732, GNorm = 1.2491, lr_0 = 8.3125e-04
Loss = 4.6393e-01, PNorm = 35.2114, GNorm = 1.2551, lr_0 = 9.7187e-04
Validation auc = 0.848045
Epoch 4
Loss = 4.4603e-01, PNorm = 35.2625, GNorm = 0.7318, lr_0 = 9.6466e-04
Validation auc = 0.848045
Epoch 5
Loss = 4.8392e-01, PNorm = 35.3139, GNorm = 0.6541, lr_0 = 9.2686e-04
Loss = 3.8302e-01, PNorm = 35.3643, GNorm = 0.8457, lr_0 = 8.9054e-04
Validation auc = 0.850786
Epoch 6
Loss = 3.4230e-01, PNorm = 35.4167, GNorm = 0.5748, lr_0 = 8.5564e-04
Loss = 3.7712e-01, PNorm = 35.4653, GNorm = 0.7018, lr_0 = 8.2211e-04
Validation auc = 0.847679
Epoch 7
Loss = 3.6144e-01, PNorm = 35.5201, GNorm = 0.6252, lr_0 = 7.8990e-04
Validation auc = 0.856268
Epoch 8
Loss = 3.7791e-01, PNorm = 35.5783, GNorm = 0.6660, lr_0 = 7.5591e-04
Loss = 3.2961e-01, PNorm = 35.6286, GNorm = 0.9465, lr_0 = 7.2629e-04
Validation auc = 0.855172
Epoch 9
Loss = 3.5219e-01, PNorm = 35.6836, GNorm = 0.9956, lr_0 = 6.9783e-04
Validation auc = 0.859375
Epoch 10
Loss = 3.0906e-01, PNorm = 35.7429, GNorm = 1.3370, lr_0 = 6.7048e-04
Loss = 3.1424e-01, PNorm = 35.8045, GNorm = 1.0185, lr_0 = 6.4421e-04
Validation auc = 0.863213
Epoch 11
Loss = 3.3069e-01, PNorm = 35.8651, GNorm = 0.4977, lr_0 = 6.1650e-04
Validation auc = 0.865406
Epoch 12
Loss = 2.8039e-01, PNorm = 35.9168, GNorm = 0.7619, lr_0 = 5.9234e-04
Loss = 2.8775e-01, PNorm = 35.9663, GNorm = 0.3237, lr_0 = 5.6913e-04
Validation auc = 0.869792
Epoch 13
Loss = 2.8320e-01, PNorm = 36.0201, GNorm = 0.8247, lr_0 = 5.4682e-04
Loss = 3.0992e-01, PNorm = 36.0745, GNorm = 0.8138, lr_0 = 5.2540e-04
Validation auc = 0.870340
Epoch 14
Loss = 2.7832e-01, PNorm = 36.1239, GNorm = 0.7053, lr_0 = 5.0481e-04
Validation auc = 0.871985
Epoch 15
Loss = 2.9774e-01, PNorm = 36.1787, GNorm = 2.1659, lr_0 = 4.8309e-04
Loss = 2.8304e-01, PNorm = 36.2274, GNorm = 0.4771, lr_0 = 4.6416e-04
Validation auc = 0.874726
Epoch 16
Loss = 2.4349e-01, PNorm = 36.2800, GNorm = 1.4441, lr_0 = 4.4597e-04
Validation auc = 0.879477
Epoch 17
Loss = 2.3483e-01, PNorm = 36.3239, GNorm = 1.0277, lr_0 = 4.2849e-04
Loss = 2.3947e-01, PNorm = 36.3666, GNorm = 1.5621, lr_0 = 4.1170e-04
Validation auc = 0.876371
Epoch 18
Loss = 2.3525e-01, PNorm = 36.4147, GNorm = 0.8302, lr_0 = 3.9399e-04
Validation auc = 0.878015
Epoch 19
Loss = 3.0595e-01, PNorm = 36.4581, GNorm = 1.1864, lr_0 = 3.7855e-04
Loss = 2.5195e-01, PNorm = 36.4984, GNorm = 0.8216, lr_0 = 3.6372e-04
Validation auc = 0.881122
Model 0 best validation auc = 0.881122 on epoch 19
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "ffn.1.weight".
Loading pretrained parameter "ffn.1.bias".
Loading pretrained parameter "ffn.4.weight".
Loading pretrained parameter "ffn.4.bias".
Model 0 test auc = 0.905261
Ensemble test auc = 0.905261
30-fold cross validation
	Seed 0 ==> test auc = 0.928630
	Seed 1 ==> test auc = 0.907636
	Seed 2 ==> test auc = 0.943526
	Seed 3 ==> test auc = 0.882607
	Seed 4 ==> test auc = 0.890246
	Seed 5 ==> test auc = 0.892559
	Seed 6 ==> test auc = 0.870606
	Seed 7 ==> test auc = 0.947479
	Seed 8 ==> test auc = 0.903720
	Seed 9 ==> test auc = 0.930991
	Seed 10 ==> test auc = 0.795291
	Seed 11 ==> test auc = 0.894284
	Seed 12 ==> test auc = 0.936275
	Seed 13 ==> test auc = 0.930272
	Seed 14 ==> test auc = 0.950706
	Seed 15 ==> test auc = 0.919849
	Seed 16 ==> test auc = 0.877632
	Seed 17 ==> test auc = 0.871467
	Seed 18 ==> test auc = 0.888110
	Seed 19 ==> test auc = 0.905920
	Seed 20 ==> test auc = 0.921946
	Seed 21 ==> test auc = 0.928851
	Seed 22 ==> test auc = 0.870864
	Seed 23 ==> test auc = 0.865779
	Seed 24 ==> test auc = 0.902960
	Seed 25 ==> test auc = 0.946100
	Seed 26 ==> test auc = 0.900540
	Seed 27 ==> test auc = 0.923984
	Seed 28 ==> test auc = 0.900345
	Seed 29 ==> test auc = 0.905261
Overall test auc = 0.904481 +/- 0.031870
Elapsed time = 0:38:51
